{"title": "【爬虫】菜鸟教程，支持翻页，存储 - 个人文章 ", "index": "mysql,python", "content": "1、项目简介\n豆瓣相信很多人都爬过，我也把我的方法拿出来交流学习，我也是菜鸟过来的，不会省略代码，此教程纯属娱乐，大神勿喷。\n2、工具\n\nrequests\nre\npygal\nmysql\nAnacond2\n\n3、爬虫完整代码\n# encoding:UTF-8\nimport re\nimport requests\nimport MySQLdb\nfrom bs4 import BeautifulSoup\n\nheaders = {'User-Agent' :'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n\n\ndef getPage(get_url):\n    r=requests.get(get_url)\n    response = r.text\n    return response\ndef filterpage():\n    pageCode = getPage(get_url)\n    pattern = re.compile('<em class=\"\">(.*?)</em>.*?<span class=\"title\">(.*?)</span>.*?<span class=\"rating_num\" property=\"v:average\">(.*?)</span>',re.S)\n    items = re.findall(pattern,pageCode)\n    pageStories = []\n    for item in items:\n        pageStories.append([item[0].strip(),item[1].strip(),item[2].strip()])\n    return pageStories\ndef save_data():\n    Dbdata=filterpage()\n    db=MySQLdb.connect(host='localhost',user='root',passwd='******',db='movie',charset='utf8')\n    cursor=db.cursor()\n    for a in Dbdata:\n        id=a[0]\n        name=a[1]\n        grade=a[2]\n        #comment=a[3]\n        value=[id,name,grade]\n        cursor.execute('insert into movie_info values(%s,%s,%s)',value)\n        db.commit()\ndef main():\n    pageStories=filterpage()\n    #print pageStories\n    for story in pageStories:\n        try:\n            print u\"序号：\",story[0],u\"电影名：\",story[1], u\"\\t评分：\", story[2]\n        except:\n            pass\n\nif __name__ == '__main__':\n    get_url = 'https://movie.douban.com/top250/'\n    i=1\n    while i < 11:\n        main()\n        save_data()\n        print u'页码',i\n        num = i * 25\n        get_url = 'https://movie.douban.com/top250?start=' + str(num) + '&filter='\n        i = i + 1\n\n\n4、前期准备\n\ninstall mysql我是在windows环境下跑爬虫的，用的是MySQL5.7，下载地址：https://dev.mysql.com/downloa...\n\n值得一提的是，mysql的安装，window版的mysql安装起来说实话还是比较麻烦的，我装了很久，没成功，最后选择下载压缩版安装。安装完之后，在mysql目录下创建my.ini配置文件，输入以下代码：\n\n[mysqld] \ntmpdir=F:\\mysql-5.7.18-winx64   # 安装目录\ndatadir=F:\\mysql-5.7.18-winx64\\data   # data目录，没有data目录请手动创建\nearly-plugin-load=\"\"\nskip-grant-tables\n\n点击保存，data目录是mysql初始化会用到的目录，一般是空目录，不然初始化不通过。特别是“ 服务没有报告任何错误。 请键入 NET HELPMSG 3534”错误。然后添加mysql的环境路径。\ncmd输入：\n\ncd F:\\mysql-5.7.18-winx64\\bin # 进入bin目录，不然有可能会报错\nmysqld initialize  # 初始化命令\nnet start mysql    # 启动服务\n创建数据表，我们需要保存的数据有ID，评分grade，还有电影名name。\nmysql>create database movie   # 创建movie数据库\nmysql>use movie # \nmysql>create table movie_info (id varchar(100),name varchar(100),grade decimal(3,1));\n\n5、目标网页分析\n\n这个教程中，我们需要爬取豆瓣top250的电影名、序号和相应的评分。F12分析网页结构。找到有《肖申克的救赎》的代码处：\n<em class=\"\">1</em>   # 序号\n.\n.\n.      \n<span class=\"title\">肖申克的救赎</span> # 电影名\n.\n.\n.\n<span class=\"rating_num\" property=\"v:average\">9.6</span>  # 评分\nok，往后翻，可以看到剩下的都是这类的结构，我们找到规律了，就可以想办法，把里面的东西给搞出来。一般常用的有re模块和beautifulsoup模块，我是用re模块正则匹配，感觉正则更强大一点，漂亮汤模块用起来简单，但是速度慢。\n6、代码分析\n6.1 爬取页面代码\ndef getPage(get_url):            # 定义一个抓取网页的方法\n    r=requests.get(get_url)      # get到目标网页\n    response = r.text\n    return response              # 返回抓取到的网页\n\n爬虫开始爬，就是给web服务器一个请求，然后抓取到返回信息。\nHTTP 请求方法有 OPTIONS、GET、HEAD、post、PUT、DELETE、TRACE、CONNECT，其中比较常用的有get和post，其他的都不常见，判断请求方式很重要。自行百度。\n\n6.2 页面代码处理\ndef filterpage():              # 页面处理方法\n    pageCode = getPage(get_url)   #传参\n    pattern = re.compile('<em class=\"\">(.*?)</em>.*?<span class=\"title\">(.*?)</span>.*?<span class=\"rating_num\" property=\"v:average\">(.*?)</span>',re.S)\n    items = re.findall(pattern,pageCode)\n    pageStories = []        # 定义一个空数组，用来存分离出来的数据\n    for item in items:      # 迭代\n        pageStories.append([item[0].strip(),item[1].strip(),item[2].strip()])# 去除空格\n    return pageStories\n正则表达式，在程序刚开始，我们导入了python的re模块，这个模块专门处理正则匹配，详细教程点这里\n\n我们用第一个(.*?)非贪婪匹配来匹配序号，接着用.*?贪婪匹配匹配不需要的代码，往后同样用非贪婪匹配来匹配我们需要的信息。\n接着用strip()方法去除空格。返回得到的字符串pageStories。\n6.3 数据存储\ndef save_data(): \n    Dbdata=filterpage() #传参\n    db=MySQLdb.connect(host='localhost',user='root',passwd='suyu.123',db='movie',charset='utf8') # 链接数据库\n    cursor=db.cursor() # 定义游标\n    for a in Dbdata:   # 迭代存储数据\n        id=a[0]\n        name=a[1]\n        grade=a[2]\n        value=[id,name,grade]\n        cursor.execute('insert into movie_info values(%s,%s,%s)',value) # sql命令存数据\n        db.commit()   # 别忘记提交变更\npython操作mysql，感觉没啥好讲的了。。\n6.4主函数\ndef main():\n    pageStories=filterpage()   # 传参\n    for story in pageStories:  # 迭代打印\n        try:\n            print u\"序号：\",story[0],u\"电影名：\",story[1], u\"\\t评分：\", story[2]\n        except:\n            pass\n主函数主要是用来打印出我们抓取的数据。\n6.5运行程序\nif __name__ == '__main__':\n    get_url = 'https://movie.douban.com/top250/' # 起始网页\n    i=1\n    while i < 11:\n        main()                  # 运行主函数\n        save_data()             # 运行存储函数\n        print u'页码',i         # \n        num = i * 25\n        get_url = 'https://movie.douban.com/top250?start=' + str(num) + '&filter='\n        i = i + 1\n通过豆瓣top250的页面分析可以知道，总共有10页，所以我们设置i<11，整个豆瓣电影top250的网址很有规律，第一页是：https://movie.douban.com/top250，第二页就是：https://movie.douban.com/top2...，这样的网页有规律，我喜欢，所以我们可以用迭代来表示所有网页，豆瓣业界良心啊。\n7、运行结果\n\nGitHub地址：https://github.com/legolas-ze...\n\n还有剩下的svg统计图，就下次更新吧。\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "4"}