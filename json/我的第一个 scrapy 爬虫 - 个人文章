{"title": "我的第一个 scrapy 爬虫 - 个人文章 ", "index": "scrapy,python", "content": "安装 python\n这个就不用我说了吧，网上教程一大堆\n安装 scrapy 包\npip install scrapy\n\n创建 scrapy 项目\nscrapy startproject aliSpider\n\n进入项目目录下，创建爬虫文件\ncmd 进入项目目录，执行命令：\nscrapy genspider -t crawl alispi job.alibaba.com\n\n编写 items.py 文件\n# -*- coding: utf-8 -*-\n\n# Define here the models for your scraped items\n#\n# See documentation in:\n# https://doc.scrapy.org/en/latest/topics/items.html\n\nimport scrapy\n\n\nclass AlispiderItem(scrapy.Item):\n    # define the fields for your item here like:\n    detail = scrapy.Field()\n    workPosition = scrapy.Field()\n    jobclass = scrapy.Field()\n    \n编写 alispi.py 文件\n# -*- coding: utf-8 -*-\nimport scrapy\nfrom scrapy.linkextractors import LinkExtractor\nfrom scrapy.spiders import CrawlSpider, Rule\nfrom aliSpider.items import AlispiderItem\n\n\nclass AlispiSpider(CrawlSpider):\n    name = 'alispi'\n    allowed_domains = ['job.alibaba.com']\n    start_urls = ['https://job.alibaba.com/zhaopin/positionList.html#page/0']\n    pagelink = LinkExtractor(allow=(\"\\d+\"))\n    rules = (\n        Rule(pagelink, callback='parse_item', follow=True),\n    )\n\n    def parse_item(self, response):\n        # for each in response.xpath(\"//tr[@style='display:none']\"):\n        for each in response.xpath(\"//tr\"):\n            item = AlispiderItem()\n            # 职位名称\n            item['detail'] = each.xpath(\"./td[1]/span/a/@href\").extract()\n            # # # 详情连接\n            item['workPosition'] = each.xpath(\"./td[3]/span/text()\").extract()\n            # # # 职位类别\n            item['jobclass'] = each.xpath(\"./td[2]/span/text()\").extract()\n            yield item\n\n执行\nscrapy crawl alispi\n\n输出到文件 items.json\nscrapy crawl alispi -o items.json\n\n执行成功会显示如下内容\n版本说明\npython 3.5.5\n\n参考：https://scrapy-chs.readthedoc...\n关注微信公众号 [prepared]，与博主深入探讨。\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}