{"title": "谈谈项目的重构与测试 - 西兑的博客 ", "index": "单元测试,mongodb,tornado,flask,python", "content": "这篇文章摘自我的博客, 欢迎大家没事去逛逛~\n背景\n这几个月我开发了公司里的一个restful webservice，起初技术选型的时候是采用了flask框架。虽然flask是一个同步的框架，但是可以配合gevent或者其它方式运行在异步的容器中(测试链接)，效果看上去也还可以，因此就采用了这种方式。\n后面阅读了tornado的源码，也去了解了各种协程框架以及运行的原理。总感觉flask的这种同步方式编程不够好，同时对于这种运行在容器里的模式目前还缺乏了解。但至少现在对于tornado的运行原理有了一定的了解，如果用tornado写的话，是很可控的，而且可以保证运行是高效的。因此就决定把原来基于flask的项目用tornado重构了。\n重构的过程\n项目重构的过程中遇到了一些问题，也学习了一些东西，这里做一个简单的总结。\n接入层\n所有框架都要处理的一个接入层的事情就是：\n\nurl-mapping\n项目初始化\n参数解析\n\n对于restful风格的接口以及项目的初始化，每个框架都有自己的方式，在它们的文档中都演示得特别清楚，所以关于这些我就不展开了。\n关于参数解析，这里并不是指简单地调用类似于get_argument这样的方法去获取数据。而是 如何从不可靠的client端传来的数据中过滤掉服务器不关注的数据，同时对服务器关注的数据作一些更强的校验，这就是协议层的事情了。\n使用谷歌的ProtocolBuffer是一个不错的方案，它有很不错的数据压缩率，也支持目前大多数主流的开发语言。但在一些小型项目中，我还是更偏向于使用json的方式，它显得更加灵活。但是对于json的话，如何作数据校验就是另外一个问题了。\n在重构前，我是通过python中的装饰器来实现的这个功能:\nclass SomeHandlerInFlask(Resource):\n    @util.deco({\n        'key_x': (str, 'form'),\n        'key_y': (int, 'form'),\n        'key_z': (str, 'url')\n    })\n    def post(self):\n        # logic code\n        pass\n在装饰器中分别从不同的地方，form或者url中获取相应的参数。如果取不到，则直接报错，逻辑也不会进入到post函数中。\n这是我基于flask这个框架自己总结出来的一套尚且还能看能用的参数解析方式，如果在每个函数中通过框架提供的get_argument来逐一获取参数，则显得太丑，而且每个接口所需要的数据是什么也不够直观。不过这种方式我自己还不是特别满意，总感觉还是有点不太舒服，也说不清不舒服在哪里。那就干脆放弃它，使用别的方式吧。\n后来我了解到了jsonschema这个东西，看了一下感觉与ProtocolBuffer很相似，只不过它是采用json的格式定义，正合我意(对于它我也有点吐槽，在数据库层有提到)，每次数据进来就对数据和schema作一次validate操作，再进入业务逻辑层。\n业务逻辑层\n业务逻辑层的重构其实改动的代码并不多，把一些同步的操作改成异步的操作。就拿如何重构某个接口来说吧，重构前的代码可能是这样的:\ndef function_before_refactor(some_params):\n    result_1 = sync_call_1(some_params)\n    result_2 = sync_call_2(some_params)\n    # some other processes\n    return result\n使用gen.coroutine重构后:\nfrom tornado import gen\n\n@gen.coroutine\ndef function_after_refactor(some_params):\n    # if you don't want to refactor\n    # just call it as it always be\n    result_1 = sync_call_1(some_params)\n    result_2 = yield async_call_2(some_params)\n    # some other processes\n    raise gen.Return(result)\n    # python3及以上的版本不需要采用抛出异常的方式，直接return就可以了\n    # return result\n考虑到函数名根本不用改，重构的过程非常容易：\n\n函数用gen.coroutine包装成协程\n已经重构成异步方式的函数调用时添加yield关键字即可\n函数返回采用raise gen.Return(result)的方式（仅限于Python 2.7）\n\n因为我目前采用的是python 2.7，所以在处理返回的时候要用抛出异常的方式，在这种方式下有一个点需要注意到，那就是与平常异常的处理的混用，不然会导致逻辑流执行混乱：\nfrom tornado import gen\n\n@gen.coroutine\ndef function_after_refactor(some_params):\n    try:\n        # some logic code\n        pass\n    except Exception as e:\n        if isinstance(e, gen.Return):\n            # return the value raised by logic\n            raise gen.Return(e.value)\n        # more exception process\n数据库层\n数据库采用的是mongodb，在flask框架中采用了mongoengine作为数据库层的orm，对于这个python-mongodb的orm产品，我个人并不是很喜欢(可能是因为我习惯了mongoose的工作方式)，这里面嵌套json的定义居然不能体现在schema中，需要分开定义两个schema，然后再作引入的操作。比如（代码只是用作演示，与项目无关）：\nclass Comment(EmbeddedDocument):\n    content = StringField()\n    # more comment details\n\nclass Page(Document):\n    comments = ListField(EmbeddedDocumentField(Comment))\n    # more page details\n而在mongoose中就直观多了:\nvar PageSchema = new Schema({\n    title       :   {type : String, required : true},\n    time        :   {type : Date, default : Date.now(), required : true},\n    comments    :   [{\n        content   :   {type : String}\n        // more comment details\n    }]\n    // more page details\n});\n扯远了，在tornado的框架中，再使用mongoengine就不合适了，毕竟有着异步和同步的区别。那有什么比较好的python-mongodb的异步orm框架呢？搜了下，有一个叫做motorengine的东西，orm的使用方式和mongoengine基本一样，但看它的star数实在不敢用呀。而且它处理异步的方式是使用回调，现在都是使用协程的年代了，想想还是算了吧。\n最后找了个motor，感觉还不错，它有对目前大部分主流协程框架的支持，操作mongodb的方式与直接使用pymongo的方式差不多（毕竟都是基于pymongo的封装嘛），但是就是没有orm的验证层，那就自己再去另外搞一个简化的orm层吧。(mongokit的orm方式看上去还不错，但貌似对协程框架的支持一般)。这里暂时先懒惰一下，还是采用了jsonschema。每次保存前都validate一下对象是否符合schema的定义。如果没有类mongoose的python-mongodb异步框架，有时间就自己写一个吧~\n这里顺带吐槽一下jsonschema，简直太琐碎了，一个很短的文档结构定义，它会描述成好几十行，我就不贴代码了，有兴趣的朋友可以戳这里http://jsonschema.net/玩玩。而且python中的jsonschema库还不支持对于default关键字的操作，参见这个issue。\n测试\n自己摸索的一种接口测试方案\npython中的测试框架有很多，只要选择一个合适的能够很方便与项目集成就好。我个人还是很喜欢unittest这个框架，小而精。我的这套测试方案也是基于unittest框架的。\n# TestUserPostAccessComponents.py\nclass TestUserPostAccessComponents(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        # 定义在其它地方，具体细节就不展示了\n        # 在setup中使用测试账号获取登陆态\n        # 并把各种中间用得到的信息放在TestUserPostAccess类上\n        setup(cls)\n\n    @classmethod\n    def tearDownClass(cls):\n        pass\n\n    def setUp(self):\n        pass\n\n    def tearDown(self):\n        pass\n\n    def test_1_user_1_user_2_add_friend(self):\n        pass\n\n    def test_2_user_1_user_2_del_friend(self):\n        pass\n\n    def test_3_user_1_add_public_user_post(self):\n        pass\n\n    # more other components\n最顶层的测试文件：\n# run_test.py\n# 各种import\n\ndef user_basic_post_access_test():\n    tests = ['test_3_user_1_add_public_user_post',\n             'test_5_user_2_as_a_stranger_can_access_public_user_post',\n             'test_4_user_1_del_public_user_post',\n             'test_6_user_1_add_private_user_post',\n             'test_8_user_2_as_a_stranger_can_not_access_private_user_post',\n             'test_9_user_1_self_can_access_private_user_post',\n             'test_7_user_1_del_private_user_post']\n    return unittest.TestSuite(map(TestUserPostAccessComponents, tests))\n\ndef other_process_test():\n    tests = [\n        # compose a process by components by yourself\n    ]\n    return unittest.TestSuite(map(OtherTestCaseComponents, tests))\n\nrunner = unittest.TextTestRunner(verbosity=2)\nrunner.run(user_basic_post_access_test())\nrunner.run(other_process_test())\n这套测试是基于 BDD (行为驱动)的测试方式，针对每一个逻辑模块，定义一个components类，把所有子操作都定义成单独的测试单元。这里面的测试单元可以是完全无序的，把逻辑有序化组织成测试用例的过程会在最外面通过TestSuit的方式组织起来。这里可能会有一些异议，因为有些人在使用这个测试类的时候是把它作为一个测试用例来组织的，当然这些都是不同的使用方式。\n这套测试方案中的每个component都是api级别的测试，并不是函数级别的测试（集成测试与单元测试），每个TestSuit都是完整的一个业务流程。这样的好处在于 测试和项目完全解耦。测试代码不用关心项目的代码是同步还是异步的。就算项目重构了，测试完全无感知，只要api没变，就可以继续工作。\n当然以上都是理想的状态，因为在刚开始写这些测试的时候我还没有总结到这些点，导致了一些耦合性的存在。比如说测试代码中import了项目中的某个函数去获取一些数据，用于检查某个component的更新操作是否成功。在重构的过程中，该函数被重构成了协程。这样一来，在测试代码中就不能采用原来一样的方式去调用了，也就是说测试代码受到了框架同步与异步的影响，下一节我们就来谈谈同步与异步的测试，以及对于这种问题的解决方案。\n异步测试&同步测试\n在tornado中，也提供了一套测试的功能，具体在tornado.testing这个模块，看它源码其实可以发现它也是基于unittest的一层封装。我心里一直有一个问题：unittest的执行流程是同步的，既然这样，它是怎么去测一个由gen.coroutine包装的协程的呢，毕竟后者是异步的。直到看了源码，恍然大悟，原来是io_loop.run_sync这个函数的功劳，具体实现在gen_test这个装饰器中，摘一部分源码（对于tornado源码不熟的同学可以先去看看tornado中的ioloop模块的实现，看完会对这个部分有更深刻的理解）：\ndef gen_test(func=None, timeout=None):\n    if timeout is None:\n        timeout = get_async_test_timeout()\n\n    def wrap(f):\n        # Stack up several decorators to allow us to access the generator\n        # object itself.  In the innermost wrapper, we capture the generator\n        # and save it in an attribute of self.  Next, we run the wrapped\n        # function through @gen.coroutine.  Finally, the coroutine is\n        # wrapped again to make it synchronous with run_sync.\n        #\n        # This is a good case study arguing for either some sort of\n        # extensibility in the gen decorators or cancellation support.\n        @functools.wraps(f)\n        def pre_coroutine(self, *args, **kwargs):\n            result = f(self, *args, **kwargs)\n            if isinstance(result, types.GeneratorType):\n                self._test_generator = result\n            else:\n                self._test_generator = None\n            return result\n\n        coro = gen.coroutine(pre_coroutine)\n\n        @functools.wraps(coro)\n        def post_coroutine(self, *args, **kwargs):\n            try:\n                return self.io_loop.run_sync(\n                    functools.partial(coro, self, *args, **kwargs),\n                    timeout=timeout)\n            except TimeoutError as e:\n                # run_sync raises an error with an unhelpful traceback.\n                # If we throw it back into the generator the stack trace\n                # will be replaced by the point where the test is stopped.\n                self._test_generator.throw(e)\n                # In case the test contains an overly broad except clause,\n                # we may get back here.  In this case re-raise the original\n                # exception, which is better than nothing.\n                raise\n        return post_coroutine\n\n    if func is not None:\n        # Used like:\n        #     @gen_test\n        #     def f(self):\n        #         pass\n        return wrap(func)\n    else:\n        # Used like @gen_test(timeout=10)\n        return wrap\n在源码中，先把某个测试单元封装成一个协程，然后获取当前线程的ioloop对象，把协程抛给他去执行，直到执行完毕。这样就完美地实现了异步到同步的过渡，满足unittest测试框架的同步需求。在具体的使用中只需要继承tornado提供的AsyncTestCase类就行了，注意这里不是unittest.TestCase。看了源码也可以发现，前者就是继承自后者的。\n# This test uses coroutine style.\nclass MyTestCase(AsyncTestCase):\n    @tornado.testing.gen_test\n    def test_http_fetch(self):\n        client = AsyncHTTPClient(self.io_loop)\n        response = yield client.fetch(\"http://www.tornadoweb.org\")\n        # Test contents of response\n        self.assertIn(\"FriendFeed\", response.body)\n回到上一节的问题，有了这种方式，就可以很容易地解决同步异步的问题了。如果测试用例中某一个函数已经被项目重构成了协程，只需要做以下三步：\n\n把测试components的类改成继承自AsyncTestCase\n该测试单元使用gen_test装饰（其它测试单元可以不用加，只需要改涉及到协程的测试单元就行）\n调用协程的地方添加yield关键字\n\n测试代码如何适应项目的重构\n\n如果是api测试测试中尽量不要调用任何项目中的代码，它只专注于测试接口是否按照预期在工作，具体里面是怎么样的不需要关心。这样的话整套测试是完全独立于项目而存在的，即使项目重构，也可以不用作任何修改，无缝对接。\n如果是单元测试参考上一节的方案。\n\n总结\n重构是一个不断优化和学习的过程，在这个过程中我踩了一些坑，也爬出了一些坑，希望可以把我的这些总结分享给大家。欢迎大家跟我交流。对于文中的一些方案，也欢迎大家拍砖，欢迎有更多的做法可以一起探讨学习。另外，对于这个项目的重构，文章里面可能还少了一些更加直观的性能测试，后面我会加上去，孝敬各位爷~\n\n                ", "mainLikeNum": ["2 "], "mainBookmarkNum": "9"}