{"title": "TensorFlow学习笔记（1）：线性回归 - 数据实验室 ", "index": "scikit-learn,tensorflow,python", "content": "前言\n本文使用tensorflow训练线性回归模型，并将其与scikit-learn做比较。数据集来自Andrew Ng的网上公开课程Deep Learning\n代码\n#!/usr/bin/env python\n# -*- coding=utf-8 -*-\n# @author: 陈水平 \n# @date: 2016-12-30\n# @description: compare scikit-learn and tensorflow, using linear regression data from deep learning course by Andrew Ng.\n# @ref: http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=DeepLearning&doc=exercises/ex2/ex2.html\n\nimport tensorflow as tf\nimport numpy as np\nfrom sklearn import linear_model\n\n# Read x and y\nx_data = np.loadtxt(\"ex2x.dat\")\ny_data = np.loadtxt(\"ex2y.dat\")\n\n\n# We use scikit-learn first to get a sense of the coefficients\nreg = linear_model.LinearRegression()\nreg.fit(x_data.reshape(-1, 1), y_data)\n\nprint \"Coefficient of scikit-learn linear regression: k=%f, b=%f\" % (reg.coef_, reg.intercept_)\n\n\n# Then we apply tensorflow to achieve the similar results\n# The structure of tensorflow code can be divided into two parts:\n\n# First part: set up computation graph\nW = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\nb = tf.Variable(tf.zeros([1]))\ny = W * x_data + b\n\nloss = tf.reduce_mean(tf.square(y - y_data)) / 2\noptimizer = tf.train.GradientDescentOptimizer(0.07)  # Try 0.1 and you will see unconvergency\ntrain = optimizer.minimize(loss)\n\ninit = tf.initialize_all_variables()\n\n# Second part: launch the graph\nsess = tf.Session()\nsess.run(init)\n\nfor step in range(1500):\n    sess.run(train)\n    if step % 100 == 0:\n        print step, sess.run(W), sess.run(b)\nprint \"Coeeficient of tensorflow linear regression: k=%f, b=%f\" % (sess.run(W), sess.run(b))\n输出如下：\nCoefficient of scikit-learn linear regression: k=0.063881, b=0.750163\n0 [ 0.45234478] [ 0.10217379]\n100 [ 0.13166969] [ 0.4169243]\n200 [ 0.09332827] [ 0.58935112]\n300 [ 0.07795752] [ 0.67282093]\n400 [ 0.07064758] [ 0.71297228]\n500 [ 0.06713474] [ 0.73227954]\n600 [ 0.06544565] [ 0.74156356]\n700 [ 0.06463348] [ 0.74602771]\n800 [ 0.06424291] [ 0.74817437]\n900 [ 0.06405514] [ 0.74920654]\n1000 [ 0.06396478] [ 0.74970293]\n1100 [ 0.06392141] [ 0.74994141]\n1200 [ 0.06390052] [ 0.75005609]\n1300 [ 0.06389045] [ 0.7501114]\n1400 [ 0.0638856] [ 0.75013816]\nCoeeficient of tensorflow linear regression: k=0.063883, b=0.750151\n思考\n对于tensorflow，梯度下降的步长alpha参数需要很仔细的设置，步子太大容易扯到蛋导致无法收敛；步子太小容易等得蛋疼。迭代次数也需要细致的尝试。\n\n                ", "mainLikeNum": ["3 "], "mainBookmarkNum": "8"}