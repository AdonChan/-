{"title": "爬虫基础练习一 爬取豆瓣电影TOP250 - Python 高手之路 ", "index": "python", "content": "这是一个很好的新手练习项目，爬取豆瓣top250的电影，并分别记录排名、片名、导演、主演、评论等信息，保存在一个txt文档里。对新手来说，难点部分在于如何找到并成功跳转到下一页，并且在最后一页的时候识别出来并停止爬虫。\n一个很基础的爬虫。以下是代码部分。\nimport requests\nfrom bs4 import BeautifulSoup\nimport time\nimport re\n\nlurl = 'https://movie.douban.com/top250'\n\nmovie = []\n\ndef getlist(listurl):\n    time.sleep(2)\n    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36'}\n    res = requests.get(listurl)\n    soup = BeautifulSoup(res.text, 'html.parser')\n    movielist = soup.select('.grid_view li')\n    for m in movielist:\n        rank = m.select('em')[0].text\n        title = m.select('.title')[0].text\n        direct = m.select('.info .bd p')[0].text.strip()\n        actor = '\\n主演:'.join(direct.split('   主演:'))\n        director = '年代:'.join(actor.split('                           '))\n        if m.select('.inq'):\n            comments = m.select('.inq')[0].text.strip()\n        else:\n            comments = 'None'\n        movie.append('排名: '+ rank+ '\\n' +'片名: '+ title + '\\n'+ director + '\\n' + '评论: '+ comments +'\\n' + '\\n')\n    if soup.select('.next a'):\n        asoup = soup.select('.next a')[0]['href']\n        Next_page = lurl + asoup\n        getlist(Next_page)\n    else:\n        print('结束')\n    return movie\n\n\n\nmovies = getlist(lurl)\n\nwith open('movie.txt', 'w') as m:\n    for a in movies:\n        m.write(a)\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "3"}