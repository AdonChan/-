{"title": "基于Sanic的微服务基础架构 - 个人文章 ", "index": "asyncio,python", "content": "介绍\n使用python做web开发面临的一个最大的问题就是性能，在解决C10K问题上显的有点吃力。有些异步框架Tornado、Twisted、Gevent 等就是为了解决性能问题。这些框架在性能上有些提升，但是也出现了各种古怪的问题难以解决。\n在python3.6中，官方的异步协程库asyncio正式成为标准。在保留便捷性的同时对性能有了很大的提升,已经出现许多的异步框架使用asyncio。\n使用较早的异步框架是aiohttp，它提供了server端和client端，对asyncio做了很好的封装。但是开发方式和最流行的微框架flask不同，flask开发简单，轻量，高效。\n微服务是最近最火开发模式，它解决了复杂性问题，提高开发效率，便于部署等优点。\n正是结合这些优点, 以Sanic为基础，集成多个流行的库来搭建微服务。 Sanic框架是和Flask相似的异步协程框架，简单轻量，并且性能很高。\n本项目就是以Sanic为基础搭建的微服务框架。\n特点\n\n使用sanic异步框架，简单，轻量，高效。\n使用uvloop为核心引擎，使sanic在很多情况下单机并发甚至不亚于Golang。\n使用asyncpg为数据库驱动，进行数据库连接，执行sql语句执行。\n使用aiohttp为Client，对其他微服务进行访问。\n使用peewee为ORM，但是只是用来做模型设计和migration。\n使用opentracing为分布式追踪系统。\n使用unittest做单元测试，并且使用mock来避免访问其他微服务。\n使用swagger做API标准，能自动生成API文档。\n\n使用\n项目地址： sanic-ms\nExample\n服务端\n使用sanic异步框架，有较高的性能，但是使用不当会造成blocking, 对于有IO请求的都要选用异步库。添加库要慎重。sanic使用uvloop异步驱动，uvloop基于libuv使用Cython编写，性能比nodejs还要高。\n功能说明：\n启动前\n@app.listener('before_server_start')\nasync def before_srver_start(app, loop):\n    queue = asyncio.Queue()\n    app.queue = queue\n    loop.create_task(consume(queue, app.config.ZIPKIN_SERVER))\n    reporter = AioReporter(queue=queue)\n    tracer = BasicTracer(recorder=reporter)\n    tracer.register_required_propagators()\n    opentracing.tracer = tracer\n    app.db = await ConnectionPool(loop=loop).init(DB_CONFIG)\n\n创建DB连接池\n创建Client连接\n创建queue, 消耗span，用于日志追踪\n创建opentracing.tracer进行日志追踪\n\n中间件\n@app.middleware('request')\nasync def cros(request):\n    if request.method == 'POST' or request.method == 'PUT':\n        request['data'] = request.json\n    span = before_request(request)\n    request['span'] = span\n\n\n@app.middleware('response')\nasync def cors_res(request, response):\n    span = request['span'] if 'span' in request else None\n    if response is None:\n        return response\n    result = {'code': 0}\n    if not isinstance(response, HTTPResponse):\n        if isinstance(response, tuple) and len(response) == 2:\n            result.update({\n                'data': response[0],\n                'pagination': response[1]\n            })\n        else:\n            result.update({'data': response})\n        response = json(result)\n        if span:\n            span.set_tag('http.status_code', \"200\")\n    if span:\n        span.set_tag('component', request.app.name)\n        span.finish()\n    return response\n\n创建span, 用于日志追踪\n对response进行封装，统一格式\n\n异常处理\n对抛出的异常进行处理，返回统一格式\n任务\n创建task消费queue中对span，用于日志追踪\n异步处理\n由于使用的是异步框架，可以将一些IO请求并行处理\nExample:\nasync def async_request(datas):\n    # async handler request\n    results = await asyncio.gather(*[data[2] for data in datas])\n    for index, obj in enumerate(results):\n        data = datas[index]\n        data[0][data[1]] = results[index]\n\n@user_bp.get('/<id:int>')\n@doc.summary(\"get user info\")\n@doc.description(\"get user info by id\")\n@doc.produces(Users)\nasync def get_users_list(request, id):\n    async with request.app.db.acquire(request) as cur:\n        record = await cur.fetch(\n            \"\"\" SELECT * FROM users WHERE id = $1 \"\"\", id)\n        datas = [\n            [record, 'city_id', get_city_by_id(request, record['city_id'])]\n            [record, 'role_id', get_role_by_id(request, record['role_id'])]\n        ]\n        await async_request(datas)\n        return record\nget_city_by_id, get_role_by_id是并行处理。\n相关连接\nsanic\n模型设计 & ORM\nPeewee is a simple and small ORM. It has few (but expressive) concepts, making it easy to learn and intuitive to use。ORM使用peewee, 只是用来做模型设计和migration, 数据库操作使用asyncpg。\n\nExample:\n# models.py\n\nclass Users(Model):\n    id = PrimaryKeyField()\n    create_time = DateTimeField(verbose_name='create time',\n                                default=datetime.datetime.utcnow)\n    name = CharField(max_length=128, verbose_name=\"user's name\")\n    age = IntegerField(null=False, verbose_name=\"user's age\")\n    sex = CharField(max_length=32, verbose_name=\"user's sex\")\n    city_id = IntegerField(verbose_name='city for user', help_text=CityApi)\n    role_id = IntegerField(verbose_name='role for user', help_text=RoleApi)\n\n    class Meta:\n        db_table = 'users'\n\n\n# migrations.py\n\nfrom sanic_ms.migrations import MigrationModel, info, db\n\nclass UserMigration(MigrationModel):\n    _model = Users\n\n    # @info(version=\"v1\")\n    # def migrate_v1(self):\n    #     migrate(self.add_column('sex'))\n\ndef migrations():\n    try:\n        um = UserMigration()\n        with db.transaction():\n            um.auto_migrate()\n            print(\"Success Migration\")\n    except Exception as e:\n        raise e\n\nif __name__ == '__main__':\n    migrations()\n\n运行命令 python migrations.py\nmigrate_v1函数添加字段sex, 在BaseModel中要先添加name字段\ninfo装饰器会创建表migrate_record来记录migrate，version每个model中必须唯一，使用version来记录是否执行过，还可以记录author，datetime\nmigrate函数必须以migrate_开头\n\n相关连接\npeewee\n数据库操作\n\nasyncpg is the fastest driver among common Python, NodeJS and Go implementations使用asyncpg为数据库驱动, 对数据库连接进行封装, 执行数据库操作。\n不使用ORM做数据库操作，一个原因是性能，ORM会有性能的损耗，并且无法使用asyncpg高性能库。另一个是单个微服务是很简单的，表结构不会很复杂，简单的SQL语句就可以处理来，没必要引入ORM。使用peewee只是做模型设计\n\nExample:\nsql = \"SELECT * FROM users WHERE name=$1\"\nname = \"test\"\nasync with request.app.db.acquire(request) as cur:\n    data = await cur.fetchrow(sql, name)\n\nasync with request.app.db.transaction(request) as cur:\n    data = await cur.fetchrow(sql, name)\n\nacquire() 函数为非事务, 对于只涉及到查询的使用非事务，可以提高查询效率\ntansaction() 函数为事务操作，对于增删改必须使用事务操作\n传入request参数是为了获取到span，用于日志追踪\n\nTODO  数据库读写分离\n\n相关连接\nasyncpgbenchmarks\n客户端\n使用aiohttp中的client，对客户端进行了简单的封装，用于微服务之间访问。Don’t create a session per request. Most likely you need a session per application which performs all requests altogether.A session contains a connection pool inside, connection reusage and keep-alives (both are on by default) may speed up total performance.\n\nExample:\n@app.listener('before_server_start')\nasync def before_srver_start(app, loop):\n    app.client =  Client(loop, url='http://host:port')\n\nasync def get_role_by_id(request, id):\n    cli = request.app.client.cli(request)\n    async with cli.get('/cities/{}'.format(id)) as res:\n        return await res.json()\n\n@app.listener('before_server_stop')\nasync def before_server_stop(app, loop):\n    app.client.close()\n\n对于访问不同的微服务可以创建多个不同的client，这样每个client都会keep-alives\n相关连接\naiohttp\n日志 & 分布式追踪系统\n使用官方logging, 配置文件为logging.yml, sanic版本要0.6.0及以上。JsonFormatter将日志转成json格式，用于输入到ESEnter OpenTracing: by offering consistent, expressive, vendor-neutral APIs for popular platforms, OpenTracing makes it easy for developers to add (or switch) tracing implementations with an O(1) configuration change. OpenTracing also offers a lingua franca for OSS instrumentation and platform-specific tracing helper libraries. Please refer to the Semantic Specification.\n\n装饰器logger\n@logger(type='method', category='test', detail='detail', description=\"des\", tracing=True, level=logging.INFO)\nasync def get_city_by_id(request, id):\n    cli = request.app.client.cli(request)\n\ntype: 日志类型，如 method, route\ncategory: 日志类别，默认为app的name\ndetail: 日志详细信息\ndescription: 日志描述，默认为函数的注释\ntracing: 日志追踪，默认为True\nlevel: 日志级别，默认为INFO\n\n分布式追踪系统\n\nOpenTracing是以Dapper，Zipkin等分布式追踪系统为依据, 建立了统一的标准。\nOpentracing跟踪每一个请求，记录请求所经过的每一个微服务，以链条的方式串联起来，对分析微服务的性能瓶颈至关重要。\n使用opentracing框架，但是在输出时转换成zipkin格式。 因为大多数分布式追踪系统考虑到性能问题，都是使用的thrift进行通信的，本着简单，Restful风格的精神，没有使用RPC通信。以日志的方式输出, 可以使用fluentd, logstash等日志收集再输入到Zipkin。Zipkin是支持HTTP输入的。\n生成的span先无阻塞的放入queue中，在task中消费队列的span。后期可以添加上采样频率。\n对于DB，Client都加上了tracing\n\n相关连接\nopentracingzipkinjaeger\nAPI接口\napi文档使用swagger标准。\nExample:\nfrom sanic_ms import doc\n\n@user_bp.post('/')\n@doc.summary('create user')\n@doc.description('create user info')\n@doc.consumes(Users)\n@doc.produces({'id': int})\nasync def create_user(request):\n    data = request['data']\n    async with request.app.db.transaction(request) as cur:\n        record = await cur.fetchrow(\n            \"\"\" INSERT INTO users(name, age, city_id, role_id)\n                VALUES($1, $2, $3, $4, $5)\n                RETURNING id\n            \"\"\", data['name'], data['age'], data['city_id'], data['role_id']\n        )\n        return {'id': record['id']}\n\nsummary: api概要\ndescription: 详细描述\nconsumes: request的body数据\nproduces: response的返回数据\ntag: API标签\n在consumes和produces中传入的参数可以是peewee的model,会解析model生成API数据, 在field字段的help_text参数来表示引用对象\n\nhttp://host:ip/openapi/spec.json 获取生成的json数据\n\n相关连接\nswagger\nResponse 数据\n在返回时，不要返回sanic的response，直接返回原始数据，会在Middleware中对返回的数据进行处理，返回统一的格式，具体的格式可以[查看]\n单元测试\n单元测试使用unittest。 mock是自己创建了MockClient，因为unittest还没有asyncio的mock，并且sanic的测试接口也是发送request请求，所以比较麻烦. 后期可以使用pytest。\nExample:\nfrom sanic_ms.tests import APITestCase\nfrom server import app\n\nclass TestCase(APITestCase):\n    _app = app\n    _blueprint = 'visit'\n\n    def setUp(self):\n        super(TestCase, self).setUp()\n        self._mock.get('/cities/1',\n                       payload={'id': 1, 'name': 'shanghai'})\n        self._mock.get('/roles/1',\n                       payload={'id': 1, 'name': 'shanghai'})\n\n    def test_create_user(self):\n        data = {\n            'name': 'test',\n            'age': 2,\n            'city_id': 1,\n            'role_id': 1,\n        }\n        res = self.client.create_user(data=data)\n        body = ujson.loads(res.text)\n        self.assertEqual(res.status, 200)\n\n其中_blueprint为blueprint名称\n在setUp函数中，使用_mock来注册mock信息, 这样就不会访问真实的服务器, payload为返回的body信息\n使用client变量调用各个函数, data为body信息，params为路径的参数信息，其他参数是route的参数\n\n代码覆盖\ncoverage erase\ncoverage run --source . -m sanic_ms tests\ncoverage xml -o reports/coverage.xml\ncoverage2clover -i reports/coverage.xml -o reports/clover.xml\ncoverage html -d reports\ncoverage2colver 是将coverage.xml 转换成 clover.xml，bamboo需要的格式是clover的。\n相关连接\nunittestcoverage\n异常处理\n使用 app.error_handler = CustomHander() 对抛出的异常进行处理\nExample:\nfrom sanic_ms.exception import ServerError\n\n@visit_bp.delete('/users/<id:int>')\nasync def del_user(request, id):\n    raise ServerError(error='内部错误',code=10500, message=\"msg\")\n\ncode: 错误码，无异常时为0，其余值都为异常\nmessage: 状态码信息\nerror: 自定义错误信息\nstatus_code: http状态码，使用标准的http状态码\n\n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "4"}