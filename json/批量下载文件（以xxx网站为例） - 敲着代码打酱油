{"title": "批量下载文件（以xxx网站为例） - 敲着代码打酱油 ", "index": "python", "content": "爸爸经常拿个收音机听评书，最近想帮爸爸在网上下个全集。打开百度搜了下评书，发现有个叫评书网的网站。搜了下单田芳说的《白眉大侠》。但是只能一回一次的单个点击下载，那不得点死。所以就想到了批量搞它。本文用的方法很简单（大神勿喷）。\n发现规律，http://www.5ips.net/down_120_001.htm这个是第一回的下载地址，用浏览器打开显示网页源码发现下载地址就在里边那就好办了。url[2]= \"/pingshu/单田芳_白眉大侠/单田芳_白眉大侠_001.mp3?key=8de4ff27ca1e24e711d0772ebe13b454_511093084\"这个是他后台临时生成的下载地址，过几分钟就会失效。规律得到了，url地址是_001表示第一回，文件地址为_001.mp3, 如果是_002就表示第二回，文件地址为_002.mp3。以此类推\n好吧直接搞起。用urllib2直接拿到网页\npsurl0 = 'http://www.5ips.net/down_120_'\npsurl0_0 = '.htm'\npsurl1 = 'http://p33d.5ips.net/pingshu/单田芳_白眉大侠/单田芳_白眉大侠_'\ndef main(index):\n    ji = \"\";\n    if index < 10:\n        ji = \"00%d\" %index;\n    elif index < 100:\n        ji = \"0%d\" %index;\n    else:\n        ji = \"%d\" %index\n    \n    url_p = psurl0 + ji + psurl0_0\n    reque = urllib2.Request(url_p, headers = headers)\n    content = urllib2.urlopen(reque).read()\n    reg = '.mp3\\?key=.*\"'\n    reslut = re.search(reg, content).group()\n    reslut = reslut.replace('\"', '')\n    newpath = psurl1 + ji + reslut\n    #down(newpath, ji + '.mp3')\npsurl0，psurl0_0，psurl1都是固定的，变得只是下载的章数和动态生成的地址码。由于下载地址直接显示到网页源码中了，所以不需要复杂的解析，直接用正则找到下载地址reslut\n拿到下载地址了直接用urllib2.urlopen下载失败了，但是把地址帖到浏览器可以播放，应该被网站禁止了。好吧，尝试其他办法。打开命令行用weget下载成功。问题解决了。weget是linux系统自带的下载工具，Mac和windows都需要自己安装。\ndef down(url, file_name):\n    option = 'wget -O ./白眉大侠/%s %s' %(file_name, url)\n    pop = subprocess.Popen(target, stdin = subprocess.PIPE, stdout = subprocess.PIPE)\n    pop.communicate(mess)\n一个循环把320回的MP3全部搞下\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}