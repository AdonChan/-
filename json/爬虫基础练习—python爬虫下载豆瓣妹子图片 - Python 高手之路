{"title": "爬虫基础练习—python爬虫下载豆瓣妹子图片 - Python 高手之路 ", "index": "python", "content": "下载指定网站上的妹子图片，这里只抓了前100页的图片，可根据需要自己设置页数cat值为图片类型，大家可以自行更改cat值体验一下，有问题留言给我，看到就会解答2 ＝ 大胸妹3 ＝ 美腿控4 ＝ 有颜值5 ＝ 大杂烩6 ＝ 小翘臀\nimport requests\nimport re\nimport time\nfrom bs4 import BeautifulSoup\n\ncat ='2'\nimg = 'http://www.dbmeinv.com/dbgroup/show.htm?cid='+ cat\nend = '/dbgroup/show.htm?cid='+ cat + '&pager_offset=100'\nurls = [ ]\ndef getURLs(mainURL):\n    time.sleep(1)\n    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36'}\n    html = requests.get(mainURL).text\n    soup = BeautifulSoup(html, 'html.parser')\n    picURL = re.findall('<img class.*?src=\"(.+?\\.jpg)\"', html, re.S)\n    for url in picURL:\n        urls.append(url)\n        print(url)\n    asoup = soup.select('.next a')[0]['href']\n    Next_page = 'http://www.dbmeinv.com' + asoup\n    if asoup != end:\n        getURLs(Next_page)\n    else:\n        print('链接已处理完毕！')\n    return urls\nurl = getURLs(img)\n\ni = 0\nfor each in url:\n    pic = requests.get(each, timeout = 10)\n    picName = 'pictures/' + str(i) + '.jpg'\n    fp = open(picName, 'wb')\n    fp.write(pic.content)\n    fp.close()\n    i += 1\n\nprint('图片下载完成')\n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "16"}