{"title": "python---线程 - python学习 ", "index": "python", "content": "操作系统线程理论\n线程概念的引入背景\n进程之前我们已经了解了操作系统中进程的概念，程序并不能单独运行，只有将程序装载到内存中，系统为它分配资源才能运行，而这种执行的程序就称之为进程。程序和进程的区别就在于：程序是指令的集合，它是进程运行的静态描述文本；进程是程序的一次执行活动，属于动态概念。在多道编程中，我们允许多个程序同时加载到内存中，在操作系统的调度下，可以实现并发地执行。这是这样的设计，大大提高了CPU的利用率。进程的出现让每个用户感觉到自己独享CPU，因此，进程就是为了在CPU上实现多道编程而提出的。有了进程为什么要有线程进程有很多优点，它提供了多道编程，让我们感觉我们每个人都拥有自己的CPU和其他资源，可以提高计算机的利用率。很多人就不理解了，既然进程这么优秀，为什么还要线程呢？其实，仔细观察就会发现进程还是有很多缺陷的，主要体现在两点上：进程只能在一个时间干一件事，如果想同时干两件事或多件事，进程就无能为力了。进程在执行的过程中如果阻塞，例如等待输入，整个进程就会挂起，即使进程中有些工作不依赖于输入的数据，也将无法执行。　　如果这两个缺点理解比较困难的话，举个现实的例子也许你就清楚了：如果把我们上课的过程看成一个进程的话，那么我们要做的是耳朵听老师讲课，手上还要记笔记，脑子还要思考问题，这样才能高效的完成听课的任务。而如果只提供进程这个机制的话，上面这三件事将不能同时执行，同一时间只能做一件事，听的时候就不能记笔记，也不能用脑子思考，这是其一；如果老师在黑板上写演算过程，我们开始记笔记，而老师突然有一步推不下去了，阻塞住了，他在那边思考着，而我们呢，也不能干其他事，即使你想趁此时思考一下刚才没听懂的一个问题都不行，这是其二。　　现在你应该明白了进程的缺陷了，而解决的办法很简单，我们完全可以让听、写、思三个独立的过程，并行起来，这样很明显可以提高听课的效率。而实际的操作系统中，也同样引入了这种类似的机制——线程。线程的出现60年代，在OS中能拥有资源和独立运行的基本单位是进程，然而随着计算机技术的发展，进程出现了很多弊端，一是由于进程是资源拥有者，创建、撤消与切换存在较大的时空开销，因此需要引入轻型进程；二是由于对称多处理机（SMP）出现，可以满足多个运行单位，而多个进程并行开销过大。因此在80年代，出现了能独立运行的基本单位——线程（Threads）。注意：进程是资源分配的最小单位,线程是CPU调度的最小单位.每一个进程中至少有一个线程。　\n进程和线程的关系\n\n线程与进程的区别可以归纳为以下4点：　　1）地址空间和其它资源（如打开文件）：进程间相互独立，同一进程的各线程间共享。某进程内的线程在其它进程不可见。　　2）通信：进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。　　3）调度和切换：线程上下文切换比进程上下文切换要快得多。　　4）在多线程操作系统中，进程不是一个可执行的实体。　　*通过漫画了解线程进城\n线程的特点\n1）轻型实体　　线程中的实体基本上不拥有系统资源，只是有一点必不可少的、能保证独立运行的资源。　　线程的实体包括程序、数据和TCB。线程是动态概念，它的动态特性由线程控制块TCB（Thread Control Block）描述。TCB包括以下信息：（1）线程状态。（2）当线程不运行时，被保存的现场资源。（3）一组执行堆栈。（4）存放每个线程的局部变量主存区。（5）访问同一个进程中的主存和其它资源。用于指示被执行指令序列的程序计数器、保留局部变量、少数状态参数和返回地址等的一组寄存器和堆栈。复制代码　　2）独立调度和分派的基本单位。　　在多线程OS中，线程是能独立运行的基本单位，因而也是独立调度和分派的基本单位。由于线程很“轻”，故线程的切换非常迅速且开销小（在同一进程中的）。　　3）共享进程资源。　　线程在同一进程中的各个线程，都可以共享该进程所拥有的资源，这首先表现在：所有线程都具有相同的进程id，这意味着，线程可以访问该进程的每一个内存资源；此外，还可以访问进程所拥有的已打开文件、定时器、信号量机构等。由于同一个进程内的线程共享内存和文件，所以线程之间互相通信不必调用内核。　　4）可并发执行。　　在一个进程中的多个线程之间，可以并发执行，甚至允许在一个进程中所有线程都能并发执行；同样，不同进程中的线程也能并发执行，充分利用和发挥了处理机与外围设备并行工作的能力。\n使用线程的实际场景\n\n开启一个字处理软件进程，该进程肯定需要办不止一件事情，比如监听键盘输入，处理文字，定时自动将文字保存到硬盘，这三个任务操作的都是同一块数据，因而不能用多进程。只能在一个进程里并发地开启三个线程,如果是单线程，那就只能是，键盘输入时，不能处理文字和自动保存，自动保存时又不能输入和处理文字。\n内存中的线程\n\n多个线程共享同一个进程的地址空间中的资源，是对一台计算机上多个进程的模拟，有时也称线程为轻量级的进程。　　而对一台计算机上多个进程，则共享物理内存、磁盘、打印机等其他物理资源。多线程的运行也多进程的运行类似，是cpu在多个线程之间的快速切换。　　不同的进程之间是充满敌意的，彼此是抢占、竞争cpu的关系，如果迅雷会和QQ抢资源。而同一个进程是由一个程序员的程序创建，所以同一进程内的线程是合作关系，一个线程可以访问另外一个线程的内存地址，大家都是共享的，一个线程干死了另外一个线程的内存，那纯属程序员脑子有问题。　　类似于进程，每个线程也有自己的堆栈，不同于进程，线程库无法利用时钟中断强制线程让出CPU，可以调用thread_yield运行线程自动放弃cpu，让另外一个线程运行。　　线程通常是有益的，但是带来了不小程序设计难度，线程的问题是：　　1. 父进程有多个线程，那么开启的子线程是否需要同样多的线程　　2. 在同一个进程中，如果一个线程关闭了文件，而另外一个线程正准备往该文件内写内容呢？　　因此，在多线程的代码中，需要更多的心思来设计程序的逻辑、保护程序的数据。\n用户级线程和内核级线程\n线程的实现可以分为两类：用户级线程(User-Level Thread)和内核线线程(Kernel-Level Thread)，后者又称为内核支持的线程或轻量级进程。在多线程操作系统中，各个系统的实现方式并不相同，在有的系统中实现了用户级线程，有的系统中实现了内核级线程。 用户级线程内核的切换由用户态程序自己控制内核切换,不需要内核干涉，少了进出内核态的消耗，但不能很好的利用多核Cpu。\n\n内核级线程内核级线程:切换由内核控制，当线程进行切换的时候，由用户态转化为内核态。切换完毕要从内核态返回用户态；可以很好的利用smp，即利用多核cpu。windows线程就是这样的。\n\n用户级与内核级线程的对比1.用户级线程和内核级线程的区别\n1 内核支持线程是OS内核可感知的，而用户级线程是OS内核不可感知的。\n2 用户级线程的创建、撤消和调度不需要OS内核的支持，是在语言（如Java）这一级处理的；而内核支持线程的创建、撤消和调度都需OS内核提供支持，而且与进程的创建、撤消和调度大体是相同的。\n3 用户级线程执行系统调用指令时将导致其所属进程被中断，而内核支持线程执行系统调用指令时，只导致该线程被中断。\n4 在只有用户级线程的系统内，CPU调度还是以进程为单位，处于运行状态的进程中的多个线程，由用户程序控制线程的轮换运行；在有内核支持线程的系统内，CPU调度则以线程为单位，由OS的线程调度程序负责线程的调度。\n5 用户级线程的程序实体是运行在用户态下的程序，而内核支持线程的程序实体则是可以运行在任何状态下的程序。\n\n2.内核线程的优缺点\n优点：当有多个处理机时，一个进程的多个线程可以同时执行。\n缺点：由内核进行调度。\n\n3.用户级线程的优缺点\n优点：\n    线程的调度不需要内核直接参与，控制简单。\n    可以在不支持线程的操作系统中实现。\n    创建和销毁线程、线程切换代价等线程管理的代价比内核线程少得多。\n    允许每个进程定制自己的调度算法，线程管理比较灵活。\n    线程能够利用的表空间和堆栈空间比内核级线程多。\n    同一进程中只能同时有一个线程在运行，如果有一个线程使用了系统调用而阻塞，那么整个进程都会被挂起。另外，页面失效也会产生同样的问题。\n缺点：\n    资源调度按照进程进行，多个处理机下，同一个进程中的线程只能在同一个处理机下分时复用\n    \n混合实现用户级与内核级的多路复用，内核同一调度内核线程，每个内核线程对应n个用户线程\n\n线程和python\n理论知识\n全局解释器锁GILPython代码的执行由Python虚拟机(也叫解释器主循环)来控制。Python在设计之初就考虑到要在主循环中，同时只有一个线程在执行。虽然 Python 解释器中可以“运行”多个线程，但在任意时刻只有一个线程在解释器中运行。　　对Python虚拟机的访问由全局解释器锁(GIL)来控制，正是这个锁能保证同一时刻只有一个线程在运行。　　在多线程环境中，Python 虚拟机按以下方式执行：　　a、设置 GIL；　　b、切换到一个线程去运行；　　c、运行指定数量的字节码指令或者线程主动让出控制(可以调用 time.sleep(0))；　　d、把线程设置为睡眠状态；　　e、解锁 GIL；　　d、再次重复以上所有步骤。　　在调用外部代码(如 C/C++扩展函数)的时候，GIL将会被锁定，直到这个函数结束为止(由于在这期间没有Python的字节码被运行，所以不会做线程切换)编写扩展的程序员可以主动解锁GIL。python线程模块的选择Python提供了几个用于多线程编程的模块，包括thread、threading和Queue等。thread和threading模块允许程序员创建和管理线程。thread模块提供了基本的线程和锁的支持，threading提供了更高级别、功能更强的线程管理的功能。Queue模块允许用户创建一个可以用于多个线程之间共享数据的队列数据结构。　　避免使用thread模块，因为更高级别的threading模块更为先进，对线程的支持更为完善，而且使用thread模块里的属性有可能会与threading出现冲突；其次低级别的thread模块的同步原语很少(实际上只有一个)，而threading模块则有很多；再者，thread模块中当主线程结束时，所有的线程都会被强制结束掉，没有警告也不会有正常的清除工作，至少threading模块能确保重要的子线程退出后进程才退出。 　　thread模块不支持守护线程，当主线程退出时，所有的子线程不论它们是否还在工作，都会被强行退出。而threading模块支持守护线程，守护线程一般是一个等待客户请求的服务器，如果没有客户提出请求它就在那等着，如果设定一个线程为守护线程，就表示这个线程是不重要的，在进程退出的时候，不用等待这个线程退出。\nthreading模块\nmultiprocess模块的完全模仿了threading模块的接口，二者在使用层面，有很大的相似性，见官网链接：\n线程的创建Threading.Thread类\n1.线程的创建创建线程的方式1：\n#!/usr/bin/env python\n# -*- coding:utf-8 -*-\nfrom threading import Thread\nimport time\ndef sayhi(name):\n    time.sleep(2)\n    print('%s say hello' %name)\n\nif __name__ == '__main__':\n    t=Thread(target=sayhi,args=('egon',))\n    t.start()\n    print('主线程')\n创建线程的方式2：\nfrom threading import Thread\nimport time\nclass Sayhi(Thread):\n    def __init__(self,name):\n        super().__init__()\n        self.name=name\n    def run(self):\n        time.sleep(2)\n        print('%s say hello' % self.name)\n\n\nif __name__ == '__main__':\n    t = Sayhi('egon')\n    t.start()\n    print('主线程')\n2.多线程与多进程pid的比较\nfrom threading import Thread\nfrom multiprocessing import Process\nimport os\n\ndef work():\n    print('hello',os.getpid())\n\nif __name__ == '__main__':\n    #part1:在主进程下开启多个线程,每个线程都跟主进程的pid一样\n    t1=Thread(target=work)\n    t2=Thread(target=work)\n    t1.start()\n    t2.start()\n    print('主线程/主进程pid',os.getpid())\n\n    #part2:开多个进程,每个进程都有不同的pid\n    p1=Process(target=work)\n    p2=Process(target=work)\n    p1.start()\n    p2.start()\n    print('主线程/主进程pid',os.getpid())\n开启效率的较量\nimport time\nfrom multiprocessing import Process\nfrom threading import Thread\nn = 10\ndef func(i):\n    global n\n    n -= 1\n\nif __name__ == '__main__':\n    start = time.time()\n    t_lst = []\n    for i in range(100):\n        t = Thread(target=func,args=(i,))\n        t.start()\n        t_lst.append(t)\n    for t in t_lst:t.join()\n    print('线程 ',time.time() - start)\n    start = time.time()\n    p_lst = []\n    for i in range(100):\n        p = Process(target=func,args=(i,))\n        p.start()\n        p_lst.append(p)\n    for p in p_lst: p.join()\n    print('进程 ：',time.time() - start)\n内存数据的共享问题\nfrom  threading import Thread\nfrom multiprocessing import Process\ndef work():\n    global n\n    n=0\n    print(\"子线程/子进程\",n)\n\nif __name__ == '__main__':\n    n=100\n    p=Process(target=work)\n    p.start()\n    p.join()\n    print('主',n) #毫无疑问子进程p已经将自己的全局的n改成了0,但改的仅仅是它自己的,查看父进程的n仍然为100\n\n\n    n=1\n    t=Thread(target=work)\n    t.start()\n    t.join()\n    print('主',n) #查看结果为0,因为同一进程内的线程之间共享进程内的数据\n多线程实现socketserver端：\nfrom threading import Thread\nimport socket\n\n\ns=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\ns.bind(('127.0.0.1',8080))\ns.listen(5)\n\ndef action(conn,addr):\n    while True:\n        data=conn.recv(1024)\n        print(\"来自客户端：{addr}消息为：{data}\".format(addr=addr,data=data.decode(\"utf-8\")))\n        conn.send(data)\n\nif __name__ == '__main__':\n\n    while True:\n        conn,addr=s.accept()\n        p=Thread(target=action,args=(conn,addr))\n        p.start()\nclient端：\nimport socket\nip_port = ('127.0.0.1',8080)\ns=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\ns.connect(ip_port)\n\nwhile True:\n    msg=input('>>: ').strip()\n    if not msg:continue\n\n    s.send(msg.encode('utf-8'))\n    data=s.recv(1024).decode(\"utf-8\")\n    print(\"来自服务端：{ip},消息为:{data}\".format(ip=ip_port,data=data))\nThread类的其他方法\nThread实例对象的方法\n  # isAlive(): 返回线程是否活动的。\n  # getName(): 返回线程名。\n  # setName(): 设置线程名。\n\nthreading模块提供的一些方法：\n  # threading.currentThread(): 返回当前的线程变量。\n  # threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。\n  # threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。\n守护线程\n无论是进程还是线程，都遵循：守护xx会等待主xx运行完毕后被销毁。需要强调的是：运行完毕并非终止运行\n1 主进程在其代码结束后就已经算运行完毕了（守护进程在此时就被回收）,然后主进程会一直等非守护的子进程都运行完毕后回收子进程的资源(否则会产生僵尸进程)，才会结束，2 主线程在其他非守护线程运行完毕后才算运行完毕（守护线程在此时就被回收）。因为主线程的结束意味着进程的结束，进程整体的资源都将被回收，而进程必须保证非守护线程都运行完毕后才能结束。\n1.守护线程例1\nfrom threading import Thread\nimport time\ndef sayhi(name):\n    time.sleep(2)\n    print('%s say hello' %name)\n\nif __name__ == '__main__':\n    t=Thread(target=sayhi,args=('egon',))\n    t.setDaemon(True) #必须在t.start()之前设置\n    t.start()\n\n    print('主线程')\n    print(t.is_alive())\n    '''\n    主线程\n    True\n    '''\n2.守护线程例2\nfrom threading import Thread\nimport time\ndef foo():\n    print(123)\n    time.sleep(1)\n    print(\"end123\")\n\ndef bar():\n    print(456)\n    time.sleep(3)\n    print(\"end456\")\n\n\nt1=Thread(target=foo)\nt2=Thread(target=bar)\n\nt1.daemon=True\nt1.start()\nt2.start()\nprint(\"main-------\")\n锁\n同步锁1.多个线程抢占资源的情况\nfrom threading import Thread\nimport os,time\ndef work():\n    global n\n    temp=n\n    time.sleep(0.1)\n    n=temp-1\nif __name__ == '__main__':\n    n=100\n    l=[]\n    for i in range(100):\n        p=Thread(target=work)\n        l.append(p)\n        p.start()\n    for p in l:\n        p.join()\n\n    print(n) #结果可能为99\n2.解决方法：\nimport threading\nR=threading.Lock()\nR.acquire()\n'''\n对公共数据的操作\n'''\nR.release()\n3.同步锁的引用\nfrom threading import Thread,Lock\nimport os,time\ndef work():\n    global n\n    lock.acquire()\n    temp=n\n    print(\"子进程temp\", temp)\n    time.sleep(0.1)\n    n=temp-1\n    print(\"子进程n\", n)\n    lock.release()\nif __name__ == '__main__':\n    lock=Lock()\n    n=5\n    l=[]\n    for i in range(5):\n        p=Thread(target=work)\n        l.append(p)\n        p.start()\n    for p in l:\n        p.join()\n    print(n)\n3.互斥锁与join的区别\n#不加锁:并发执行,速度快,数据不安全\nfrom threading import current_thread,Thread,Lock\nimport os,time\ndef task():\n    global n\n    print('%s is running' %current_thread().getName())\n    temp=n\n    time.sleep(0.5)\n    n=temp-1\n\n\nif __name__ == '__main__':\n    n=100\n    lock=Lock()\n    threads=[]\n    start_time=time.time()\n    for i in range(100):\n        t=Thread(target=task)\n        threads.append(t)\n        t.start()\n    for t in threads:\n        t.join()\n\n    stop_time=time.time()\n    print('主:%s n:%s' %(stop_time-start_time,n))\n\n'''\nThread-1 is running\nThread-2 is running\n......\nThread-100 is running\n主:0.5216062068939209 n:99\n'''\n\n\n#不加锁:未加锁部分并发执行,加锁部分串行执行,速度慢,数据安全\nfrom threading import current_thread,Thread,Lock\nimport os,time\ndef task():\n    #未加锁的代码并发运行\n    time.sleep(3)\n    print('%s start to run' %current_thread().getName())\n    global n\n    #加锁的代码串行运行\n    lock.acquire()\n    temp=n\n    time.sleep(0.5)\n    n=temp-1\n    lock.release()\n\nif __name__ == '__main__':\n    n=100\n    lock=Lock()\n    threads=[]\n    start_time=time.time()\n    for i in range(100):\n        t=Thread(target=task)\n        threads.append(t)\n        t.start()\n    for t in threads:\n        t.join()\n    stop_time=time.time()\n    print('主:%s n:%s' %(stop_time-start_time,n))\n\n'''\nThread-1 is running\nThread-2 is running\n......\nThread-100 is running\n主:53.294203758239746 n:0\n'''\n\n#有的同学可能有疑问:既然加锁会让运行变成串行,那么我在start之后立即使用join,就不用加锁了啊,也是串行的效果啊\n#没错:在start之后立刻使用jion,肯定会将100个任务的执行变成串行,毫无疑问,最终n的结果也肯定是0,是安全的,但问题是\n#start后立即join:任务内的所有代码都是串行执行的,而加锁,只是加锁的部分即修改共享数据的部分是串行的\n#单从保证数据安全方面,二者都可以实现,但很明显是加锁的效率更高.\nfrom threading import current_thread,Thread,Lock\nimport os,time\ndef task():\n    time.sleep(3)\n    print('%s start to run' %current_thread().getName())\n    global n\n    temp=n\n    time.sleep(0.5)\n    n=temp-1\n\n\nif __name__ == '__main__':\n    n=100\n    lock=Lock()\n    start_time=time.time()\n    for i in range(100):\n        t=Thread(target=task)\n        t.start()\n        t.join()\n    stop_time=time.time()\n    print('主:%s n:%s' %(stop_time-start_time,n))\n\n'''\nThread-1 start to run\nThread-2 start to run\n......\nThread-100 start to run\n主:350.6937336921692 n:0 #耗时是多么的恐怖\n\n\n4.死锁与递归锁进程也有死锁与递归锁所谓死锁： 是指两个或两个以上的进程或线程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程，如下就是死锁\nimport time\nfrom threading import Lock,Thread\nnoodle = 100\nfork = 100\nnoodle_lock = Lock()\nfork_lock = Lock()\n\ndef eat1(name):\n    global noodle,fork\n    noodle_lock.acquire()\n    print('%s拿到面了' % name)\n    fork_lock.acquire()\n    print('%s拿到叉子了' % name)\n    noodle -= 1\n    print('%s吃面'%name)\n    time.sleep(0.1)\n    fork_lock.release()\n    print('%s放下叉子了' % name)\n    noodle_lock.release()\n    print('%s放下面' % name)\n\ndef eat2(name):\n    global noodle,fork\n    fork_lock.acquire()\n    print('%s拿到叉子了'%name)\n    noodle_lock.acquire()\n    print('%s拿到面了'%name)\n    noodle -= 1\n    print('%s吃面'%name)\n    time.sleep(0.1)\n    noodle_lock.release()\n    print('%s放下面'%name)\n    fork_lock.release()\n    print('%s放下叉子了'%name)\n\n\nfor i in ['alex','wusir','egon','快老师']:\n    Thread(target=eat1,args=(i,)).start()\n    Thread(target=eat2,args=(i+'2',)).start()\n解决方法，递归锁，在Python中为了支持在同一线程中多次请求同一资源，python提供了可重入锁RLock。这个RLock内部维护着一个Lock和一个counter变量，counter记录了acquire的次数，从而使得资源可以被多次require。直到一个线程所有的acquire都被release，其他的线程才能获得资源。上面的例子如果使用RLock代替Lock，则不会发生死锁：\nimport time\nfrom threading import Thread,RLock\nnoodle = 100\nfork = 100\nnoodle_lock = fork_lock = RLock()\ndef eat1(name):\n    global noodle,fork\n    noodle_lock.acquire()\n    print('%s拿到面了' % name)\n    fork_lock.acquire()\n    print('%s拿到叉子了' % name)\n    noodle -= 1\n    print('%s吃面'%name)\n    time.sleep(0.1)\n    fork_lock.release()\n    print('%s放下叉子了' % name)\n    noodle_lock.release()\n    print('%s放下面' % name)\n\ndef eat2(name):\n    global noodle,fork\n    fork_lock.acquire()\n    print('%s拿到叉子了'%name)\n    noodle_lock.acquire()\n    print('%s拿到面了'%name)\n    noodle -= 1\n    print('%s吃面'%name)\n    time.sleep(0.1)\n    noodle_lock.release()\n    print('%s放下面'%name)\n    fork_lock.release()\n    print('%s放下叉子了'%name)\n\n\nfor i in ['alex','wusir','egon','快老师']:\n    Thread(target=eat1,args=(i,)).start()\n    Thread(target=eat2,args=(i+'2',)).start()\n使用互斥锁解决死锁问题：\nimport time\nfrom threading import Thread,Lock\nnoodle = 100\nfork = 100\nnoodle_fork_lock = Lock()\ndef eat1(name):\n    global noodle,fork\n    noodle_fork_lock.acquire()\n    print('%s拿到面了' % name)\n    print('%s拿到叉子了' % name)\n    noodle -= 1\n    print('%s吃面'%name)\n    time.sleep(0.1)\n    print('%s放下叉子了' % name)\n    noodle_fork_lock.release()\n    print('%s放下面' % name)\n\ndef eat2(name):\n    global noodle,fork\n    noodle_fork_lock.acquire()\n    print('%s拿到叉子了'%name)\n    print('%s拿到面了'%name)\n    noodle -= 1\n    print('%s吃面'%name)\n    time.sleep(0.1)\n    print('%s放下面'%name)\n    noodle_fork_lock.release()\n    print('%s放下叉子了'%name)\n\n\nfor i in ['alex','wusir','egon','快老师']:\n    Thread(target=eat1,args=(i,)).start()\n    Thread(target=eat2,args=(i+'2',)).start()\n信号量\n同进程的一样Semaphore管理一个内置的计数器，每当调用acquire()时内置计数器-1；调用release() 时内置计数器+1；计数器不能小于0；当计数器为0时，acquire()将阻塞线程直到其他线程调用release()。\n实例：(同时只有5个线程可以获得semaphore,即可以限制最大连接数为5)：\nfrom threading import Thread,Semaphore\nimport threading\nimport time\n\ndef func():\n    sm.acquire()\n    print('%s get sm' %threading.current_thread().getName())\n    time.sleep(3)\n    sm.release()\nif __name__ == '__main__':\n    sm=Semaphore(5)\n    for i in range(23):\n        t=Thread(target=func)\n        t.start()\n定时器\nfrom threading import Timer\n \ndef hello():\n    print(\"hello, world\")\n \nt = Timer(1, hello)\nt.start()  # after 1 seconds, \"hello, world\" will be printed\n线程队列\nqueue队列 ：使用import queue，用法与进程Queue一样queue is especially useful in threaded programming when information must be exchanged safely between multiple threads.\n1.先进先出\nimport queue\n\n# q = queue.Queue()  先进先出\n# 在线程之间数据安全，自带线程锁的数据容器\n\nlq = queue.LifoQueue() # 栈 先进后出 算法和数据结构中\nlq.put(1)\nlq.put(2)\nlq.put(3)\nprint(lq.get())\nprint(lq.get())\nprint(lq.get())\n# print(lq.get())#如果队列里边没有值了，进行get操作，会堵塞\n优先级队列\nimport queue\npq = queue.PriorityQueue()  # 优先级队列\npq.put(3)\npq.put(5)\npq.put(2)\nprint(pq.get())\nprint(pq.get())\nprint(pq.get())\n\npq.put('c')\npq.put('a')\npq.put('A')\nprint(pq.get())\nprint(pq.get())\nprint(pq.get())\n\npq.put((10,'asfghfgk'))\npq.put((20,'2iyfhejcn'))\npq.put((15,'qwuriyhf'))\nprint(pq.get())\nprint(pq.get())\nprint(pq.get())\nPython标准模块--concurrent.futures\nhttps://docs.python.org/dev/l...\n#1 介绍\nconcurrent.futures模块提供了高度封装的异步调用接口\nThreadPoolExecutor：线程池，提供异步调用\nProcessPoolExecutor: 进程池，提供异步调用\nBoth implement the same interface, which is defined by the abstract Executor class.\n\n#2 基本方法\n#submit(fn, *args, **kwargs)\n异步提交任务\n\n#map(func, *iterables, timeout=None, chunksize=1) \n取代for循环submit的操作\n\n#shutdown(wait=True) \n相当于进程池的pool.close()+pool.join()操作\nwait=True，等待池内所有任务执行完毕回收完资源后才继续\nwait=False，立即返回，并不会等待池内的任务执行完毕\n但不管wait参数为何值，整个程序都会等到所有任务执行完毕\nsubmit和map必须在shutdown之前\n\n#result(timeout=None)\n取得结果\n\n#add_done_callback(fn)\n回调函数\nimport os\nimport time\nimport random\nfrom threading import get_ident\nfrom concurrent.futures import ThreadPoolExecutor\n\nt_pool = ThreadPoolExecutor(os.cpu_count())\n\n\ndef func(i):\n    time.sleep(random.randint(1,2))\n    print(\"线程：{name},任务{i}\".format(name=get_ident(),i=i))\n    return \"*\"*i\n\n\ndef call_bak(ret):\n    print(\"线程：{name},返回值长度：{i}\".format(name=get_ident(),i=len(ret.result())))\n\nprint(\"主线程：{name}\".format(name=get_ident()))\n\n\nfor i in range(1,20):\n    t_pool.submit(func,i).add_done_callback(call_bak)\n\n                ", "mainLikeNum": ["2 "], "mainBookmarkNum": "1"}