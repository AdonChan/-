{"title": "CentOS7之Scrapy爬虫部署 - 渴望越狱的猫 ", "index": "网页爬虫,mongodb,scrapyd,scrapy,python", "content": "scrapyd\n安装:\nsudo pip install scrapyd\n配置:\n#文件~/.scrapyd.conf\n#内容如下:\n[scrapyd]\neggs_dir    = /home/sirius/scrapyd/eggs\nlogs_dir    = /home/sirius/scrapyd/logs\nitems_dir   = /home/sirius/scrapyd/items\njobs_to_keep = 5\ndbs_dir     = /home/sirius/scrapyd/dbs\nmax_proc    = 0\nmax_proc_per_cpu = 4\nfinished_to_keep = 50\npoll_interval = 5\nbind_address = 0.0.0.0\nhttp_port   = 6800\ndebug       = off\nrunner      = scrapyd.runner\napplication = scrapyd.app.application\nlauncher    = scrapyd.launcher.Launcher\nwebroot     = scrapyd.website.Root\n\n[services]\nschedule.json     = scrapyd.webservice.Schedule\ncancel.json       = scrapyd.webservice.Cancel\naddversion.json   = scrapyd.webservice.AddVersion\nlistprojects.json = scrapyd.webservice.ListProjects\nlistversions.json = scrapyd.webservice.ListVersions\nlistspiders.json  = scrapyd.webservice.ListSpiders\ndelproject.json   = scrapyd.webservice.DeleteProject\ndelversion.json   = scrapyd.webservice.DeleteVersion\nlistjobs.json     = scrapyd.webservice.ListJobs\n#daemonstatus.json = scrapyd.webservice.DaemonStatus\n\nsupervisor\n守护进程，用这个的原因实在是因为scrapyd太脆弱了，一看不住就挂了\n安装:\nsudo pip install supervisor\n\n配置:\nsudo mkdir -p /etc/supervisor/\n\n＃导入默认配置\nsudo su - root -c \"echo_supervisord_conf > /etc/supervisor/supervisord.conf\"\n\n#链接管理\n[inet_http_server]         ; inet (TCP) server disabled by default\nport=127.0.0.1:9001        ; (ip_address:port specifier, *:port for all iface)\n;username=user              ; (default is no username (open server))\n;password=123               ; (default is no password (open server))  \n\n[supervisorctl]\n;serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL  for a unix socket\nserverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket\n;username=chris              ; should be same as http_username if set\n;password=123                ; should be same as http_password if set\n;prompt=mysupervisor         ; cmd line prompt (default \"supervisor\")\n;history_file=~/.sc_history  ; use readline history if available\n\n#设置管理进程\n[program:scrapyd]\ncommand=scrapyd\nautostart=true\nautorestart=unexpected\n\n启动\n`创建文件/usr/lib/systemd/system/supervisord.service内容如下:\n\n[Unit]                                                              \nDescription=supervisord - Supervisor process control system for UNIX\nDocumentation=http://supervisord.org                                \nAfter=network.target                                                \n\n[Service]                                                           \nType=forking                                                        \nExecStart=/usr/bin/supervisord -c /etc/supervisor/supervisord.conf             \nExecReload=/usr/bin/supervisorctl reload                            \nExecStop=/usr/bin/supervisorctl shutdown                            \nUser=<user>\n\n[Install]                                                           \nWantedBy=multi-user.target\n\n#启动\nsudo systemctl enable supervisord\nsudo systemctl start supervisord\n\n#查看\nsupervisorctl\n\n#如一切正常\n|>$ scrapyd   RUNNING   pid 8059, uptime 0:02:02\n\n#常用命令\nstatus #查看状态\nreload #重新载入\nrestart scrapyd #重启任务\nupdate #可以更新 supervisor 配置\ntail -f scrapyd stderr #检查日志\n\n爬虫部署:\n\n部署:\ncd <项目目录>\nscrapyd-deploy\n\n\nAPI控制:\ncurl http://localhost:6800/schedule.json -d project=myproject -d spider=somespider\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "2"}