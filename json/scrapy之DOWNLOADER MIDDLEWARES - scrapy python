{"title": "scrapy之DOWNLOADER MIDDLEWARES - scrapy python  ", "index": "python", "content": "0.前言\n第一次写博客，想想都还有点小激动，其实早就想写写这段时间的学习历程了，奈何文字功底不强，总是刚提笔就放下了。觉得以后还是要坚持下去~~这篇文章主要讲了在scrapy中的DOWNLOADER MIDDLEWARES\n1.scrapy中的DOWNLOADER_MIDDLEWARES\n\n下载器中间件事Scrapy在处理请求/响应时的钩子，是用来全局改变Scrapy的请求和响应的一个轻量，底层的系统\n1.1激活下载器中间件\n要激活下载器中间件组件，将其加入到DOWNLOADER_MIDDLEWARES设置中。该设置是一个字典，键为中间件的类的路径，值为其中间件的顺序，如：\nDOWNLOADER_MIDDLEWARES = {\n'myproject.middlewares.CustomDownloaderMiddleware': 543,\n}\nDOWNLOADER_MIDDLEWARES设置会与 Scrapy 定义的DOWNLOADER_MIDDLEWARES_BASE 设置合并(但不是覆盖)，而后根据顺序(order)进行排序，最后得到启用中间件的有序列表: 第一个中间件是最靠近引擎的，最后一个中间件是最靠近下载器的。关于如何分配中间件的顺序请查看DOWNLOADER_MIDDLEWARES_BASE 设置，而后根据您想要放置中间件的位置选择一个值。由于每个中间件执行不同的动作，您的中间件可能会依赖于之前(或者之后)执行的中间件，因此顺序是很重要的。如果您想禁止内置的(在DOWNLOADER_MIDDLEWARES_BASE 中设置并默认启用的)中间件，您必须在项目的 DOWNLOADER_MIDDLEWARES 设置中定义该中间件，并将其值赋为None。例如，如果您想要关闭user-agent 中间件：\nDOWNLOADER_MIDDLEWARES = {\n'myproject.middlewares.CustomDownloaderMiddleware': 543,\n'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,\n}\n1.2编写自己的中间件下载组件\n每个中间件组成部分都是一个Python类，这个类定义了以下方法中的一个或多个：\nclass scrapy.downloadermiddlewares.DownloaderMiddleware\n    process_request(request,spider)\n    process_response(request, response, spider)\n    process_exception(request, exception, spider)\n详细介绍：\nproces_request(request,spider)：\n\n每个request通过下载中间件时，该方法被调用\n必须返回其中之一：None，Response对象，Request对象或者raise IgnoreRequest。\n如果返回None，Scrapy将继续处理该Request，执行其他的中间件的相应方法，直到合适的下载处理函数被调用，请求被执行，响应被下载\n如果返回 Response对象，Scrapy将不会调用其他任proces_request()或者process_exception()方法，或者相应的下载函数；它将返回这个响应。已安装的中间件的 process_response()方法则会在每个response返回时被调用。\n如果其返回 Request 对象，Scrapy 则停止调用 process_request 方法并重新调度返回的request。当新返回的request被执行后，相应地中间件链将会根据下载的response被调用。\n如果其raise一个IgnoreRequest 异常，则安装的下载中间件的 process_exception() 方法会被调用。如果没有任何一个方法处理该异常， 则 request 的 errback( Request.errback )方法会被调用。如果没有代码处理抛出的异常， 则该异常被忽略且不记录(不同于其他异常那样)。\n\n参数：\n 1.request ( Request 对象) – 处理的 request\n 2.spider ( Spider 对象) – 该 request 对应的 spider\n\n\n\nprocess_response(request, response, spider)：\n\n必须返回以下之一：Response 对象、Request 对象或raise IgnoreRequest。\n如果其返回一个Response(可以与传入的 response 相同，也可以是全新的对象) 该 response 会被在链中的其他中间件的process_response()方法处理。\n如果其返回一个 Request 对象，则中间件链停止，返回的 request 会被重新调度下载。处理类似于 process_request()返回 request 所做的那样。\n果其抛出一个 IgnoreRequest 异常，则调用 request 的 errback(Request.errback)。如果没有代码处理抛出的异常，则该异常被忽略且不记录(不同于其他异常那样)。\n\n参数\n  1.request (Request对象) – response 所对应的 request\n  2.response (Response对象) – 被处理的 response\n  3.spider (Spider对象) – response 所对应的 spider\n\n\n\nprocess_exception(request, exception, spider)：\n\n返回以下之一： 返回None 、一个 Response 对象、或者一个 Request 对象。\n如果其返回None，Scrapy 将会继续处理该异常，接着调用已安装的其他中间件的 process_exception()方法，直到所有中间件都被调用完毕，则调用默认的异常处理。\n如果其返回一个 Response 对象，则已安装的中间件链的 process_response()方法被调用。Scrapy 将不会调用任何其他中间件的 process_exception() 方法。\n如果其返回一个Request对象，则返回的request将会被重新调用下载。这将停止中间件的 process_exception()方法执行，就如返回一个 response 的那样。\n参数\n\n     1.request(Request 对象) – 产生异常的 request\n     2.exception(Exception 对象) – 抛出的异常\n     3.spider(Spider 对象) – request 对应的 spider\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "1"}