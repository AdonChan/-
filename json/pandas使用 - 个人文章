{"title": "pandas使用 - 个人文章 ", "index": "python,pandas", "content": "写这篇文章,主要是想按照一定的逻辑顺总结一下自己做项目以来,序用到过的pandas的知识点.虽然pandas官方文档上各个方面都写的很清楚,但是还是想自己再写一份,一个是想作为个人梳理,另外也可以把最经常使用的部分拎出来,更清晰一些.\n不定时更新.\n数据的IO\nMySQL\n1.读mysq数据\ndf = pd.read_sql(sql, db.conn)\n其中sql是需要的sql语句,db是创建的数据库连接对象.\n一般来说,这样基本就能满足需求. \n额外的参数\n\n 1. chunksize : int, default None\n    当数据量比较大,或者想将读入的数据分割成指定行数的一个个block,则可以设置这个参数.其会返回一个迭代器,迭代器中的元素为chunksize行数的记录.\n    \n 2. index_col : string or list of strings, optional, default: None\n    可以设置某些列为索引列.\n\npandas.read_sql文档\n2.写mysql数据\nengine = create_engine('mysql+pymysql://root:password@localhost/schemeName', echo=False)\n\ndf.to_sql(tablename, engine, if_exists='append', index=index)\n将df的数据写入到数据库表中.pandas文档中提供的例子是SQlite的数据库,所以不能直接用db.conn去充当engine.\n参数说明\n1. if_exists: {‘fail’, ‘replace’, ‘append’}, default ‘fail’\n当数据库中存在要写入的table时,三种处理方式\nfail:那么写入失败\nreplace:把原来的table删掉,写入新的\nappend:在原来的table上,添加新的记录\n\n2. index : boolean, default True\n当设为True时,会把df的index当成一列写入数据库.\n\npandas.DataFrame.to_sql文档\ncsv\n1.读数据\ndf = pd.read_csv(path + filename, header=None, names=[name1, name2])\n参数说明\n1.header: int or list of ints, default ‘infer’\n用来指定行号作为数据的开始和列的名称.header设为None是告诉其打开的文件里没有列名.如果打开的文件有列名的时候,可以不设置这一项,这样系统会自动推测出列名.\n\n2.names : array-like, default None\n显示地指定列的名称.当header是None的时候,需要加上这个.\n关于这个函数,可设置的参数还比较多,不过目前使用的也就这几个,所以先不描述其他了.\npandas.read_csv文档\n2.写数据\ndf.to_csv(path+filename, index=False, header=header, mode='a')\n参数说明\n1.index: boolean, default True\n说明是否需要写入df的index.\n\n2.header : boolean or list of string, default True\n说明是否要把列名写入.也可以在这里重新设置写入的列名.\n\n3.mode : str,default ‘w’\npython的写入模式.\npandas.DataFrame.to_csv文档\nexcel\n直接创建dateFrame\n数据的选择\n简单选择\n\n选择部分行\n选择部分列\n选择数值\n\n按照条件进行筛选\n\n单一条件筛选\n多个条件筛选\n\n数据的聚合值描述\n数据的修改\n索引信息的修改\n数据的合并\n\nconcat\nmerge\njoin\n\n数据的可视化\n时间序列相关\n数据采样\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}