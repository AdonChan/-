{"title": "Pythonic “Data Science” Specialization - GeauxEric ", "index": "pandas,python,data-mining,r", "content": "Why The \"Data Science\" Specialization\n\n\n温习统计学的知识, 为更深层次的学习做准备\nAndrew Ng 在 2015 GTC 的演讲中说, deep learning 就是 black magic; 我们理解50%, 但不知道另外的50%是如何work的. 我在台下想, 对于那可以理解的50%, 我好像都只懂了5%.\n参考\"标准高效\"的流程\nmine: emacs org mode + emacs magit + bitbucket + python. There must be some room for improvement.\n\nHow\n课程用的是R. 我不想再学一门类似的语言了, 我会找出相对应的numpy 和 scipy solution.\n  \n  Getting and Cleaning Data\n\n\nRaw data 的来源\n\n\nWebsite APIs\nDatabases\nJson\nRaw texts\n\nData analysis 流程\n\n\n\nRaw data --> Processing scripts --> tidy data (often ignored in the classes but really important)\n\n\nRecord the meta data\n\nRecord the recipes \n\n\n--> data analysis (covered in machine learning classes)\n--> data communication\n\n什么是干净的data\n\n\nEach variable you measure should be in one column, 一个变量占一列.\nThere should be one table for each \"kind\" of variable, generally data should be save in one file per table 为什么呢? 管理起来不会麻烦麽?\nIf you have multiple tables, they should include a column in the table thta allows them to be linked. 参见 dataframe.merge dataframe.join in pandas\n\n\nThe code book\n\n代码簿? (⊙o⊙)…\n\n\nInfo about the variables (including units!)\n单位很重要! 没有单位的测量是没有物理意义的!\n但测量时候必须要考虑的有效位数在课程中却没有提及. 大抵是因为python 和 R 对于有效位数handle地很好? 不需要像C 里边一样考虑 float 或者 double? 某些极端情况下也会需要像sympy这样的library吧.\nInfo about the summary choice you made\nInfo about the experimental study design you used\n\n代码簿的作用类似于wet lab中的实验记录本. 很庆幸很早就知道了emacs 的 org mode, 用在这里很适合. 但是 Info about the variables 的重要性被我忽略了.\n\n如果feature的数量很多, 而且feature本身意义深刻, 就需要仔细挑选. 记得一次听报告, 有家金融公司用decision tree 做portfolio, 算法本身稀松平常, 但是对于具体用了哪些feature, lecturer守口如瓶.\n\n\"There are many stages to the design and analysis of a successful study. The last of these steps is the calculation of an inferential statistic such as a P value, and the application of a 'decision rule' to it (for example, P < 0.05). In practice, decisions that are made earlier in data analysis have a much greater impact on results — from experimental design to batch effects, lack of adjustment for confounding factors, or simple measurement error. Arbitrary levels of statistical significance can be achieved by changing the ways in which data are cleaned, summarized or modelled.\"\n\nLeek, Jeffrey T., and Roger D. Peng. \"Statistics: P values are just the tip of the iceberg.\" Nature 520.7549 (2015): 612-612.\n\nDownloading Files\n\n我通常都是直接用wget, 但是那样就不容易整合到脚本中. 几个很可能会在download时候用到的python function:\n\n# set up the env\nos.path.dirname(os.path.realpath(__file__))\nos.getcwd()\nos.path.join()\nos.chdir()\nos.path.exists()\nos.makedirs()\n\n# dowload\nurllib.request.urlretrieve()\nurllib.request.urlopen()\n\n# to tag your downloaded files\ndatetime.timezone()\ndatetime.datetime.now()\n\n# an example\nimport shutil\nimport ssl\nimport urllib.request as ur\n\ndef download(myurl):\n    \"\"\"\n    download to the current directory\n    \"\"\"\n    fn = myurl.split('/')[-1]\n    context = ssl._create_unverified_context()\n    with ur.urlopen(myurl, context=context) as response, open(fn, 'wb') as out_file:\n        shutil.copyfileobj(response, out_file)\n\n    return fn\n\n\n\n\nLoading flat files\n\npandas.read_csv()\n\n\nReading XML\n\nHere is a very good introduction\n\nBelow are my summaries:\n\npython 标准库中自带了xml.etree.ElementTree用来解析xml. 其中, ElementTree 表示整个XML文件, Element表示一个node.\n\nThe first element in every XML document is called the root element. 一个XML文件只能又一个root, 因此以下的不符合xml规范:\n\n<foo></foo>\n<bar></bar>\n\n\nrecursively 遍历\n\n# an excersice \n# find all elements with zipcode equals 21231\nxml_fn = download(\"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml\")\ntree = ET.parse(xml_fn)\nfor child in tree.iter():\n    if child.tag == 'zipcode' and child.text == '21231':\n        print(child)\n\n\nJSON\n\n\nJSON stands for Javascript Object Notation\n\nlightweight data storage\n\nJSON 的格式肉眼看起来就像是nested python dict. python 自带的json的用法类似pickle.\n\nPattern Matching\n\nPython makes a distinction between matching and searching. Matching looks only at the start of the target string, whereas searching looks for the pattern anywhere in the target.\n\nAlways use raw strings for regx.\n\nCharacter sets\nsth like r'[A-Za-z_]' would match an underscore or any uppercase or lowercase ASCII letter.\n\nCharacters that have special meanings in other regular expression contexts do not have special meanings within square brackets. The only character with a special meaning inside square brackets is a ^, and then only if it is the first character after the left (open- ing) bracket.\n\nSummarizing Data\n\nimport pandas as pd\ndf = pd.DataFrame\n# Look at a bit of the data\ndf.head()\ndf.tail()\n\n# summary\ndf.describe()\ndf.quantile()\n\n# cov and corr\n# DataFrame’s corr and cov methods return a full correlation or covariance matrix as a DataFrame, respectively\n\n# to calcuate pairwise correlation between a DataFrame's columns or rows\ndset.corrwith(dset['<one col name>'])\n\n# you can write your own analsis function and apply it to the dataframe, for example:\nf = lambda x: x.max() - x.min()\ndf.apply(f, axis=1)\n\n\n\nCheck for missing values\n\ndf.dropna()\ndf.fillna(0)\n# to modify inplace\n_ = df.fillna(0, inplace=True)\n\n# fill the nan with the mean\n# 或者用naive bayesian的prediction\ndata.fillna(data.mean())\n\n\n\nExploratory Data Analysis\n\nAnalytic graphics\n\nPrinciples of Analytic Graphics\n\n\nShow comparisons\nIf you build a model that can do some predictions, please come along with the performance of random guess.\nShow causality, mechanism, explanation, systematic structure\nShow multivariate dataThe world is inherently multivariate\nIntegration of evidence\nDescribe and document the evidence with appropriate labels, scales, sources, etc.\n\nSimple Summaries of Data\n\nTwo dimensions\n\n\nscatterplots\nsmooth scatterplots\n\n> 2 dimensions\n\n\nOverlayed/multiple 2-D plots; coplots\nUse color, size, shape to add dimensions\nSpinning plots\nActual 3-D plots (not very useful)\n\nGraphics File Devices\n\n\npdf: usefule for line-type graphics, resizes well, not efficient if a plot has many objects/points\nsvg: XML-based scalable vector graphics; supports animation and interactivity, potentially useful for web-based plots\npng: bitmapped format, good for line drawings or images with solid colors, uses lossless compression, most web browers can read this format natively, does not resize well\njpeg: good for photographs or natural scenes, uses lossy compression, does not resize well\ntiff: bitmapped format, supports lossless compression\n\nSimulation in R\n\n\n\nrnorm:generate random Normal variates with a given mean and standard deviation\n\ndnorm: evaluate the Normal probability density (with a given mean/SD) at a point (or vector of points)\npnorm: evaluate the cumulative distribution function for a Normal distribution\nd for density\n\nr for random number generation\n\np for cumulative distribution\n\nq for quantile function\n\nSetting the random number seed with set.seed ensures reproducibility\n\n> set.seed(1)\n> rnorm(5)\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "4"}