{"title": "爬虫养成记 - 网络下载器urllib2初认识 - helloword ", "index": "网页爬虫,python", "content": "申明：本系列文章借鉴了慕课网的课程，http://www.imooc.com/learn/563。慕课网是一个非常赞的学习网站。\nurllib2是python2.x下的一个模块，在Python3.x中，urllib2被拆分成urllib.request和urllib.error.\n实现一个最简单的下载器\n使用urllib2.urlopen(url)函数可以给服务器发送一个请求。该函数返回一个file-like object. 该返回的对象有三个额外的函数：\n\ngeturl() 取得服务器返回的url。一般用来判断是否需要重定向。\ninfo() 获取页面的meta信息\ngetcode() 获取响应的http状态码\n\n例如我们写了一小段程序\nimport urllib2\n\nresponse = urllib2.urlopen(\"http://www.baidu.com\")\nprint response.getcode()\nprint response.info()\n用来下载百度首页的内容。\n构造一个request对象\nurllib2.urlopen()函数不仅仅能接收一个url字符串，还能接收一个request对象。我们可以在Request对象中添加数据和header。\n设置请求头\nimport urllib2\n\nrequest = urllib2.Request('https://www.zhihu.com/question/28593608/answer/141936198')\nrequest.add_header('User-Agent', 'Mozilla/5.0')\n\nresponse = urllib2.urlopen(request)\nprint response.read()\nPost请求方法和在请求中添加数据\n上面的代码是一个爬取知乎某一个回答的代码。我们可以看到，我们并没有在request中添加data。urllib2 默认没有data的，请求方式为GET。urllib2 如果添加了data，那么请求方式为POST。例如：\nimport urllib\n\nvalues = {\n    \"name\": \"charlie\",\n    \"age\": 20,\n    \"gender\": \"male\"\n}\n\ndata = urllib.urlencode(values)\n\nrequest.add_data(data)\n我们使用POST方式提交数据的时候，我们需要创建一个字典型数据，并且用urllib.urlencode()函数将器编码成字符串，并用Request.add_data()函数添加到request中。\ncookie、https、Proxy、HttpRedirect\n实际情况中，往往比上面的更加复杂，例如很多网站会设置cookie、可以会使用https加密传输，可能会设置代理，会有重定向等。如何要处理上面这些特殊的情境，那么我们则需要添加特殊的处理器。\n\nHTTPCookieProcessor\nProxyHandler\nHTTPHandler\nHTTPRedirectHandler\n\n构造好上述对象后，需要运用urllib2.build_opener()创建一个opener.然后将opener安装到urllib2中: urllib2.install_opener(opener)。例如：\nimport urllib2\nimport cookielib\n\ncookie_jar = cookielib.CookieJar()\ncookie_processor = urllib2.HTTPCookieProcessor(cookiejar=cookie_jar)\nopener = urllib2.build_opener(cookie_processor)\nurllib2.install_opener(opener)\n\nresponse = urllib2.urlopen(\"http://www.baidu.com\")\nfor item in cookie_jar:\n    print item.name, item.value\n如上述代码所示，我们先新建了一个CookieJar。CookieJar是一个内存中保存cookie的对象。然后我们构造一个cookie的处理器——HTTPCookieProcessor。然后我们在根据cookie处理器构造一个opener。\nopener的概念\nopener我们可以理解成打开网页获取response的东西。默认的opener只能接收url、data或resquest等的一个opener。如果我们想要获得更加多的功能，那么我们就需要构造一个有HttpCookieProcessor的opener。\n更多关于urllib2的opener概念，可以阅读一篇非常棒的文章：http://cuiqingcai.com/968.html\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "2"}