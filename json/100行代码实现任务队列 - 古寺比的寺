{"title": "100行代码实现任务队列 - 古寺比的寺 ", "index": "python,并发,队列", "content": "最近刚看完python多线程，为了加深印象，按照1分钟实现“延迟消息”功能的思路，实现了一个简易版的异步队列。\n\n高效延时消息，包含两个重要的数据结构：\n\n1.环形队列，例如可以创建一个包含3600个slot的环形队列（本质是个数组）\n2.任务集合，环上每一个slot是一个Set<Task>\n\n同时，启动一个timer，这个timer每隔1s，在上述环形队列中移动一格，有一个Current Index指针来标识正在检测的slot。\nTask结构中有两个很重要的属性：\n（1）Cycle-Num：当Current Index第几圈扫描到这个Slot时，执行任务（2）Task-Function：需要执行的任务指针\n\n下边是代码（代码不止100行，但是在200行内，也算100行了。）\n#! -*- coding: utf-8 -*-\n\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\ntry:\n    import simplejson as json\nexcept ImportError:\n    import json\n\nimport os\nimport errno\nimport Queue\nimport random\nimport logging\nfrom functools import wraps\nfrom threading import Timer, RLock, Thread\nfrom time import sleep, time\nfrom base64 import b64encode, b64decode\n\n# json 的数据结构\n# tasks = {\n#     index: {\n#         cycle_num: [(func, bargs)]\n#     }\n# }\n\nlogging.basicConfig(level=logging.DEBUG,\n                    format='(%(asctime)-15s) %(message)s',)\ntasks_file = 'tasks.json'\nflags = os.O_CREAT | os.O_EXCL | os.O_WRONLY\n\n# 为了防止任务太多需要生成过多的线程，我们使用Queue 来限制生成的线程数量\nWORKER_NUMS = 2\nq = Queue.Queue(WORKER_NUMS)\n\nlock = RLock()\n\n\ndef check_file():\n    try:\n        file_handle = os.open(tasks_file, flags)\n    except OSError as e:\n        if e.errno == errno.EEXIST:  # Failed as the file already exists.\n            pass\n        else:\n            raise\n    else:\n        with os.fdopen(file_handle, 'w') as file_obj:\n            file_obj.write(\"{}\")\n\n\ndef set_delay_task(func_name, *args, **kwargs):\n    # 使用锁来保证每次只要一个线程写入文件，防止数据出错\n    with lock:\n        with open(tasks_file, 'r+') as json_file:\n            count_down = kwargs.pop('count_down', 0)\n            tasks = json.load(json_file)\n            # 执行时间\n            exec_time = int(time()) + count_down\n            # 循环索引\n            index = str(exec_time % 3600)\n            # 圈数\n            cycle_num = str(exec_time / 3600 + 1)\n            dargs = pickle.dumps((args, kwargs))\n            bargs = b64encode(dargs)\n            index_data = tasks.get(index, {})\n            index_data.setdefault(cycle_num, []).append((func_name, bargs))\n            tasks[index] = index_data\n            json_file.seek(0)\n            json.dump(tasks, json_file)\n            logging.debug('Received task: %s' % func_name)\n\n\ndef get_delay_tasks():\n    with open(tasks_file, 'r+') as json_file:\n        tasks = json.load(json_file)\n        # 执行时间\n        current_time = int(time())\n        # 循环索引\n        index = str(current_time % 3600)\n        # 圈数\n        cycle_num = str(current_time / 3600 + 1)\n        current_tasks = tasks.get(index, {}).get(cycle_num, [])\n    tasks = []\n    for func, bargs in current_tasks:\n        dargs = b64decode(bargs)\n        args, kwargs = pickle.loads(dargs)\n        tasks.append((func, (args, kwargs)))\n    return tasks\n\n\ndef get_method_by_name(method_name):\n    possibles = globals().copy()\n    possibles.update(locals())\n    method = possibles.get(method_name)\n    return method\n\n\ndef create_task(task_class, func, task_name=None, **kwargs):\n\n    def execute(self):\n        args, kwargs = self.data or ((), {})\n        return func(*args, **kwargs)\n\n    attrs = {\n        'execute': execute,\n        'func_name': func.__name__,\n        '__module__': func.__module__,\n        '__doc__': func.__doc__\n    }\n    attrs.update(kwargs)\n\n    klass = type(\n        task_name or func.__name__,\n        (task_class,),\n        attrs\n    )\n\n    return klass\n\n\nclass Hu(object):\n\n    def __init__(self, func_name=None):\n        self.func_name = func_name\n        check_file()\n\n    def task(self):\n        def deco(func):\n            self.func_name = func.__name__\n            klass = create_task(Hu, func, self.func_name)\n            func.delay = klass(func_name=klass.func_name).delay\n            @wraps(func)\n            def wrapper(*args, **kwargs):\n                return func(*args, **kwargs)\n            return wrapper\n        return deco\n\n    def delay(self, *args, **kwargs):\n        _args = [self.func_name]\n        _args.extend(args)\n        Timer(0, set_delay_task, _args, kwargs).start()\n        return True\n\n\ndef boss():\n    while True:\n        current_tasks = get_delay_tasks()\n        for func, params in current_tasks:\n            # Task accepted: auth.tasks.send_msg\n            logging.debug('Task accepted: %s' % func)\n            q.put((func, params))\n        sleep(1)\n\n\ndef worker():\n    while True:\n        func, params = q.get()\n        print 'get task: %s\\n' % func\n        method = get_method_by_name(func)\n        args, kwargs = params\n        # Task auth.tasks.send_msgsucceeded in\n        start_time = time()\n        method(*args, **kwargs)\n        end_time = time()\n        logging.debug('Task %s succeeded in %s' % (str(func), end_time - start_time))\n        q.task_done()\n\n\ndef main():\n    check_file()\n    print('starting at:', time())\n    for target in (boss, worker):\n        t = Thread(target=target)\n        t.start()\n    print('all DONE at:', time())\n\nhu = Hu()\n\n# 使用方式如下：\n\n@hu.task()\ndef test(num):\n    sleep(2)\n    print 'test: %s' % num\n\n\nif __name__ == '__main__':\n    for i in range(10):\n        test.delay(i, count_down=random.randint(1, 10))\n    main()\n\n# output\n\n(2017-03-21 15:59:20,394) Received task: test\n(2017-03-21 15:59:20,396) Received task: test\n(2017-03-21 15:59:20,397) Received task: test\n(2017-03-21 15:59:20,398) Received task: test\n(2017-03-21 15:59:20,400) Received task: test\n(2017-03-21 15:59:20,401) Received task: test\n(2017-03-21 15:59:20,403) Received task: test\n(2017-03-21 15:59:20,404) Received task: test\n(2017-03-21 15:59:20,406) Received task: test\n(2017-03-21 15:59:20,408) Received task: test\nget task: test\n\n(2017-03-21 15:59:21,395) Task accepted: test\n(2017-03-21 15:59:22,397) Task accepted: test\n(2017-03-21 15:59:22,397) Task accepted: test\n(2017-03-21 15:59:22,397) Task accepted: test\ntest: 2\nget task: test\n\n(2017-03-21 15:59:23,399) Task test succeeded in 2.0037419796\n(2017-03-21 15:59:24,404) Task accepted: test\ntest: 1\nget task: test\n按照1分钟实现“延迟消息”功能的思路。队列的数据结构为\n{\n    index: {\n        cycle_num: [(func, bargs)]\n    }\n}\nindex的值为 1-3600。每小时一个循环。cycle_num 则是 由 (时间戳 / 3600 + 1) 计算得到的值，是圈数。\n每当有任务加入，我们计算出index和cycle_num 将参数和方法名写入json文件。读取任务时，计算当前 index和cycle_num， 取出需要执行的任务，使用多线程的形式执行。\n为了防止任务太多需要生成过多的线程，我们使用Queue 来限制生成的线程数量。\n加锁的主要作用是防止多线程同时操作文件读写，影响数据一致性。\n当然，也可以使用redis 存储队列，因为 redis 是单线程操作，可以防止多线程操作影响数据一致性的问题。这一部分有需要的可以自己实现。\n参考：\n\npython线程笔记\n1分钟实现“延迟消息”功能\n\n\n\n>欢迎关注\n>请我喝芬达\n\n\n\n\n\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "3"}