{"title": "Python利用正则抓取网页内容保存到本地 - python ", "index": "python,mechanize", "content": "目标是收集国内银行的域名列表，于是在人行的网站上找到了汇总信息，网址是http://www.cbrc.gov.cn/chinese/jrjg/index.html截图是\n查看一下他的html源码，需要抓取部分的是：\n<li\n                                                    style=\"margin: 0px 10px 0px 5px; width: 120px; float: left; height: 30px; display: inline;\">\n                                                    <a href=\"http://www.icbc.com.cn/\" target=\"_blank\"  style=\"color:#08619D\">\n                                                                                                            中国工商银行\n                                                                                                         </a>\n                                                </li>\n                                                                                                                                                                                                                                                       <li\n                                                    style=\"margin: 0px 10px 0px 5px; width: 120px; float: left; height: 30px; display: inline;\">\n                                                    <a href=\"http://www.abchina.com/\" target=\"_blank\"  style=\"color:#08619D\">\n                                                                                                            中国农业银行\n                                                                                                         </a>\n                                                </li>\n提炼一下，我们需要提取的是Url和银行的名称，那么可以先把源码中的t删除，然后用正则表达式匹配\n<a href=\"(.*)\" target=\"_blank\" style=\"color:#08619D\">\\r\\n(.*)\\r\\n</a>\n\n分析完毕，下面是代码实现了，第一个版本如下：\n#!/usr/bin/env python\n# -*- encoding: utf-8 -*-\nimport os,re\nimport mechanize\n\nbrowser = mechanize.Browser()\nbrowser.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\nres  = browser.open('http://www.cbrc.gov.cn/chinese/jrjg/index.html')\ndata = res.read()\ndata = data.replace('\\t','')\nregx = '<a href=\"(.*)\" target=\"_blank\" style=\"color:#08619D\">\\r\\n(.*)\\r\\n</a>'\ndomainlist =  re.findall(regx,data)\nprint len(domainlist)\nfor domain in domainlist:\n    print domain[1].decode('utf-8'), domain[0] \n\nwith open(u'金融.txt','wb') as fp:\n    str1 = ''\n    for domain in domainlist:\n            str1 += domain[1]+ '----' + domain[0] + '----'+ '\\r\\n'\n    fp.write(str1)\n\n首先声明一个浏览器对象，并修改了其http头的user-agent信息；然后打开Url，获取Html源码，并将't'删除；之后利用Python的正则匹配，将Url和银行名称提炼出来；最后将这些信息写入到文件中。注意一点，print到屏幕上时，需要将中文字符解码为utf-8才能打印，写入文件是不需要的。\n那么升级一下，我需要的不是url，而是银行对应的域名，可以用tld模块来提取import部分添加\nfrom tld import get_tld\n在使用tld模块从url提取域名的过程中，会发现莫名其妙的问题，不知道是提取正则提取Url时，url不规范导致的还是其他原因，总有一些Url没法提取域名，于是会发生报错信息，我这边从新写了一下，增加容错性\ndef my_get_tld(url):\n    try:\n        str = get_tld(url = url,fail_silently=True)\n        if str == None:\n            return ''\n        else:\n            return str.encode('utf8')\n    except:\n        return ''\n于是写入文本的代码修改成\nwith open(u'金融.txt','wb') as fp:\n    str1 = ''\n    for domain in domainlist:\n            str1 += domain[1]+ '----' + domain[0] + '----' + my_get_tld(url = domain[0]) + '\\r\\n'\n    fp.write(str1)\nOK，运行之后就可以得到需要的内容了\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "2"}