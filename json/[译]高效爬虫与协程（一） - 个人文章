{"title": "[译]高效爬虫与协程（一） - 个人文章 ", "index": "协程,异步,asyncio,python", "content": "本文是对 500 Lines or Less 一书中高效爬虫与协程一章的翻译，鉴于篇幅略长，分成几个部分来翻译了。网上已经有对这本书的翻译了，比如 star 很多的这个，然而偏偏这一章只翻译了一点开头的，并且质量一般般，遂有了此文。\n介绍\n经典计算机科学强调高效的算法以便能尽快完成计算。但是许多网络程序消耗的时间不是在计算上，它们通常维持着许多缓慢的连接，或者等待一些不频繁的事件发生。这些程序代表了另一个不同的挑战：如何高效地监听大量网络事件。解决这个问题的一个现代方法是采用异步 I/O，即“async”。\n本章介绍了一个简单的网络爬虫。爬虫是个经典的异步程序，因为它要等待许多网络响应，但几乎没有计算。它一次可以抓取的页面越多，完成的就越快。如果为每一个网络请求分配一个线程，那么随着并发的请求越来越多，它最终会在耗尽系统套接字（socket）之前，耗尽内存或者其他线程相关的资源。使用异步 I/O 可以避免对线程的依赖。\n我们通过三步来实现这个例子。我们首先展示一个异步的事件循环，并用这个事件循环和回调来实现一个简略的爬虫。它非常高效，但是如果要扩展它以适应更加复杂的问题会遇到难以管理的意大利面条式代码。因而接下来我们展示既高效又易扩展的 Python 协程。在 Python 中我们使用生成器函数来实现简单的协程。最后，我们将使用 Python 的标准库“asyncio”提供的协程，它的功能更加全面。我们通过异步队列（async queue）来协调他们。\n爬虫的任务\n一个网络爬虫会寻找并下载某个网站上所有的页面，用来存档或者索引。爬虫从一个根 URL 开始，爬取每一个页面，从中找出未访问过的页面的链接，然后把新链接加入一个队列。当它爬取到一个没有新链接的页面，并且队列为空时，爬虫便停下来。\n我们可以通过同时下载多个页面来加速这个过程。当爬虫发现新链接的时候，它会启动多个爬取页面的操作，每个都有自己的套接字。当网页响应到达时它开始解析数据，并往队列里添加新的链接。大量的并发请求可能导致一些性能降低，因而我们限制同一时间内请求的数量，把其他的链接加入队列，直到有一些运行中的请求完成。\n传统方法\n如何让爬虫并发运行呢？传统的办法是建立一个线程池。每个进程每次将负责通过一个套接字下载一个页面。比如，下载 xkcd.com 的一个页面：\ndef fetch(url):\n    sock = socket.socket()\n    sock.connect(('xkcd.com', 80))\n    request = 'GET {} HTTP/1.0\\r\\nHost: xkcd.com\\r\\n\\r\\n'.format(url)\n    sock.send(request.encode('ascii'))\n    response = b''\n    chunk = sock.recv(4096)\n    while chunk:\n        response += chunk\n        chunk = sock.recv(4096)\n    \n    # Page is now downloaded.\n    links = parse_links(response)\n    q.add(links)\n默认情况下，套接字操作是阻塞的：当一个线程调用 connect 或 recv 这类方法时，它会被阻塞直到操作完成。因此，为了一次下载多个页面，我们需要许多线程。一个复杂点的程序会在线程池中保留空闲的线程来避免频繁创建线程的开销，然后再从线程池中取出并重用这些线程去处理随后的任务；这样达到的效果和使用套接字连接池一样。\n然而，线程是昂贵的，并且操作系统对进程、用户或机器可以创建的线程数量有强制性的上限。在 Jesse 的电脑上，一个 Python 线程大约消耗 50K 内存，并且无法启动数以万计的线程。如果我们要处理上万个并发操作，我们会在耗尽套接字之前用完线程。瓶颈在于每一个线程的开销或者系统对线程数量的限制。\n在他那篇颇有影响力的文章《The C10K problem》中，Dan Kegel 概述了用多线程并发处理 I/O 问题的局限性。\n是时候让网络服务器同时处理数以万计的客户端请求了，不是吗？毕竟，Web 那么大。\nKegel 在 1999 年创造了“C10K”这个词。现在听起来一万个连接很少，但问题只是在大小上发生了变化，类型并没有变。回到那个年代，一个连接使用一个线程来处理 C10K 问题是不实际的。现在的数量已经是当初的好几个数量级了。说实话，我们的爬虫小玩具使用线程的方式也能运行的很好。但对于需要面对数十万个连接的大规模应用程序来说，使用线程的缺陷还是依旧在这儿：大部分操作系统还能创建套接字，但是不能再继续创建线程了。我们如何克服这个难题呢？\n异步\n异步 I/O 框架使用非阻塞套接字在单个的线程上执行并发操作。在我们的异步爬虫里，我们在连接到服务器之前将套接字设置为非阻塞的：\nsock = socket.socket()\nsock.setblocking(False)\ntry:\n    sock.connect(('xkcd.com', 80))\nexcept BlockingIOError:\n    pass\n恼人的是，非阻塞套接字的 connect 方法会抛出一个异常，即便它没有出现什么错误。这个异常复制了底层 C 函数的行为，它将 errno 设置为 EINPROGRESS 以告诉你它已经开始工作。\n现在我们的爬虫需要一种方法来知道什么时候连接建立了，以便发起 HTTP 请求。我们可以在一个循环中不断尝试：\nrequest = 'GET {} HTTP/1.0\\r\\nHost: xkcd.com\\r\\n\\r\\n'.format(url)\nencoded = request.encode('ascii')\n\nwhile True:\n    try:\n        sock.send(encoded)\n        break  # Done.\n    except OSError as e:\n        pass\n\nprint('sent')\n这种方法不仅费电，而且无法有效等待多个套接字上的事件。以前的时候，BSD Unix 的解决办法是提供一个 C 函数 select，它可以在非阻塞的套接字（或者一个小套接字数组）上等待事件发生。在现代，互联网应用对巨量连接的需求催生了 select 的替代品 poll，然后是 BSD 上的 kqueue 和 Linux 上的 epoll。这些 API 类似于 select，但是在面对巨量连接时具有良好的性能。\nPython 3.4 的 DefaultSelector 使用你的系统上最佳的 select 类函数。要注册有关网络 I/O 的通知，我们创建一个非阻塞套接字并使用默认选择器（selector）注册：\nfrom selectors import DefaultSelector, EVENT_WRITE\n\nselector = DefaultSelector()\n\nsock = socket.socket()\nsock.setblocking(False)\ntry:\n    sock.connect(('xkcd.com', 80))\nexcept BlockingIOError:\n    pass\n\ndef connected():\n    selector.unregister(sock.fileno())\n    print('connected!')\n\nselector.register(sock.fileno(), EVENT_WRITE, connected)\n我们忽略了伪错误然后调用 selector.register，传入套接字的文件描述符和一个常量，来代表我们正在等待的事件。我们传入的这个常量是 EVENT_WRITE 以便在建立连接时得到通知——也就是说，我们想知道何时套接字是可写的。我们还传入了个 Python 函数 connected，它会在那个事件发生时运行。这样一种函数通常被叫做回调函数（callback）。\n我们在一个循环中处理 I/O 通知：\ndef loop():\n    while True:\n        events = selector.select()\n        for event_key, event_mask in events:\n            callback = event_key.data\n            callback()\nconnected 回调函数贮存在 event_key.data 中，当非阻塞套接字建立连接后我们从 event_key.data 中获取并且执行它。\n与我们上面快速旋转的循环不同，这里对 select 的调用会暂停等待下一个 I/O 事件。然后这个循环运行正在等待这些事件的回调函数。尚未完成的操作仍然保持等待，直到事件循环触发某个未来的事件。\n我们都已经展示了什么？我们展示了如何开始一个操作，并在操作完成时执行相应的回调函数。异步框架建立在我们已经介绍过的两个特性——非阻塞套接字和事件循环——上来在单个线程上执行并发操作。\n我们在这里实现了“并发”，但不是传统上的“并行”。也就是说，我们建立了个可以进行重叠的 I/O 的小型系统。它能在其他操作正在执行的时候开始新的操作。它实际上并不使用多个核并行执行计算。但是，这个系统是为 I/O 密集型而不是 CPU 密集任务设计的。\n因此，我们的事件循环在并发 I/O 中是高效的，因为它不会将线程资源用于每个连接。但是在继续之前，我们来纠正一个常见的误解，即异步比多线程快。通常情况下，异步更慢——事实上，在 Python 中像我们这样的事件循环在处理少量非常活跃的连接时比多线程适当慢一点。在没有全局解释器锁的环境中运行时，线程在这样的负载下甚至会执行得更好。异步 I/O 适合需要处理大量缓慢的连接和不频繁的事件的应用程序。\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "9"}