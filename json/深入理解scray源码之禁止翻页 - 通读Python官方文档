{"title": "深入理解scray源码之禁止翻页 - 通读Python官方文档 ", "index": "scrapy,python", "content": "在用scrapy爬取新闻网站时，我们可能只希望爬取最新的新闻。这时我们需要提供一个禁止翻页的逻辑。\n而scrapy.linkextractors.LinkExctractor并没有提供这样的接口。\n所以我们需要自己构建一个新的link extractor。通过阅读源码，我们发现LinkExtractor 的公开方法extract_links返回的是一个scrapy.link中的Link列表，而Link对象有四个槽：url,text, fragment, nofollow。我们在这里我们只要对url属性做一下过滤就可以了。\nfrom scrapy.linkextractors import LinkExtractor\n\n\nclass LinKExtractorPlus(LinkExtractor):\n    def __init__(self, *args, **kwargs):\n        LinkExtractor.__init__(self, *args, **kwargs)\n\n    def extract_links(self, response):\n        links = super(LinKExtractorPlus, self).extract_links(response)\n        # 去掉翻页（只含有数字的链接）\n        links = filter(lambda x: not (x.text.isdigit()), links)\n        # 去掉翻页，长度小于5，且含有\"页\"字的链接\n        links = filter(lambda x: not (len(x.text) < 5 and u'页' in x.text), links)\n\n        return links\n\n你可以在scrapy shell中调用这个类，来检测一下它是否达到了过滤翻页链接的目的。你也可以通过增加filter条件，扩展这个类。\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}