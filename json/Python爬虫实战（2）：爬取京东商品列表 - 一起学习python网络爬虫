{"title": "Python爬虫实战（2）：爬取京东商品列表 - 一起学习python网络爬虫 ", "index": "编程,网页爬虫,python", "content": "\n1，引言\n在上一篇《python爬虫实战：爬取Drupal论坛帖子列表》，爬取了一个用Drupal做的论坛，是静态页面，抓取比较容易，即使直接解析html源文件都可以抓取到需要的内容。相反，JavaScript实现的动态网页内容，无法从html源代码抓取需要的内容，必须先执行JavaScript。\n我们在《Python爬虫使用Selenium+PhantomJS抓取Ajax和动态HTML内容》一文已经成功检验了动态网页内容的抓取方法，本文将实验程序进行改写，使用开源Python爬虫规定的标准python内容提取器，把代码变得非常简洁。\n2，技术要点\n我们在多个文章说过本开源爬虫的目的：节省程序员的时间。关键是省去编写提取规则的时间，尤其调试规则很花时间，节省时间问题在《1分钟快速生成用于网页内容提取的xslt》一文已经有了解决方案，本文我们用京东网站作为测试目标，而电商网站都有很多动态内容，比如，产品价格和评论数等等，往往采用后加载的方式，在html源文档加载完成以后再执行javascript代码把动态内容填写上，所以，本案例主要验证动态内容的抓取。\n另外，本文案例没有使用GooSeeker爬虫API，而是把MS谋数台生成的xslt脚本程序保存在本地文件中，在程序运行的时候把文件读出来注入到gsExtractor提取器。后续会有专门的案例演示 API的使用方法。\n总之，本示例两个技术要点总结如下：从本地文件读取xlst程序把xlst注入到提取器gsExtractor中，利用xslt从网页上一次提取性多个字段内容。\n3，python源代码\n# -*- coding:utf-8 -*- \n# 爬取京东商品列表， 以手机商品列表为例\n# 示例网址：http://list.jd.com/list.html?cat=9987,653,655&page=1&JL=6_0_0&ms=5\n# crawler_jd_list.py\n# 版本: V1.0\n\nfrom urllib import request\nfrom lxml import etree\nfrom selenium import webdriver\nfrom gooseeker import gsExtractor\nimport time\n\nclass Spider:\n    def __init__(self):\n        self.scrollpages = 0\n        self.waittime = 3\n        self.phantomjsPath = 'C:\\\\phantomjs-2.1.1-windows\\\\bin\\\\phantomjs.exe'\n\n    def getContent(self, url):\n        browser = webdriver.PhantomJS( executable_path = self.phantomjsPath )\n        browser.get(url)\n        time.sleep(self.waittime)\n        html = browser.execute_script(\"return document.documentElement.outerHTML\")\n        doc = etree.HTML(html)\n        jdlistExtra = gsExtractor()\n        jdlistExtra.setXsltFromFile(\"jd_list.xml\")\n        output = jdlistExtra.extract(doc)\n        return output\n\n    def saveContent(self, filepath, content):\n        file_obj = open(filepath, 'w', encoding='UTF-8')\n        file_obj.write(content)\n        file_obj.close()\n\nurl = 'http://list.jd.com/list.html?cat=9987,653,655&page=1&JL=6_0_0&ms=5'\njdspider = Spider()\nresult = jdspider.getContent(url)\njdspider.saveContent('京东手机列表_1.xml', str(result))\n\n源代码下载位置请看文章末尾的GitHub源。\n4，抓取结果\n运行上面的代码，就会爬取京东手机品类页面的所有手机型号、价格等信息，并保存到本地文件“京东手机列表_1.xml”中。我们用浏览器打开这个结果文件，会看到如下的内容\n5，相关文档\n1， Python即时网络爬虫项目: 内容提取器的定义\n6，集搜客GooSeeker开源代码下载源\n1， GooSeeker开源Python网络爬虫GitHub源\n7，文档修改历史\n1，2016-06-08：V1.0\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "17"}