{"title": "【爬虫系列之三】URLError异常处理以及Cookie的使用 - 喝醉的清茶 ", "index": "python", "content": "一、urlError的处理\n出现urlError产生的原因很多，比如:网络没法连接，连接不到服务器，或者服务器不存在。在代码中，我们需要用try-except的语句来捕获相应的异常\nimport urllib2\n \nreq = urllib2.Request('http://blog.csdn.net/cqcre')\ntry:\n    urllib2.urlopen(req)\nexcept urllib2.HTTPError, e:#使用hasattr属性判断code是否存在\n    print e.code\nexcept urllib2.URLError, e:\n    print e.reason\nelse:\n    print \"OK\"\n上述代码，可以看到httperror,这里HTTPError是URLError的子类，在你利用urlopen方法发出一个请求时，服务器上都会对应一个应答对象response，其中它包含一个数字”状态码”。举个例子，假如response是一个”重定向”，需定位到别的地址获取文档，urllib2将对此进行处理，此处需要了解HTTP状态码相关知识。\n二、Cookie的使用\ncookie，一般是某些网站为了辨别用户身份，进行session跟踪，从而存储在客户端的数据。比如某些网站需要登录，才能访问某些页面。这里我们可以使用urllib2库保存我们登录的cookie，然后再进行抓取内容。\n2.1、Opener\n当你获取一个URL你使用一个opener(一个urllib2.OpenerDirector的实例)。在前面，我们都是使用的默认的opener，也就是urlopen,它是一个特殊的opener，可以理解成opener的一个特殊实例，传入的参数仅仅是url，data，timeout。\n如果我们需要用到Cookie，只用这个opener是不能达到目的的，所以我们需要创建更一般的opener来实现对Cookie的设置。\n2.2 Cookielib\ncookielib模块的主要作用是提供可存储cookie的对象，以便于与urllib2模块配合使用来访问Internet资源。 Cookielib模块非常强大，我们可以利用本模块的CookieJar类的对象来捕获cookie并在后续连接请求时重新发送，比如可以实现模拟登录 功能。该模块主要的对象有CookieJar、FileCookieJar、MozillaCookieJar、LWPCookieJar。\n它们的关系：CookieJar —-派生—->FileCookieJar —-派生—–>MozillaCookieJar和LWPCookieJar\n2.2.1 获取Cookie保存到变量\nimport urllib2\nimport cookielib\n#声明一个CookieJar对象实例来保存cookie\ncookie = cookielib.CookieJar()\n#利用urllib2库的HTTPCookieProcessor对象来创建cookie处理器\nhandler=urllib2.HTTPCookieProcessor(cookie)\n#通过handler来构建opener\nopener = urllib2.build_opener(handler)\n#此处的open方法同urllib2的urlopen方法，也可以传入request\nresponse = opener.open('http://www.baidu.com')\nfor item in cookie:\n    print 'Name = '+item.name\n    print 'Value = '+item.value\n2.2.2 保存Cookie到文件\nimport cookielib\nimport urllib2\n\n#设置保存cookie的文件，同级目录下的cookie.txt\nfilename = 'cookie.txt'\n#声明一个MozillaCookieJar对象实例来保存cookie，之后写入文件\ncookie = cookielib.MozillaCookieJar(filename)\n#利用urllib2库的HTTPCookieProcessor对象来创建cookie处理器\nhandler = urllib2.HTTPCookieProcessor(cookie)\n#通过handler来构建opener\nopener = urllib2.build_opener(handler)\n#创建一个请求，原理同urllib2的urlopen\nresponse = opener.open(\"http://www.baidu.com\")\n#保存cookie到文件\ncookie.save(ignore_discard=True, ignore_expires=True)\nignore_discard的意思是即使cookies将被丢弃也将它保存下来，ignore_expires的意思是如果在该文件中 cookies已经存在，则覆盖原文件写入\n2.2.3 从文件中读取cookie\nimport cookielib\nimport urllib2\n\n#创建MozillaCookieJar实例对象\ncookie = cookielib.MozillaCookieJar()\n#从文件中读取cookie内容到变量\ncookie.load('cookie.txt', ignore_discard=True, ignore_expires=True)\n#创建请求的request\nreq = urllib2.Request(\"http://www.baidu.com\")\n#利用urllib2的build_opener方法创建一个opener\nopener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookie))\nresponse = opener.open(req)\nprint response.read()\n这一篇又折腾折腾，结束了，可能看起来比较无聊，都是为了接下来的各种实战来做准备的，从下一篇开始，正式的进行网站的爬虫了。\n推荐阅读：\n【爬虫系列之一】爬虫开发环境的搭建【爬虫系列之二】python基础知识的了解\n更多精彩内容，欢迎大家关注我的微信公众号：喝醉的清茶\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}