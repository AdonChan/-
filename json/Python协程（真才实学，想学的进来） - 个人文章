{"title": "Python协程（真才实学，想学的进来） - 个人文章 ", "index": "python", "content": "\n真正有知识的人的成长过程，就像麦穗的成长过程：麦穗空的时候，麦子长得很快，麦穗骄傲地高高昂起，但是，麦穗成熟饱满时，它们开始谦虚，垂下麦芒。\n——蒙田《蒙田随笔全集》\n\n上篇论述了关于python多线程是否是鸡肋的问题，得到了一些网友的认可，当然也有一些不同意见，表示协程比多线程不知强多少，在协程面前多线程算是鸡肋。好吧，对此我也表示赞同，然而上篇我论述的观点不在于多线程与协程的比较，而是在于IO密集型程序中，多线程尚有用武之地。\n　　对于协程，我表示其效率确非多线程能比，但本人对此了解并不深入，因此最近几日参考了一些资料，学习整理了一番，在此分享出来仅供大家参考，如有谬误请指正，多谢。\n申明：本文介绍的协程是入门级别，大神请绕道而行，谨防入坑。\n文章思路：本文将先介绍协程的概念，然后分别介绍Python2.x与3.x下协程的用法，最终将协程与多线程做比较并介绍异步爬虫模块。\n\n[](https://thief.one/2017/02/20/... \"协程\")协程\n概念\n　　协程，又称微线程，纤程，英文名Coroutine。协程的作用，是在执行函数A时，可以随时中断，去执行函数B，然后中断继续执行函数A（可以自由切换）。但这一过程并不是函数调用（没有调用语句），这一整个过程看似像多线程，然而协程只有一个线程执行。\n[](https://thief.one/2017/02/20/... \"优势\")优势\n\n执行效率极高，因为子程序切换（函数）不是线程切换，由程序自身控制，没有切换线程的开销。所以与多线程相比，线程的数量越多，协程性能的优势越明显。\n不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在控制共享资源时也不需要加锁，因此执行效率高很多。\n\n　　说明：协程可以处理IO密集型程序的效率问题，但是处理CPU密集型不是它的长处，如要充分发挥CPU利用率可以结合多进程+协程。\n　　以上只是协程的一些概念，可能听起来比较抽象，那么我结合代码讲一讲吧。这里主要介绍协程在Python的应用，Python2对协程的支持比较有限，生成器的yield实现了一部分但不完全，gevent模块倒是有比较好的实现；Python3.4以后引入了asyncio模块，可以很好的使用协程。\nPython2.x协程\npython2.x协程应用：\n\nyield\ngevent\n\npython2.x中支持协程的模块不多，gevent算是比较常用的，这里就简单介绍一下gevent的用法。\n[](https://thief.one/2017/02/20/... \"Gevent\")Gevent\n　　gevent是第三方库，通过greenlet实现协程，其基本思想：　　当一个greenlet遇到IO操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO。\n[](https://thief.one/2017/02/20/... \"Install\")Install\npip install gevent最新版貌似支持windows了，之前测试好像windows上运行不了……\n[](https://thief.one/2017/02/20/... \"Usage\")Usage\n首先来看一个简单的爬虫例子：\n#! -*- coding:utf-8 -*-\nimport gevent\nfrom gevent import monkey;monkey.patch_all()\nimport urllib2\ndef get_body(i):\n    print \"start\",i\n    urllib2.urlopen(\"http://cn.bing.com\")\n    print \"end\",i\ntasks=[gevent.spawn(get_body,i) for i in range(3)]\ngevent.joinall(tasks)\n运行结果：\nstart 0\nstart 1\nstart 2\nend 2\nend 0\nend 1\n说明：从结果上来看，执行get_body的顺序应该先是输出”start”，然后执行到urllib2时碰到IO堵塞，则会自动切换运行下一个程序（继续执行get_body输出start），直到urllib2返回结果，再执行end。也就是说，程序没有等待urllib2请求网站返回结果，而是直接先跳过了，等待执行完毕再回来获取返回值。值得一提的是，在此过程中，只有一个线程在执行，因此这与多线程的概念是不一样的。换成多线程的代码看看:\nimport threading\nimport urllib2\ndef get_body(i):\n    print \"start\",i\n    urllib2.urlopen(\"http://cn.bing.com\")\n    print \"end\",i\nfor i in range(3):\n    t=threading.Thread(target=get_body,args=(i,))\n    t.start()\n运行结果：\nstart 0\nstart 1\nstart 2\nend 1\nend 2\nend 0\n说明：从结果来看，多线程与协程的效果一样，都是达到了IO阻塞时切换的功能。不同的是，多线程切换的是线程（线程间切换），协程切换的是上下文（可以理解为执行的函数）。而切换线程的开销明显是要大于切换上下文的开销，因此当线程越多，协程的效率就越比多线程的高。（猜想多进程的切换开销应该是最大的）\n[](https://thief.one/2017/02/20/... \"Gevent使用说明\")Gevent使用说明\n\nmonkey可以使一些阻塞的模块变得不阻塞，机制：遇到IO操作则自动切换，手动切换可以用gevent.sleep(0)（将爬虫代码换成这个，效果一样可以达到切换上下文）\ngevent.spawn 启动协程，参数为函数名称，参数名称\ngevent.joinall 停止协程\n\n[](https://thief.one/2017/02/20/... \"Python3.x协程\")Python3.x协程\npython3.5协程使用可以移步：Python3.5协程学习研究\n为了测试Python3.x下的协程应用，我在virtualenv下安装了python3.6的环境。python3.x协程应用：\n\nasynico + yield from（python3.4）\nasynico + await（python3.5）\ngevent\n\nPython3.4以后引入了asyncio模块，可以很好的支持协程。\n[](https://thief.one/2017/02/20/... \"asynico\")asynico\n　　asyncio是Python 3.4版本引入的标准库，直接内置了对异步IO的支持。asyncio的异步操作，需要在coroutine中通过yield from完成。\n[](https://thief.one/2017/02/20/... \"Usage\")Usage\n例子：（需在python3.4以后版本使用）\nimport asyncio\n@asyncio.coroutine\ndef test(i):\n    print(\"test_1\",i)\n    r=yield from asyncio.sleep(1)\n    print(\"test_2\",i)\nloop=asyncio.get_event_loop()\ntasks=[test(i) for i in range(5)]\nloop.run_until_complete(asyncio.wait(tasks))\nloop.close()\n运行结果：\ntest_1 3\ntest_1 4\ntest_1 0\ntest_1 1\ntest_1 2\ntest_2 3\ntest_2 0\ntest_2 2\ntest_2 4\ntest_2 1\n说明：从运行结果可以看到，跟gevent达到的效果一样，也是在遇到IO操作时进行切换（所以先输出test_1，等test_1输出完再输出test_2）。但此处我有一点不明，test_1的输出为什么不是按照顺序执行的呢？可以对比gevent的输出结果（希望大神能解答一下）。\nasyncio说明\n　　@asyncio.coroutine把一个generator标记为coroutine类型，然后，我们就把这个coroutine扔到EventLoop中执行。　　test()会首先打印出test_1，然后，yield from语法可以让我们方便地调用另一个generator。由于asyncio.sleep()也是一个coroutine，所以线程不会等待asyncio.sleep()，而是直接中断并执行下一个消息循环。当asyncio.sleep()返回时，线程就可以从yield from拿到返回值（此处是None），然后接着执行下一行语句。　　把asyncio.sleep(1)看成是一个耗时1秒的IO操作，在此期间，主线程并未等待，而是去执行EventLoop中其他可以执行的coroutine了，因此可以实现并发执行。\n[](https://thief.one/2017/02/20/... \"asynico/await\")asynico/await\n　　为了简化并更好地标识异步IO，从Python 3.5开始引入了新的语法async和await，可以让coroutine的代码更简洁易读。　　请注意，async和await是针对coroutine的新语法，要使用新的语法，只需要做两步简单的替换：\n\n把@asyncio.coroutine替换为async；\n把yield from替换为await。\n\n[](https://thief.one/2017/02/20/... \"Usage\")Usage\n例子（python3.5以后版本使用）：\nimport asyncio\nasync def test(i):\n    print(\"test_1\",i)\n    await asyncio.sleep(1)\n    print(\"test_2\",i)\nloop=asyncio.get_event_loop()\ntasks=[test(i) for i in range(5)]\nloop.run_until_complete(asyncio.wait(tasks))\nloop.close()\n\n运行结果与之前一致。说明：与前一节相比，这里只是把yield from换成了await，@asyncio.coroutine换成了async，其余不变。\n[](https://thief.one/2017/02/20/... \"gevent\")gevent\n同python2.x用法一样。\n[](https://thief.one/2017/02/20/... \"协程VS多线程\")协程VS多线程\n　　如果通过以上介绍，你已经明白多线程与协程的不同之处，那么我想测试也就没有必要了。因为当线程越来越多时，多线程主要的开销花费在线程切换上，而协程是在一个线程内切换的，因此开销小很多，这也许就是两者性能的根本差异之处吧。（个人观点）\n[](https://thief.one/2017/02/20/... \"异步爬虫\")异步爬虫\n　　也许关心协程的朋友，大部分是用其写爬虫（因为协程能很好的解决IO阻塞问题），然而我发现常用的urllib、requests无法与asyncio结合使用，可能是因为爬虫模块本身是同步的（也可能是我没找到用法）。那么对于异步爬虫的需求，又该怎么使用协程呢？或者说怎么编写异步爬虫？给出几个我所了解的方案：\n\ngrequests （requests模块的异步化）\n爬虫模块+gevent（比较推荐这个）\naiohttp （这个貌似资料不多，目前我也不太会用）\nasyncio内置爬虫功能 （这个也比较难用）\n\n[](https://thief.one/2017/02/20/... \"协程池\")协程池\n作用：控制协程数量\nfrom bs4 import BeautifulSoup\nimport requests\nimport gevent\nfrom gevent import monkey, pool\nmonkey.patch_all()\njobs = []\nlinks = []\np = pool.Pool(10)\nurls = [\n    'http://www.google.com',\n    # ... another 100 urls\n]\ndef get_links(url):\n    r = requests.get(url)\n    if r.status_code == 200:\n        soup = BeautifulSoup(r.text)\n        links + soup.find_all('a')\nfor url in urls:\n    jobs.append(p.spawn(get_links, url))\ngevent.joinall(jobs)\n\n                ", "mainLikeNum": ["4 "], "mainBookmarkNum": "6"}