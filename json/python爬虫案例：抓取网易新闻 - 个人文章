{"title": "python爬虫案例：抓取网易新闻 - 个人文章 ", "index": "网页爬虫,python", "content": "此文属于入门级级别的爬虫，老司机们就不用看了。\n本次主要是爬取网易新闻，包括新闻标题、作者、来源、发布时间、新闻正文。\n首先我们打开163的网站，我们随意选择一个分类，这里我选的分类是国内新闻。然后鼠标右键点击查看源代码，发现源代码中并没有页面正中的新闻列表。这说明此网页采用的是异步的方式。也就是通过api接口获取的数据。\n那么确认了之后可以使用F12打开谷歌浏览器的控制台，点击Network，我们一直往下拉，发现右侧出现了：\"... special/00804KVA/cm_guonei_03.js? .... \"之类的地址，点开Response发现正是我们要找的api接口。\n可以看到这些接口的地址都有一定的规律：“cm_guonei_03.js”、 “cm_guonei_04.js”，那么就很明显了：\n\nhttp://temp.163.com/special/0...*).js\n上面的连接也就是我们本次抓取所要请求的地址。接下来只需要用到的python的两个库：\n\nrequests\njson\nBeautifulSoup\n\nrequests库就是用来进行网络请求的，说白了就是模拟浏览器来获取资源。由于我们采集的是api接口，它的格式为json，所以要用到json库来解析。BeautifulSoup是用来解析html文档的，可以很方便的帮我们获取指定div的内容。\n下面开始编写我们爬虫：\n第一步先导入以上三个包：\nimport json\nimport requests\nfrom bs4 import BeautifulSoup\n接着我们定义一个获取指定页码内数据的方法：\ndef get_page(page):\n    url_temp = 'http://temp.163.com/special/00804KVA/cm_guonei_0{}.js'\n    return_list = []\n    for i in range(page):\n        url = url_temp.format(i)\n        response = requests.get(url)\n        if response.status_code != 200:\n            continue\n        content = response.text  # 获取响应正文\n        _content = formatContent(content)  # 格式化json字符串\n        result = json.loads(_content)\n        return_list.append(result)\n    return return_list\n这样子就得到每个页码对应的内容列表：\n之后通过分析数据可知下图圈出来的则是需要抓取的标题、发布时间以及新闻内容页面。\n既然现在已经获取到了内容页的url，那么接下来开始抓取新闻正文。\n在抓取正文之前要先分析一下正文的html页面，找到正文、作者、来源在html文档中的位置。\n我们看到文章来源在文档中的位置为：id = \"ne_article_source\" 的 a 标签。作者位置为：class = \"ep-editor\" 的 span 标签。正文位置为：class = \"post_text\" 的 div 标签。\n下面试采集这三个内容的代码：\ndef get_content(url):\n    source = ''\n    author = ''\n    body = ''\n    resp = requests.get(url)\n    if resp.status_code == 200:\n        body = resp.text\n        bs4 = BeautifulSoup(body)\n        source = bs4.find('a', id='ne_article_source').get_text()\n        author = bs4.find('span', class_='ep-editor').get_text()\n        body = bs4.find('div', class_='post_text').get_text()\n    return source, author, body\n\n到此为止我们所要抓取的所有数据都已经采集了。\n那么接下来当然是把它们保存下来，为了方便我直接采取文本的形式来保存。下面是最终的结果：\n格式为json字符串，“标题” ： [ ‘日期’， ‘url’， ‘来源’， ‘作者’， ‘正文’ ]。\n要注意的是目前实现的方式是完全同步的，线性的方式，存在的问题就是采集会非常慢。主要延迟是在网络IO上，下次可以升级为异步IO，异步采集，有兴趣的可以关注下次的文章。\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}