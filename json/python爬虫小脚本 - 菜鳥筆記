{"title": "python爬虫小脚本 - 菜鳥筆記 ", "index": "python", "content": "天朝上网需要经常改hosts文件的，你们都懂的。要在网上找啊，找到了还要复制粘贴，那叫一个麻烦啊。我是出了名的懒人嘛，写个脚本干这事吧……\n#!/usr/bin/env python\nimport urllib\nimport os\nimport platform\nimport shutil\n\n#获取网页内容，网址是假的，我只是想说一下方法\nr = urllib.urlopen('http://www.baidu.com/hosts.html')\n\nfor line in r:\n    if line.find('NEW HOSTS') >= 0:\n        url = line[line.find('http://'):][:line[line.find('http://'):].find('\"')]\n\n#设置hosts文件路径\nif platform.system() == 'Windows':\n    sysdir = os.getenv('SystemDrive')\n    hostspath = sysdir + '/windows/system32/drivers/etc/hosts'\nif platform.system() == 'Linux':\n    hostspath = '/etc/hosts'\n\n#备份hosts文件\nif os.path.isfile(hostspath+'_bak') == False:\n    shutil.copyfile(hostspath,hostspath+'_bak')\nshutil.copyfile(hostspath+'_bak',hostspath)\n\n#读取文件，准备添加\nhost = open(hostspath,'r')\ncontent = host.read()\nhost.close()\nr = urllib.urlopen(url)\n\n#开始添加\nfor line in r:\n    line=line.strip('\\n')\n    content = content + line\n    \n#写入并关闭文件\nhost = open(hostspath,'w')\nhost.write(content)\nhost.close()\n\n                ", "mainLikeNum": ["2 "], "mainBookmarkNum": "7"}