{"title": "Nova如何统计节点硬件资源 - Code and Cole ", "index": "python,openstack", "content": "引言\n当我们在使用那些建设在OpenStack之上的云平台服务的时候，往往在概览页面都有一个明显的位置用来展示当前集群的一些资源使用情况，如，CPU，内存，硬盘等资源的总量、使用量、剩余量。而且，每当我们拓展集群规模之后，概览页面上的资源总量也会自动增加，我们都熟知，OpenStack中的Nova服务负责管理这些计算资源，那么你有没有想过，它们是如何被Nova服务获取的吗？\nNova如何统计资源\n我们知道，统计资源的操作属于Nova服务内部的机制，考虑到资源统计结果对后续操作(如创建虚拟机，创建硬盘)的重要性，我们推断该机制的运行顺序一定先于其他服务。\n通过上述简单的分析，再加上一些必要的Debug操作，我们得出：该机制的触发点位于nova.service.WSGIService.start方法中：\n    def start(self):\n        \"\"\"Start serving this service using loaded configuration.\n\n        Also, retrieve updated port number in case '0' was passed in, which\n        indicates a random port should be used.\n\n        :returns: None\n\n        \"\"\"\n        if self.manager:\n            self.manager.init_host()\n            self.manager.pre_start_hook()\n            if self.backdoor_port is not None:\n                self.manager.backdoor_port = self.backdoor_port\n        self.server.start()\n        if self.manager:\n            self.manager.post_start_hook()\n\n其中，self.manager.pre_start_hook()的作用就是去获取资源信息,它的直接调用为nova.compute.manager.pre_start_hook如下：\n    def pre_start_hook(self):\n        \"\"\"After the service is initialized, but before we fully bring\n        the service up by listening on RPC queues, make sure to update\n        our available resources (and indirectly our available nodes).\n        \"\"\"\n        self.update_available_resource(nova.context.get_admin_context())\n...\n    @periodic_task.periodic_task\n    def update_available_resource(self, context):\n        \"\"\"See driver.get_available_resource()\n\n        Periodic process that keeps that the compute host's understanding of\n        resource availability and usage in sync with the underlying hypervisor.\n\n        :param context: security context\n        \"\"\"\n        new_resource_tracker_dict = {}\n        nodenames = set(self.driver.get_available_nodes())\n        for nodename in nodenames:\n            rt = self._get_resource_tracker(nodename)\n            rt.update_available_resource(context)\n            new_resource_tracker_dict[nodename] = rt\n\n        # Delete orphan compute node not reported by driver but still in db\n        compute_nodes_in_db = self._get_compute_nodes_in_db(context,\n                                                            use_slave=True)\n\n        for cn in compute_nodes_in_db:\n            if cn.hypervisor_hostname not in nodenames:\n                LOG.audit(_(\"Deleting orphan compute node %s\") % cn.id)\n                cn.destroy()\n\n        self._resource_tracker_dict = new_resource_tracker_dict\n上述代码中的rt.update_available_resource()的直接调用实为nova.compute.resource_tracker.update_available_resource()如下:\n    def update_available_resource(self, context):\n        \"\"\"Override in-memory calculations of compute node resource usage based\n        on data audited from the hypervisor layer.\n\n        Add in resource claims in progress to account for operations that have\n        declared a need for resources, but not necessarily retrieved them from\n        the hypervisor layer yet.\n        \"\"\"\n        LOG.audit(_(\"Auditing locally available compute resources\"))\n        resources = self.driver.get_available_resource(self.nodename)\n\n        if not resources:\n            # The virt driver does not support this function\n            LOG.audit(_(\"Virt driver does not support \"\n                 \"'get_available_resource'  Compute tracking is disabled.\"))\n            self.compute_node = None\n            return\n        resources['host_ip'] = CONF.my_ip\n\n        # TODO(berrange): remove this once all virt drivers are updated\n        # to report topology\n        if \"numa_topology\" not in resources:\n            resources[\"numa_topology\"] = None\n\n        self._verify_resources(resources)\n        \n        self._report_hypervisor_resource_view(resources)\n\n        return self._update_available_resource(context, resources)\n\n上述代码中的self._update_available_resource的作用是根据计算节点上的资源实际使用结果来同步数据库记录，这里我们不做展开；self.driver.get_available_resource()的作用就是获取节点硬件资源信息，它的实际调用为：\nclass LibvirtDriver(driver.ComputeDriver):\n    def get_available_resource(self, nodename):\n        \"\"\"Retrieve resource information.\n\n        This method is called when nova-compute launches, and\n        as part of a periodic task that records the results in the DB.\n\n        :param nodename: will be put in PCI device\n        :returns: dictionary containing resource info\n        \"\"\"\n\n        # Temporary: convert supported_instances into a string, while keeping\n        # the RPC version as JSON. Can be changed when RPC broadcast is removed\n        stats = self.get_host_stats(refresh=True)\n        stats['supported_instances'] = jsonutils.dumps(\n                stats['supported_instances'])\n        return stats\n        \n    def get_host_stats(self, refresh=False):\n        \"\"\"Return the current state of the host.\n\n        If 'refresh' is True, run update the stats first.\n        \"\"\"\n        return self.host_state.get_host_stats(refresh=refresh)\n        \n        def _get_vcpu_total(self):\n        \"\"\"Get available vcpu number of physical computer.\n\n        :returns: the number of cpu core instances can be used.\n\n        \"\"\"\n        if self._vcpu_total != 0:\n            return self._vcpu_total\n\n        try:\n            total_pcpus = self._conn.getInfo()[2] + 1\n        except libvirt.libvirtError:\n            LOG.warn(_LW(\"Cannot get the number of cpu, because this \"\n                         \"function is not implemented for this platform. \"))\n            return 0\n\n        if CONF.vcpu_pin_set is None:\n            self._vcpu_total = total_pcpus\n            return self._vcpu_total\n\n        available_ids = hardware.get_vcpu_pin_set()\n        if sorted(available_ids)[-1] >= total_pcpus:\n            raise exception.Invalid(_(\"Invalid vcpu_pin_set config, \"\n                                      \"out of hypervisor cpu range.\"))\n        self._vcpu_total = len(available_ids)\n        return self._vcpu_total\n\n.....\nclass HostState(object):\n    \"\"\"Manages information about the compute node through libvirt.\"\"\"\n    def __init__(self, driver):\n        super(HostState, self).__init__()\n        self._stats = {}\n        self.driver = driver\n        self.update_status()\n\n    def get_host_stats(self, refresh=False):\n        \"\"\"Return the current state of the host.\n\n        If 'refresh' is True, run update the stats first.\n        \"\"\"\n        if refresh or not self._stats:\n            self.update_status()\n        return self._stats\n        \n    def update_status(self):\n        \"\"\"Retrieve status info from libvirt.\"\"\"\n        ...\n        data[\"vcpus\"] = self.driver._get_vcpu_total()\n        data[\"memory_mb\"] = self.driver._get_memory_mb_total()\n        data[\"local_gb\"] = disk_info_dict['total']\n        data[\"vcpus_used\"] = self.driver._get_vcpu_used()\n        data[\"memory_mb_used\"] = self.driver._get_memory_mb_used()\n        data[\"local_gb_used\"] = disk_info_dict['used']\n        data[\"hypervisor_type\"] = self.driver._get_hypervisor_type()\n        data[\"hypervisor_version\"] = self.driver._get_hypervisor_version()\n        data[\"hypervisor_hostname\"] = self.driver._get_hypervisor_hostname()\n        data[\"cpu_info\"] = self.driver._get_cpu_info()\n        data['disk_available_least'] = _get_disk_available_least()\n        ...\n注意get_available_resource方法的注释信息，完全符合我们开始的推断。我们下面单以vcpus为例继续调查资源统计流程，self.driver._get_vcpu_total的实际调用为LibvirtDriver._get_vcpu_total(上述代码中已给出)，如果配置项vcpu_pin_set没有生效，那么得到的_vcpu_total的值为self._conn.getInfo()[2]（self._conn可以理解为libvirt的适配器，它代表与kvm,qemu等底层虚拟化工具的抽象连接，getInfo()就是对libvirtmod.virNodeGetInfo的一次简单的封装，它的返回值是一组数组，其中第三个元素就是vcpus的数量），我们看到这里基本就可以了，再往下就是libvirt的C语言代码而不是Python的范畴了。\n另一方面，如果我们配置了vcpu_pin_set配置项，那么该配置项就被hardware.get_vcpu_pin_set方法解析成一个可用CPU位置索引的集合，再通过对该集合求长后，我们也能得到最终想要的vcpus的数量。\n如上，就是Nova统计节点硬件资源的整个逻辑过程(vcpus为例)。\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}