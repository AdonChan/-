{"title": "手把手教你监督学习（附python实战代码） - 个人文章 ", "index": "人工智能,算法,python", "content": "摘要： 想学监督学习？底子一定要打好！\n\n为什么选择人工智能和机器学习？\n人类的未来是人工智能/机器学习。任何不了解的它们的人很快就会发现自己已经落后了。在这个充满创新的世界中醒来感觉科技越来越像魔术。有许多种方法和技术来执行人工智能和机器学习来解决实时问题，其中监督学习是最常用的方法之一。\n什么是监督学习？\n在监督学习中，我们从导入包含训练属性和目标属性的数据集开始。监督式学习算法将学习训练样本与其相关目标变量之间的关系，并应用该学习关系对全新输入（无目标）进行分类。\n为了说明监督学习是如何工作的，让我们从一个根据他学习的小时数来预测学生分数的例子。\n在数学上，Y = f（X）+ C\n其中，f将是标记学生为考试准备的小时数之间的关系；\nX是INPUT（他准备的小时数）；\nY是输出（标记在考试中得分的学生）；\nC将是随机错误。\n监督学习算法的最终目标是以给定的新输入X，输出最大精度预测Y。算法工程师们已经发明了几种方法来实现监督学习，我们将探索一些最常用的方法。\n基于给定的数据集，机器学习问题分为两类：分类和回归。如果给定的数据同时具有输入（训练）值和输出（目标）值，那么这是一个分类问题。如果数据集具有不带任何目标标签的属性的连续数值，则它属于回归问题。例如：\n分类：有输出标签，它是猫还是狗？\n回归：房子卖多少钱？\n分类\n举一个一位希望分析乳腺癌数据的医学研究人员的例子，以预测患者应接受三种特定治疗中的哪一种。该数据分析任务被称为分类，其中构建模型或分类器以预测类别标签，诸如“处理A”，“处理B”或“处理C”。\n分类是预测问题，包括分类预测和分类无序的类别标签。这是一个两步过程，由学习步骤和分类步骤组成。\n分类的最佳方法\n一些最常用的分类算法\n1.K-最近邻；\n2.决策树；\n3.朴素贝叶斯；\n4.支持向量机；\n在学习步骤中，分类模型通过分析训练集来建立分类器。在分类步骤中是预测给定数据的类别标签。分析中的数据集元组及其关联的类标签被分成一个训练集和测试集。构成训练集的各个元组从随机抽样的数据集中进行分析。剩余的元组形成测试集并且独立于训练元组，这意味着它们不会用于构建分类器。\n测试集用于估计分类器的预测准确度。分类器的准确性是分类器正确分类的测试元组的百分比。为了获得更高的精度，最好的方法是测试不同的算法，并在每个算法中尝试不同的参数。最好的一个可以通过交叉验证来选择。\n要针对某个问题选择一个好的算法，对于不同的算法必须考虑准确性、训练时间、线性、参数数量和特殊情况等参数。\n教程：基于IRIS数据集的Scikit-Learn中实现KNN，根据给定的输入对花的类型进行分类。\n第一步，为了应用我们的机器学习算法，我们需要了解和探索给定的数据集。在这个例子中，我们使用从scikit-learn软件包导入的IRIS数据集。\n现在让我们深入代码并探索IRIS数据集。\n确保你的机器上安装了Python。另外，使用PIP安装以下软件包：\npip install pandas\npip install matplotlib\npip install scikit-learn\n\n\n在这段代码中，我们使用Pandas中的几种方法了解了IRIS数据集的属性。\nfrom sklearn import datasets\nimport pandas as pd\nimport matplotlib.pyplot as plt\n# Loading IRIS dataset from scikit-learn object into iris variable.\niris = datasets.load_iris()\n# Prints the type/type object of iris\nprint(type(iris))\n# <class 'sklearn.datasets.base.Bunch'>\n# prints the dictionary keys of iris data\nprint(iris.keys())\n# prints the type/type object of given attributes\nprint(type(iris.data), type(iris.target))\n# prints the no of rows and columns in the dataset\nprint(iris.data.shape)\n# prints the target set of the data\nprint(iris.target_names)\n# Load iris training dataset\nX = iris.data\n# Load iris target set\nY = iris.target\n# Convert datasets' type into dataframe\ndf = pd.DataFrame(X, columns=iris.feature_names)\n# Print the first five tuples of dataframe.\nprint(df.head())\n\n输出：\n<class ‘sklearn.datasets.base.Bunch’> dict_keys([‘data’, ‘target’, ‘target_names’, ‘DESCR’, ‘feature_names’])] <class ‘numpy.ndarray’> <class ‘numpy.ndarray’> (150, 4) [‘setosa’ ‘versicolor’ ‘virginica’] sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2\n\nScikit-learn中的K-最近邻居如果一个算法仅仅存储了训练集的元组并且等待给出测试元组，那么就被认为是一个懒惰学习者。只有当它看到测试元组时才会执行泛化，以便根据元组与存储的训练元组的相似性对元组进行分类。\nK-最近邻分类器就是一个懒惰的学习者。\nKNN基于类比学习，即将给定的测试元组与类似的训练元组进行比较。训练元组由n个属性描述，每个元组代表一个n维空间中的一个点。这样，所有训练元组都存储在n维模式空间中。当给定未知元组时，k-最近邻分类器在模式空间中搜索最接近未知元组的k个训练元组。这k个训练元组是k未知元组的k个“最近邻居”。\n在下面这个代码段中，我们从sklearn提供进口KNN分类器，并将其应用于我们的输入数据，然后对花进行分类。\nfrom sklearn import datasets\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Load iris dataset from sklearn\niris = datasets.load_iris()\n\n# Declare an of the KNN classifier class with the value with neighbors.\nknn = KNeighborsClassifier(n_neighbors=6)\n\n# Fit the model with training data and target values\nknn.fit(iris['data'], iris['target'])\n\n# Provide data whose class labels are to be predicted\nX = [\n    [5.9, 1.0, 5.1, 1.8],\n    [3.4, 2.0, 1.1, 4.8],\n]\n\n# Prints the data provided\nprint(X)\n\n# Store predicted class labels of X\nprediction = knn.predict(X)\n\n# Prints the predicted class labels of X\nprint(prediction)\n\n输出：\n[1 1]\n这里 ，0对应Versicolor\n1对应Virginic \n2对应Setosa\n基于给定的输入，机器使用KNN预测两种花是Versicolor。\nKNN直观的IRIS数据集分类\n\n回归回归通常被称为确定两个或更多变量之间的关系。例如，考虑你必须根据给定的输入数据X来预测一个人的收入。\n这里的目标变量意味着我们关心预测的未知变量，连续意味着Y可以承担的值不存在间隙（不连续性）。\n预测收入是一个典型的回归问题。你的输入数据应该包含所有可以预测收入的信息（称为特征），例如他的工作时间、教育经历、职位、他住的地方。\n流行的回归模型\n一些常用的回归模型是：\n\n线性回归\nLogistic回归\n多项式回归\n\n线性回归使用的是最佳拟合直线（也称为回归线）建立因变量（Y）与一个或多个自变量（X）之间的关系。\n在数学上，h（xi）=βo+β1* xi + e，其中βo是截距，β1是线的斜率，e是误差项。\n从图形上看，\n\nLogistic Regression是一种算法，用于响应变量是分类的地方。Logistic回归的想法是找出特征与特定结果的概率之间的关系。\n在数学上，p（X）=βo+β1* X，其中p（x）= p（y = 1 | x）\n从图形上看，\n\n多项式回归是一种回归分析的形式，其中自变量x和因变量y之间的关系被建模为x中的n次多项式。\n解决线性回归问题\n我们有我们的数据集X和相应的目标值Y，我们使用普通最小二乘来学习一个线性模型，我们可以用它来预测一个新的y，给出一个以前看不见的x，尽可能小的误差。\n给定的数据被分成一个训练数据集和一个测试数据集。训练集具有标签（特征加载），所以算法可以从这些标记的例子中学习。测试集没有任何标签，也就是说，你还不知道试图预测的价值。\n我们将考虑一个要素进行训练，并应用线性回归方法拟合训练数据，然后使用测试数据集预测输出。\n在scikit-learn中实现线性回归\nfrom sklearn import datasets, linear_model\nimport matplotlib.pyplot as plt\nimport numpy as np\n# Load the diabetes dataset\ndiabetes = datasets.load_diabetes()\n# Use only one feature for training\ndiabetes_X = diabetes.data[:, np.newaxis, 2]\n# Split the data into training/testing sets\ndiabetes_X_train = diabetes_X[:-20]\ndiabetes_X_test = diabetes_X[-20:]\n# Split the targets into training/testing sets\ndiabetes_y_train = diabetes.target[:-20]\ndiabetes_y_test = diabetes.target[-20:]\n# Create linear regression object\nregr = linear_model.LinearRegression()\n# Train the model using the training sets\nregr.fit(diabetes_X_train, diabetes_y_train)\n# Input data\nprint('Input Values')\nprint(diabetes_X_test)\n# Make predictions using the testing set\ndiabetes_y_pred = regr.predict(diabetes_X_test)\n# Predicted Data\nprint(\"Predicted Output Values\")\nprint(diabetes_y_pred)\n# Plot outputs\nplt.scatter(diabetes_X_test, diabetes_y_test, color='black')\nplt.plot(diabetes_X_test, diabetes_y_pred, color='red', linewidth=1)\nplt.show()\n\n输出：\nInput Values\n[\n[ 0.07786339]  [-0.03961813]  [ 0.01103904]  [-0.04069594]    [-0.03422907]  [ 0.00564998]  [ 0.08864151]  [-0.03315126] [-0.05686312]  [-0.03099563]  [ 0.05522933]  [-0.06009656]\n[ 0.00133873]  [-0.02345095]  [-0.07410811]  [ 0.01966154][-0.01590626]  [-0.01590626]  [ 0.03906215]  [-0.0730303 ]\n]\nPredicted Output Values\n[ \n225.9732401   115.74763374  163.27610621  114.73638965   120.80385422  158.21988574  236.08568105  121.81509832   \n99.56772822   123.83758651  204.73711411   96.53399594  \n154.17490936  130.91629517   83.3878227   171.36605897 \n137.99500384  137.99500384  189.56845268   84.3990668 \n]\n\n\n（糖尿病_X_测试，糖尿病_y_pred）预测之间的图将在线方程上连续。\n结束笔记用于监督机器学习的其他Python软件包。\nScikit-Learn，Tensorflow，Pytorch。\n本文由@阿里云云栖社区组织翻译。\n文章原标题《supervised-learning-with-python》，\n译者：虎说八道，审校：袁虎。\n原文链接\n本文为云栖社区原创内容，未经允许不得转载。\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}