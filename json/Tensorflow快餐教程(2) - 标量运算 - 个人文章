{"title": "Tensorflow快餐教程(2) - 标量运算 - 个人文章 ", "index": "深度学习,神经网络,python", "content": "Tensorflow的Tensor意为张量。一般如果是0维的数组，就是一个数据，我们称之为标是Scalar；1维的数组，称为向量Vector；2维的数组，称为矩阵Matrics；3维及以上的数组，称为张量Tensor。在机器学习中，用途最广泛的是向量和矩阵的运算。这也是我们学习中的第一个难关。不过，这一节我们先打标量的基础。\n上节我们学过，Tensorflow的运行需要一个Session对象。下面代码中所用的sess都是通过\nsess = tf.Session()\n\n获取的Session对象，以下就都省略不写了。\n标量Scalar\n标量是指只有一个数字的结构。我们尝试将一个整数赋给一个Tensorflow的常量，看看是什么效果：\n  >>> a10 = 1\n   >>> b10 = tf.constant(a10)\n   >>> print(b10) Tensor(\"Const_6:0\", shape=(), dtype=int32)\n   >>> sess.run(b10) 1\n\n我们可以看到，tf.constant(a10)生成了一个shape为空的，类型为int32的张量。\nTensorflow是一个经过数据类型优化的高性能系统，所以对于数据类型的要求比较高。比如我们想对上面的标量b10进行求正弦值的运算，就会得到下面的错误，sin运算只支持浮点数和复数类型：\n>>> b11 = tf.sin(b10)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 6862, in sin\n    \"Sin\", x=x, name=name)\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 609, in _apply_op_helper\n    param_name=input_name)\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 60, in _SatisfiesTypeConstraint\n    \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\nTypeError: Value passed to parameter 'x' has DataType int32 not in list of allowed values: \n\n后面我们还会多次遇到数据类型不符合要求，以至于无法运算的错误。所以我们首先要学习下Tensorflow的数据类型。\nTensorflow的数据类型\nTensorflow主要支持以下数据类型\n整型：\ntf.int8: 8位带符号整数tf.uint8: 8位无符号整数tf.int16: 16位带符号整数tf.int32: 32位带符号整数tf.int64: 64位带符号整数\n浮点型：\ntf.float32: 32位浮点数tf.float64: 64位浮点数\n复数:\ntf.complex64: 64位复数tf.complex128: 128位复数在Tensorflow的很多运算中，都支持通过dtype=的方式来指定数据类型。例：\n>>> b01 = tf.constant(1,dtype=tf.uint8)\n>>> print(b01)\nTensor(\"Const_7:0\", shape=(), dtype=uint8)\n>>> b02 = tf.constant(1,dtype=tf.float64)\n>>> print(b02)\nTensor(\"Const_8:0\", shape=(), dtype=float64)\n>>> sess.run(b01)\n1\n>>> sess.run(b02)\n1.0\nTensor到某类型数据的转换\n通过tf.constant函数，我们可以将数据转换成Tensor。同样，Tensorflow也提供了Tensor到各种数据类型的转换函数。例，将Tensor转换成tf.int32:\n>>> b03 = tf.to_int32(b02)\n>>> print(b03)\nTensor(\"ToInt32:0\", shape=(), dtype=int32)\n>>> sess.run(b03)\n1\n>>> b04 = sess.run(b03)\n>>> print(b04)\n1\n从上面代码可以看到，b03 run的结果就是一个整数，不是Tensor.类似的函数还有tf.to_int64, tf.to_float, tf.to_double等。\n定义这么多函数太麻烦了，还有一个通用的转换函数tf.cast. 格式为：tf.cast(Tensor, 类型名)。例：\n>>> b05 = tf.cast(b02, tf.complex128)\n>>> sess.run(b05)\n(1+0j)\n\n饱和转换\n如果是将大类型如int64转成小类型int16，tf.cast转换可能会产生溢出。这在机器学习的计算中是件可怕的事情。在这种情况下，我们就需要使用饱和类型转换saturate_cast来保驾护航。\n比如我们要把65536转换成tf.int8类型：\n>>> b06 = tf.constant(65536,dtype=tf.int64)\n>>> print(b06)\nTensor(\"Const_9:0\", shape=(), dtype=int64)\n>>> sess.run(b06)\n65536\n>>> b07 = tf.saturate_cast(b06,tf.int8)\n>>> sess.run(b07)\n127\n\n标量算术运算\n标量Tensor常量可以进行算术运算。本质上是调用tf.add, tf.sub, tf.mul, tf.truediv, tf.mod等重载函数。\n例：\n>>> d01 = tf.constant(1)\n>>> d02 = tf.constant(2)\n>>> d_add = d01 + d02\n>>> print(d_add)\nTensor(\"add:0\", shape=(), dtype=int32)\n>>> d_sub = d01 - d02\n>>> print(d_sub)\nTensor(\"sub:0\", shape=(), dtype=int32)\n>>> d_mul = d01 * d02\n>>> print(d_mul)\nTensor(\"mul:0\", shape=(), dtype=int32)\n>>> d_div = d01 / d02\n>>> print(d_div)\nTensor(\"truediv:0\", shape=(), dtype=float64)\n>>> d_mod = d01 % d02\n>>> print(d_mod)\nTensor(\"mod:0\", shape=(), dtype=int32)\n>>> d_minus = -d01\n>>> print(d_minus)\nTensor(\"Neg:0\", shape=(), dtype=int32)\n对于除法多说两句，Tensor有两种除法，一种是\"/\"，另一种是\"//\"。\"/\"是浮点除法，对应的是tf.truediv，而\"//\"是计算整除，对应tf.floordiv。\n>>> d_div = d01 / d02\n>>> print(d_div)\nTensor(\"truediv:0\", shape=(), dtype=float64)\n>>> d_div2 = d01 // d02\n>>> print(d_div2)\nTensor(\"floordiv:0\", shape=(), dtype=int32)\n\n标量逻辑运算\n对于>, <, >=, <=等关系，都会生成一个需要Session来运算的Tensor对象。只有==是例外，它会立即返回这两个Tensor是否是同一对象的结果。\n>>> d11 = d01 > d02\n>>> d12 = d01 < d02\n>>> d13 = d01 == d02\n>>> d14 = d01 >= d02\n>>> d15 = d01 <= d02\n>>> print(d11)\nTensor(\"Greater_1:0\", shape=(), dtype=bool)\n>>> print(d12)\nTensor(\"Less:0\", shape=(), dtype=bool)\n>>> print(d13)\nFalse\n>>> print(d14)\nTensor(\"GreaterEqual:0\", shape=(), dtype=bool)\n>>> print(d15)\nTensor(\"LessEqual:0\", shape=(), dtype=bool)\n>>> d11 = d01 > d02\n\n常用标量数学函数\n首先还是强调一下注意类型，比如整形，一定要先转换成浮点型才能进行sqrt，sin等数学函数计算。例：\n>>> d31 = tf.constant(100, dtype=tf.float64)\n>>> d32 = tf.sqrt(d31)\n>>> sess.run(d32)\n10.0\n\n另外不要忘了，像sin, cos, tan这些函数是支持复数的哦。例：\n>>> d40 = tf.constant(1+2j)\n>>> d41 = tf.sin(d40)\n>>> sess.run(d41)\n\n(3.165778513216168+1.9596010414216063j)中间结果也可以不用Tensor保存，直接用立即数，例：\n>>> d42 = tf.cos(0.5+0.3j)\n>>> sess.run(d42)\n(0.917370851271881-0.14599480570180629j)\n\n常量、占位符和变量\n前面我们主要使用立即数和常量。常量是通过tf.constant定义的，一旦定义就不能改变值的Tensor。如果要想改变Tensor的值，有两种变法：一种是根本就不赋值，先放个占位符；另一种是初始化成一个带值的变量，将来再改变值。下面简单介绍一下占位符和变量。\nplaceholder占位符在算法计算时，有很多公式需要的数值是需要从外部拿到的，随时替换的。这时候我们就可以用一个占位符来写Tensor，需要计算时再把真数据通过feed_dict给填充进去就可以。我们来看个例子：\n>>> d50 = tf.placeholder(tf.float32, name =\"input1\")\n>>> d51 = tf.sin(d50)\n>>> sess.run(d51, feed_dict={d50: 0.2})\n0.19866933\n\nd50开始只用个placeholder，这样的话是没有办法通过之前不加feed_dict参数的sess.run来运行的。通过指定feed_dict={d50: 0.2}，我们就用数据替换掉了placeholder，就可以正常运行了。\n变量\n变量与占位符不同的一点是，变量在使用之前需要做初始化。初始化不但要在变量定义时写，还要调用相应的函数在使用前执行才可以。我们还是举例说明：\n>>> d60 = tf.Variable(1, dtype=tf.float32, name='number1')\n>>> d61 = tf.tan(d60)\n>>> init_op = tf.global_variables_initializer()\n>>> sess.run(init_op)\n>>> sess.run(d61)\n1.5574077\n\n在使用变量之前，我们可以一次性调用tf.global_variables_initializer函数去初始化所有变量，并且通过Session去执行。在此之后才能使用变量。\n变量初始化之后，就可以通过assign函数来赋新值，例：\n  >>> d62 = d60.assign(d60 * 2)\n    >>> sess.run(d62)\n    2.0\n    >>> sess.run(d61)\n    -2.1850398\n\n小结\n小结一下，这节主要介绍了数据类型，标量常用的计算函数，还有使用占位符和变量的方法。下一节我们正式开始线性代数之旅，走进向量、矩阵和张量。\n详情请阅读原文\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "1"}