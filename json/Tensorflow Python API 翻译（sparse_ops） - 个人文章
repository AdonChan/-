{"title": "Tensorflow Python API 翻译（sparse_ops） - 个人文章 ", "index": "python", "content": "作者：chen_h微信号 & QQ：862251340微信公众号：coderpai简书地址：https://www.jianshu.com/p/c23...\n\n计划现将 tensorflow 中的 Python API 做一个学习，这样方便以后的学习。原文链接\n\n该章介绍有关稀疏张量的API\n\n稀疏张量表示\n对于多维稀疏数据，TensorFlow提供了稀疏张量表示。稀疏张量里面的值都是采用IndexedSlices索引来表示，这样能更加高效的表示数据。\n\nclass tf.SparseTensor\n解释：这个函数的作用是表示一个稀疏张量。\nTensorflow使用三个密集张量：indices，values，dense_shape，来表示一个稀疏张量。在Python接口中，这三个张量被整合到一个SparseTensor类中，如果你调换了这三个密集张量的位置，那么在进行操作之前，SparseTensor类会自动调换三个张量的位置。\n具体的说，稀疏张量表示为SparseTensor(values, indices, dense_shape):\n\n\nindices: 一个二维的张量，数据类型是int64，数据维度是[N, ndims]。\n\nvalues: 一个一维的张量，数据类型是任意的，数据维度是[N]。\n\ndense_shape: 一个一维的张量，数据类型是int64，数据维度是[ndims]。\n\n其中，N表示稀疏张量中存在N个值，ndims表示SparseTensor的维度。\n相应的密集张量满足：\ndense.shape = dense_shape\ndense[tuple(indices[i])] = values[i]\n按照惯例，indices中的索引应该按照从小到大的顺序排序。SparseTensor中三个密集张量的顺序不是强制的，你可以乱序，SparseTensor会自动将它排序。\n比如：\nSparseTensor(values=[1, 2], indices=[[0, 0], [1, 2]], shape=[3, 4])\n那么密集张量就是：\n[[1, 0, 0, 0]\n [0, 0, 2, 0]\n [0, 0, 0, 0]]\n\ntf.SparseTensor.__init__(indices, values, shape)\n解释：这个函数的作用是构建一个SparseTensor。\n输入参数：\n\n\nindices: 一个二维的张量，数据类型是int64，数据维度是[N, ndims]。\n\nvalues: 一个一维的张量，数据类型是任意的，数据维度是[N]。\n\ndense_shape: 一个一维的张量，数据类型是int64，数据维度是[ndims]。\n\n输出参数：\n一个稀疏张量SparseTensor。\n\ntf.SparseTensor.indices\n解释：这个函数的作用是取出密集矩阵中非零值得索引。\n使用例子：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np\n\na = tf.SparseTensor(indices=[[4, 1], [1, 2]], values=[1, 2], shape=[3, 4])\nb = a.indices\nsess = tf.Session()\nprint sess.run(a)\nprint sess.run(b)\nsess.close()\n输出参数：\n一个二维的张量，数据类型是int64，数据维度是[N, ndims]。其中，N表示在稀疏张量中非零值的个数，ndims表示稀疏张量的秩。\n\ntf.SparseTensor.values\n解释：这个函数的作用是取出密集矩阵中非零值。\n使用例子：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np\n\na = tf.SparseTensor(indices=[[4, 1], [1, 2]], values=[1, 2], shape=[3, 4])\nb = a.values\nsess = tf.Session()\nprint sess.run(a)\nprint sess.run(b)\nsess.close()\n输出参数：\n一个一维的张量，数据类型是任意的。\n\ntf.SparseTensor.dtype\n解释：这个函数的作用是返回张量中元素的类型。\n使用例子：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np\n\na = tf.SparseTensor(indices=[[4, 1], [1, 2]], values=tf.constant([1, 2]), shape=[3, 4])\nb = a.dtype\nsess = tf.Session()\nprint b\nsess.close()\n输出参数：\n返回张量中元素的类型。\n\ntf.SparseTensor.shape\n解释：这个函数的作用是返回稀疏张量的维度。\n使用例子：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np\n\na = tf.SparseTensor(indices=[[4, 1], [1, 2]], values=tf.constant([1, 2]), shape=[3, 4])\nb = a.shape\nsess = tf.Session()\nprint sess.run(b)\nsess.close()\n输出参数：\n返回稀疏张量的维度。\n\ntf.SparseTensor.graph\n解释：这个函数的作用是返回包含该稀疏张量的图。\n使用例子：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np\n\na = tf.SparseTensor(indices=[[4, 1], [1, 2]], values=tf.constant([1, 2]), shape=[3, 4])\nb = a.graph\nsess = tf.Session()\nprint b\nsess.close()\n输出参数：\n返回包含该稀疏张量的图。\n\nclass tf.SparseTensorValue\n解释：这个函数的作用是查看设置稀疏张量的值。\n使用例子：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np\n\na = tf.SparseTensorValue(indices=[[4, 1], [1, 2]], values=tf.constant([1, 2]), shape=[3, 4])\nsess = tf.Session()\nprint a\nprint a[0]\nprint a[1]\nprint a[2]\nsess.close()\n\ntf.SparseTensorValue.indices\n解释：这个函数的作用是返回稀疏张量中值的存在位置。\n使用例子：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np\n\na = tf.SparseTensorValue(indices=[[4, 1], [1, 2]], values=tf.constant([1, 2]), shape=[3, 4])\nsess = tf.Session()\nprint a.indices\nsess.close()\n输出参数：\n返回稀疏张量中值的存在位置。\n\ntf.SparseTensorValue.shape\n解释：这个函数的作用是返回稀疏张量的维度。\n使用例子：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np\n\na = tf.SparseTensorValue(values=tf.constant([1, 2]), indices=[[4, 1], [1, 2]], shape=[3, 4])\nsess = tf.Session()\nprint a.shape\nsess.close()\n输出参数：\n返回稀疏张量的维度。\n\ntf.SparseTensorValue.shape\n解释：这个函数的作用是返回稀疏张量中的元素。\n使用例子：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np\n\na = tf.SparseTensorValue(values=tf.constant([1, 2]), indices=[[4, 1], [1, 2]], shape=[3, 4])\nsess = tf.Session()\nprint sess.run(a.values)  # 这是一个张量，所以用sess.run()\nsess.close()\n输出参数：\n返回稀疏张量中的元素。\n\n稀疏张量与密集张量的转换\nTensorFlow提供了稀疏张量与密集张量之间的转换操作。\n\ntf.sparse_to_dense(sparse_indices, output_shape, sparse_values, default_value, name=None)\n解释：这个函数的作用是将一个稀疏表示转换成一个密集张量。具体将稀疏张量sparse转换成密集张量dense如下：\n# If sparse_indices is scalar\ndense[i] = (i == sparse_indices ? sparse_values : default_value)\n\n# If sparse_indices is a vector, then for each i\ndense[sparse_indices[i]] = sparse_values[i]\n\n# If sparse_indices is an n by d matrix, then for each i in [0, n)\ndense[sparse_indices[i][0], ..., sparse_indices[i][d-1]] = sparse_values[i]\n默认情况下，dense中的填充值default_value都是0，除非该值被设置成一个标量。\n使用例子：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np\n\na = tf.sparse_to_dense(sparse_indices = [[1,2],[2,1]], output_shape = [3,3], \n    sparse_values = [2,3], default_value = 1)\nsess = tf.Session()\nprint sess.run(a) \nsess.close()\n输入参数：\n\n\nsparse_indices: 一个Tensor，数据类型必须是int32或者int64。数据维度0维，一维或者二维都可以，或者更加高纬度的sparse_indices[i]。\n\noutput_shape: 一个Tensor，数据类型必须和sparse_indices相同。数据维度是一维，表示输出密集张量的维度。\n\nsparse_values: 一个Tensor，数据维度是一维，其中的每一个元素对应sparse_indices中坐标的值。\n\ndefault_value: 一个Tensor，数据类型必须和sparse_values相同，数据维度是一个标量。设置稀疏索引不指定的值。\n\nname: （可选）为这个操作取一个名字。\n\n输出参数：\n一个Tensor，数据类型和sparse_values相同。密集张量的数据维度是output_shape。\n\ntf.sparse_tensor_to_dense(sp_input, default_value, name=None)\n解释：这个函数的作用是将一个稀疏张量SparseTensor转换成一个密集张量。\n这个操作是一个便利的将稀疏张量转换成密集张量的方法。\n比如，sp_input的数据维度是[3, 5]，非空值为：\n[0, 1]: a\n[0, 3]: b\n[2, 0]: c\ndefault_value值为x，那么输出的密集张量的维度是[3, 5]，具体的展示形式如下：\n[[x a x b x]\n [x x x x x]\n [c x x x x]]\n使用例子：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np\n\na = tf.SparseTensor(indices = [[0, 1], [0, 3], [2, 0]], values=[1,2,3], shape=[3, 5])\nb = tf.sparse_tensor_to_dense(a, default_value = 11)\nsess = tf.Session()\nprint sess.run(b)\nsess.close()\n输入参数：\n\n\nsp_input: 一个SparseTensor。\n\ndefault_value: 数据维度是一个标量，设置稀疏索引不指定的值。\n\nname: （可选）设置返回张量名称的前缀。\n\n输出参数：\n一个密集张量，数据维度是sp_input.shape，密集张量里面的值为sp_input中指定的值，没有索引的值为default_value值。\n异常：\n\n类型错误: 如果sp_input不是一个SparseTensor，将报错。\n\ntf.sparse_to_indicator(sp_input, vocab_size, name=None)\n解释：这个函数的作用是将稀疏张量SparseTensor的坐标转换成密集张量中的布尔坐标。\nsp_input中的最后一维被丢弃，并且用sp_input在该位的值来代替，如果sp_input.shape = [D0, D1, D2, ..., Dn, K]，其中K是最后一维，那么output.shape = [D0, D1, D2, ..., Dn, vocab_size]，其中：\noutput[d_0, d_1, ..., d_n, sp_input[d_0, d_1, ..., d_n, k]] = True\noutput中其余值为False。\n比如，sp_input.shape = [2, 3, 4]，非空值如下：\n[0, 0, 0]: 0\n[0, 1, 0]: 10\n[1, 0, 3]: 103\n[1, 1, 2]: 112\n[1, 1, 3]: 113\n[1, 2, 1]: 121\n并且vocab_size = 200，那么输出output.shape = [2, 3, 200]，并且output中的值都是False，除了以下位置：\n(0, 0, 0), (0, 1, 10), (1, 0, 103), (1, 1, 112), (1, 1, 113), (1, 2, 121).\n使用例子：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np\n\na = tf.SparseTensor(indices = [[0, 1], [0, 3], [2, 0]], values=[1,2,3], shape=[3, 5])\nb = tf.sparse_to_indicator(a, 10)\nsess = tf.Session()\nprint sess.run(b)\nsess.close()\n输入参数：\n\n\nsp_input: 一个SparseTensor，数据类型是int32或者int64。\n\nvocab_size: sp_Input最后一维的新的维度，并且0 <= sp_input.shape > vocab_size。\n\nname: （可选）设置返回张量名称的前缀。\n\n输出参数：\n一个经过修改的密集布尔张量。\n异常：\n\n类型错误: 如果sp_input不是一个SparseTensor，将报错。\n\n稀疏张量的操作\nTensorFlow提供了一些对于稀疏张量的操作函数。\n\ntf.sparse_concat(concat_dim, sp_inputs, name=None)\n解释：这个函数的作用是将一系列的SparseTensor，按照指定的维度进行合并。\n具体合并思路是，先将稀疏张量看成是一个密集张量，然后按照指定的维度进行张量合并，最后将合并成的密集张量看成是一个稀疏张量。\n输入的数据中，SparseTensor的数据维度必须是相同的，并且indices，values和shapes的长度必须相同。\n输出数据的维度将由输入数据的维度决定，除了需要合并的那一维度，这一维度是所有数据该维度的相加总和。\n输出张量中的元素将会被重新保存在稀疏张量中，并且按照原来的顺序进行排序。\n这个操作的时间复杂度是O(M log M)，其中，M是输入数据中所有非空元素的个数总和。\n比如，当concat_dim = 1时：\nsp_inputs[0]: shape = [2, 3]\n[0, 2]: \"a\"\n[1, 0]: \"b\"\n[1, 1]: \"c\"\n\nsp_inputs[1]: shape = [2, 4]\n[0, 1]: \"d\"\n[0, 2]: \"e\"\n那么输出数据为：\nshape = [2, 7]\n[0, 2]: \"a\"\n[0, 4]: \"d\"\n[0, 5]: \"e\"\n[1, 0]: \"b\"\n[1, 1]: \"c\"\n用图形表示，如下：\n[    a] concat [  d e  ] = [    a   d e  ]\n[b c  ]           [         ]     [b c          ]\n使用例子：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np\n\na = tf.SparseTensor(indices = [[0, 1], [0, 3], [2, 0]], values=[1,2,3], shape=[3, 5])\naa = tf.SparseTensor(indices = [[1, 1], [1, 3], [2, 1]], values=[11,12,13], shape=[3, 5])\nb = tf.sparse_concat(0, [a, aa])\nsess = tf.Session()\nprint sess.run(b)\nprint sess.run(tf.sparse_tensor_to_dense(b))\nsess.close()\n输入参数：\n\n\nconcat_dim: 需要合并的维度。\n\nsp_inputs: 一个需要合并的SparseTensor列表。\n\nname: （可选）设置返回张量名称的前缀。\n\n输出参数：\n一个经过合并的SparseTensor。\n异常：\n\n类型错误: 如果sp_inputs不是一个SparseTensor列表。\n\ntf.sparse_reorder(sp_input, name=None)\n解释：这个函数的作用是将SparseTensor中的元素进行重新排列，按照索引从小到大进行排序。\n重排列不会影响SparseTensor的维度。\n比如，如果sp_input的维度是[4, 5]，indices / values如下：\n[0, 3]: b\n[0, 1]: a\n[3, 1]: d\n[2, 0]: c\n那么输出的SparseTensor的维度还是[4, 5] ，indices / values如下：\n[0, 1]: a\n[0, 3]: b\n[2, 0]: c\n[3, 1]: d\n使用例子：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np\n\na = tf.SparseTensor(indices = [[2, 1], [0, 3], [2, 0]], values=[1,2,3], shape=[3, 5])\nb = tf.sparse_reorder(a)\nsess = tf.Session()\nprint sess.run(b)\nsess.close()\n输入参数：\n\n\nsp_input: 一个SparseTensor。\n\nname: （可选）设置返回张量名称的前缀。\n\n输出参数：\n一个SparseTensor，数据维度和数据类型都不变，只有其中的值进行了有序的排序。\n异常：\n\n类型错误: 如果sp_input不是一个SparseTensor。\n\ntf.sparse_retain(sp_input, to_retain, name=None)\n解释：这个函数的作用是保留SparseTensor中指定的非空元素。\n比如，如果sp_input的数据维度是[4, 5]，并且拥有4个非空值如下：\n[0, 1]: a\n[0, 3]: b\n[2, 0]: c\n[3, 1]: d\n而且to_retain = [True, False, False, True]，那么最后输出数据SparseTensor的数据维度是[4, 5]，并且保留两个非空值如下：\n[0, 1]: a\n[3, 1]: d\n使用例子：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np\n\na = tf.SparseTensor(indices = [[2, 1], [0, 3], [2, 0]], values=[1,2,3], shape=[3, 5])\nb = tf.sparse_retain(a, [False, False, True])\nsess = tf.Session()\nprint sess.run(b)\nsess.close()\n输入参数：\n\n\nsp_input: 一个SparseTensor，包含N个非空元素。\n\nto_retain: 一个布尔类型的向量，向量长度是N，并且其中包含M个True值。\n\n输出参数：\n一个SparseTensor，数据维度和输入数据相同，其中包含M个非空值，该值的位置根据True的位置来决定。\n异常：\n\n类型错误: 如果sp_input不是一个SparseTensor。\n\ntf.sparse_fill_empty_rows(sp_input, default_value, name=None)\n解释：这个函数的作用是将二维的SparseTensor中，将空的行中填充指定元素的值。\n如果一行中不存在元素，那么就将改行的坐标[row, 0]填上default_value。\n比如，我们假设sp_input的数据维度是[5, 6]，并且非空值如下：\n[0, 1]: a\n[0, 3]: b\n[2, 0]: c\n[3, 1]: d\n因为在稀疏张量中，第一行和第四行中不存在值，那么我们需要在[1, 0]和[4, 0]坐标填上default_value，如下：\n[0, 1]: a\n[0, 3]: b\n[1, 0]: default_value\n[2, 0]: c\n[3, 1]: d\n[4, 0]: default_value\n请注意，输入可能有空列在最后，但对这个操作没有任何影响。\n输出的SparseTensor将是一个按照从小到大的顺序进行排序，并且输出数据和输入数据拥有相同的数据维度。\n这个操作还会返回一个布尔向量，其中的布尔值，如果是True值，那么表示该行添加了一个default_value，计算公式如下：\nempty_row_indicator[i] = True iff row i was an empty row.\n使用例子：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np\n\na = tf.SparseTensor(indices = [[2, 1], [0, 3], [2, 0]], values=[1,2,3], shape=[6, 5])\nb, bb = tf.sparse_fill_empty_rows(a, 10)\nsess = tf.Session()\nprint sess.run(b)\nprint '----'\nprint sess.run(bb)\nsess.close()\n输入参数：\n\n\nsp_input: 一个SparseTensor，数据维度是[N, M]。\n\ndefault_value: 需要向空行填充的值，数据类型和sp_input相同。\n\nname: （可选）设置返回张量名称的前缀。\n\n输出参数：\n\n\nsp_ordered_output: 一个SparseTensor，数据维度是[N, M]，并且其中所有空行填充了default_value。\n\nempty_row_indicator: 一个布尔类型的向量，数据长度是N，如果该行填充了default_value，那么该位置的布尔值为True。\n\n异常：\n\n类型错误: 如果sp_input不是一个SparseTensor。\n\n作者：chen_h微信号 & QQ：862251340简书地址：https://www.jianshu.com/p/c23...\nCoderPai 是一个专注于算法实战的平台，从基础的算法到人工智能算法都有设计。如果你对算法实战感兴趣，请快快关注我们吧。加入AI实战微信群，AI实战QQ群，ACM算法微信群，ACM算法QQ群。长按或者扫描如下二维码，关注 “CoderPai” 微信号（coderpai）\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}