{"title": "大数据分析02——成都二手房(热度) - 个人文章 ", "index": "python,网页爬虫,大数据", "content": "背景本文是《大数据分析01——成都二手房(平均价格)》的续集，前一篇文章中我们学习了如何使用爬虫获取数据，以及查看各个区域的平均价格做个大概的了解。但是存在２个问题：（１）爬虫爬取了大量重复的数据，影响了分析结果（２）没有帮助用户定位到自己满意的房源本文将详细讲解如何解决这２个问题。\n数据去重解决的思路来子我自己提的问题爬虫如何去重，感兴趣的朋友可以过去看看。根据大家的建议我去重新学习scrapy的框架：\nScrapy运行流程大概如下：\n首先，引擎(engine)从调度器(Scheduler)中取出一个链接(URL)用于接下来的抓取引擎把URL封装成一个请求传给下载器(Donwloader)，下载器把资源下载下来，并封装成应答包(Response)然后，爬虫解析Response若是解析出实体（Item),则交给实体管道(Pipeline)进行进一步的处理。若是解析出的是链接（URL）,则把URL交给Scheduler等待抓取。\n这个Scheduler的中间件不就负责URL的去重吗，然后我去掉request这个模块，让所有的请求都使用Scrapy.requset去发送，果然数据不会再重复了。最终我拿到了２万多条不重复的数据，与链家官方提示的只相差几百条数据，不清除是链家自己有重复的数据，还是我在输入验证码的时候丢失了这部分数据。后期再跟踪吧。但是现在的数据已经可以反应真实情况了。\n定位房源首先，我重新做了一张各个区平均房价的透视图，大家可以和前一篇文章的比较一下，看看重复数据vs完整数据的差别：\n然后，我们想知道现在大家都更关注那个区域的房源，于是我把楼盘“看房数”和\"关注数\"堆叠起来作为关注度，得到下图：\n看来天府新区和高新区限购后，大家都开始看周边的房子，比如龙泉驿，温江，双流。\n那么究竟有哪些比较火的楼盘了，继续把“看房数”和\"关注数\"加起来，然后对“看房数”和\"关注数\"大于２００的做个过滤（这里的price是总价）：\n刚好公司一位同事也准备买房子，他想在双流买一套二的，价格在60-90ｗ，我们利用他给的条件加上“热度”，我过滤出下面数据：\n最后，看看我们的数据都集中在哪些地区吧，这里度量我们用的平均价格，对应图标，越红表示价格越高，楼盘越多：\n谢谢观看，觉得不错的朋友点个赞呗。\n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "0"}