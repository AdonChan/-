{"title": "flume架构解析 - 心随风扬 ", "index": "python,架构,java,工具", "content": "Flume是Apache开发的一款多平台、分布式、高可用的数据收集聚合系统。今天从设计角度来解析Flume的架构组成及其特点。\n首先谈一下数据流(data flow)。Flume本质上是对数据流的处理，其定义数据处理的最小单元是event，一个event由包含数据的有效负载(payload)和一组可选属性组成。Flume实际上处理的就是events flow。\nFlume在数据收集和聚合上有很大的灵活性，这得益于其整个系统可以由单个或者多个节点(agent)拼接而成。每个节点负责从上游数据源向下游数据接收方分发event。每个节点既可以作为数据源也可以作为数据接收方。\n在节点的内部，agent由source、channel和sink组成。source负责消费从上游节点获取的events，并将其放到channel中，目前Flume支持Avro、Thrift、Syslog、Netcat等数据流。channel分为两种类型，一种是memory channel，它适合高吞吐量场景，但节点挂掉后数据可能会丢失。另一种是file channel，也就是channel里的数据会同步到硬盘里，节点意外挂掉后数据可恢复，但处理时间会稍长一些，Flume默认使用file channel。sink从channel取数据并将其放入下游节点。\n下图是从多个web server数据源收集数据，并统一聚合到一个节点，然后将数据导入到hdfs中。\nhttps://flume.apache.org/_images/UserGuide_image02.png\n\nFlume节点还支持更复杂的多源、多数据沉积池的组合，如下图：\nhttps://flume.apache.org/_images/UserGuide_image01.png\n\nFlume采用事务来保证数据传输的可靠性。每个event只有当被确认传递到下游节点或者数据沉积池之后才把该event从channel中删除。节点中的sources和sinks被包含在一个事务中。source接收上游的events，若其中一个event接收异常，则所有的events都丢弃，这将导致数据重发。同理，sink在将events导入到下游数据沉积池时，任何一个event发送异常，则所有的events都将重新发送。\n具体如何使用配置请参考：https://flume.apache.org/Flum...\n\n                ", "mainLikeNum": ["2 "], "mainBookmarkNum": "1"}