{"title": "Windows系统中Python实现每日定时自动登录签到 - 个人文章 ", "index": "python,python爬虫,python3.x", "content": "之前说要每周写的。。然后最近忙着毕业就一直没动。>.<感觉月更都困难了。\n问题描述\n在每天比如10点到11点之间定时自动登陆网站，签到\n实现思路\n\n使用fiddler抓包工具先登陆一遍，把请求的地址，header等信息都拿到。\n使用python写一个脚本，模拟浏览器向服务器发送登陆，签到请求\n使用批处理bat来写几句话，随机在一小时内运行python脚本\n使用Windows自带的计划任务，定时每日10点运行bat脚本\n\n另外，之前不想那么麻烦写代码，还去找了一个叫做按键精灵的软件来模拟执行。不过那个软件是模拟鼠标和键盘，所以执行的时候会有界面出现，而且你的鼠标和键盘不能动，所以后来放弃了。如果觉得这个麻烦也可以试试那个。可以生成一个按键小精灵的exe，用计划任务定时执行。这个软件也很邪教啊，还可以自动截图。\n实现过程\n一、fiddler抓包\n这个直接下载然后上手做就可以了，打开工具，然后进行正常的登陆，每一个请求的过程都有。主要目的是找到每个发送请求的url和header信息。比如我练习网站的登陆请求发送的url是http://XXX.com/Home/Login/log...。\n这个具体的url也可以用谷歌浏览器chrome进入审查元素去选取按钮，简陋一些的网站可以看到js代码是怎么跳转过去的。如果遇到一些按钮点击一次以后无法再点，可以用这个办法找它的url。\n二、python写请求脚本\n这里用这里用python3写的，这部分总结晚点写：P\nimport urllib.request  \nimport urllib  \nimport gzip  \nimport http.cookiejar  \nimport time\n  \n# generate request header, deal with cookie  \ndef getOpener(head):  \n    # deal with the Cookies  \n    cj = http.cookiejar.CookieJar()\n    pro = urllib.request.HTTPCookieProcessor(cj)  \n    opener = urllib.request.build_opener(pro)  \n    header = []  \n    for key, value in head.items():  \n        elem = (key, value)  \n        header.append(elem)  \n    opener.addheaders = header  \n    return opener  \n  \n#encapsulate the header as the browser\nheader = {  \n    'Connection': 'Keep-Alive',  \n    'Accept-Language': 'zh-CN',  \n    'Accept': 'image/jpeg, application/x-ms-application, image/gif, application/xaml+xml, image/pjpeg, application/x-ms-xbap, application/vnd.ms-excel, application/vnd.ms-powerpoint, application/msword, */*',  \n    'User-Agent': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET4.0C; .NET4.0E)',  \n    'Accept-Encoding': 'gzip, deflate',  \n    'X-Requested-With': 'XMLHttpRequest',  \n    'Host': 'http://XXX.com/',  \n}  \n\n\nurl = 'http://XXX.com/Home/Login/login_submit'  \nopener = getOpener(header)  \n  \nid = 'xxxx'#你的用户名  \npassword = 'fddafda'#你的密码，抓包是什么就输什么，有时候是md5加密的\npostDict = {  \n        'logname': id,  \n        'passwd': password,  \n}  \n#这里的post数据的json可以检查fiddler的webform里会有。\n\npostData = urllib.parse.urlencode(postDict).encode()  \nop = opener.open(url, postData)  \ndata = op.read()  \nprint(data)\n\n#签到\nurl = 'http://XXX.com/index/index/sign/P/in'\nop = opener.open(url)\ndata = op.read()\nprint(data)\n\n\n三、bat调用python脚本\n@echo off\nrem 这里就是先用cd命令转到.py文件所在的地址\nC:\ncd C:\\Windows\\\n\nrem 用random生成一个数字对3600秒取余得到一个一小时内的随机秒数存在rd中\nset /a rd=%random%%%3600\nrem ping用于等待若干秒\nping -n %rd% 127.0.0.1 > nul \npython test.py\n\nrem 生成日志\nset  today=%date:~0,4%-%date:~5,2%-%date:~8,2%\necho login at %today%_%time:~0,2%:%time:~3,2%  >> E:\\LogFile\\log%today%.txt\nexit\nrem是注释可以删，python里面还有一个pythonw.exe调用这个可以完全不出现界面。如果命令行cmd里面没有python，去环境变量path里面加一下python所在的地址。\n总结\n实现这个小任务，让我发现python的功能确实很大，而且可以用的库也非常多。这里主要是在廖雪峰的python教程中查看的python基本的东西。然后搜了一个例子。模仿着做的。\n另外，对前端的启发也蛮大的。防止这些爬虫去解析前端的信息，主要可以有以下措施：\n\n对所有发布的网站中JS进行压缩混淆加密\n一些关键数据可以用图片展示，增加一点爬取难度\n登陆设置验证码和动态token\n\n\n                ", "mainLikeNum": ["9 "], "mainBookmarkNum": "20"}