{"title": "Python数据分析学习笔记之Pandas入门 - 倚楼听风雨 ", "index": "pandas,python", "content": "pandas(Python data analysis)是一个Python数据分析的开源库。pandas两种数据结构：DataFrame和Series\n安装：pandas依赖于NumPy,python-dateutil,pytz\npip install pandas\nDataFrame\nDataFrame是一种带标签的二维对象。与excel表格或关系数据库中的表非常神似。可以用以下方式来创建DataFrame：\n\n从另一个DataFrame来创建DataFrame\n从具有二维形状的NumPy数组或者数组的复合结构来生成DataFrame\n可以用Series来创建DataFrame\nDataFrame可以从类似CSV之类的文件来生成\n\n准备数据资料:http://www.exporedata.net/Dow... 下载一个csv数据文件。\nfrom pandas.io.parsers import read_csv\n\ndf = read_csv(\"WHO_first9cols.csv\")\nprint \"Dataframe\", df\nprint \"Shape\", df.shape\nprint \"Length\", len(df)\nprint \"Column Headers\", df.columns\nprint \"Data types\", df.dtypes\nprint \"Index\", df.index\nprint \"Values\", df.values\n\n注意：DataFrame带有一个索引，类似于关系数据库中的主键。我们既可以手动创建，也可以自动创建。访问df.index如果需要遍历数据，请使用df.values获取所有值，非数字的数值在被输出时标记为nan。\nSeries\nSeries是一个由不同类型元素组成的一维数组，该数据结构也具有标签。可以通过以下方式创建Series数据结构：\n\n由Python字典来创建\n由NumPy数组来创建\n由单个标量值来创建\n\n创建Series数据结构时，可以向构造函数递交一组轴标签，这些标签通常称为索引。对DataFrame列执行查询操作时，会返回一个Series\nfrom pandas.io.parsers import read_csv\nimport numpy as np\n\ndf = read_csv(\"WHO_first9cols.csv\")\n#这里对DataFrame列进行查询操作，返回一个Series\ncountry_col = df[\"Country\"]\nprint \"Type df\", type(df)\nprint \"Type country col\", type(country_col)\n\nprint \"Series shape\", country_col.shape\nprint \"Series index\", country_col.index\nprint \"Series values\", country_col.values\nprint \"Series name\", country_col.name\n\nprint \"Last 2 countries\", country_col[-2:]\nprint \"Last 2 countries type\", type(country_col[-2:])\n#NumPy的函数同样适用于pandas的DataFrame和Series\nprint \"df signs\", np.sign(df)\nlast_col = df.columns[-1]\nprint \"Last df column signs\", last_col, np.sign(df[last_col])\n\nprint np.sum(df[last_col] - df[last_col].values)\n利用pandas查询数据\n数据准备：pip install Quandl 或者手动从http://www.quandl.com/SIDC/SU... 下载csv文件。\nimport Quandl\n\n# Data from http://www.quandl.com/SIDC/SUNSPOTS_A-Sunspot-Numbers-Annual\n# PyPi url https://pypi.python.org/pypi/Quandl\nsunspots = Quandl.get(\"SIDC/SUNSPOTS_A\")\nprint \"Head 2\", sunspots.head(2) \nprint \"Tail 2\", sunspots.tail(2)\n\nlast_date = sunspots.index[-1]\nprint \"Last value\", sunspots.loc[last_date]\n\nprint \"Values slice by date\", sunspots[\"20020101\": \"20131231\"]\n\nprint \"Slice from a list of indices\", sunspots.iloc[[2, 4, -4, -2]]\n\nprint \"Scalar with Iloc\", sunspots.iloc[0, 0]\nprint \"Scalar with iat\", sunspots.iat[1, 0]\n\nprint \"Boolean selection\", sunspots[sunspots > sunspots.mean()]\nprint \"Boolean selection with column label\", sunspots[sunspots.Number > sunspots.Number.mean()]\n\nDataFrame的统计函数describe、count、mad、median、min、max、,pde、std、var、skew、kurt\nDataFrame分组与聚合\nimport pandas as pd\nfrom numpy.random import seed\nfrom numpy.random import rand\nfrom numpy.random import random_integers\nimport numpy as np\n\nseed(42)\n\ndf = pd.DataFrame({'Weather' : ['cold', 'hot', 'cold', 'hot',\n   'cold', 'hot', 'cold'],\n   'Food' : ['soup', 'soup', 'icecream', 'chocolate',\n   'icecream', 'icecream', 'soup'],\n   'Price' : 10 * rand(7), 'Number' : random_integers(1, 9, size=(7,))})\n\nprint df\nweather_group = df.groupby('Weather')\n\ni = 0\n\nfor name, group in weather_group:\n   i = i + 1\n   print \"Group\", i, name\n   print group\n\nprint \"Weather group first\\n\", weather_group.first()\nprint \"Weather group last\\n\", weather_group.last()\nprint \"Weather group mean\\n\", weather_group.mean()\n\nwf_group = df.groupby(['Weather', 'Food'])\nprint \"WF Groups\", wf_group.groups\n#通过agg方法，可以对数据组施加一系列的NumPy函数。\nprint \"WF Aggregated\\n\", wf_group.agg([np.mean, np.median])\nDataFrame的串联与附加操作\n数据库的数据表有内部连接和外部连接。DataFrame也有类似操作，即串联和附加。函数concat()的作用是串联DataFrame，追加数据行使用append()函数。例如\npd.concat([df[:3],df[3:]])\ndf[:3].append(df[5:])\npandas提供merge()或DataFrane的join()方法都能实现类似数据库的连接操作功能。默认情况下join()方法会按照索引进行连接，不过，有时候这不符合我们的要求。数据准备：tips.csv\nEmpNr,Amount\n5,10\n9,5\n7,2.5\ndest.csv\nEmpNr,Dest\n5,The Hague\n3,Amsterdam\n9,Rotterdam\n\ndests = pd.read_csv('dest.csv')\ntips = pd.read_csv('tips.csv')\n#使用merge()函数按照员工编号进行连接处理\nprint \"Merge() on key\\n\", pd.merge(dests, tips, on='EmpNr')\n#用join()方法执行连接操作时，需要使用后缀来指示左、右操作对象。\nprint \"Dests join() tips\\n\", dests.join(tips, lsuffix='Dest', rsuffix='Tips')\n#用merge()执行内部连接时，更显示的方法如下\nprint \"Inner join with merge()\\n\", pd.merge(dests, tips, how='inner')\n#稍作修改便变成完全外部连接，缺失的数据变为NaN\nprint \"Outer join\\n\", pd.merge(dests, tips, how='outer')\n\n处理缺失的数据\n缺失的数据变为NaN(非数字)，还有一个类似的符号NaT(非日期). 可以使用pandas的两个函数来进行判断isnull(),notnull(), fillna()方法可以用一个标量值来替换缺失的数据。\nimport pandas as pd\nimport numpy as np\n\ndf = pd.read_csv('WHO_first9cols.csv')\n# Select first 3 rows of country and Net primary school enrolment ratio male (%)\ndf = df[['Country', df.columns[-2]]][:2]\nprint \"New df\\n\", df\nprint \"Null Values\\n\", pd.isnull(df)\nprint \"Total Null Values\\n\", pd.isnull(df).sum()\nprint \"Not Null Values\\n\", df.notnull()\nprint \"Last Column Doubled\\n\", 2 * df[df.columns[-1]]\nprint \"Last Column plus NaN\\n\", df[df.columns[-1]] + np.nan\nprint \"Zero filled\\n\", df.fillna(0)\n处理日期数据\nhttp://pandas.pydata.org/pand...各种频率(freq)短码对照表:\n\nB    business day frequency\nC    custom business day frequency (experimental)\nD    calendar day frequency\nW    weekly frequency\nM    month end frequency\nSM    semi-month end frequency (15th and end of month)\nBM    business month end frequency\nCBM    custom business month end frequency\nMS    month start frequency\nSMS    semi-month start frequency (1st and 15th)\nBMS    business month start frequency\nCBMS    custom business month start frequency\nQ    quarter end frequency\nBQ    business quarter endfrequency\nQS    quarter start frequency\nBQS    business quarter start frequency\nA    year end frequency\nBA    business year end frequency\nAS    year start frequency\nBAS    business year start frequency\nBH    business hour frequency\nH    hourly frequency\nT, min    minutely frequency\nS    secondly frequency\nL, ms    milliseconds\nU, us    microseconds\nN    nanoseconds\n\nimport pandas as pd\nfrom pandas.tseries.offsets import DateOffset\nimport sys\n\nprint \"Date range\", pd.date_range('1/1/1900', periods=42, freq='D')\n\ntry:\n   print \"Date range\", pd.date_range('1/1/1677', periods=4, freq='D')\nexcept:\n   etype, value, _ = sys.exc_info()\n   print \"Error encountered\", etype, value\n\noffset = DateOffset(seconds=2 ** 63/10 ** 9)\nmid = pd.to_datetime('1/1/1970')\nprint \"Start valid range\", mid - offset\nprint \"End valid range\", mid + offset\nprint pd.to_datetime(['1900/1/1', '1901.12.11'])\n\nprint \"With format\", pd.to_datetime(['19021112', '19031230'], format='%Y%m%d')\n\nprint \"Illegal date\", pd.to_datetime(['1902-11-12', 'not a date'])\nprint \"Illegal date coerced\", pd.to_datetime(['1902-11-12', 'not a date'], coerce=True)\n据透视表(pivot_table)\n数据透视表可以用来汇总数据。pivot_table()函数及相应的DataFrame方法。\nimport pandas as pd\nfrom numpy.random import seed\nfrom numpy.random import rand\nfrom numpy.random import random_integers\nimport numpy as np\n\nseed(42)\nN = 7\ndf = pd.DataFrame({\n   'Weather' : ['cold', 'hot', 'cold', 'hot',\n   'cold', 'hot', 'cold'],\n   'Food' : ['soup', 'soup', 'icecream', 'chocolate',\n   'icecream', 'icecream', 'soup'],\n   'Price' : 10 * rand(N), 'Number' : random_integers(1, 9, size=(N,))})\n\nprint \"DataFrame\\n\", df\n#cols指定需要聚合的列，aggfunc指定聚合函数。\nprint pd.pivot_table(df, cols=['Food'], aggfunc=np.sum)\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "7"}