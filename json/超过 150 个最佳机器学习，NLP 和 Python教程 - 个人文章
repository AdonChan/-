{"title": "超过 150 个最佳机器学习，NLP 和 Python教程 - 个人文章 ", "index": "python", "content": "作者：chen_h微信号 & QQ：862251340微信公众号：coderpai简书地址：http://www.jianshu.com/p/2be3...\n\n\n我把这篇文章分为四个部分：机器学习，NLP，Python 和 数学。我在每一部分都会包含一些关键主题，但是网上资料太广泛了，所以我不可能包括每一个可能的主题。\n如果你发现好的教程，请告诉我。在这篇文章中，我把每个主题的教程数量都是控制在五到六个，这些精选出来的教程都是非常重要的。每一个链接都会链接到别的链接，从而导致很多新的教程。\nMachine Learning\n\n\nMachine Learning is Fun! (medium.com/@ageitgey)\nMachine Learning Crash Course: Part I, Part II, Part III (Machine Learning at Berkeley)\n\nAn Introduction to Machine Learning Theory and Its Applications: A Visual Tutorial with Examples (toptal.com)\n\nA Gentle Guide to Machine Learning (monkeylearn.com)\n\nWhich machine learning algorithm should I use? (sas.com)\n\nActivation and Loss Functions\n\n\nSigmoid neurons (neuralnetworksanddeeplearning.com)\n\nWhat is the role of the activation function in a neural network? (quora.com)\n[Comprehensive list of activation functions in neural networks with pros/cons]12\n\n\nActivation functions and it’s types-Which is better? (medium.com)\n\nMaking Sense of Logarithmic Loss (exegetic.biz)\n\nLoss Functions (Stanford CS231n)\n\nL1 vs. L2 Loss function (rishy.github.io)\n\nThe cross-entropy cost function (neuralnetworksanddeeplearning.com)\n\nBias\n\n\nRole of Bias in Neural Networks (stackoverflow.com)\n\nBias Nodes in Neural Networks (makeyourownneuralnetwork.blogspot.com)\n\nWhat is bias in artificial neural network? (quora.com)\n\nPerceptron\n\n\nPerceptrons (neuralnetworksanddeeplearning.com)\n\nThe Perception (natureofcode.com)\n\nSingle-layer Neural Networks (Perceptrons) (dcu.ie)\n\nFrom Perceptrons to Deep Networks (toptal.com)\n\nRegression\n\n\nIntroduction to linear regression analysis (duke.edu)\n\nLinear Regression (ufldl.stanford.edu)\n\nLinear Regression (readthedocs.io)\n\nLogistic Regression (readthedocs.io)\n[Simple Linear Regression Tutorial for Machine Learning]29\n\n[Logistic Regression Tutorial for Machine Learning]30\n\n\nSoftmax Regression (ufldl.stanford.edu)\n\nGradient Descent\n\n\nLearning with gradient descent (neuralnetworksanddeeplearning.com)\n\nGradient Descent (iamtrask.github.io)\n\nHow to understand Gradient Descent algorithm (kdnuggets.com)\n[An overview of gradient descent optimization algorithms]35\n\n\nOptimization: Stochastic Gradient Descent (Stanford CS231n)\n\nGenerative Learning\n\n\nGenerative Learning Algorithms (Stanford CS229)\n\nA practical explanation of a Naive Bayes classifier (monkeylearn.com)\n\nSupport Vector Machines\n\n\nAn introduction to Support Vector Machines (SVM) (monkeylearn.com)\n\nSupport Vector Machines (Stanford CS229)\n\nLinear classification: Support Vector Machine, Softmax (Stanford 231n)\n\nBackpropagation\n\n\nYes you should understand backprop (medium.com/@karpathy)\n\nCan you give a visual explanation for the back propagation algorithm for neural networks? (github.com/rasbt)\n[How the backpropagation algorithm works]45\n\n\nBackpropagation Through Time and Vanishing Gradients (wildml.com)\n[A Gentle Introduction to Backpropagation Through Time]47\n\n\nBackpropagation, Intuitions (Stanford CS231n)\n\nDeep Learning\n\n\nDeep Learning in a Nutshell (nikhilbuduma.com)\n\nA Tutorial on Deep Learning (Quoc V. Le)\n\nWhat is Deep Learning? (machinelearningmastery.com)\n\nWhat’s the Difference Between Artificial Intelligence, Machine Learning, and Deep Learning? (nvidia.com)\n\nOptimization and Dimensionality Reduction\n\n\nSeven Techniques for Data Dimensionality Reduction (knime.org)\n\nPrincipal components analysis (Stanford CS229)\n\nDropout: A simple way to improve neural networks (Hinton @ NIPS 2012)\n\nHow to train your Deep Neural Network (rishy.github.io)\n\n\nLong Short Term Memory(LSTM) \n\n[A Gentle Introduction to Long Short-Term Memory Networks by the Experts]57\n\n\nUnderstanding LSTM Networks (colah.github.io)\n\nExploring LSTMs (echen.me)\n\nAnyone Can Learn To Code an LSTM-RNN in Python (iamtrask.github.io)\n\nConvolutional Neural Networks (CNNs)\n\n\nIntroducing convolutional networks (neuralnetworksanddeeplearning.com)\n[Deep Learning and Convolutional Neural Networks]62\n\n\nConv Nets: A Modular Perspective (colah.github.io)\n\nUnderstanding Convolutions (colah.github.io)\n\nRecurrent Neural Nets (RNNs)\n\n\nRecurrent Neural Networks Tutorial (wildml.com)\n\nAttention and Augmented Recurrent Neural Networks (distill.pub)\n[The Unreasonable Effectiveness of Recurrent Neural Networks]68\n\n\nA Deep Dive into Recurrent Neural Nets (nikhilbuduma.com)\n\nReinforcement Learning\n\n[Simple Beginner’s guide to Reinforcement Learning & its implementation]70\n\n\nA Tutorial for Reinforcement Learning (mst.edu)\n\nLearning Reinforcement Learning (wildml.com)\n\nDeep Reinforcement Learning: Pong from Pixels (karpathy.github.io)\n\nGenerative Adversarial Networks (GANs)\n\n\nWhat’s a Generative Adversarial Network? (nvidia.com)\n[Abusing Generative Adversarial Networks to Make 8-bit Pixel Art]75\n\n\nAn introduction to Generative Adversarial Networks (with code in TensorFlow) (aylien.com)\n\nGenerative Adversarial Networks for Beginners (oreilly.com)\n\nMulti-task Learning\n[An Overview of Multi-Task Learning in Deep Neural Networks]78\n\nNLP\n\n\nA Primer on Neural Network Models for Natural Language Processing (Yoav Goldberg)\n\nThe Definitive Guide to Natural Language Processing (monkeylearn.com)\n\nIntroduction to Natural Language Processing (algorithmia.com)\n\nNatural Language Processing Tutorial (vikparuchuri.com)\n\nNatural Language Processing (almost) from Scratch (arxiv.org)\n\nDeep Learning and NLP\n\n\nDeep Learning applied to NLP (arxiv.org)\n\nDeep Learning for NLP (without Magic) (Richard Socher)\n\nUnderstanding Convolutional Neural Networks for NLP (wildml.com)\n\nDeep Learning, NLP, and Representations (colah.github.io)\n\nEmbed, encode, attend, predict: The new deep learning formula for state-of-the-art NLP models (explosion.ai)\n[Understanding Natural Language with Deep Neural Networks Using Torch]89\n\n\nDeep Learning for NLP with Pytorch (pytorich.org)\n\nWord Vectors\n\n\nBag of Words Meets Bags of Popcorn (kaggle.com)\nOn word embeddings Part I, Part II, Part III (sebastianruder.com)\n\nThe amazing power of word vectors (acolyer.org)\n\nword2vec Parameter Learning Explained (arxiv.org)\nWord2Vec Tutorial — The Skip-Gram Model, [Negative Sampling]98\n\n\nEncoder-Decoder\n\n\nAttention and Memory in Deep Learning and NLP (wildml.com)\n\nSequence to Sequence Models (tensorflow.org)\n\nSequence to Sequence Learning with Neural Networks (NIPS 2014)\n\nMachine Learning is Fun Part 5: Language Translation with Deep Learning and the Magic of Sequences (medium.com/@ageitgey)\n[How to use an Encoder-Decoder LSTM to Echo Sequences of Random Integers]103\n\n\ntf-seq2seq (google.github.io)\n\nPython\n\n\n7 Steps to Mastering Machine Learning With Python (kdnuggets.com)\n\nAn example machine learning notebook (nbviewer.jupyter.org)\n\nExamples\n\n[How To Implement The Perceptron Algorithm From Scratch In Python]107\n\n\nImplementing a Neural Network from Scratch in Python (wildml.com)\n\nA Neural Network in 11 lines of Python (iamtrask.github.io)\n[Implementing Your Own k-Nearest Neighbour Algorithm Using Python]110\n\n\nDemonstration of Memory with a Long Short-Term Memory Network in Python (machinelearningmastery.com)\n\nHow to Learn to Echo Random Integers with Long Short-Term Memory Recurrent Neural Networks (machinelearningmastery.com)\n[How to Learn to Add Numbers with seq2seq Recurrent Neural Networks]113\n\n\nScipy and numpy\n\n\nScipy Lecture Notes (scipy-lectures.org)\n\nPython Numpy Tutorial (Stanford CS231n)\n\nAn introduction to Numpy and Scipy (UCSB CHE210D)\n\nA Crash Course in Python for Scientists (nbviewer.jupyter.org)\n\nscikit-learn\n\n\nPyCon scikit-learn Tutorial Index (nbviewer.jupyter.org)\n\nscikit-learn Classification Algorithms (github.com/mmmayo13)\n\nscikit-learn Tutorials (scikit-learn.org)\n\nAbridged scikit-learn Tutorials (github.com/mmmayo13)\n\nTensorflow\n\n\nTensorflow Tutorials (tensorflow.org)\n\nIntroduction to TensorFlow — CPU vs GPU (medium.com/@erikhallstrm)\n\nTensorFlow: A primer (metaflow.fr)\n\nRNNs in Tensorflow (wildml.com)\n\nImplementing a CNN for Text Classification in TensorFlow (wildml.com)\n\nHow to Run Text Summarization with TensorFlow (surmenok.com)\n\nPyTorch\n\n\nPyTorch Tutorials (pytorch.org)\n\nA Gentle Intro to PyTorch (gaurav.im)\n\nTutorial: Deep Learning in PyTorch (iamtrask.github.io)\n\nPyTorch Examples (github.com/jcjohnson)\n\nPyTorch Tutorial (github.com/MorvanZhou)\n\nPyTorch Tutorial for Deep Learning Researchers (github.com/yunjey)\n\nMath\n\n\nMath for Machine Learning (ucsc.edu)\n\nMath for Machine Learning (UMIACS CMSC422)\n\nLinear algebra\n\n\nAn Intuitive Guide to Linear Algebra (betterexplained.com)\n\nA Programmer’s Intuition for Matrix Multiplication (betterexplained.com)\n\nUnderstanding the Cross Product (betterexplained.com)\n\nUnderstanding the Dot Product (betterexplained.com)\n\nLinear Algebra for Machine Learning (U. of Buffalo CSE574)\n\nLinear algebra cheat sheet for deep learning (medium.com)\n\nLinear Algebra Review and Reference (Stanford CS229)\n\nProbability\n\n\nUnderstanding Bayes Theorem With Ratios (betterexplained.com)\n\nReview of Probability Theory (Stanford CS229)\n\nProbability Theory Review for Machine Learning (Stanford CS229)\n\nProbability Theory (U. of Buffalo CSE574)\n\nProbability Theory for Machine Learning (U. of Toronto CSC411)\n\nCalculus\n\n\nHow To Understand Derivatives: The Quotient Rule, Exponents, and Logarithms (betterexplained.com)\n[How To Understand Derivatives: The Product, Power & Chain Rules]150\n\n\nVector Calculus: Understanding the Gradient (betterexplained.com)\n\nDifferential Calculus (Stanford CS224n)\n\nCalculus Overview (readthedocs.io)\n\n\n作者：chen_h微信号 & QQ：862251340简书地址：http://www.jianshu.com/p/2be3...\nCoderPai 是一个专注于算法实战的平台，从基础的算法到人工智能算法都有设计。如果你对算法实战感兴趣，请快快关注我们吧。加入AI实战微信群，AI实战QQ群，ACM算法微信群，ACM算法QQ群。长按或者扫描如下二维码，关注 “CoderPai” 微信号（coderpai）\n\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "6"}