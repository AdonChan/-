{"title": "基于 asyncio 的Python异步爬虫框架 - 个人文章 ", "index": "网页爬虫,python爬虫,python", "content": "aspider\nA web scraping micro-framework based on asyncio.\n轻量异步爬虫框架aspider，基于asyncio，目的是让编写单页面爬虫更方便更迅速，利用异步特性让爬虫更快（减少在IO上的耗时）\n介绍\npip install aspider\nItem\n对于单页面，只要实现框架定义的 Item 就可以实现对目标数据的抓取：\nimport asyncio\n\nfrom aspider import Request\n\nrequest = Request(\"https://news.ycombinator.com/\")\nresponse = asyncio.get_event_loop().run_until_complete(request.fetch())\n\n# Output\n# [2018-07-25 11:23:42,620]-Request-INFO  <GET: https://news.ycombinator.com/>\n# <Response url[text]: https://news.ycombinator.com/ status:200 metadata:{}>\nSpider\n对于页面目标较多，需要进行深度抓取时，Spider就派上用场了\nimport aiofiles\n\nfrom aspider import AttrField, TextField, Item, Spider\n\n\nclass HackerNewsItem(Item):\n    target_item = TextField(css_select='tr.athing')\n    title = TextField(css_select='a.storylink')\n    url = AttrField(css_select='a.storylink', attr='href')\n\n    async def clean_title(self, value):\n        return value\n\n\nclass HackerNewsSpider(Spider):\n    start_urls = ['https://news.ycombinator.com/', 'https://news.ycombinator.com/news?p=2']\n\n    async def parse(self, res):\n        items = await HackerNewsItem.get_items(html=res.body)\n        for item in items:\n            async with aiofiles.open('./hacker_news.txt', 'a') as f:\n                await f.write(item.title + '\\n')\n\n\nif __name__ == '__main__':\n    HackerNewsSpider.start()\n支持JS的加载\nRequest类也可以很好的工作并返回内容，这里以这个为例演示下抓取需要加载js才可以抓取的例子：\nrequest = Request(\"https://www.jianshu.com/\", load_js=True)\nresponse = asyncio.get_event_loop().run_until_complete(request.fetch())\nprint(response.body)\n如果喜欢，可以玩玩看，项目Github地址：aspider\n\n                ", "mainLikeNum": ["3 "], "mainBookmarkNum": "2"}