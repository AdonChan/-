{"title": "Python中的加权随机 - 扑克 ", "index": "python", "content": "我们平时比较多会遇到的一种情景是从一堆的数据中随机选择一个, 大多数我们使用random就够了, 但是假如我们要选取的这堆数据分别有自己的权重, 也就是他们被选择的概率是不一样的, 在这种情况下,  就需要使用加权随机来处理这些数据\n\n1. 简单线性方法\n\n下面是一种简单的方案, 传入权重的列表(weights), 然后会返回随机结果的索引值(index), 比如我们传入[2, 3, 5], 那么就会随机的返回0(概率0.2), 1(概率0.3), 2(概率0.5)\n\n简单的思路就是把所有的权重加和, 然后随机一个数, 看看落在哪个区间\n\nimport random\n\ndef weighted_choice(weights):\n    totals = []\n    running_total = 0\n\n    for w in weights:\n        running_total += w\n        totals.append(running_total)\n\n    rnd = random.random() * running_total\n    for i, total in enumerate(totals):\n        if rnd < total:\n            return i\n\n\n2. 加速搜索\n\n上面这个方法看起来非常简单, 已经可以完成我们所要的加权随机, 然是最后的这个for循环貌似有些啰嗦, Python有个内置方法bisect可以帮我们加速这一步\n\nimport random\nimport bisect\n\ndef weighted_choice(weights):\n    totals = []\n    running_total = 0\n\n    for w in weights:\n        running_total += w\n        totals.append(running_total)\n\n    rnd = random.random() * running_total\n    return bisect.bisect_right(totals, rnd)\n\n\nbisect方法可以帮我们查找rnd在totals里面应该插入的位置, 两个方法看起来差不多, 但是第二个会更快一些, 取决于weights这个数组的长度, 如果长度大于1000, 大约会快30%左右\n\n3. 去掉临时变量\n\n其实在这个方法里面totals这个数组并不是必要的, 我们调整下策略, 就可以判断出weights中的位置\n\ndef weighted_choice(weights):\n  rnd = random.random() * sum(weights)\n  for i, w in enumerate(weights):\n      rnd -= w\n      if rnd < 0:\n          return i\n\n\n这个方法比第二种方法竟然快了一倍, 当然, 从算法角度角度, 复杂度是一样的, 只不过我们把赋值临时变量的功夫省下来了, 其实如果传进来的weights是已经按照从大到小排序好的话, 速度会更快, 因为rnd递减的速度最快(先减去最大的数)\n\n4. 更多的随机数\n\n如果我们使用同一个权重数组weights, 但是要多次得到随机结果, 多次的调用weighted_choice方法, totals变量还是有必要的, 提前计算好它, 每次获取随机数的消耗会变得小很多\n\nclass WeightedRandomGenerator(object):\n    def __init__(self, weights):\n        self.totals = []\n        running_total = 0\n\n        for w in weights:\n            running_total += w\n            self.totals.append(running_total)\n\n    def next(self):\n        rnd = random.random() * self.totals[-1]\n        return bisect.bisect_right(self.totals, rnd)\n\n    def __call__(self):\n        return self.next()\n\n\n在调用次数超过1000次的时候, WeightedRandomGenerator的速度是weighted_choice的100倍\n\n所以我们在对同一组权重列表进行多次计算的时候选择方法4, 如果少于100次, 则使用方法3\n\n5. 使用accumulate\n\n在python3.2之后, 提供了一个itertools.accumulate方法, 可以快速的给weights求累积和\n\n>>>> from itertools import accumulate\n>>>> data  = [2, 3, 5, 10]\n>>>> list(accumulate(data))\n[2, 5, 10, 20]\n\n\n如果你有更好的方法, 欢迎在留言区讨论\n\n参考文章: Weighted random generation in Python\n\n本文发表在致趣技术团队博客, 加入致趣\n\n                ", "mainLikeNum": ["2 "], "mainBookmarkNum": "11"}