{"title": "Python库大全（涵盖了Python应用的方方面面），建议收藏留用！ - 个人文章 ", "index": "python,大数据,服务器", "content": "学Python，想必大家都是从爬虫开始的吧。毕竟网上类似的资源很丰富，开源项目也非常多。\nPython学习网络爬虫主要分3个大的版块：抓取，分析，存储\n当我们在浏览器中输入一个url后回车，后台会发生什么？\n简单来说这段过程发生了以下四个步骤：\n\n查找域名对应的IP地址。\n向IP对应的服务器发送请求。\n服务器响应请求，发回网页内容。\n浏览器解析网页内容。\n\n网络爬虫要做的，简单来说，就是实现浏览器的功能。通过指定url，直接返回给用户所需要的数据，而不需要一步步人工去操纵浏览器获取。\n抓取这一步，你要明确要得到的内容是什么？是HTML源码，还是Json格式的字符串等。将得到内容逐一解析就好。具体的如何解析，以及如何处理数据，文章后面提供了非常详细的且功能强大的开源库列表。\n当然了，爬去别人家的数据，很有可能会遭遇反爬虫机制的，怎么办？使用代理。\n适用情况：限制IP地址情况，也可解决由于“频繁点击”而需要输入验证码登陆的情况。\n这种情况最好的办法就是维护一个代理IP池，网上有很多免费的代理IP，良莠不齐，可以通过筛选找到能用的。\n对于“频繁点击”的情况，我们还可以通过限制爬虫访问网站的频率来避免被网站禁掉。\n有些网站会检查你是不是真的浏览器访问，还是机器自动访问的。这种情况，加上User-Agent，表明你是浏览器访问即可。有时还会检查是否带Referer信息还会检查你的Referer是否合法，一般再加上Referer。也就是伪装成浏览器，或者反“反盗链”。\n对于网站有验证码的情况，我们有三种办法：\n\n使用代理，更新IP。\n使用cookie登陆。\n验证码识别。\n\n接下来我们重点聊聊验证码识别。这个python   q-u-n 227--435---450就是小编期待大家一起交流讨论，各种入门资料啊，进阶资料啊，框架资料啊 免费领取\n可以利用开源的Tesseract-OCR系统进行验证码图片的下载及识别，将识别的字符传到爬虫系统进行模拟登陆。当然也可以将验证码图片上传到打码平台上进行识别。如果不成功，可以再次更新验证码识别，直到成功为止。\n好了，爬虫就简单聊到这儿，有兴趣的朋友可以去网上搜索更详细的内容。\n文末附上本文重点：实用Python库大全。\n网络\nurllib -网络库(stdlib)。\nrequests -网络库。\ngrab – 网络库（基于pycurl）。\npycurl – 网络库（绑定libcurl）。\nurllib3 – Python HTTP库，安全连接池、支持文件post、可用性高。\nhttplib2 – 网络库。\nRoboBrowser – 一个简单的、极具Python风格的Python库，无需独立的浏览器即可浏览网页。\nMechanicalSoup -一个与网站自动交互Python库。\nmechanize -有状态、可编程的Web浏览库。\nsocket – 底层网络接口(stdlib)。\n网络爬虫框架\ngrab – 网络爬虫框架（基于pycurl/multicur）。\nscrapy – 网络爬虫框架。\npyspider – 一个强大的爬虫系统。\ncola – 一个分布式爬虫框架。\nHTML/XML解析器\nlxml – C语言编写高效HTML/ XML处理库。支持XPath。\ncssselect – 解析DOM树和CSS选择器。\npyquery – 解析DOM树和jQuery选择器。\nBeautifulSoup – 低效HTML/ XML处理库，纯Python实现。\nhtml5lib – 根据WHATWG规范生成HTML/ XML文档的DOM。该规范被用在现在所有的浏览器上。\nfeedparser – 解析RSS/ATOM feeds。\nMarkupSafe – 为XML/HTML/XHTML提供了安全转义的字符串。\n文本处理\n用于解析和操作简单文本的库。\ndifflib – （Python标准库）帮助进行差异化比较。\nLevenshtein – 快速计算Levenshtein距离和字符串相似度。\nfuzzywuzzy – 模糊字符串匹配。\nesmre – 正则表达式加速器。\nftfy – 自动整理Unicode文本，减少碎片化。\n自然语言处理\n处理人类语言问题的库。\nNLTK -编写Python程序来处理人类语言数据的最好平台。\nPattern – Python的网络挖掘模块。他有自然语言处理工具，机器学习以及其它。\nTextBlob – 为深入自然语言处理任务提供了一致的API。是基于NLTK以及Pattern的巨人之肩上发展的。\njieba – 中文分词工具。\nSnowNLP – 中文文本处理库。\nloso – 另一个中文分词库。\n浏览器自动化与仿真\nselenium – 自动化真正的浏览器（Chrome浏览器，火狐浏览器，Opera浏览器，IE浏览器）。\nGhost.py – 对PyQt的webkit的封装（需要PyQT）。\nSpynner – 对PyQt的webkit的封装（需要PyQT）。\nSplinter – 通用API浏览器模拟器（selenium web驱动，Django客户端，Zope）。\n多重处理\nthreading – Python标准库的线程运行。对于I/O密集型任务很有效。对于CPU绑定的任务没用，因为python GIL。\nmultiprocessing – 标准的Python库运行多进程。\ncelery – 基于分布式消息传递的异步任务队列/作业队列。\nconcurrent-futures – concurrent-futures 模块为调用异步执行提供了一个高层次的接口。\n异步\n异步网络编程库\nasyncio – （在Python 3.4 +版本以上的 Python标准库）异步I/O，时间循环，协同程序和任务。\nTwisted – 基于事件驱动的网络引擎框架。\nTornado – 一个网络框架和异步网络库。\npulsar – Python事件驱动的并发框架。\ndiesel – Python的基于绿色事件的I/O框架。\ngevent – 一个使用greenlet 的基于协程的Python网络库。\neventlet – 有WSGI支持的异步框架。\nTomorrow – 异步代码的奇妙的修饰语法。\n队列\ncelery – 基于分布式消息传递的异步任务队列/作业队列。\nhuey – 小型多线程任务队列。\nmrq – Mr. Queue – 使用redis & Gevent 的Python分布式工作任务队列。\nRQ – 基于Redis的轻量级任务队列管理器。\nsimpleq – 一个简单的，可无限扩展，基于Amazon SQS的队列。\npython-gearman – Gearman的Python API。\n云计算\npicloud – 云端执行Python代码。\ndominoup.com – 云端执行R，Python和matlab代码\n网页内容提取\n提取网页内容的库。\nHTML页面的文本和元数据\nnewspaper – 用Python进行新闻提取、文章提取和内容策展。\nhtml2text – 将HTML转为Markdown格式文本。\npython-goose – HTML内容/文章提取器。\nlassie – 人性化的网页内容检索工具\nWebSocket\n用于WebSocket的库。\nCrossbar – 开源的应用消息传递路由器（Python实现的用于Autobahn的WebSocket和WAMP）。\nAutobahnPython – 提供了WebSocket协议和WAMP协议的Python实现并且开源。\nWebSocket-for-Python – Python 2和3以及PyPy的WebSocket客户端和服务器库。\nDNS解析\ndnsyo – 在全球超过1500个的DNS服务器上检查你的DNS。\npycares – c-ares的接口。c-ares是进行DNS请求和异步名称决议的C语言库。\n计算机视觉\nOpenCV – 开源计算机视觉库。\nSimpleCV – 用于照相机、图像处理、特征提取、格式转换的简介，可读性强的接口（基于OpenCV）。\nmahotas – 快速计算机图像处理算法（完全使用 C++ 实现），完全基于 numpy 的数组作为它的数据类型。\n代理服务器\nshadowsocks – 一个快速隧道代理，可帮你穿透防火墙（支持TCP和UDP，TFO，多用户和平滑重启，目的IP黑名单）。\ntproxy – tproxy是一个简单的TCP路由代理（第7层），基于Gevent，用Python进行配置。\n另：Python有很多Web开发框架,大而全的开发框架非Django莫属,用得也最广泛.有很多公司有使用Django框架,如某狐,某讯等。以简洁著称的web.py,flask都非常易于上手,以异步高性能著称的tornado,源代码写得美如画,知乎,Quora都在用。\n本文作者：q1622479435阅读原文本文为云栖社区原创内容，未经允许不得转载。\n\n                ", "mainLikeNum": ["30 "], "mainBookmarkNum": "61"}