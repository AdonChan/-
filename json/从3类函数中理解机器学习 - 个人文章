{"title": "从3类函数中理解机器学习 - 个人文章 ", "index": "javascript,python", "content": "3类函数\n凸函数\n\n凹函数\n\n其他类别函数\n\n\n函数性质\n\n凸函数：凸函数的任何极小值也是最小值。严格凸函数最多有一个最小值。\n凹函数：凹函数的任何极大值也是最大值。严格凹函数最多有一个最大值。\n非凹凸函数：有多个极大极小值，只有局部最优解\n\n\n机器学习的任务\n机器学习的任务可以理解成下图：从一堆输入，经过处理，得到想要的输出\n\n\n这个机器学习任务流程，可以抽象成函数：y=f(x)，x为输入，y为理想的输出\n于是乎，机器学习就可以看作是求函数y=f(x)的最优解了\n\n\n损失函数（ loss）的引入\n\n所谓的损失函数，就是用来衡量预测值和实际值之间的误差\n我们的目标就是，找到使损失函数达到最小值时候的参数\n\n\n过拟合和欠拟合问题\n判断机器学习是否执行得好，有以下2个目标：\n-- 使训练错误率尽可能低（可以通过神经网络，函数逼近的方法）-- 使训练错误率与测试错误率的差距尽可能小（可以用正则化的方法）\n\n欠拟合：训练错误率比较高\n过拟合：测试错误率与训练错误率差距比较大\n\n\n训练\n\n我们的目标是，找到使损失函数达到最小值时候的参数\n此时，我们可以对损失函数进行求导（导数也成为梯度），寻找极值，常用的方法有：随机梯度下降（SGD）\n训练就是不断寻找使损失函数达到最小值时候的参数的过程，因为一般的函数具有多个局部最优解\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}