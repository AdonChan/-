{"title": "Python爬虫实战（1）：爬取Drupal论坛帖子列表 - 一起学习python网络爬虫 ", "index": "网页爬虫,编程,python", "content": "\n1，引言\n在《Python即时网络爬虫项目: 内容提取器的定义》一文我们定义了一个通用的python网络爬虫类，期望通过这个项目节省程序员一半以上的时间。本文将用一个实例讲解怎样使用这个爬虫类。我们将爬集搜客老版论坛，是一个用Drupal做的论坛。\n2，技术要点\n我们在多个文章都在说：节省程序员的时间。关键是省去编写提取规则的时间，尤其是调试规则的正确性很花时间。在《1分钟快速生成用于网页内容提取的xslt》演示了怎样快速生成提取规则，接下来我们再通过GooSeeker的api接口实时获得提取规则，对网页进行抓取。本示例主要有如下两个技术要点：\n\n通过GooSeeker API实时获取用于页面提取的xslt\n使用GooSeeker提取器gsExtractor从网页上一次提取多个字段内容。\n\n3，python源代码\n# _*_coding:utf8_*_\n# crawler_gooseeker_bbs.py\n# 版本: V1.0\n\nfrom urllib import request\nfrom lxml import etree\nfrom gooseeker import GsExtractor\n\n# 访问并读取网页内容\nurl = \"http://www.gooseeker.com/cn/forum/7\"\nconn = request.urlopen(url)\ndoc = etree.HTML(conn.read())\n\nbbsExtra = GsExtractor() \nbbsExtra.setXsltFromAPI(\"31d24931e043e2d5364d03b8ff9cc77e\" , \"gooseeker_bbs_xslt\")   # 设置xslt抓取规则，第一个参数是app key，请到会员中心申请\nresult = bbsExtra.extract(doc)   # 调用extract方法提取所需内容\n\nprint(str(result))\n\n源代码下载位置请看文章末尾的GitHub源。\n4，抓取结果\n运行上节的代码，即可在控制台打印出提取结果，是一个xml文件，如果加上换行缩进，内容如下图：\n5，相关文档\n1， Python即时网络爬虫项目: 内容提取器的定义\n6，集搜客GooSeeker开源代码下载源\n1， GooSeeker开源Python网络爬虫GitHub源\n7，文档修改历史\n\n2016-06-06：V1.0\n2016-06-06：V2.0\n2016-06-06：V2.1，增加GitHub下载源\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "10"}