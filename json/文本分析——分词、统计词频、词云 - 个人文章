{"title": "文本分析——分词、统计词频、词云 - 个人文章 ", "index": "数据分析,python", "content": "导入包\nimport os\nimport sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport re\nfrom pandas import Series, DataFrame  \n\nimport string\nimport re\nimport jieba\nimport jieba.analyse\nimport datetime\nfrom wordcloud import WordCloud, ImageColorGenerator\nimport codecs\n\n导入文件和数据\ngongdan = pd.read_excel('Gongdan.xlsx')\n\n数据预处理\ngongdan['content'] = [str(i) for i in gongdan['content']]\ngongdan['content'] = [''.join(re.findall(u'[\\u4e00-\\u9fff]+', i)) for i in gongdan['content']]\nindexs = list(gongdan['content'][pd.isnull(gongdan['content'])].index)\ngongdan = gongdan.drop(indexs)\nindexs = list(gongdan['content'][gongdan['content']==''].index)\ngongdan = gongdan.drop(indexs)\n\ncontent = gongdan['content']\n\ncont = ''.join(content)\ncont = ''.join(re.findall(u'[\\u4e00-\\u9fa5]+', cont))\n\n分词并去除停用词\nstopwords = set()\nfr = codecs.open('stopwords.txt', 'r', 'utf-8')\nfor word in fr:\n   stopwords.add(str(word).strip())\nfr.close()\n\njieba.load_userdict(\"dict.txt\")\ntext = list(jieba.cut(cont, cut_all=False, HMM=True))\ntext = list(filter(lambda x: x not in stopwords, text))\ntext = [str(i) for i in text if i != ' ']\n\nTfidf 算法\nfrom sklearn import feature_extraction\nfrom sklearn.feature_extraction.text import TfidfTransformer  \nfrom sklearn.feature_extraction.text import CountVectorizer  \n\ntest = ' '.join(text)\ntlist = []\ntlist.append(test)\n\nvectorizer=CountVectorizer()#该类会将文本中的词语转换为词频矩阵，矩阵元素a[i][j] 表示j词在i类文本下的词频\ntransformer = TfidfTransformer()#该类会统计每个词语的tf-idf权值\ntfidf = transformer.fit_transform(vectorizer.fit_transform(tlist))  #第一个fit_transform是计算tf-idf，第二个fit_transform是将文本转为词频矩阵  \n\nword=vectorizer.get_feature_names()#获取词袋模型中的所有词语  \nweight=tfidf.toarray()#将tf-idf矩阵抽取出来，元素a[i][j]表示j词在i类文本中的tf-idf权重  \ntfidf_list = {}\nfor i in range(len(weight)):#打印每类文本的tf-idf词语权重，第一个for遍历所有文本，第二个for便利某一类文本下的词语权重  \n    for j in range(len(word)):  \n        tfidf_list[word[j]] = weight[i][j]\n\n词云\nfont_path = 'yahei.ttf'\n\nfrom PIL import Image\nback_coloring = np.array(Image.open('circle.jpg'))\n\nwc = WordCloud(font_path=font_path,  # 设置字体\n               background_color=\"white\",  # 背景颜色\n               max_words=60,  # 词云显示的最大词数\n               mask=back_coloring,  # 设置背景图片\n               stopwords=stopwords,\n               max_font_size=100,  # 字体最大值\n               random_state=42,\n               width=1000, height=860, margin=2,# 设置图片默认的大小,但是如果使用背景图片的话,那么保存的图片大小将会按照其大小保存,margin为词语边缘距离\n#               prefer_horizontal=1,\n               )\n\nwc.generate_from_frequencies(tfidf_list)\n\nplt.imshow(wc, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.figure()\nwc.to_file(\"w.png\")\n\n# create coloring from image\nimage_colors = ImageColorGenerator(back_coloring)\n# recolor wordcloud and show\n# we could also give color_func=image_colors directly in the constructor\nplt.imshow(wc.recolor(color_func=image_colors), interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.figure()\nplt.imshow(back_coloring, cmap=plt.cm.gray, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n\n\n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "1"}