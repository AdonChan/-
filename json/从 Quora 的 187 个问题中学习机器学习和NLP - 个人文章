{"title": "从 Quora 的 187 个问题中学习机器学习和NLP - 个人文章 ", "index": "python", "content": "作者：chen_h微信号 & QQ：862251340微信公众号：coderpai简书地址：http://www.jianshu.com/p/ac18...\n\n\nQuora 已经变成了一个获取重要资源的有效途径。许多的顶尖研究人员都会积极的在现场回答问题。\n以下是一些在 Quora 上有关 AI 的主题。如果你已经在 Quora 上面注册了账号，你可以订阅这些主题。\n\n\nComputer-Science (5.6M followers)\n\nMachine-Learning (1.1M followers)\n\nArtificial-Intelligence (635K followers)\n\nDeep-Learning (167K followers)\n\nNatural-Language-Processing (155K followers)\n\nClassification-machine-learning (119K followers)\n\nArtificial-General-Intelligence (82K followers)\n\nConvolutional-Neural-Networks-CNNs (25K followers)\n\nComputational-Linguistics (23K followers)\n\nRecurrent-Neural-Networks (17.4K followers)\n\n虽然 Quora 有许多主题的常见问题（FAQ）页面（比如，这是一个机器学习的 FAQ），但是这些 FAQ 都是非常不全面的，或者不够精致。在这篇文章中，我试图做一个更加全面的有关机器学习和NLP问题的FAQ。\nQuora 中的问答没有那么有结构性，很多对问题的回答都是非常不尽如人意。所以，我们尽量去整理一些好的问题和一些相关的好的问答。\nMachine Learning\n\nHow do I learn machine learning?\nWhat is machine learning?\nWhat is machine learning in layman’s terms?\nWhat is the difference between statistics and machine learning?\nWhat machine learning theory do I need to know in order to be a successful machine learning practitioner?\nWhat are the top 10 data mining or machine learning algorithms?\nWhat exactly is a “hyperparameter” in machine learning terminology?\nHow does a machine-learning engineer decide which neural network architecture (feed-forward, recurrent or CNN) to use to solve their problem?\nWhat’s the difference between gradient descent and stochastic gradient descent?\nHow can I avoid overfitting?\nWhat is the role of the activation function in a neural network?\nWhat is the difference between a cost function and a loss function in machine learning?\nWhat is the difference between a parametric learning algorithm and a nonparametric learning algorithm?\nWhat is regularization in machine learning?\nWhat is the difference between L1 and L2 regularization?\nWhat is the difference between Dropout and Batch Normalization?\nWhat is an intuitive explanation for PCA?\nWhen and where do we use SVD?\nWhat is an intuitive explanation of the relation between PCA and SVD?\nWhich is your favorite Machine Learning algorithm?\nWhat is the future of machine learning?\nWhat are the Top 10 problems in Machine Learning for 2017?\n\nClassification\n\nWhat are the advantages of different classification algorithms?\nWhat are the advantages of using a decision tree for classification?\nWhat are the disadvantages of using a decision tree for classification?\nWhat are the advantages of logistic regression over decision trees?\nHow does randomization in a random forest work?\nWhich algorithm is better for non linear classification?\nWhat is the difference between Linear SVMs and Logistic Regression?\nHow can l apply an SVM for categorical data?\nHow do I select SVM kernels?\nHow is root mean square error (RMSE) and classification related?\nWhy is “naive Bayes” naive?\n\nRegression\n\nHow would linear regression be described and explained in layman’s terms?\nWhat is an intuitive explanation of a multivariate regression?\nWhy is logistic regression considered a linear model?\nLogistic Regression: Why sigmoid function?\nWhen should we use logistic regression and Neural Network?\nHow are linear regression and gradient descent related?\nWhat is the intuition behind SoftMax function?\nWhat is softmax regression?\n\nSupervised Learning\n\nWhat is supervised learning?\nWhat does “supervision” exactly mean in the context of supervised machine learning?\nWhy isn’t supervised machine learning more automated?\nWhat are the advantages and disadvantages of a supervised learning machine?\nWhat are the main supervised machine learning methods?\nWhat is the difference between supervised and unsupervised learning algorithms?\n\nReinforcement Learning\n\nHow do I learn reinforcement learning?\nWhat’s the best way and what are the best resources to start learning about deep reinforcement learning?\nWhat is the difference between supervised learning and reinforcement learning?\nHow does one learn a reward function in Reinforcement Learning (RL)?\nWhat is the Future of Deep Reinforcement Learning (DL + RL)?\nIs it possible to use reinforcement learning to solve any supervised or unsupervised problem?\nWhat are some practical applications of reinforcement learning?\nWhat is the difference between Q-learning and R-learning?\nIn what way can Q-learning and neural networks work together?\n\nUnsupervised Learning\n\nWhy is unsupervised learning important?\nWhat is the future of deep unsupervised learning?\nWhat are some issues with Unsupervised Learning?\nWhat is unsupervised learning with example?\nWhy could generative models help with unsupervised learning?\nWhat are some recent and potentially upcoming breakthroughs in unsupervised learning?\nCan neural networks be used to solve unsupervised learning problems?\nWhat is the state of the art of Unsupervised Learning, and is human-likeUnsupervised Learning possible in the near future?\nWhy is reinforcement learning not considered unsupervised learning?\n\nDeep Learning\n\nWhat is deep learning?\nWhat is the difference between deep learning and usual machine learning?\nAs a beginner, how should I study deep learning?\nWhat are the best resources to learn about deep learning?\nWhat is the difference between deep learning and usual machine learning?\nWhat’s the most effective way to get started with Deep Learning?\nIs there something that Deep Learning will never be able to learn?\nWhat are the limits of deep learning?\nWhat is next for deep learning?\nWhat other ML areas can replace deep learning in the future?\nWhat is the best back propagation (deep learning) presentation for dummies?\nDoes anyone ever use a softmax layer mid-neural network rather than at the end?\nWhat’s the difference between backpropagation and backpropagation through time?\nWhat is the best visual explanation for the back propagation algorithm for neural networks?\nWhat is the practical usage of batch normalization in neural networks?\nIn layman’s terms, what is batch normalisation, what does it do, and why does it work so well?\nDoes using Batch Normalization reduce the capacity of a deep neural network?\nWhat is an intuitive explanation of Deep Residual Networks?\nIs fine tuning a pre-trained model equivalent to transfer learning?\nWhat would be a practical use case for Generative models?\nIs cross-validation heavily used in Deep Learning or is it too expensive to be used?\nWhat is the importance of Deep Residual Networks?\nWhere is Sparsity important in Deep Learning?\nWhy are Autoencoders considered a failure?\nIn deep learning, why don’t we use the whole training set to compute the gradient?\n\nConvolutional Neural Networks\n\nWhat is a convolutional neural network?\nWhat is an intuitive explanation for convolution?\nHow do convolutional neural networks work?\nHow long will it take for me to go from machine learning basics to convolutional neural network?\nWhy are convolutional neural networks well-suited for image classification problems?\nIs a pooling layer necessary in CNN? Can it be replaced by convolution?\nHow can the filters used in Convolutional Neural Networks be optimized or reduced in size?\nIs the number of hidden layers in a convolutional neural network dependent on size of data set?\nHow can convolutional neural networks be used for non-image data?\nCan I use Convolution neural network to classify small number of data, 668 images?\nWhy are CNNs better at classification than RNNs?\nWhat is the difference between a convolutional neural network and a multilayer perceptron?\nWhat makes convolutional neural network architectures different?\nWhat’s an intuitive explanation of 1x1 convolution in ConvNets?\nWhy does the convolutional neural network have higher accuracy, precision, and recall rather than other methods like SVM, KNN, and Random Forest?\nHow can I train Convolutional Neural Networks (CNN) with non symmetric images of different sizes?\nHow can l choose the dimensions of my convolutional filters and pooling in convolutional neural network?\nWhy would increasing the amount of training data decrease the performance of a convolutional neural network?\nHow can l explain that applying max-pooling/subsampling in CNN doesn’t cause information loss?\nHow do Convolutional Neural Networks develop more complex features?\nWhy don’t they use activation functions in some CNNs for some last convolution layers?\nWhat methods are used to increase the inference speed of convolutional neural networks?\nWhat is the usefulness of batch normalization in very deep convolutional neural network?\nWhy do we use fully connected layer at the end of a CNN instead of convolution layers?\nWhat may be the cause of this training loss curve for a convolution neural network?\nThe convolutional neural network I’m trying to train is settling at a particular training loss value and a training accuracy just after a few epochs. What can be the possible reasons?\nWhy do we use shared weights in the convolutional layers of CNN?\nWhat are the advantages of Fully Convolutional Networks over CNNs?\nHow is Fully Convolutional Network (FCN) different from the original Convolutional Neural Network (CNN)?\n\nRecurrent Neural Networks\n\nArtificial Intelligence: What is an intuitive explanation for recurrent neural networks?\nHow are RNNs storing ‘memory’?\nWhat are encoder-decoder models in recurrent neural networks?\nWhy do Recurrent Neural Networks (RNN) combine the input and hidden state together and not seperately?\nWhat is an intuitive explanation of LSTMs and GRUs?\nAre GRU (Gated Recurrent Unit) a special case of LSTM?\nHow many time-steps can LSTM RNNs remember inputs for?\nHow does attention model work using LSTM?\nHow do RNNs differ from Markov Chains?\nFor modelling sequences, what are the pros and cons of using Gated Recurrent Units in place of LSTMs?\nWhat is exactly the attention mechanism introduced to RNN (recurrent neural network)? It would be nice if you could make it easy to understand!\nIs there any intuitive or simple explanation for how attention works in the deep learning model of an LSTM, GRU, or neural network?\nWhy is it a problem to have exploding gradients in a neural net (especially in an RNN)?\nFor a sequence-to-sequence model in RNN, does the input have to contain only sequences or can it accept contextual information as well?\nCan “generative adversarial networks” be used in sequential data in recurrent neural networks? How effective would they be?\nWhat is the difference between states and outputs in LSTM?\nWhat is the advantage of combining Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN)?\nWhich is better for text classification: CNN or RNN?\nHow are recurrent neural networks different from convolutional neural networks?\n\nNatural Language Processing\n\nAs a beginner in Natural Language processing, from where should I start?\nWhat is the relation between sentiment analysis, natural language processing and machine learning?\nWhat is the current state of the art in natural language processing?\nWhat is the state of the art in natural language understanding?\nWhich publications would you recommend reading for someone interested in natural language processing?\nWhat are the basics of natural language processing?\nCould you please explain the choice constraints of the pros/cons while choosing Word2Vec, GloVe or any other thought vectors you have used?\nHow do you explain NLP to a layman?\nHow do I explain NLP, text mining, and their difference in layman’s terms?\nWhat is the relationship between N-gram and Bag-of-words in natural language processing?\nIs deep learning suitable for NLP problems like parsing or machine translation?\nWhat is a simple explanation of a language model?\nWhat is the definition of word embedding (word representation)?\nHow is Computational Linguistics different from Natural Language Processing?\nNatural Language Processing: What is a useful method to generate vocabulary for large corpus of data?\nHow do I learn Natural Language Processing?\nNatural Language Processing: What are good algorithms related to sentiment analysis?\nWhat makes natural language processing difficult?\nWhat are the ten most popular algorithms in natural language processing?\nWhat is the most interesting new work in deep learning for NLP in 2017?\nHow is word2vec different from the RNN encoder decoder?\nHow does word2vec work?\nWhat’s the difference between word vectors, word representations and vector embeddings?\nWhat are some interesting Word2Vec results?\nHow do I measure the semantic similarity between two documents?\nWhat is the state of the art in word sense disambiguation?\nWhat is the main difference between word2vec and fastText?\nIn layman terms, how would you explain the Skip-Gram word embedding model in natural language processing (NLP)?\nIn layman’s terms, how would you explain the continuous bag of words (CBOW) word embedding technique in natural language processing (NLP)?\nWhat is natural language processing pipeline?\nWhat are the available APIs for NLP (Natural Language Processing)?\nHow does perplexity function in natural language processing?\nHow is deep learning used in sentiment analysis?\n\nGenerative Adversarial Networks\n\nWas Jürgen Schmidhuber right when he claimed credit for GANs at NIPS 2016?\nCan “generative adversarial networks” be used in sequential data in recurrent neural networks? How effective would they be?\nWhat are the (existing or future) use cases where using Generative Adversarial Network is particularly interesting?\nCan autoencoders be considered as generative models?\nWhy are two separate neural networks used in Generative Adversarial Networks?\nWhat is the advantage of generative adversarial networks compared with other generative models?\nWhat are some exciting future applications of Generative Adversarial Networks?\nDo you have any ideas on how to get GANs to work with text?\nIn what way are Adversarial Networks related or different to Adversarial Training?\nWhat are the pros and cons of using generative adversarial networks (a type of neural network)?\nCan Generative Adversarial networks use multi-class labels?\n\n\n作者：chen_h微信号 & QQ：862251340简书地址：http://www.jianshu.com/p/ac18...\nCoderPai 是一个专注于算法实战的平台，从基础的算法到人工智能算法都有设计。如果你对算法实战感兴趣，请快快关注我们吧。加入AI实战微信群，AI实战QQ群，ACM算法微信群，ACM算法QQ群。长按或者扫描如下二维码，关注 “CoderPai” 微信号（coderpai）\n\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "1"}