{"title": "tensorflow学习笔记3——MNIST应用篇 - 个人文章 ", "index": "python", "content": "MNIST的卷积神经网络应用\n卷积神经网络的概念\n卷积神经网络（Convolutional Neural Network,CNN）是一种前馈神经网络，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。[2]  它包括卷积层(convolutional layer)和池化层(pooling layer)。\n使用卷积神经网络来训练MNIST数据集\n    import tensorflow as tf\n    import numpy as np\n    from tensorflow.examples.tutorials.mnist import input_data\n    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n\n    trX, trY, teX, teY = mnist.train.images, mnist.train.labels,         mnist.test.images, mnist.test.labels\n\n    trX = trX.reshape(-1, 28, 28, 1)#28*28*1 input image\n    teX = teX.reshape(-1, 28, 28, 1)\n\n    X = tf.placeholder(\"float\", [None, 28, 28, 1])\n    Y = tf.placeholder(\"float\", [None, 10])\n    conv_dropout  = tf.placeholder(\"float\")\n    dense_dropout = tf.placeholder(\"float\")\n    w1 = tf.Variable(tf.radom_normal([3, 3, 1, 32], stddev=0.01))\n    w2 = tf.Variable(tf.radom_normal([3, 3, 32, 64], stddev=0.01))\n    w3 = tf.Variable(tf.radom_normal([3, 3, 64, 128], stddev=0.01))\n    w4 = tf.Variable(tf.radom_normal([4*4*128, 1024], stddev=0.01))\n    wo = tf.Variable(tf.random_normal([1024, 10], stddev=0.01))\n\n    #卷积和池化、dropout\n    def conv_and_pool(x, w, step, dropout):\n        x = tf.nn.relu(tf.nn.conv2d(x, w, strides=[1,1,1,1], padding='SAME'))\n        x = tf.nn.max_pool(x, ksize=[1, step, step, 1], strides=[1, step, step, 1], padding='SAME')\n        x = tf.nn.dropout(dropout)\n        return x\n    #构建模型\n    def conv_model(x, w1, w2, w3, w4, wo, dropout, dense_do):\n        x = conv_and_pool(x, w1, 2, 0.5)#第一层卷积 \n        x = conv_and_pool(x, w2, 2, 0.5)#第二层卷积 \n        x = conv_and_pool(x, w3, 2, 0.5)#第三层卷积 \n\n        x = tf.nn.relu(tf.nn.matmul(x, w4))#全连接\n        x = tf.nn.dropout(x, dense_do)#dropout,防止过拟合\n\n        x = tf.nn.relu(tf.nn.matmul(x, wo))#输出预测分类\n        return x;\n\n    py_x = conv_model(X, w1, w2, w3, w4, wo, conv_dropout, dense_dropout)\n\n    cost =     tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=Y))\n    train_op = tf.train.RMSPropOptimizer(0.001, 0.9).minize(cost)\n    predict_op = tf.argmax(py_x, 1)\n\n    batch_size = 128\n    test_size = 256\n\n    #训练模型和评估模型\n    with tf.Sesseion() as sess:\n        tf.global_variables_initializer().run()\n\n        for i in range(100):\n            training_batch = zip(range(0, len(trX), batch_size),         range(batch_size, len(trX)+1, batch_size))\n        for start, end in training_batch:\n            sess.run(train_op, feed_dict={X:trX[start:end], Y:trY[start:end], conv_dropout:0.8, dense_dropout:0.5})\n        \n    test_indices = np.arange(len(txX))\n    np.random.shuffle(test_indices)\n    test_indices = test_indices[0:test_size]\n    print(i, np.mean(np.ragmax(teY[test_indices], axis=1) == sess.run(predict_op, feed_dict={X:teX[test_indices], conv_dropout:1.0, dense_dropout:1.0})))\n\n输出结果：\n0.1796880.4531250.6718750.7734380.7656250.7890620.8046880.843750.7968750.828125...0.9531250.9218750.9453120.93750.9140620.9296880.9531250.9375\nMNIST的循环神经网络应用\n循环神经网络的概念(RNN,又称为递归神经网络)\n在传统的神经网络模型中，是从输入层到隐含层再到输出层，层与层之间是全连接的，每层之间的节点是无连接的。但是这种普通的神经网络对于很多问题却无能无力。例如，你要预测句子的下一个单词是什么，一般需要用到前面的单词，因为一个句子中前后单词并不是独立的。RNN(Recurrent Neuron Network)是一种对序列数据建模的神经网络，即一个序列当前的输出与前面的输出也有关。具体的表现形式为网络会对前面的信息进行记忆并应用于当前输出的计算中，即隐藏层之间的节点不再无连接而是有连接的，并且隐藏层的输入不仅包括输入层的输出还包括上一时刻隐藏层的输出。RNN在自然语言处理领域的以下几个方向应用得非常成功:\n\n机器翻译;\n语音识别;\n图像描述生成(把RNN和CNN结合，根据图像的特征生成描述)\n语言模型与文本生成，即利用生成的模型预测下一个单词的可能性.\n\n使用循环神经网络(RNN)训练MNIST数据集\n    import tensorflow as tf\n    from tensorflow.examples.tutorials.mnist import input_data\n    from tensorflow.contrib import rnn\n    tf.set_random_seed(1)\n\n    mnist = input_data.read_data_sets('/tmp/data', one_hot=True)\n    optimize_op = 0.01\n    train_count = 100000\n    batch_size  = 128\n\n    #\n    n_inputs = 28\n    n_steps = 28\n    n_hidden_units = 128\n    n_classes = 10\n\n    x = tf.placeholder(tf.float32, [None, 28, 28])\n    y = tf.placeholder(tf.float32, [None, 10])\n\n    weights = {\n        'in': tf.Variable(tf.random_normal([28, 128])),\n        'out': tf.Variable(tf.random_normal([128, 10])),\n    }\n\n    baises = {\n        'in': tf.Variable(tf.constant(0.1, shape=[128, ])),\n        'out': tf.Variable(tf.constant(0.1, shape=[10, ])),\n    }\n\n    def RNN(X, weights, baises):\n        #Xtransform to [128*28, 28]\n        X = tf.reshape(X, [-1, 28])\n        X_in = tf.matmul(X, weights['in']) + baises['in']\n        #[128*28, 128]->vonvert[128, 28, 128]\n        X_in = tf.reshape(X_in, [-1, 28, 128])\n        lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden_units, forget_bias=1.0, state_is_tuple=True)\n        init_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\n        #dynamic_rnn\n        #outputs, final_state = rnn.static_rnn(lstm_cell, X_in, initial_state=init_state)\n        outputs, final_state = tf.nn.dynamic_rnn(lstm_cell, X_in,         initial_state=init_state, time_major=False)\n        results = tf.matmul(final_state[1], weights['out']) + baises['out']\n        return results;\n\n    pred = RNN(x, weights, baises)\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n    train_op = tf.train.AdamOptimizer(optimize_op).minimize(cost)\n\n    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n    init = tf.global_variables_initializer()\n    with tf.Session() as sess:\n        sess.run(init)\n        step = 0\n        while step * batch_size < train_count:\n            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n            batch_xs = batch_xs.reshape([batch_size, 28, 28])\n            sess.run([train_op], feed_dict={\n             x: batch_xs,\n             y: batch_ys,\n             })\n        \n            if step % 20 == 0:\n               print(sess.run(accuracy, feed_dict={x:batch_xs, y:batch_ys,}))\n            step += 1\n\n输出结果：\n0.1796880.4531250.6718750.773438...0.93750.9140620.9296880.9531250.9375\nMNIST的自编码网络实现应用\n自编码网络的概念\n自编码器是神经网络的一种，是一种无监督学习方法，使用了反向传播算法，目标是使输出=输入。 自编码器内部有隐藏层 ，可以产生编码表示输入。自编码器主要作用在于通过复现输出而捕捉可以代表输入的重要因素，利用中间隐层对输入的压缩表达，达到像PCA那样的找到原始信息主成分的效果。\n使用自编码网络编码MNIST\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\nfrom tensorflow.contrib import rnn\nimport matplotlib.pyplot as plt\nimport numpy as np\ntf.set_random_seed(1)\n\nmnist = input_data.read_data_sets('/tmp/data', one_hot=True)\nlearning_rate = 0.01\ntraining_epochs = 20\nbatch_size  = 256#batch size for once training\ndisplay_step = 1\n\nexamples_to_show = 10#images to show in view\n\nn_hidden_1 = 256#first hidden layer feature count\nn_hidden_2 = 128#second hidden layer feature count\nn_input = 784 #input data count\n\n\nX = tf.placeholder(\"float\", [None, n_input])#input image data\n\n\nweights = {\n     'encoder_h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n     'encoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n     'decoder_h1': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])),\n     'decoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_input])),\n }\nbiases = {\n     'encoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n     'encoder_b2': tf.Variable(tf.random_normal([n_hidden_2])),\n     'decoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n     'decoder_b2': tf.Variable(tf.random_normal([n_input])),\n }\n\ndef encoder(x):\n    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1,         weights['encoder_h2']), biases['encoder_b2']))\n    return layer_2\n\ndef decoder(x):\n    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']))\n    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))\n    return layer_2\n\nencoder_op = encoder(X)#encoder image data   decoder_op = decoder(encoder_op)#decoder image data\ny_pred = decoder_op#prediction image data   y_true = X   cost = tf.reduce_mean(tf.pow(y_pred - y_true, 2))   optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)   init = tf.global_variables_initializer()   with tf.Session() as sess:\n   sess.run(init)\n   total_batch = int(mnist.train.num_examples/batch_size)\n   for epoch in range(training_epochs):\n      for i in range(total_batch):\n          batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n          _, c = sess.run([optimizer, cost], feed_dict={X:batch_xs})\n      if epoch %display_step == 0:\n         print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c))\n  print (\"Optimization Finished!\")\n  encode_decode = sess.run(y_pred, feed_dict={X: \n  mnist.test.images[:examples_to_show]})\n  \n  f, a = plt.subplots(2, 10, figsize=(10, 2))#绘图比较原始图片和编码网络重建结果\n  print (\"after plt.subplots\")\n  for i in range(examples_to_show):\n      a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))#测试集\n      a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))#重建结果\n   f.show()\n   plt.draw()\n   \n输出结果:\n\n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "1"}