{"title": "scrapy学习之路2(图片下载与下载的路径获取) - 个人文章 ", "index": "python,scrapy", "content": "图片下载和拿到下载后的路径\n1\nitems.py\nimport scrapy\n\nclass InfoItem(scrapy.Item):\n    url = scrapy.Field()\n    url_object_id = scrapy.Field()\n    small_image = scrapy.Field()\n    small_image_path = scrapy.Field()\n    big_image = scrapy.Field()\n    big_image_path = scrapy.Field()\n    code = scrapy.Field()\n    date = scrapy.Field()\n    lengths = scrapy.Field()\n    author = scrapy.Field()\n    cate = scrapy.Field()\n    av_artor = scrapy.Field()\nspider/jxxx.py\n# -*- coding: utf-8 -*-\nimport scrapy\nfrom urllib import parse\nfrom scrapy.http import Request\nfrom JaSpider.items import InfoItem\nfrom JaSpider.utils.common import get_md5\n\n\nclass JxxxSpider(scrapy.Spider):\n    name = 'jxxx'\n    allowed_domains = ['www.jxxx.com']\n    start_urls = ['http://www.jxxx.com/cn/vl_update.php']\n\n    def parse(self, response):\n        for i in response.css('.video'):\n            small_image = i.css('img::attr(src)').extract_first() # 小封面图的爬取，后面通过meta传到parse_info中\n            link = i.css('a::attr(href)').extract_first() # 详情页的url爬取\n            real_url = parse.urljoin(response.url, link) # 详情页的完整地址\n            yield Request(url=real_url, meta={'small_image': small_image}, callback=self.parse_info)\n        # 下一页的爬取与请求    \n        next_url = response.css('.page_selector .page.next::attr(href)').extract_first()\n        perfect_next_url = parse.urljoin(response.url, next_url)\n        if next_url:\n            yield Request(url=perfect_next_url, callback=self.parse)\n\n    def parse_info(self, response):\n        small_image = \"http:\"+response.meta['small_image']\n        big_image = \"http:\"+response.xpath('//div[@id=\"video_jacket\"]/img/@src').extract_first()\n        code = response.css('#video_id .text::text').extract_first()\n        date = response.css('#video_date .text::text').extract_first()\n        lengths = response.css('#video_length .text::text').extract_first()\n        author = response.css('#video_director .director a::text').extract_first() if response.css('#video_director .director a::text').extract_first() else \"不明\"\n        cate = ','.join([i.css('a::text').extract_first() for i in response.css('#video_genres .genre') if i.css('a::text').extract_first()])\n        av_artor = ','.join([i.css('a::text').extract_first() for i in response.css('.star') if i.css('a::text').extract_first()])\n        # print(\"http:\"+small_image)\n        info_item = InfoItem()\n        info_item['url'] = response.url\n        info_item['url_object_id'] = get_md5(response.url)\n        info_item['small_image'] = small_image\n        info_item['big_image'] = [big_image]\n        info_item['code'] = code\n        info_item['date'] = date\n        info_item['lengths'] = lengths\n        info_item['author'] = author\n        info_item['cate'] = cate\n        info_item['av_artor'] = av_artor\n        yield info_item\n\n2\n打开pipeline功能  settings.py\n注意!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!：spider/jxxx.py\n3\n如要进一步定制功能settings.py\npipeline.py\n\n4\n补充新建utils/common.py\nimport hashlib\n\n\ndef get_md5(url):\n    if isinstance(url, str):\n        url = url.encode(\"utf-8\")\n    m = hashlib.md5()\n    m.update(url)\n    return m.hexdigest()\n\n\nif __name__ == \"__main__\":\n    a = get_md5('http://www.haddu.com')\n    print(a)\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}