{"title": "TensorFlow实战之：Quick Start - 某熊的全栈之路 ", "index": "机器学习,python,tensorflow", "content": "Introduction\nQuickStart\ntensorflow-googles-latest-machine\nInstallation\n\n因为众所周知的原因，在国内搭建Tensorflow的环境又经历了一些波折。笔者习惯用Docker作为复杂依赖项目的开发环境，Google提供的安装方式有如下几个。\nBinary Installation\nTensorFlow的Python的API是2.7，最简单的方式就是在MAC或者Unix上使用pip命令导入。\nLinux\n# For CPU-only version\n$ pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl\n\n# For GPU-enabled version (only install this version if you have the CUDA sdk installed)\n$ pip install https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl\nMac OS X\n# Only CPU-version is available at the moment.\n$ pip install https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl\n\nDocker\n笔者就是用的这个方式，不过可能比较笨吧，之前用的代理下载DockerHub的镜像都没问题，但是死活下不了TensorFlow，只能默默开了个VPS下了镜像然后打包成tar再拖到本地导入，笔者打包的tar文件在这里。导入到本地的Docker镜像库中只需要：\ndocker load < /tmp/tensorflow.tar\n具体的Docker的安装过程可以参考笔者的其他文章，镜像下载导入好了之后直接：\ndocker run -it b.gcr.io/tensorflow/tensorflow\n这个默认的镜像比较小，只包含了一些必要的运行条件，Google还提供了一个更完整的镜像b.gcr.io/tensorflow/tensorflow-full。\n如果需要重新编译的话：\ntensorflow/tensorflow\n$ docker build -t $USER/tensorflow -f Dockerfile.lite .\n\ntensorflow/tensorflow-full\n同样需要依赖于tensor flow的基础镜像，所以还是得翻墙\n$ git clone https://github.com/tensorflow/tensorflow\n$ docker build -t $USER/tensorflow-full -f Dockerfile.cpu .\n\n[](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/docker#tensorflowtensorflow-gpu)tensorflow/tensorflow-gpu\n这个需要的稍微复杂一点：\n$ cp -a /usr/local/cuda .\n$ docker build -t $USER/tensorflow-gpu-base -f Dockerfile.gpu_base .\n# Flatten the image\n$ export TC=$(docker create $USER/tensorflow-gpu-base)\n$ docker export $TC | docker import - $USER/tensorflow-gpu-flat\n$ docker rm $TC\n$ export TC=$(docker create $USER/tensorflow-gpu-flat /bin/bash)\n$ docker commit --change='CMD [\"/bin/bash\"]'  --change='ENV CUDA_PATH /usr/local/cuda' --change='ENV LD_LIBRARY_PATH /usr/local/cuda/lib64' --change='WORKDIR /root' $TC $USER/tensorflow-full-gpu\n$ docker rm $TC\n\nVirtualEnv\n这也是Google官方推荐的一种构建方式，virtualenv是Python领域的一种环境管理，首先是安装所有必备工具：\n# On Linux:\n$ sudo apt-get install python-pip python-dev python-virtualenv\n\n# On Mac:\n$ sudo easy_install pip  # If pip is not already installed\n$ sudo pip install --upgrade virtualenv\n其次是创建一个新的工作区间：\n$ virtualenv --system-site-packages ~/tensorflow\n$ cd ~/tensorflow\n接下来是启用这个工作区间：\n$ source bin/activate  # If using bash\n$ source bin/activate.csh  # If using csh\n(tensorflow)$  # Your prompt should change\n然后在该工作区间中，安装TensorFlow：\n(tensorflow)$ pip install --upgrade <$url_to_binary.whl>\n最后直接运行程序：\n(tensorflow)$ python tensorflow/models/image/mnist/convolutional.py\n\n# When you are done using TensorFlow:\n(tensorflow)$ deactivate  # Deactivate the virtualenv\n\n$  # Your prompt should change back\nExample\n有人在Github上开源了一波TensorFlow的示范教程，大概是这里TensorFlow-Tutorials。\nMultiply\nimport tensorflow as tf\n\na = tf.placeholder(\"float\") # Create a symbolic variable 'a'\nb = tf.placeholder(\"float\") # Create a symbolic variable 'b'\n\ny = tf.mul(a, b) # multiply the symbolic variables\n\nsess = tf.Session() # create a session to evaluate the symbolic expressions\n\nprint \"%f should equal 2.0\" % sess.run(y, feed_dict={a: 1, b: 2}) # eval expressions with parameters for a and b\nprint \"%f should equal 9.0\" % sess.run(y, feed_dict={a: 3, b: 3})\nLinear Regression\nimport tensorflow as tf\nimport numpy as np\n\ntrX = np.linspace(-1, 1, 101)\ntrY = 2 * trX + np.random.randn(*trX.shape) * 0.33 # create a y value which is approximately linear but with some random noise\n\nX = tf.placeholder(\"float\") # create symbolic variables\nY = tf.placeholder(\"float\")\n\n\ndef model(X, w):\n    return tf.mul(X, w) # lr is just X*w so this model line is pretty simple\n\n\nw = tf.Variable(0.0, name=\"weights\") # create a shared variable (like theano.shared) for the weight matrix\ny_model = model(X, w)\n\ncost = (tf.pow(Y-y_model, 2)) # use sqr error for cost function\n\ntrain_op = tf.train.GradientDescentOptimizer(0.01).minimize(cost) # construct an optimizer to minimize cost and fit line to my data\n\nsess = tf.Session()\ninit = tf.initialize_all_variables() # you need to initialize variables (in this case just variable W)\nsess.run(init)\n\nfor i in range(100):\n    for (x, y) in zip(trX, trY): \n        sess.run(train_op, feed_dict={X: x, Y: y})\n\nprint(sess.run(w))  # something around 2\nLogistic Regression\nimport tensorflow as tf\nimport numpy as np\nimport input_data\n\n\ndef init_weights(shape):\n    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n\n\ndef model(X, w):\n    return tf.matmul(X, w) # notice we use the same model as linear regression, this is because there is a baked in cost function which performs softmax and cross entropy\n\n\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\ntrX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n\nX = tf.placeholder(\"float\", [None, 784]) # create symbolic variables\nY = tf.placeholder(\"float\", [None, 10])\n\nw = init_weights([784, 10]) # like in linear regression, we need a shared variable weight matrix for logistic regression\n\npy_x = model(X, w)\n\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(py_x, Y)) # compute mean cross entropy (softmax is applied internally)\ntrain_op = tf.train.GradientDescentOptimizer(0.05).minimize(cost) # construct optimizer\npredict_op = tf.argmax(py_x, 1) # at predict time, evaluate the argmax of the logistic regression\n\nsess = tf.Session()\ninit = tf.initialize_all_variables()\nsess.run(init)\n\nfor i in range(100):\n    for start, end in zip(range(0, len(trX), 128), range(128, len(trX), 128)):\n        sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})\n    print i, np.mean(np.argmax(teY, axis=1) ==\n                     sess.run(predict_op, feed_dict={X: teX, Y: teY}))\n\n                ", "mainLikeNum": ["3 "], "mainBookmarkNum": "23"}