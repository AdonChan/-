{"title": "Python爬虫案例：抓取豆瓣编程类高评分书籍 - 个人文章 ", "index": "linux,python", "content": "对于很多正在学习计算机的朋友来说，选择合适的学习材料是非常重要的。\n本文将通过 Python 来爬取豆瓣编程类评分大于 9.0 的书籍。\n此案例很适合入门爬虫的朋友学习，总共也就 3 个函数。\n下图是最终的结果：\n下面进入正题：\n一、采集源分析：\n首先我们找到豆瓣的编程类书籍网址：\nhttps://book.douban.com/tag/编程\n进入网址之后我们翻到最下面的分页导航：\n通过分析分页地址我们可以得出：\n\nhttps://book.douban.com/tag/%...{偏移量}&type=T\n这个地址则是我们要采集的内容。第一页 start = 0，第二页 start = 20 ... 以此类推。\n找到了要采集的 URL 之后，接下来就是分析我们真正需要的数据在 HTML 文档中的位置。\nF12 打开控制台发现，这些 li 标签正是我们的目标内容。而书名、评论、评分分别对应li 下面的 h2 标签、class 为 rating_nums 的 span 标签， class 为 pl 的 span 标签。\n见下图：\n有了以上内容，那么我们很容易就有了思路：\n\n抓取页面上所有的 li 标签\n循环处理这里 li 标签，找到我们所需的三个内容，并存储到列表中\n根据评分排序\n保存数据到 csv\n\n二、依赖的包：\n\n除了上次使用到的 requests, BeautifulSoup, 还增加了几个包。\n\nre 正则表达式处理\nnumpy 很强大的数据处理库，因为本文要进行排序，所以使用这个包会很方便\ncsv 用于把最终的结果保存到csv中\ntime 这里主要用到了 sleep 功能\n\n三、编码\n首先我们定义一个 get 函数，接受一个页码，表示要爬取到多少页。\n这个函数的主要功能就是抓取指定页码所有的书的信息，包括书名、评分、评论数。并且保存到一个二维数组中。\n代码解读：\n因为豆瓣的分页是根据 URL 中的 start 参数（相当于偏移量）来分的，所以在刚开始定义了一个 offset 变量，根据我们传入的页码来计算正确的 start 参数的值。\n后面通过 find_all 方法获取所有的 li 对象，存入 book_info_list 列表中，那么接下来就是遍历这个列表，从每一个元素中得到 star、 title、comment 三个变量。最终得到一个二维数组 result。\n定义排序方法，接收上面得出的 result 变量，并且将这个列表根据评分来排序。\n\n将最终排好的数据写入 csv 中。\n\n四、总结\n以上则是我们爬取豆瓣的小案例，有经验的朋友们会发现这个案例有很大的不足之处。\n在运行这个程序的时候，我们会发现会非常缓慢。原因就是每次请求豆瓣的分页 URl 之后，接下来紧跟着一条龙的获取书名等操作，获取完这个页面的所有数据之后再接着抓取下一个分页页面。也就是完全同步的编码方式。所以慢是必然的。\n那么如何调整代码结构才能使程序运行迅速呢？\n这里介绍一个简单又常用的方法：\n我们可以采用多线程技术，python 的 threading 包是专门用于多线程处理的。采用这种方式又多增加了两个包：\n\nthreading\nqueue\n\n可以将上述代码的下载分页 URL 部分代码放入一个单独的线程去跑，并将下载好的 HTML 文档存入一个队列中。然后多开几个线程去队列中读取数据，并用 BS4 来分析，将分析得到的 list 数据结构追加到外部的另一个list 中。最后再去排序这另一个列表。\n获取源码请到：“ 后端漫谈 ” 公众号后台回复 “douban”。\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}