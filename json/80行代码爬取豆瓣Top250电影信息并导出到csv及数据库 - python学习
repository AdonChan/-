{"title": "80行代码爬取豆瓣Top250电影信息并导出到csv及数据库 - python学习 ", "index": "数据处理,mysql,csv,网络爬虫,python", "content": "查看源码\n\n1 下载页面并处理\nDOWNLOAD_URL = 'http://movie.douban.com/top250/'\nhtml = requests.get(url).text\ntree = lxml.html.fromstring(html)\n\n2 提取数据\n观察该网站html结构\n可知该页面下所有电影包含在 ol 标签下。每个 li 标签包含单个电影的内容。\n使用XPath语句获取该ol标签\nmovies = tree.xpath(\"//ol[@class='grid_view']/li\")\n在ol标签中遍历每个li标签获取单个电影的信息。\n以电影名字为例\nfor movie in movies:\n    name_num = len(movie.xpath(\"descendant::span[@class='title']\"))\n    name = ''\n    for num in range(0, name_num):\n        name += movie.xpath(\"descendant::span[@class='title']\")[num].text.strip()\n    name = ' '.join(name.replace('/', '').split())  # 清洗数据\n\n其余部分详见源码\n\n3 页面跳转\n\n检查“后页”标签。跳转到下一页面\nnext_page = DOWNLOAD_URL + tree.xpath(\"//span[@class='next']/a/@href\")[0]\n返回None则已获取所有页面。\n\n4 导入csv\n创建csv文件\nwriter = csv.writer(open('movies.csv', 'w', newline='', encoding='utf-8'))\nfields = ('rank',  'name', 'score', 'country', 'year', 'category', 'votes', 'douban_url')\nwriter.writerow(fields)\n其余部分详见源码\n\n5 导入数据库（以mysql为例）\n\n先在mysql中创建数据库与表，表的属性应与要插入的数据保持一致\n连接数据库db = pymysql.connect(host='127.0.0.1', port=3306, user='root', passwd=PWD, db='douban',charset='utf8') 创建游标cur = db.cursor()\n\n将获取的电影信息导入数据库\n\nsql = \"INSERT INTO test(rank, NAME, score, country, year, \" \\\n          \"category, votes, douban_url) values(%s,%s,%s,%s,%s,%s,%s,%s)\"\n    try:\n        cur.executemany(sql, movies_info)\n        db.commit()\n    except Exception as e:\n        print(\"Error:\", e)\n        db.rollback()\n\n6 效果显示\n\n因Windows系统默认以ANSI编码打开Excel，所以直接用Excel打开csv文件会出现乱码，需对其重新编码。\n\n以上所有内容可以在80行Python代码内完成，很简单吧。(｀・ω・´)\n\n                ", "mainLikeNum": ["3 "], "mainBookmarkNum": "19"}