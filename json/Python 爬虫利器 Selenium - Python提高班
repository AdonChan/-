{"title": "Python 爬虫利器 Selenium - Python提高班 ", "index": "selenium,python,网页爬虫", "content": "前面几节，我们学习了用 requests 构造页面请求来爬取静态网页中的信息以及通过 requests 构造 Ajax 请求直接获取返回的 JSON 信息。\n还记得前几节，我们在构造请求时会给请求加上浏览器 headers,目的就是为了让我们的请求模拟浏览器的行为，防止被网站的反爬虫策略限制。今天要介绍的 Selenium 是一款强大的工具，它可以控制我们的浏览器，这样一来程序的行为就和人类完全一样了。\n通过使用 Selenium 可以解决几个问题：\n\n页面内容是由 JavaScript 动态生成，通过 requests 请求页面无法获取内容。\n爬虫程序被反爬虫策略限制\n让程序的行为和人一样\n\n\n安装pip install selenium\n\n安装浏览器驱动驱动下载地址\n下载后把驱动文件加入环境变量。或者直接把驱动文件和 Python脚本放到同一文件夹下面\n\n\n测试   安装完成后，可以编写以下脚本来测试是否安装成功。\nfrom selenium import webdriver\ndriver = webdriver.Chrome()  # 创建一个 Chrome WebDriver 实例\ndriver.get('https://www.baidu.com/')  # 打开网址\n运行后会发现程序自动打开了 Chrome 浏览器，并且定向到了百度首页。\n\n\n与页面交互   WebDriver定义了很多方法，我们可以很方便的操作页面上的元素   比如获取元素，可以通过 driver.find_element_by_id(\"id\")或者driver.find_element_by_name(\"name\")以及 xpath路径的方式来获取元素。可以通过send_keys 向输入框中写入文本。\nfrom selenium import webdriver\ndriver = webdriver.Chrome()\ndriver.get('https://www.baidu.com/')\nsearch_input = driver.find_element_by_id(\"kw\") # 获取到百度搜索框\nsearch_input.send_keys(\"刘亦菲\")  # 自动输入 刘亦菲\nsubmit = driver.find_element_by_id(\"su\")  # 获取到百度一下按钮\nsubmit.click()  # 点击搜索\n运行以上脚本，程序会自动打开 Chrome 浏览器，并自动搜索 刘亦菲\n\n其他操作   Selenium 可以进行各种各样的操作，使程序完全符合人类的操作习惯。下面看一下还有哪些功能。\n具体可以看官方文档，这里贴一下地址https://selenium-python-zh.readthedocs.io/en/latest/index.html\n\n\n\n                ", "mainLikeNum": ["7 "], "mainBookmarkNum": "6"}