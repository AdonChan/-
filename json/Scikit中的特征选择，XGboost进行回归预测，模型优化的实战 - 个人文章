{"title": "Scikit中的特征选择，XGboost进行回归预测，模型优化的实战 - 个人文章 ", "index": "pandas,numpy,python", "content": "前天偶然在一个网站上看到一个数据分析的比赛（sofasofa），自己虽然学习一些关于机器学习的内容，但是并没有在比赛中实践过，于是我带着一种好奇心参加了这次比赛。\n\n赛题：足球运动员身价估计比赛概述\n本比赛为个人练习赛，主要针对于于数据新人进行自我练习、自我提高，与大家切磋。 \n练习赛时限：2018-03-05 至 2020-03-05 \n任务类型：回归 \n背景介绍:  每个足球运动员在转会市场都有各自的价码。本次数据练习的目的是根据球员的各项信息和能力值来预测该球员的市场价值。 \n\n\n根据以上描述，我们很容易可以判断出这是一个回归预测类的问题。当然，要想进行预测，我们首先要做的就是先看看数据的格式以及内容（由于参数太多，我就不一一列举了，大家可以直接去网上看，下面我简单贴个图）：\n\n简单了解了数据的格式以及大小以后，由于没有实践经验，我就凭自己的感觉，单纯的认为一下几个字段可能是最重要的：\n\n\n字段\n含义\n\n\n\nclub\n该球员所属的俱乐部。该信息已经被编码。\n\n\nleague\n该球员所在的联赛。已被编码。\n\n\npotential\n球员的潜力。数值变量。\n\n\ninternational_reputation\n国际知名度。数值变量。\n\n\n\n巧合的是刚好这些字段都没有缺失值，我很开心啊，心想着可以直接利用XGBoost模型进行预测了。具体XGBoost的使用方法，可以参考：XGBoost以及官方文档XGBoost Parameters。说来就来，我开始了coding工作，下面就贴出我的第一版代码：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @File  : soccer_value.py\n# @Author: Huangqinjian\n# @Date  : 2018/3/22\n# @Desc  :\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nimport numpy as np\nfrom xgboost import plot_importance\nfrom sklearn.preprocessing import Imputer\n\n\ndef loadDataset(filePath):\n    df = pd.read_csv(filepath_or_buffer=filePath)\n    return df\n\n\ndef featureSet(data):\n    data_num = len(data)\n    XList = []\n    for row in range(0, data_num):\n        tmp_list = []\n        tmp_list.append(data.iloc[row]['club'])\n        tmp_list.append(data.iloc[row]['league'])\n        tmp_list.append(data.iloc[row]['potential'])\n        tmp_list.append(data.iloc[row]['international_reputation'])\n        XList.append(tmp_list)\n    yList = data.y.values\n    return XList, yList\n\n\ndef loadTestData(filePath):\n    data = pd.read_csv(filepath_or_buffer=filePath)\n    data_num = len(data)\n    XList = []\n    for row in range(0, data_num):\n        tmp_list = []\n        tmp_list.append(data.iloc[row]['club'])\n        tmp_list.append(data.iloc[row]['league'])\n        tmp_list.append(data.iloc[row]['potential'])\n        tmp_list.append(data.iloc[row]['international_reputation'])\n        XList.append(tmp_list)\n    return XList\n\n\ndef trainandTest(X_train, y_train, X_test):\n    # XGBoost训练过程\n    model = xgb.XGBRegressor(max_depth=5, learning_rate=0.1, n_estimators=160, silent=False, objective='reg:gamma')\n    model.fit(X_train, y_train)\n\n    # 对测试集进行预测\n    ans = model.predict(X_test)\n\n    ans_len = len(ans)\n    id_list = np.arange(10441, 17441)\n    data_arr = []\n    for row in range(0, ans_len):\n        data_arr.append([int(id_list[row]), ans[row]])\n    np_data = np.array(data_arr)\n\n    # 写入文件\n    pd_data = pd.DataFrame(np_data, columns=['id', 'y'])\n    # print(pd_data)\n    pd_data.to_csv('submit.csv', index=None)\n\n    # 显示重要特征\n    # plot_importance(model)\n    # plt.show()\n\nif __name__ == '__main__':\n    trainFilePath = 'dataset/soccer/train.csv'\n    testFilePath = 'dataset/soccer/test.csv'\n    data = loadDataset(trainFilePath)\n    X_train, y_train = featureSet(data)\n    X_test = loadTestData(testFilePath)\n    trainandTest(X_train, y_train, X_test)\n然后我就把得到的结果文件submit.csv提交到网站上，看了结果，MAE为106.6977，排名24/28,很不理想。不过这也在预料之中，因为我基本没有进行特征处理。\n我当然不满意啦，一直想着怎么能提高准确率呢？后来就想到了可以利用一下scikit这个库啊！在scikit中包含了一个特征选择的模块sklearn.feature_selection，而在这个模块下面有以下几个方法：\n\nRemoving features with low variance（剔除低方差的特征）\nUnivariate feature selection（单变量特征选择）\nRecursive feature elimination（递归功能消除）\nFeature selection using SelectFromModel（使用SelectFromModel进行特征选择）\n\n我首先想到的是利用单变量特征选择的方法选出几个跟预测结果最相关的特征。根据官方文档，有以下几种得分函数来检验变量之间的依赖程度：\n\n对于回归问题: f_regression, mutual_info_regression\n\n对于分类问题: chi2, f_classif, mutual_info_classif\n\n\n由于这个比赛是一个回归预测问题，所以我选择了f_regression这个得分函数（刚开始我没有注意，错误使用了分类问题中的得分函数chi2，导致程序一直报错！心很累~）\n\nf_regression的参数： sklearn.feature_selection.f_regression(X, y, center=True) X：一个多维数组，大小为(n_samples, n_features)，即行数为训练样本的大小，列数为特征的个数y：一个一维数组，长度为训练样本的大小return：返回值为特征的F值以及p值\n\n不过在进行这个操作之前，我们还有一个重大的任务要完成，那就是对于空值的处理！幸运的是scikit中也有专门的模块可以处理这个问题：Imputation of missing values\n\nsklearn.preprocessing.Imputer的参数：sklearn.preprocessing.Imputer(missing_values=’NaN’, strategy=’mean’, axis=0, verbose=0, copy=True)\n\n其中strategy代表对于空值的填充策略（默认为mean，即取所在列的平均数进行填充）：\n\n\nstrategy='median'，代表取所在列的中位数进行填充\n\nstrategy='most_frequent', 代表取所在列的众数进行填充\n\naxis默认值为0：\n\n\naxis=0，代表按列进行填充\n\naxis=1，代表按行进行填充\n\n其他具体参数可以参考：sklearn.preprocessing.Imputer\n根据以上，我对数据进行了一些处理：\nfrom sklearn.feature_selection import f_regression\nfrom sklearn.preprocessing import Imputer\n\nimputer = Imputer(missing_values='NaN', strategy='mean', axis=0)\nimputer.fit(data.loc[:, 'rw':'lb'])\nx_new = imputer.transform(data.loc[:, 'rw':'lb'])\ndata_num = len(x_new)\nXList = []\nyList = []\nfor row in range(0, data_num):\n    tmp_list = []\n    tmp_list.append(x_new[row][0])\n    tmp_list.append(x_new[row][1])\n    tmp_list.append(x_new[row][2])\n    tmp_list.append(x_new[row][3])\n    tmp_list.append(x_new[row][4])\n    tmp_list.append(x_new[row][5])\n    tmp_list.append(x_new[row][6])\n    tmp_list.append(x_new[row][7])\n    tmp_list.append(x_new[row][8])\n    tmp_list.append(x_new[row][9])\n    XList.append(tmp_list)\n    yList.append(data.iloc[row]['y'])\n\nF = f_regression(XList, yList)\nprint(len(F))\nprint(F)\n\n测试结果：\n2\n(array([2531.07587725, 1166.63303449, 2891.97789543, 2531.07587725,\n       2786.75491791, 2891.62686404, 3682.42649607, 1394.46743196,\n        531.08672792, 1166.63303449]), array([0.00000000e+000, 1.74675421e-242, 0.00000000e+000, 0.00000000e+000,\n       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 1.37584507e-286,\n       1.15614152e-114, 1.74675421e-242]))\n根据以上得到的结果，我选取了rw,st,lw,cf,cam,cm(选取F值相对大的)几个特征加入模型之中。以下是我改进后的代码：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @File  : soccer_value.py\n# @Author: Huangqinjian\n# @Date  : 2018/3/22\n# @Desc  :\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nimport numpy as np\nfrom xgboost import plot_importance\nfrom sklearn.preprocessing import Imputer\n\n\ndef loadDataset(filePath):\n    df = pd.read_csv(filepath_or_buffer=filePath)\n    return df\n\n\ndef featureSet(data):\n    imputer = Imputer(missing_values='NaN', strategy='mean', axis=0)\n    imputer.fit(data.loc[:, ['rw', 'st', 'lw', 'cf', 'cam', 'cm']])\n    x_new = imputer.transform(data.loc[:, ['rw', 'st', 'lw', 'cf', 'cam', 'cm']])\n    data_num = len(data)\n    XList = []\n    for row in range(0, data_num):\n        tmp_list = []\n        tmp_list.append(data.iloc[row]['club'])\n        tmp_list.append(data.iloc[row]['league'])\n        tmp_list.append(data.iloc[row]['potential'])\n        tmp_list.append(data.iloc[row]['international_reputation'])\n        tmp_list.append(data.iloc[row]['pac'])\n        tmp_list.append(data.iloc[row]['sho'])\n        tmp_list.append(data.iloc[row]['pas'])\n        tmp_list.append(data.iloc[row]['dri'])\n        tmp_list.append(data.iloc[row]['def'])\n        tmp_list.append(data.iloc[row]['phy'])\n        tmp_list.append(data.iloc[row]['skill_moves'])\n        tmp_list.append(x_new[row][0])\n        tmp_list.append(x_new[row][1])\n        tmp_list.append(x_new[row][2])\n        tmp_list.append(x_new[row][3])\n        tmp_list.append(x_new[row][4])\n        tmp_list.append(x_new[row][5])\n        XList.append(tmp_list)\n    yList = data.y.values\n    return XList, yList\n\n\ndef loadTestData(filePath):\n    data = pd.read_csv(filepath_or_buffer=filePath)\n    imputer = Imputer(missing_values='NaN', strategy='mean', axis=0)\n    imputer.fit(data.loc[:, ['rw', 'st', 'lw', 'cf', 'cam', 'cm']])\n    x_new = imputer.transform(data.loc[:, ['rw', 'st', 'lw', 'cf', 'cam', 'cm']])\n    data_num = len(data)\n    XList = []\n    for row in range(0, data_num):\n        tmp_list = []\n        tmp_list.append(data.iloc[row]['club'])\n        tmp_list.append(data.iloc[row]['league'])\n        tmp_list.append(data.iloc[row]['potential'])\n        tmp_list.append(data.iloc[row]['international_reputation'])\n        tmp_list.append(data.iloc[row]['pac'])\n        tmp_list.append(data.iloc[row]['sho'])\n        tmp_list.append(data.iloc[row]['pas'])\n        tmp_list.append(data.iloc[row]['dri'])\n        tmp_list.append(data.iloc[row]['def'])\n        tmp_list.append(data.iloc[row]['phy'])\n        tmp_list.append(data.iloc[row]['skill_moves'])\n        tmp_list.append(x_new[row][0])\n        tmp_list.append(x_new[row][1])\n        tmp_list.append(x_new[row][2])\n        tmp_list.append(x_new[row][3])\n        tmp_list.append(x_new[row][4])\n        tmp_list.append(x_new[row][5])\n        XList.append(tmp_list)\n    return XList\n\n\ndef trainandTest(X_train, y_train, X_test):\n    # XGBoost训练过程\n    model = xgb.XGBRegressor(max_depth=5, learning_rate=0.1, n_estimators=160, silent=False, objective='reg:gamma')\n    model.fit(X_train, y_train)\n\n    # 对测试集进行预测\n    ans = model.predict(X_test)\n\n    ans_len = len(ans)\n    id_list = np.arange(10441, 17441)\n    data_arr = []\n    for row in range(0, ans_len):\n        data_arr.append([int(id_list[row]), ans[row]])\n    np_data = np.array(data_arr)\n\n    # 写入文件\n    pd_data = pd.DataFrame(np_data, columns=['id', 'y'])\n    # print(pd_data)\n    pd_data.to_csv('submit.csv', index=None)\n\n    # 显示重要特征\n    # plot_importance(model)\n    # plt.show()\n\nif __name__ == '__main__':\n    trainFilePath = 'dataset/soccer/train.csv'\n    testFilePath = 'dataset/soccer/test.csv'\n    data = loadDataset(trainFilePath)\n    X_train, y_train = featureSet(data)\n    X_test = loadTestData(testFilePath)\n    trainandTest(X_train, y_train, X_test)\n\n再次提交，这次MAE为    42.1227，排名16/28。虽然提升了不少，不过距离第一名还是有差距，仍需努力。\n接下来，我们来处理一下下面这个字段：\n\n由于这两个字段是标签，需要进行处理以后（标签标准化）才用到模型中。我们要用到的函数是sklearn.preprocessing.LabelEncoder：\n    le = preprocessing.LabelEncoder()\n    le.fit(['Low', 'Medium', 'High'])\n    att_label = le.transform(data.work_rate_att.values)\n    # print(att_label)\n    def_label = le.transform(data.work_rate_def.values)\n    # print(def_label)\n当然你也可以使用pandas直接来处理离散型特征变量，具体内容可以参考：pandas使用get_dummies进行one-hot编码。顺带提一句，scikit中也有一个方法可以来处理，可参考：sklearn.preprocessing.OneHotEncoder。\n调整后的代码：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @File  : soccer_value.py\n# @Author: Huangqinjian\n# @Date  : 2018/3/22\n# @Desc  :\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nfrom sklearn import preprocessing\nimport numpy as np\nfrom xgboost import plot_importance\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.cross_validation import train_test_split\n\n\ndef featureSet(data):\n    imputer = Imputer(missing_values='NaN', strategy='mean', axis=0)\n    imputer.fit(data.loc[:, ['rw', 'st', 'lw', 'cf', 'cam', 'cm']])\n    x_new = imputer.transform(data.loc[:, ['rw', 'st', 'lw', 'cf', 'cam', 'cm']])\n\n    le = preprocessing.LabelEncoder()\n    le.fit(['Low', 'Medium', 'High'])\n    att_label = le.transform(data.work_rate_att.values)\n    # print(att_label)\n    def_label = le.transform(data.work_rate_def.values)\n    # print(def_label)\n\n    data_num = len(data)\n    XList = []\n    for row in range(0, data_num):\n        tmp_list = []\n        tmp_list.append(data.iloc[row]['club'])\n        tmp_list.append(data.iloc[row]['league'])\n        tmp_list.append(data.iloc[row]['potential'])\n        tmp_list.append(data.iloc[row]['international_reputation'])\n        tmp_list.append(data.iloc[row]['pac'])\n        tmp_list.append(data.iloc[row]['sho'])\n        tmp_list.append(data.iloc[row]['pas'])\n        tmp_list.append(data.iloc[row]['dri'])\n        tmp_list.append(data.iloc[row]['def'])\n        tmp_list.append(data.iloc[row]['phy'])\n        tmp_list.append(data.iloc[row]['skill_moves'])\n        tmp_list.append(x_new[row][0])\n        tmp_list.append(x_new[row][1])\n        tmp_list.append(x_new[row][2])\n        tmp_list.append(x_new[row][3])\n        tmp_list.append(x_new[row][4])\n        tmp_list.append(x_new[row][5])\n        tmp_list.append(att_label[row])\n        tmp_list.append(def_label[row])\n        XList.append(tmp_list)\n    yList = data.y.values\n    return XList, yList\n\n\ndef loadTestData(filePath):\n    data = pd.read_csv(filepath_or_buffer=filePath)\n    imputer = Imputer(missing_values='NaN', strategy='mean', axis=0)\n    imputer.fit(data.loc[:, ['rw', 'st', 'lw', 'cf', 'cam', 'cm']])\n    x_new = imputer.transform(data.loc[:, ['rw', 'st', 'lw', 'cf', 'cam', 'cm']])\n\n    le = preprocessing.LabelEncoder()\n    le.fit(['Low', 'Medium', 'High'])\n    att_label = le.transform(data.work_rate_att.values)\n    # print(att_label)\n    def_label = le.transform(data.work_rate_def.values)\n    # print(def_label)\n\n    data_num = len(data)\n    XList = []\n    for row in range(0, data_num):\n        tmp_list = []\n        tmp_list.append(data.iloc[row]['club'])\n        tmp_list.append(data.iloc[row]['league'])\n        tmp_list.append(data.iloc[row]['potential'])\n        tmp_list.append(data.iloc[row]['international_reputation'])\n        tmp_list.append(data.iloc[row]['pac'])\n        tmp_list.append(data.iloc[row]['sho'])\n        tmp_list.append(data.iloc[row]['pas'])\n        tmp_list.append(data.iloc[row]['dri'])\n        tmp_list.append(data.iloc[row]['def'])\n        tmp_list.append(data.iloc[row]['phy'])\n        tmp_list.append(data.iloc[row]['skill_moves'])\n        tmp_list.append(x_new[row][0])\n        tmp_list.append(x_new[row][1])\n        tmp_list.append(x_new[row][2])\n        tmp_list.append(x_new[row][3])\n        tmp_list.append(x_new[row][4])\n        tmp_list.append(x_new[row][5])\n        tmp_list.append(att_label[row])\n        tmp_list.append(def_label[row])\n        XList.append(tmp_list)\n    return XList\n\n\ndef trainandTest(X_train, y_train, X_test):\n    # XGBoost训练过程\n    model = xgb.XGBRegressor(max_depth=6, learning_rate=0.05, n_estimators=500, silent=False, objective='reg:gamma')\n    model.fit(X_train, y_train)\n\n    # 对测试集进行预测\n    ans = model.predict(X_test)\n\n    ans_len = len(ans)\n    id_list = np.arange(10441, 17441)\n    data_arr = []\n    for row in range(0, ans_len):\n        data_arr.append([int(id_list[row]), ans[row]])\n    np_data = np.array(data_arr)\n\n    # 写入文件\n    pd_data = pd.DataFrame(np_data, columns=['id', 'y'])\n    # print(pd_data)\n    pd_data.to_csv('submit.csv', index=None)\n\n    # 显示重要特征\n    # plot_importance(model)\n    # plt.show()\n\nif __name__ == '__main__':\n    trainFilePath = 'dataset/soccer/train.csv'\n    testFilePath = 'dataset/soccer/test.csv'\n    data = pd.read_csv(trainFilePath)\n    X_train, y_train = featureSet(data)\n    X_test = loadTestData(testFilePath)\n    trainandTest(X_train, y_train, X_test)\n这次只提高到了40.8686。暂时想不到提高的方法了，还请大神多多赐教！\n\n更多内容欢迎关注我的个人公众号\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}