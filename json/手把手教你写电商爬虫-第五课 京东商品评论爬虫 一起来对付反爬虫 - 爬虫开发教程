{"title": "手把手教你写电商爬虫-第五课 京东商品评论爬虫 一起来对付反爬虫 - 爬虫开发教程 ", "index": "网页爬虫,大数据,电商网站,python,javascript", "content": "系列教程：\n手把手教你写电商爬虫-第一课 找个软柿子捏捏\n手把手教你写电商爬虫-第二课 实战尚妆网分页商品采集爬虫\n手把手教你写电商爬虫-第三课 实战尚妆网AJAX请求处理和内容提取\n手把手教你写电商爬虫-第四课 淘宝网商品爬虫自动JS渲染\n四节课过去了，咱们在爬虫界也都算见过世面的人，现在再来一些什么ajax加载之类的小鱼小虾应该不在话下了，即使是淘宝这种大量的ajax，我们祭上我们的核武器，也轻松应对了，这一课主要是来看看除了技术上的页面处理外，我们还会遇上更棘手的问题，就是反爬虫，当然现在有各种各样的反爬虫，今天就先介绍最简单的一种：限制IP。\n今天咱们的对手依然是业界大佬，马云最忌惮的男人，宅男心中爱恨交错的对象 - JD.COM\n也不用我安利，特别是程序员，有几个没给京东送过钱的。废话不多说，先上工具：\n1、神箭手云爬虫，2、Chrome浏览器 3、Chrome的插件XpathHelper 不知道是干嘛的同学请移步第一课\n打开网站瞅一眼：\n\n好了，相信我，截这张图绝对不是在虐你们这些单身狗。我们就是科学的研究一下这个页面，没啥特别的：大厂风，硬仗准备。\n先来挑一个分类吧，这次挑一个大家都熟悉的互联网书类：\nhttp://search.jd.com/Search?keyword=Python&enc=utf-8&book=y&wq=Python&pvid=33xo9lni.p4a1qb\n\n你们的最爱，python从入门到放弃的全部资料。\n和前面几节课类似的分析这节课就不做了，对于分页，ajax请求什么的，大家可以直接参考前面的四节课，这一刻主要特别的是，我们在采集商品的同时，会将京东的商品评价采集下来。同时呢，我们也探讨下该如何应对京东对IP的限制，OK，先直接上代码：\nvar configs = {  \n    domains: [\"search.jd.com\",\"item.jd.com\",\"club.jd.com\"],  \n    scanUrls: [\"http://search.jd.com/Search?keyword=Python&enc=utf-8&qrst=1&rt=1&stop=1&book=y&vt=2&page=1&s=1&click=0\"],  \n    contentUrlRegexes: [\"http://item\\\\.jd\\\\.com/\\\\d+.html\"],  \n    helperUrlRegexes: [\"http://search\\\\.jd\\\\.com/Search\\\\?keyword=Python&enc=utf-8&qrst=1&rt=1&stop=1&book=y&vt=2&page=\\\\d+&s=1&click=0\"],//可留空  \n    fields: [  \n        {  \n            // 第一个抽取项  \n            name: \"title\",  \n            selector: \"//div[@id='name']/h1\",//默认使用XPath  \n            required: true //是否不能为空  \n        },  \n        {  \n            // 第一个抽取项  \n            name: \"productid\",  \n            selector: \"//div[contains(@class,'fl')]/span[2]\",//默认使用XPath  \n            required: true //是否不能为空  \n        },  \n        {  \n            name: \"comments\",  \n            sourceType: SourceType.AttachedUrl,  \n            attachedUrl: \"http://club.jd.com/productpage/p-{productid}-s-0-t-3-p-0.html\",  \n            selectorType: SelectorType.JsonPath,  \n            selector: \"$.comments\",  \n            repeated: true,  \n            children:[  \n                {  \n                    name: \"com_content\",  \n                    selectorType: SelectorType.JsonPath,  \n                    selector: \"$.content\"  \n                },  \n                {  \n                    name: \"com_nickname\",  \n                    selectorType: SelectorType.JsonPath,  \n                    selector: \"$.nickname\"  \n                },  \n            ]  \n        }  \n    ]  \n};  \nconfigs.onProcessHelperUrl = function(url, content, site){  \n    if(!content.indexOf(\"抱歉，没有找到\")){  \n        var currentPage = parseInt(url.substring(url.indexOf(\"&page=\") + 6));  \n        if(currentPage == 0){  \n            currentPage = 1;  \n        }  \n        var page = currentPage + 2;  \n        var nextUrl = url.replace(\"&page=\" + currentPage, \"&page=\" + page);  \n        site.addUrl(nextUrl);  \n    }  \n    return true;  \n};  \nvar crawler = new Crawler(configs);  \ncrawler.start();  \n\n这里主要给大家讲一下这个评论的配置，由于评论是多项，且评论还有子项，在框架中，是通过children关键字来配置的。具体参照代码既可，我们可以在子项中在定义不同的字段，像这里的comments抽取项会有content和nickname两个子抽取项，分别对应的是评论的内容和昵称。\n这里是一个简化的版本，由于京东页面相对很复杂，我们在抽取评论的时候，只抽取前一部分评论，当然我们还可以拿到更多的信息，包括评论数，评论人的等级等等，这里大家就自行探索吧。\n最后，由于京东会对IP进行封锁，虽然说神箭手会自动分布式开启爬虫，不过依然扛不住京东大叔的封锁，因此这里需要通过接入代理IP解决这样的问题，类似开启js渲染，爬取速度会大大下降，需要大家耐心等待结果喽，代码如下：\nconfigs.enableProxy = true;  \n\n大功告成，开启爬虫，喝杯咖啡，京东商品的评论就可以看到啦：\n\n评论因为是数字，因此会存储的时候，会直接存储成json格式：\n\n对爬虫感兴趣的童鞋可以加qq群讨论：342953471。\n\n                ", "mainLikeNum": ["4 "], "mainBookmarkNum": "23"}