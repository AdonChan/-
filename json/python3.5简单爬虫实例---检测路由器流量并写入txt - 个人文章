{"title": "python3.5简单爬虫实例---检测路由器流量并写入txt - 个人文章 ", "index": "python", "content": "写在前面\n本人的所有文章只适合善于使用百度的人，因为所有基础知识个个博客复制粘贴了无数遍，我这里均不会详细讲述。\n在这里我表示所有不经验证的转载都是耍流氓，把一篇篇错误的文章转载的到处都是，不知道浪费了多少人的时间精力去反复调试错误的代码，尤其是对初学者有极大的打击性。\n大家在学习python爬虫的过程中，会发现一个问题，语法我看完了，说的也很详细，我也认真看了，爬虫还是不会写，或者没有思路，所以我的所有文章都会从实例的角度来解析一些常见的问题和报错。\n环境交代：win10+python3.6代码非常简单，\n\n模拟登陆，没有\n网页标签过滤，没有\n多线程，也没有\n文本处理，只有涉及到字符串截取\n本地文本写入，有\n\n这么低级的代码是因为这个路由器页面非常垃圾，用不到~~~，不过这样也适合初学者观看，当然了，后续会尝试添加更多功能\n\n首先我们对自己的需求要进行分析，新手嘛，先把复杂的东西简单化，模块化，整理出思路，再一步步的去实现，最后整合。\n\n\n获得数据\n\n网页编码，编码没有处理好会报错，涉及到一些函数\n编码转换，read()方法获取到的非字符串类型，要预先进行处理\n\n\n\n处理数据\n方法有很多，正则，字符串截取，等等不一一介绍，适合的才是最好的，我觉得正则是很强大的，但是也是相当反人类的\n\n\n保存数据\n\n注意win下路径和linux下路径写法不同\n写入的编码类型需要进行处理\n\n\n\n重点讲一讲我遇到的坑\n一般来讲右键查看页面编码，如图所示，因为在国外是非常奇怪的编码当时我就蒙蔽了，这是什么鬼~这个时候我们需要用到chardet库来判断编码类型，拿百度举例，自行百度python第三方库如何安装，这里不做阐述\nimport chardet\nimport urllib.request\nhtml = urllib.request.urlopen('http://www.baidu.com/').read()\nprint (chardet.detect(html))\n得到的结果如下：\nC:\\python\\python.exe D:/python/test/2.py\n{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}\n\nProcess finished with exit code 0\n1.取得字符串\nimport urllib.request\nimport os\nfrom bs4 import BeautifulSoup\nimport time\n\ndef getHtml(url):\n    html = urllib.request.urlopen(url).read()\n    return html\n\n#获取字符串，因为我在国外，路由器low到爆，编码格式也蛋疼了我很久\nhtml = getHtml(\"http://192.168.0.254/pub/fbx_info.txt\")\n#将read()获取的是bytes编码转化成str\nhtml = html.decode(\"ISO-8859-1\")\n因为是欧洲网站，获取的却是一个 【ISO-8859-1】的网页编码。由于这里我们用read()方法读取，获取到的是bytes类型，此时需要转换成str类型的，才可以进行下一步的处理，如果不处理就会有下列错误TypeError: a bytes-like object is required, not 'str'这里可以使用decode()方法处理一下html = html.decode(\"ISO-8859-1\")使用type()方法检测下编码print(type(html))反馈，成功<class 'str'>\n2.处理字符串\n#操作字符串\nhtml = html.split('WAN')[1].split('Ethernet')[0]\ntime = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n#因为使用记事本，在记事本中换行只认\\r\\n\nstr = time+html+\"\\r\\n\"\n这里我使用的是split()方法，使用方法呢，推荐大家学会查手册，这里也不详细再解释了。我通过split()方法截取到了自己需要的字符串，然后用time()函数获取当前本地时间，然后用+连接符把当前本地时间和处理后的字符串连接起来，再在末尾接上换行符rn，因为懒到只用记事本，换行符这里只算一个小坑\n3.写入txt\n# 保存文件为txt，win环境路径\noutfile = open(\"C:\\\\Users\\\\sw\\\\Desktop\\\\route.txt\",\"a+\",encoding=\"utf-8\",newline='\\n')\noutfile.write(str)\noutfile.close()\nprint(\"文件已保存到本地\")\n关于open函数，每一个参数，此篇博文讲的非常清楚非常详细，感谢博主的整理，大家可以看看，建议收藏http://blog.csdn.net/doiido/a...要强调的有2个参数encoding和newline，因为用的比较少，然后很多文章并不会提到\n\n有人可能会说，哇，真的懒没错，我就是懒，而且再说了，写了还没人家写的好，那我何必误人子弟。\n下面贴上全部代码\nimport urllib.request\nimport os\nfrom bs4 import BeautifulSoup\nimport time\n\ndef getHtml(url):\n    html = urllib.request.urlopen(url).read()\n    return html\n\n#获取字符串，因为我在国外，路由器low到爆，编码格式也蛋疼了我很久\nhtml = getHtml(\"http://192.168.0.254/pub/fbx_info.txt\")\n#将read()获取的是bytes编码转化成str\nhtml = html.decode(\"ISO-8859-1\")\n\n#再次检测编码\n#print(type(html))\n\n#操作字符串\nhtml = html.split('WAN')[1].split('Ethernet')[0]\ntime = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n#因为使用记事本，在记事本中换行只认\\r\\n\nstr = time+html+\"\\r\\n\"\n\n# 保存文件为txt，注意win环境路径写法\n#print(type(str))\noutfile = open(\"C:\\\\Users\\\\sw\\\\Desktop\\\\route.txt\",\"a+\",encoding=\"utf-8\",newline='\\n')\noutfile.write(str)\noutfile.close()\nprint(\"文件已保存到本地\")\n本来当初的想法是每秒获取一次流量，写入txt，再读txt，通过数据来绘图但是有事暂时搁下了，只是win计划任务定时运行，勉强凑活用下日后再学习补充\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "3"}