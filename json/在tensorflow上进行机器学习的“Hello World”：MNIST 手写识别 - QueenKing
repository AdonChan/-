{"title": "在tensorflow上进行机器学习的“Hello World”：MNIST 手写识别 - QueenKing ", "index": "深度学习,python,tensorflow,机器学习", "content": "安装好了tensorflow（TensorFlow 安装笔记），接下来就在他的官网指导下进行Mnist手写数字识别实验。\nsoftmax 实验过程\n进入tfgpu虚拟环境后，首先进入目录:/anaconda2/envs/tfgpu/lib/python2.7/site-packages/tensorflow/examples/tutorials/mnist/,然后进入IPython交互终端。\nIn [4]: from tensorflow.examples.tutorials.mnist import input_data\n   ...: mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n   ...: \nSuccessfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\nExtracting MNIST_data/train-images-idx3-ubyte.gz\nSuccessfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\nSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\nSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\n\nIn [5]: import tensorflow as tf\n\nIn [6]: x = tf.placeholder(tf.float32, [None, 784])\n\nIn [7]: W = tf.Variable(tf.zeros([784, 10]))\n   ...: b = tf.Variable(tf.zeros([10]))\n   ...: \n\nIn [8]: y = tf.nn.softmax(tf.matmul(x, W) + b)\n\nIn [9]: y_ = tf.placeholder(tf.float32, [None, 10])\n\nIn [10]: cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n\nIn [11]: train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n\nIn [12]: init = tf.initialize_all_variables()\n\nIn [13]: sess = tf.Session()\n    ...: sess.run(init)\n    ...: \nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce 940M\nmajor: 5 minor: 0 memoryClockRate (GHz) 1.124\npciBusID 0000:08:00.0\nTotal memory: 1023.88MiB\nFree memory: 997.54MiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:839] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce 940M, pci bus id: 0000:08:00.0)\n\nIn [14]: for i in range(1000):\n    ...:   batch_xs, batch_ys = mnist.train.next_batch(100)\n    ...:   sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n    ...:   \n\nIn [15]: correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n\nIn [16]: accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    ...: \n\nIn [17]: print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n0.9186\n\nsoftmax实验说明\nIn [4]：主要是下载数据\n\nIn [6]：意思是先分配输入x，None即输入图片数量稍后运行时确定，784即28*28，把一张28*28的图片拉长成为一维向量，保证每张图片拉长方式相同即可\n\nIn [7]：分配权重w和偏置b\n\nIn [8]：实现softmax模型，获得输出判断值y\n\nIn [9]: 分配实际判断值y_\n\nIn [10]:获得交叉熵形式的代价函数\n\nIn [11]：每一步使用0.5的学习率（步长）来进行梯度下降算法\n\nIn [12]：初始化所有变量\n\nIn [13]：开启一个会话，启动模型\n\nIn [14]：进行1000次随机梯度下降算法\n\nIn [15]:比较输出判断值y和真实判断值y_\n\nIn [16]:获得准确率\n\nIn [17]：获得测试集上的准确率:91.86%\n\n神经网络实验过程\nIn [1]: from tensorflow.examples.tutorials.mnist import input_data\n   ...: mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n   ...: \nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nExtracting MNIST_data/train-images-idx3-ubyte.gz\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\n\nIn [2]: import tensorflow as tf\n   ...: sess = tf.InteractiveSession()\n   ...: \nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce 940M\nmajor: 5 minor: 0 memoryClockRate (GHz) 1.124\npciBusID 0000:08:00.0\nTotal memory: 1023.88MiB\nFree memory: 997.54MiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:839] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce 940M, pci bus id: 0000:08:00.0)\n\nIn [3]: def weight_variable(shape):\n   ...:   initial = tf.truncated_normal(shape, stddev=0.1)\n   ...:   return tf.Variable(initial)\n   ...: \n   ...: def bias_variable(shape):\n   ...:   initial = tf.constant(0.1, shape=shape)\n   ...:   return tf.Variable(initial)\n   ...: \n\nIn [4]: \n\nIn [4]: def conv2d(x, W):\n   ...:   return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n   ...: \n   ...: def max_pool_2x2(x):\n   ...:   return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n   ...:                         strides=[1, 2, 2, 1], padding='SAME')\n   ...: \n\nIn [5]: W_conv1 = weight_variable([5, 5, 1, 32])\n   ...: b_conv1 = bias_variable([32])\n   ...: \n\nIn [6]: \n\nIn [7]: x = tf.placeholder(tf.float32, shape=[None, 784])\n   ...: y_ = tf.placeholder(tf.float32, shape=[None, 10])\n   ...: \n\nIn [8]: x_image = tf.reshape(x, [-1,28,28,1])\n   ...: \n\nIn [9]: h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n   ...: h_pool1 = max_pool_2x2(h_conv1)\n   ...: \n\nIn [10]: W_conv2 = weight_variable([5, 5, 32, 64])\n    ...: b_conv2 = bias_variable([64])\n    ...: \n    ...: h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n    ...: h_pool2 = max_pool_2x2(h_conv2)\n    ...: \n\nIn [11]: W_fc1 = weight_variable([7 * 7 * 64, 1024])\n    ...: b_fc1 = bias_variable([1024])\n    ...: \n    ...: h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n    ...: h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n    ...: \n\nIn [12]: keep_prob = tf.placeholder(tf.float32)\n    ...: h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n    ...: \n\nIn [13]: W_fc2 = weight_variable([1024, 10])\n    ...: b_fc2 = bias_variable([10])\n    ...: \n    ...: y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n    ...: \n\nIn [14]: cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n    ...: train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n    ...: correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n    ...: accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    ...: sess.run(tf.initialize_all_variables())\n    ...: for i in range(2000):\n    ...:   batch = mnist.train.next_batch(50)\n    ...:   if i%100 == 0:\n    ...:     train_accuracy = accuracy.eval(feed_dict={\n    ...:         x:batch[0], y_: batch[1], keep_prob: 1.0})\n    ...:     print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n    ...:   train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n    ...: \n    ...: print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n    ...:     x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n    ...: \nstep 0, training accuracy 0.04\nstep 100, training accuracy 0.86\nstep 200, training accuracy 0.92\nstep 300, training accuracy 0.88\nstep 400, training accuracy 0.96\nstep 500, training accuracy 0.9\nstep 600, training accuracy 1\nstep 700, training accuracy 0.98\nstep 800, training accuracy 0.92\nstep 900, training accuracy 0.98\nstep 1000, training accuracy 0.94\nstep 1100, training accuracy 0.96\nstep 1200, training accuracy 1\nstep 1300, training accuracy 0.98\nstep 1400, training accuracy 0.94\nstep 1500, training accuracy 0.96\nstep 1600, training accuracy 1\nstep 1700, training accuracy 0.92\nstep 1800, training accuracy 0.92\nstep 1900, training accuracy 0.96\nI tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (256):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (512):     Total Chunks: 1, Chunks in use: 0 768B allocated for chunks. 6.4KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/bfc_allocator.cc:639] Bin (1024):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\n...\n...\n...\n...\nLimit:                   836280320\nInUse:                    83845120\nMaxInUse:                117678336\nNumAllocs:                  246915\nMaxAllocSize:             45883392\n\nW tensorflow/core/common_runtime/bfc_allocator.cc:270] *****_******________________________________________________________________________________________\nW tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 957.03MiB.  See logs for memory state.\nW tensorflow/core/framework/op_kernel.cc:936] Resource exhausted: OOM when allocating tensor with shape[10000,28,28,32]\nE tensorflow/core/client/tensor_c_api.cc:485] OOM when allocating tensor with shape[10000,28,28,32]\n     [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape, Variable/read)]]\n\n\nIn [20]: cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n    ...: train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n    ...: correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n    ...: accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    ...: sess.run(tf.initialize_all_variables())\n    ...: for i in range(20000):\n    ...:   batch = mnist.train.next_batch(50)\n    ...:   if i%100 == 0:\n    ...:     train_accuracy = accuracy.eval(feed_dict={\n    ...:         x:batch[0], y_: batch[1], keep_prob: 1.0})\n    ...:     print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n    ...:   train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n    ...: \n    ...: print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n    ...:     x: mnist.test.images[0:200,:], y_: mnist.test.labels[0:200,:], keep_prob: 1.0}))\n    ...: \nstep 0, training accuracy 0.12\nstep 100, training accuracy 0.78\nstep 200, training accuracy 0.88\nstep 300, training accuracy 0.96\nstep 400, training accuracy 0.9\nstep 500, training accuracy 0.96\nstep 600, training accuracy 0.94\nstep 700, training accuracy 0.92\nstep 800, training accuracy 0.92\nstep 900, training accuracy 0.96\nstep 1000, training accuracy 0.94\nstep 1100, training accuracy 0.98\nstep 1200, training accuracy 0.96\nstep 1300, training accuracy 1\nstep 1400, training accuracy 0.98\n...\n...\n...\ntest accuracy 0.995\n\nIn [21]: cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n...: train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n...: correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n...: accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n...: sess.run(tf.initialize_all_variables())\n...: for i in range(20000):\n...:   batch = mnist.train.next_batch(50)\n...:   if i%100 == 0:\n...:     train_accuracy = accuracy.eval(feed_dict={\n...:         x:batch[0], y_: batch[1], keep_prob: 1.0})\n...:     print \"step %d, training accuracy %g\"%(i, train_accuracy)\n...:   train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n...: \n...: print \"test accuracy %g\"%accuracy.eval(feed_dict={\n...:     x: mnist.test.images[200:400,:], y_: mnist.test.labels[200:400,:], keep_prob: 1.0})\n...:     \n...: \nstep 0, training accuracy 0.12\nstep 100, training accuracy 0.94\nstep 200, training accuracy 0.86\nstep 300, training accuracy 0.96\nstep 400, training accuracy 0.9\nstep 500, training accuracy 1\nstep 600, training accuracy 0.96\nstep 700, training accuracy 0.88\nstep 800, training accuracy 1\nstep 900, training accuracy 0.98\nstep 1000, training accuracy 0.96\nstep 1100, training accuracy 0.94\nstep 1200, training accuracy 0.96\nstep 1300, training accuracy 0.96\nstep 1400, training accuracy 0.94\nstep 1500, training accuracy 0.98\nstep 1600, training accuracy 0.96\nstep 1700, training accuracy 0.98\n...\n...\n...\ntest accuracy 0.975\n\nIn [22]: for i in range(20000):\n...:   batch = mnist.train.next_batch(50)\n...:   if i%100 == 0:\n...:     train_accuracy = accuracy.eval(feed_dict={\n...:         x:batch[0], y_: batch[1], keep_prob: 1.0})\n...:     print \"step %d, training accuracy %g\"%(i, train_accuracy)\n...:   train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n...: \n...: print \"test accuracy %g\"%accuracy.eval(feed_dict={\n...:     x: mnist.test.images[400:1000,:], y_: mnist.test.labels[400:1000,:], keep_prob: 1.0})\n...: \nstep 0, training accuracy 1\nstep 100, training accuracy 1\nstep 200, training accuracy 0.98\nstep 300, training accuracy 0.98\nstep 400, training accuracy 0.98\nstep 500, training accuracy 1\nstep 600, training accuracy 0.96\nstep 700, training accuracy 0.96\n...\n...\n...\ntest accuracy  0.983333\n\n神经网络实验说明\nIn [1]: 导入数据，即测试集和验证集\n\nIn [2]: 引入 tensorflow 启动InteractiveSession(比session更灵活)\n\nIn [3]: 定义两个初始化w和b的函数，方便后续操作\n\nIn [4]: 定义卷积和池化函数，这里卷积采用padding，使得输入输出图像一样大，池化采取2x2，那么就是4格变一格\n\nIn [5]: 定义第一层卷积的w和b\n\nIn [7]: 分配输入x和y_\n\nIn [8]: 修改x的shape\n\nIn [9]: 把x_image和w进行卷积，加上b，然后应用ReLU激活函数，最后进行max-pooling\n\nIn [10]: 第二层卷积，和第一层卷积类似\n\nIn [11]: 全连接层\n\nIn [12]: 为了减少过拟合，可以在输出层之前加入dropout。（但是本例子比较简单，即使不加，影响也不大）\n\nIn [13]: 由一个softmax层来得到输出\n\nIn [14]: 定义代价函数，训练步骤，用ADAM来进行优化，可以看出，最后测试集太大了，我得显存不够    \n\nIn [20]: 只使用1~200个图片作为测试集，正确率是 0.995\n\nIn [21]: 只使用201~400个图片作为测试集，正确率是 0.975\n\nIn [22]: 只使用401~1000个图片作为测试集，正确率是 0.983333\n\n这个CNN的结构如下图所示：\n\n修改CNN\n现在尝试修改这个CNN结构，增加特征数量以期获得更好的效果，修改后的CNN结构如图：\n\n实验过程如下：\nIn [23]:     def weight_variable(shape):\n    ...:       initial = tf.truncated_normal(shape, stddev=0.1)\n    ...:       return tf.Variable(initial)\n    ...:     \n    ...:     def bias_variable(shape):\n    ...:       initial = tf.constant(0.1, shape=shape)\n    ...:       return tf.Variable(initial)\n    ...:     def conv2d(x, W):\n    ...:       return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n    ...:     def max_pool_2x2(x):\n    ...:       return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n    ...:                             strides=[1, 2, 2, 1], padding='SAME')\n    ...:     W_conv1 = weight_variable([5, 5, 1, 64])\n    ...:     b_conv1 = bias_variable([64])\n    ...:     h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n    ...:     h_pool1 = max_pool_2x2(h_conv1)\n    ...:     W_conv2 = weight_variable([5, 5, 64, 128])\n    ...:     b_conv2 = bias_variable([128])\n    ...:     \n    ...:     h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n    ...:     h_pool2 = max_pool_2x2(h_conv2)\n    ...:     W_fc1 = weight_variable([7 * 7 * 128, 1024])\n    ...:     b_fc1 = bias_variable([1024])\n    ...:     \n    ...:     h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*128])\n    ...:     h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n    ...:     keep_prob = tf.placeholder(\"float\")\n    ...:     h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n    ...:     W_fc2 = weight_variable([1024, 10])\n    ...:     b_fc2 = bias_variable([10])\n    ...:     \n    ...:     y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n    ...:     cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n    ...:     train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n    ...:     correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n    ...:     accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n    ...:     sess.run(tf.initialize_all_variables())\n    ...:     for i in range(20000):\n    ...:       batch = mnist.train.next_batch(50)\n    ...:       if i%100 == 0:\n    ...:         train_accuracy = accuracy.eval(feed_dict={\n    ...:             x:batch[0], y_: batch[1], keep_prob: 1.0})\n    ...:         print \"step %d, training accuracy %g\"%(i, train_accuracy)\n    ...:       train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n    ...:     \n    ...:     print \"test accuracy %g\"%accuracy.eval(feed_dict={\n    ...:         x: mnist.test.images[0:200,:], y_: mnist.test.labels[0:200,:], keep_prob: 1.0})\n    ...: \n    ...\n    ...\n    ...\n    test accuracy 1\nIn [24]: for i in range(20000):\n    ...:    batch = mnist.train.next_batch(50)\n    ...:    if i%100 == 0:\n    ...:       train_accuracy = accuracy.eval(feed_dict={\n    ...:          x:batch[0], y_: batch[1], keep_prob: 1.0})\n    ...:       print \"step %d, training accuracy %g\"%(i, train_accuracy)\n    ...:    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n    ...: \n    ...: print \"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images[200:400,:], y_: mnist.test.labels[200:400,:], keep_prob: 1.0})\n    ...: \n    ...\n    ...\n    ...\n    test accuracy 0.975\nIn [25]: for i in range(20000):\n    ...:    batch = mnist.train.next_batch(50)\n    ...:    if i%100 == 0:\n    ...:       train_accuracy = accuracy.eval(feed_dict={\n    ...:          x:batch[0], y_: batch[1], keep_prob: 1.0})\n    ...:       print \"step %d, training accuracy %g\"%(i, train_accuracy)\n    ...:    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n    ...: \n    ...: print \"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images[400:1000,:], y_: mnist.test.labels[400:1000,:], keep_prob: 1.0})\n    ...: \n    ...\n    ...\n    ...\n    W tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 717.77MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nIn [26]: print \"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images[400:600,:], y_: mnist.test.labels[400:600,:], keep_prob: 1.0})\n    ...:\n    test accuracy 0.985\nIn [28]: print \"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images[600:800,:], y_: mnist.test.labels[600:800,:], keep_prob: 1.0})\n    ...: \n    ...: \n    ...: \ntest accuracy 0.985\nIn [29]: print \"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images[800:1000,:], y_: mnist.test.labels[800:1000,:], keep_prob: 1.0})\n    ...: \n    ...: \ntest accuracy 0.995\n\n修改前的平均准确率是：\n（ 0.995*2 + 0.975*2 + 0.9833*6 ）/ 10 = 0.98398\n\n修改后的平均准确率是：\n（1*2 + 0.975*2+ 0.985*4 + 0.995*2）/ 10 = 0.98800\n\n可以看出增加特征过后，准确率提高了，但是内存消耗也变大了（400~1000的图片验证出现了OOM错误），而且实验过程中也感受到时间消耗更大，怎么取舍就取决于具体需求和具体的硬件配置了。\n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "3"}