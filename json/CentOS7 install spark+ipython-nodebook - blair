{"title": "CentOS7 install spark+ipython-nodebook - blair ", "index": "spark,python", "content": "ipython-nodebook\n\nIPython notebook 目前已经成为用 Python 做教学、计算、科研的一个重要工具。\nIPython Notebook 使用浏览器作为界面，向后台的 IPython 服务器发送请求，并显示结果。\n在浏览器的界面中使用单元(Cell)保存各种信息。Cell 有多种类型，经常使用的有表示格式化文本的 Markdown单元，和表示代码的 Code单元。\n\n\n本文主要介绍在 centos7 minimal 上安装 ipython-nodebook 流程\n1. install ifconfig\nyum search ifconfig\nyum install net-tools.x86_64\n2. install vim\nyum search vim\nyum install vim-enhanced\n3. install wget\n[libin@centos-linux-1 x]$ yum search wget\nLoaded plugins: fastestmirror\nLoading mirror speeds from cached hostfile\n* base: mirrors.skyshe.cn\n* extras: mirrors.163.com\n* updates: mirrors.163.com\n============================================================================================ N/S matched: wget =============================================================================================\nwget.x86_64 : A utility for retrieving files using the HTTP or FTP protocols\n\n Name and summary matches only, use \"search all\" for everything.\n\n[libin@centos-linux-1 x]$ yum install wget.x86_64\n4. install Jdk\n# green install jdk-7u80-linux-x64.gz\n# edit /etc/profile add\n## libin add ##\n\n### JAVA ###\nJAVA_HOME=/home/x/jdk\nJAVA_BIN=$JAVA_HOME/bin\nPATH=$JAVA_HOME/bin:$PATH\nCLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/jre/lib/dt.jar:$JAVA_HOME/jre/lib/tools.jar\nexport JAVA_HOME JAVA_BIN PATH CLASSPATH\n\"/etc/profile\" 86L, 2035C\n\n# /etc/profile：该文件是用户登录时，操作系统定制用户环境时使用的第一个文件，应用于登录到系统的每一个用户。 对所有用户有效 ##\n5. install Scala\n# green install scala-2.10.4.tgz\n# edit /etc/profile add\n\n### Scala ###\n#export SCALA_HOME=/usr/local/xSoft/scala\nexport SCALA_HOME=/home/x/scala\nexport PATH=${SCALA_HOME}/bin:$PATH\n6. install Spark (Standalone)\ngreen install spark-1.5.2-bin-hadoop2.6.tgz\ncp conf/spark-env.sh.template conf/spark-env.sh\nedit conf/spark-env.sh add\nexport JAVA_HOME=/home/x/jdk\nexport SCALA_HOME=/home/x/scala\nexport SPARK_HOME=/home/x/spark\nexport SPARK_MASTER_IP=192.168.181.113\nexport MASTER=spark://192.168.181.113:7077\n\nexport SPARK_EXECUTOR_INSTANCES=2\nexport SPARK_EXECUTOR_CORES=1\n\nexport SPARK_WORKER_MEMORY=1000m\nexport SPARK_EXECUTOR_MEMORY=300m\n\nexport SPARK_LIBRARY_PATH=${SPARK_HOME}/lib\n\n#export SPARK_LAUNCH_WITH_SCALA=0\n#export SCALA_LIBRARY_PATH=${SPARK_HOME}/lib\n\n\n#export SPARK_LIBRARY_PATH=/home/deploy/spark/spark-1.5.2-bin-hadoop2.6/lib\n7. install ipython-nodebook\nopenssh、zlib\nyum -y install openssh-clients\nyum install zlib\nsetuptools、pip\ntar xvf setuptools-18.1.tar.gz\ncd setuptools-18.1\nsudo python setup.py build\nsudo python setup.py install\n\ntar xvf pip-8.1.0.tar.gz\ncd pip-8.1.0\nsudo python setup.py build\nsudo python setup.py install\nipython、matplotlib\nsudo pip install ipython\nsudo pip install matplotlib\npython-dev、g++\nsudo yum install python-devel （如果没有安装 python 源代码，会报找不到 Python.h 的头文件错误）\nsudo yum install gcc-c++\n install python-notebook \n# 前面install的各种py相关, 为个这一步\n\nsudo pip install notebook\n8. start-up notebook\nPYSPARK_DRIVER_PYTHON=ipython PYSPARK_DRIVER_PYTHON_OPTS=\"notebook --ip=192.168.181.113\" /home/x/spark/bin/pyspark\n浏览器访问 http://192.168.181.113:8888/notebooks\n\n9. spark-notebook example1\n%pylab inline\n%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata =[33,25,20,12,10]\nplt.figure(num=1, figsize=(6,6))\nplt.axes(aspect=1)\nplt.title('Plot 3', size=14)\nplt.pie(data, labels=('Group 1','Group 2','Group 3','Group 4','Group 5'))\nplt.savefig('/home/x/spark/test_libin/plot3.png', format='png')\n\nmaybe attention point\npython -V\n\n#若系统默认是python2.6，需要升级到2.7\ntar xvf Python-2.7.tgz\n./configure --with-zlib=/usr/include --prefix=/usr/local/python27 --prefix=/usr/local/python27\n\nmake\nmake install\nmv /usr/bin/python /usr/bin/python_old\nln -s /usr/local/python27/bin/python /usr/bin/\npython\n此处已经可以正常使用python2.7了\n但是因为yum是使用的2.6的版本来用的，所以 还需要修改一下\n[root@wangyuelou Python-2.7.2]# vim /usr/bin/yum\n#!/usr/bin/python   #修改此处为2.6的位置\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "3"}