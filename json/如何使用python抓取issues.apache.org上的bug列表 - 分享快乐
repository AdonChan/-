{"title": "如何使用python抓取issues.apache.org上的bug列表 - 分享快乐 ", "index": "python", "content": "问题描述\n开源在Apache的项目中，通常我们会关心我们开源的项目中每天bug的数量、最新的10条问题，统计各模块的bug数量，按照人名统计等工作。但这些数据都在apache网站上，存在两个问题，一个是国内平常访问Apache如果不走代理就会比较慢；二是数据没办法供内部系统使用。于是我想到用一个脚本每天定时运行来解决数据的问题。通过脚本从Apache上把数据拉下来存储在自己内部数据库中，基于本地数据库运行的内部系统可以完成各种图表展示和数据统计的工作，这样即提高了数据访问的效率，也可以很好的和内部系统结合完成自动化的问题跟踪和解决。同时还可以将外部系统和内部bug跟踪系统进行对比，将重复的问题自动化的补充答案。等等，优点多多。\n欢迎大家打开脑洞提出更多的方案！\n\n1.使用说明\n脚本依赖:\n此脚本依赖于requests,各位点击连接自取，安装requests可能会依赖于pip，大家可以把python升级到2.7以上安装pip，2.7以下用网上教程会报错。\n脚本使用说明:\npython SCRIPT_NAME FILE_NAMESCRIPT_NAME:下面这段代码所在的文件名FILE_NAME: 将数据导入到的目标文件名，后缀默认为csv\n示例:\npython jira.py ~/dataFile\n2.分享完整代码\n打开python的文件jira.py，内容如下：\nimport requests\nimport sys\nreload(sys)\n##设置系统编码，如果不是utf-8会有错误\nsys.setdefaultencoding('utf-8')\n\ndataFileName=sys.argv[1]\njiraFileName=dataFileName+'.csv'\nprint \"Load from JIRA -------------------\"\n##load from JIRA\nurl = \"https://issues.apache.org/jira/sr/jira.issueviews:searchrequest-csv-all-fields/temp/SearchRequest.csv?jqlQuery=project+%3D+TRAFODION+AND+resolution+%3D+Unresolved+ORDER+BY+priority+DESC%2C+updated+DESC\"\nr = requests.get(url)\nwith open(jiraFileName, 'w') as f:\n    f.write(r.text)\n3.遇到的问题总结\n1)操作系统中最初用的是python2.6的环境，结果安装pip一直报错，先是报没有权限，这个只要用sudo可以解决；接下来是报一些语法错误,如下图：2)系统编码问题，不设置sys.setdefaultencoding('utf-8')，python脚本就会暴出编码问题。\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}