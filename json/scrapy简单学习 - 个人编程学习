{"title": "scrapy简单学习 - 个人编程学习 ", "index": "scrapy,python", "content": "学习网站：scrapy入门教程\n1.创建项目：cmd打开scrapy所在位置，输入命令\nscrapy startproject tutorial\n2.定义item：编辑item.py,对您想要采集的数据类型进行定义。例如：\nimport scrapy\n\nclass DmozItem(scrapy.Item):\n    title = scrapy.Field()\n    link = scrapy.Field()\n    desc = scrapy.Field()\n3.编写爬虫：在spiders的文件下新建一个domz_spider.py文件，代码如下：\nimport scrapy\n\nfrom tutorial.items import DmozItem\n\nclass DmozSpider(scrapy.Spider):\n    name = \"dmoz\"\n    allowed_domains = [\"dmoz.org\"]\n    start_urls = [\n        \"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/\",\n        \"http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/\"\n    ]\n\n    def parse(self, response):\n        for sel in response.xpath('//ul/li'):\n            item = DmozItem()\n            item['title'] = sel.xpath('a/text()').extract()\n            item['link'] = sel.xpath('a/@href').extract()\n            item['desc'] = sel.xpath('text()').extract()\n            yield item\n\n4.启动爬虫：在cmd的命令行转至spiders的根目录下，输入命令\nscrapy crawl dmoz     \n5.保存数据：\nscrapy crawl dmoz -o items.json\n或者\nscrapy crawl dmoz -o items.csv\n\n                ", "mainLikeNum": ["4 "], "mainBookmarkNum": "18"}