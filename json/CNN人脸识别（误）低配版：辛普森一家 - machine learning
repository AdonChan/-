{"title": "CNN人脸识别（误）低配版：辛普森一家 - machine learning ", "index": "python,tensorflow", "content": "看动画也不忘机器学习✌( •̀ ω •́ )y：\n这个项目在Keras（后端为Tensorflow）上实现用神经网络根据动画片截图对辛普森一家的成员进行分类，使用的是目前最复杂和艰深的神经网络之一：卷积神经网络（Convolutional Neural Network，CNN）。数据集为11个辛普森家族的成员的动画片截图，存放在11个文件夹中，每个成员有大约1000张图片。这些图片有不一样的尺寸，在进过归一化后和标签一起输入神经网络进行训练\n由于这次图像识别训练直接用的图片，因此该程序实际上可以用来做很多事情（验证码识别，智能交通领域的机器视觉，行人和车辆识别），只需更换文件夹路径，指向新的数据集即可。\n\n直接上代码：\n导入依赖库：\nfrom PIL import Image\nimport numpy as np\nimport os\nimport glob\nimport re\nimport keras\nfrom keras.optimizers import SGD, Adam\nfrom keras.models import Sequential\nfrom keras.models import load_model\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\n*定义函数：从数据集中导入图片，归一化后再转化为特征矩阵：每个文件夹中取前100张图片的数据放到测试集，剩余的样本全都作为训练集。*\ndef read_img(location):\n    x_train = [] \n    y_train = [] \n    x_test = [] \n    y_test = [] \n    label_name = [] \n    dirs = os.listdir(location) \n    label = 0 \n    count = 0\n    for i in dirs: #loop all directory\n        print(i)\n        n = 0 \n        label_name.append(i) #save folder name in var label_name\n        x_s = 200\n        y_s = 200\n        for pic in glob.glob(location+'\\\\'+i+'\\*.jpg'): \n            im = Image.open(pic) #open data\n            im = im.resize((x_s, y_s), Image.ANTIALIAS)\n            im = np.array(im) #store im as numpy array\n            if(im.shape[0]==200 and im.shape[1]==200): \n                r = im[:,:,0]\n                g = im[:,:,1]\n                b = im[:,:,2]\n                if(n<100): \n                    x_test.append([r,g,b]) #save in x_test\n                    y_test.append([label]) #save in y_test\n                else: #remaining data set as training data\n                    x_train.append([r,g,b]) #save in x_train\n                    y_train.append([label]) #save in y_train\n                n = n + 1 \n                count = count + 1 \n        label = label + 1 #increment label\n    print(label_name)\n    print(dirs)\n    return np.array(x_train),np.array(y_train),np.array(x_test),np.array(y_test)\n将图片经过归一化处理，变为200p200p的尺寸：*原图：\n归一化的图片：\n通过定义的函数生成训练数据、训练标签、测试数据、测试标签：\npath='E:\\\\JLD\\\\desktop\\\\the-simpsons-characters-dataset\\\\simpsons_dataset'\nimg_rows = 200 #num of image height\nimg_cols = 200 #num of image width\nnum_class = 11 #num of classes/labels\nx_train,y_train,x_test,y_test = read_img(path) \n输出的结果：完成对11个文件夹的遍历，并输出训练标签向量和测试标签向量：\n\n对训练数据和测试数据的值做线性变化，提高机器学习的速率，并将标签转化为向量，以便用交叉熵计算loss值：\nx_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3) \nx_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3) \ninput_shape = (img_rows, img_cols, 3)\nx_train = x_train.astype('float32') \nx_test = x_test.astype('float32') \nx_train /= 255 \nx_test /= 255 \ny_train = keras.utils.to_categorical(y_train, num_class) \ny_test = keras.utils.to_categorical(y_test, num_class) \n输出训练训练特征矩阵、训练标签向量、测试特征矩阵、测试标签向量的维度：\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)\n运行结果：\n\n定义CNN神经网络模型：\nmodel = Sequential()\nmodel.add(Conv2D(64, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_class, activation='softmax'))\n编译模型：用交叉熵作为损失值，随机梯度下降作为优化器，预测的准确率用以定义模型的好坏。\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n              metrics=['accuracy'])\n训一次模型并保存：模型一个批次处理64个样本，迭代1次，用测试集数据做验证。\nmodel.fit(x_train, y_train, batch_size=64, epochs=1, verbose=1, validation_data=(x_test, y_test))\nmodel.save('Simpson.h5')\n循环进行模型训练，每一次循环迭代一次训练，保存并读取模型，循环十次，这样写是因为避免显存溢出导致之前所有训练结果丢失。该语句可重复运行。机器学习，俗称“炼丹”：\nfor i in range(0,10):\n    print('The '+str(i)+' th Iteration')\n    model=load_model('Simpson.h5')\n    model.fit(x_train, y_train, batch_size=64, epochs=1, verbose=1, validation_data=(x_test, y_test))\n    model.save('Simpson.h5')\n    K.clear_session()\n运行结果：该模型在测试集上最终达到了99.09%的准确率。\n若要用该模型进行识别应用，只需调用model.predict()函数就行。\n\n                ", "mainLikeNum": ["2 "], "mainBookmarkNum": "7"}