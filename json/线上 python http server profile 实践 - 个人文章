{"title": "线上 python http server profile 实践 - 个人文章 ", "index": "python", "content": "背景：\nqa 容器数量过高，可能的原因有 api 请求的不合理调用，api 本身的性能问题等，目前的问题难以定位，所以准备出一个 qa 的 profile 分析资源消耗。\n需求\n可视化的形式查看整体 http server 的响应时间占比，定位大头优先消除。\n工具\npython 系的 profile 工具整体上是在太少，cprofile 用起来有些蛋疼，找了半天决定用 nylas 之前的一个 demo。\n这个工具需要 server 端是 gevent，号称不用 gevent 也能用，不过需要改代码。\nprofile 工具，此工具采用unix singal 的方式定时采集 frame python 的栈信息，需要 hack 到生成代码，并且需要启动一个采集进程，由于 github 给出的应该是个 demo，可视化的 server 目前长时间采集会有问题（采集一段时间后数据过大，页面卡顿，但是原服务的响应                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            似乎不受影响）\n另外，原项目中的代码需要 python 编译时做一些事情，我 fork 了一份做了一点修改。具体操作见 README\nhttps://github.com/duoduo369/...\n用法\n我决定还是从 README 贴过来\ntest.sh 脚本的内容就是一波 curl 请求，每秒执行一次，跑个一小时好了，再大 demo 的 http 可视化工具可能卡。\ngit clone 这个项目\ncd 到项目目录\npip install -e .\n\n将 stacksampler.py 复制到项目目录，在按照 readme\n中代码修改的方式修改对应代码\n\n项目启动后执行\npython -m stackcollector.collector --host localhost --ports 16384 --interval 60\n写一个批量请求脚本 test.sh\n每秒执行\nwatch -n1 test.sh\n\n可视化工具\npython -m stackcollector.visualizer --port 5555\n如果项目所在机器无法通过5555端口访问，将 /var/lib/stackcollector\n下的所有文件复制到可以访问机器访问\n分析\n就拿 demo 中的这张图来看，需要横着看+竖着看，每一行相加，每一块儿（假设为 A）垂直上面一格所有小块相加等于这一块（A）。所以找面积最大的追踪查看即可。\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "1"}