{"title": "保存数据到MySql数据库——我用scrapy写爬虫（二） - 泰客笔记 ", "index": "scrapy,python", "content": "写在前面\n上一篇（https://www.tech1024.cn/origi... ）说了如何创建项目，并爬去网站内容，下面我们说一下如何保存爬去到的数据\n开始爬取\n创建Spider，上一篇我们已经创建了ImoocSpider，我们做一下修改，可以连续下一页爬取。scrapyDemo/spiders目录下的ImoocSpider类：\n# -*- coding: utf-8 -*-\n\nimport scrapy\nfrom urllib import parse as urlparse\nfrom scrapyDemo.ImoocCourseItem import ImoocCourseItem\n\n\n# 慕课网爬取\nclass ImoocSpider(scrapy.Spider):\n    # spider的名字定义了Scrapy如何定位(并初始化)spider，所以其必须是唯一的\n    name = \"imooc\"\n\n    # URL列表\n    start_urls = ['http://www.imooc.com/course/list']\n    #  域名不在列表中的URL不会被爬取。\n    allowed_domains = ['www.imooc.com']\n\n    def parse(self, response):\n        learn_nodes = response.css('a.course-card')\n\n        item = ImoocCourseItem()\n        # 遍历该页上所有课程列表\n        for learn_node in learn_nodes:\n            course_url = learn_node.css(\"::attr(href)\").extract_first()\n            # 拼接课程详情页地址\n            course_url = urlparse.urljoin(response.url, course_url)\n            # 课程地址\n            item['course_url'] = course_url\n            # 课程图片\n            item['image'] = learn_node.css(\n                \"img.course-banner::attr(src)\").extract_first()\n            # 进入课程详情页面\n            yield scrapy.Request(\n                url=course_url, callback=self.parse_learn, meta=item)\n\n        # 下一页地址\n        next_page_url = response.css(\n            u'div.page a:contains(\"下一页\")::attr(href)').extract_first()\n        if next_page_url:\n            yield scrapy.Request(\n                url=urlparse.urljoin(response.url, next_page_url),\n                callback=self.parse)\n\n    def parse_learn(self, response):\n        item = response.meta\n        # 课程标题\n        item['title'] = response.xpath(\n            '//h2[@class=\"l\"]/text()').extract_first()\n        # 课程简介\n        item['brief'] = response.xpath(\n            '//div[@class=\"course-brief\"]/p/text()').extract_first()\n        yield item\n这里用到了scrapyDemo目录下ImoocCourseItem类，下面我就说一下。\nItem数据容器\n在scrapyDemo目录下创建ImoocCourseItem.py，这个类就是我们用了保存数据的容器，我们定义了标题、图片、简介、地址。scrapyDemo目录下ImoocCourseItem类：\n# -*- coding: utf-8 -*-\n\n# Define here the models for your scraped items\n#\n# See documentation in:\n# http://doc.scrapy.org/en/latest/topics/items.html\n\nimport scrapy\n\n\nclass ImoocCourseItem(scrapy.Item):\n    # define the fields for your item here like:\n    title = scrapy.Field()\n    # cate = scrapy.Field()\n    image = scrapy.Field()\n    # desc = scrapy.Field()\n    brief = scrapy.Field()\n    # cate = scrapy.Field()\n    course_url = scrapy.Field()\n    pass\n\nPipeline管道\nPipeline是用来处理抓取到的数据，我们在scrapyDemo目录下创建ScrapydemoPipeline.py类\n# -*- coding: utf-8 -*-\n\n# Define your item pipelines here\n#\n# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n# See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html\n\nfrom scrapyDemo.db.dbhelper import DBHelper\n\n\nclass ScrapydemoPipeline(object):\n    # 连接数据库\n    def __init__(self):\n        self.db = DBHelper()\n    \n    def process_item(self, item, spider):\n        # 插入数据库\n        self.db.insert(item)\n        return item\n\n别忘了在配置文件中开启管道哦，scrapyDemo目录下的settings.py文件中，找到下ITEM_PIPELINES,修改为\nITEM_PIPELINES = {\n   'scrapyDemo.pipelines.ScrapydemoPipeline': 300,\n}\n数据库操作\n这里面我们用到了数据库的操作DBHelper类，那么我们在scrapyDemo/db目录下创建dbhelper.py 模块，记得再创建一个__init__.py哦。\n# -*- coding: utf-8 -*-\n\nimport pymysql\nfrom twisted.enterprise import adbapi\nfrom scrapy.utils.project import get_project_settings  #导入seetings配置\nimport time\n\n\nclass DBHelper():\n    '''这个类也是读取settings中的配置，自行修改代码进行操作'''\n\n    def __init__(self):\n        settings = get_project_settings()  #获取settings配置，设置需要的信息\n\n        dbparams = dict(\n            host=settings['MYSQL_HOST'],  #读取settings中的配置\n            db=settings['MYSQL_DBNAME'],\n            user=settings['MYSQL_USER'],\n            passwd=settings['MYSQL_PASSWD'],\n            charset='utf8',  #编码要加上，否则可能出现中文乱码问题\n            cursorclass=pymysql.cursors.DictCursor,\n            use_unicode=False,\n        )\n        #**表示将字典扩展为关键字参数,相当于host=xxx,db=yyy....\n        dbpool = adbapi.ConnectionPool('pymysql', **dbparams)\n\n        self.dbpool = dbpool\n\n    def connect(self):\n        return self.dbpool\n\n    #创建数据库\n    def insert(self, item):\n        sql = \"insert into tech_courses(title,image,brief,course_url,created_at) values(%s,%s,%s,%s,%s)\"\n        #调用插入的方法\n        query = self.dbpool.runInteraction(self._conditional_insert, sql, item)\n        #调用异常处理方法\n        query.addErrback(self._handle_error)\n\n        return item\n\n    #写入数据库中\n    def _conditional_insert(self, tx, sql, item):\n        item['created_at'] = time.strftime('%Y-%m-%d %H:%M:%S',\n                                           time.localtime(time.time()))\n        params = (item[\"title\"], item['image'], item['brief'],\n                  item['course_url'], item['created_at'])\n        tx.execute(sql, params)\n\n    #错误处理方法\n\n    def _handle_error(self, failue):\n        print('--------------database operation exception!!-----------------')\n        print(failue)\n\n这里用到了pymysql和adbapi，adbapi是python的数据库连接池，可以pip安装：\npip install pymysql\npip install Twisted\n这里面还用到了get_project_settings方法，意思是从配置文件settings.py里边获取数据库配置信息，我们在scrapyDemo目录下的settings.py文件最后加入数据库信息\n#Mysql数据库的配置信息\nMYSQL_HOST = '192.168.6.1'\nMYSQL_DBNAME = 'scrapy_demo_db'         #数据库名字，请修改\nMYSQL_USER = 'root'             #数据库账号，请修改 \nMYSQL_PASSWD = 'abc-123'         #数据库密码，请修改\n\nMYSQL_PORT = 3306               #数据库端口，在dbhelper中使用\n建表语句如下：\nDROP TABLE IF EXISTS `tech_courses`;\nCREATE TABLE `tech_courses` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `title` varchar(255) DEFAULT NULL,\n  `image` varchar(255) DEFAULT NULL,\n  `brief` varchar(255) DEFAULT NULL,\n  `course_url` varchar(255) DEFAULT NULL,\n  `created_at` timestamp NULL DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=0 DEFAULT CHARSET=utf8mb4;\n大功告成\n我们在命令行运行项目\nF:\\techlee\\python\\scrapyDemo>scrapy crawl imooc\n2017-10-25 23:29:18 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: scrapyDemo)\n2017-10-25 23:29:18 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'scrapyDemo', 'NEWSPIDER_MODULE': 'scrapyDemo.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapyDemo.spiders']}\n2017-10-25 23:29:19 [scrapy.middleware] INFO: Enabled extensions:\n['scrapy.extensions.corestats.CoreStats',\n\n……\n\n2017-10-26 00:06:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.imooc.com/learn/127> (referer: http://www.imooc.com/course/list?page=26)\n2017-10-26 00:06:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.imooc.com/learn/127>\n{'course_url': 'http://www.imooc.com/learn/127', 'image': '//img1.mukewang.com/53966c2c00018bed06000338-240-135.jpg', 'depth': 26, 'download_timeout': 180.0, 'download_slot': 'www.imooc.com', 'retry_times': 1, 'download_latency': 0.24331021308898926, 'title': '玩儿转Swift', 'brief': '简介：我们期望用户在看完这套教程后，对swift语言的了解能达到中上水平。这意味着在接触Cocoa Touch将一点儿都不费劲，对一些高级概念，诸如闭包 、协议、泛型、内存管理都能有所理解并且有所实践。这套教程一定比市面上普遍看到的Swift中文教程深入，并且演示示例更丰富。'}\n2017-10-26 00:06:48 [scrapy.core.engine] INFO: Closing spider (finished)\n2017-10-26 00:06:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n{'downloader/exception_count': 24,\n 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 24,\n 'downloader/request_bytes': 359595,\n 'downloader/request_count': 836,\n 'downloader/request_method_count/GET': 836,\n 'downloader/response_bytes': 8680952,\n 'downloader/response_count': 812,\n 'downloader/response_status_count/200': 812,\n 'finish_reason': 'finished',\n 'finish_time': datetime.datetime(2017, 10, 25, 16, 6, 48, 884826),\n 'item_scraped_count': 779,\n 'log_count/DEBUG': 1616,\n 'log_count/INFO': 18,\n 'log_count/WARNING': 1,\n 'request_depth_max': 32,\n 'response_received_count': 812,\n 'retry/count': 24,\n 'retry/reason_count/twisted.internet.error.TimeoutError': 24,\n 'scheduler/dequeued': 835,\n 'scheduler/dequeued/memory': 835,\n 'scheduler/enqueued': 835,\n 'scheduler/enqueued/memory': 835,\n 'start_time': datetime.datetime(2017, 10, 25, 15, 55, 43, 289328)}\n2017-10-26 00:06:48 [scrapy.core.engine] INFO: Spider closed (finished)\n\n如果没有报错，我们的数据库是不是有数据了呢\n779    玩儿转Swift    //img1.mukewang.com/53966c2c00018bed06000338-240-135.jpg    简介：我们期望用户在看完这套教程后，对swift语言的了解能达到中上水平。这意味着在接触Cocoa Touch将一点儿都不费劲，对一些高级概念，诸如闭包、协议、泛型、内存管理都能有所理解并且有所实践。这套教程一定比市面上普遍看到的Swift中文教程深入，并且演示示例更丰富。    http://www.imooc.com/learn/127    2017-10-26 00:06:48\n778    iOS9那些神坑    //img1.mukewang.com/576b7a6a0001573206000338-240-135.jpg    简介：为啥我用iOS9开发的应用无法进行网络请求？为啥多出了一个Bitcode编译选项？什么又是白名单呢？这些都是iOS9的一些新特性，在我们的这门课程中都会为大家一一介绍。\n    http://www.imooc.com/learn/609    2017-10-26 00:06:08\n777    Cocos2d-x坦克大战--上    //img4.mukewang.com/570763d20001662806000338-240-135.jpg    简介：FC上的坦克大战相信大家都玩过~有逃学玩坦克的可以自己默默的扣一个1了~我们现在长大了，学习游戏开发了。有没有想过将小时候玩过的游戏复刻出来了？不为了彰显自己的技术，只为了小时候因为玩游戏而逃学挨过的打。由资深游戏开发者徐波老师为大家复刻的FC坦克大战吧\n    http://www.imooc.com/learn/610    2017-10-26 00:06:08\n776    快速入门ThinkPHP 5.0 --模型篇    //img2.mukewang.com/594cf6120001ddaf06000338-240-135.jpg    简介：一个标准的网站一定离不开数据库的操作，在本套课程中我和你一起来揭开ThinkPHP5 数据操作的神秘面纱，和你一起愉快的使用 ThinkPHP5 操作数据库，让数据库操作变的更愉悦。    http://www.imooc.com/learn/854    2017-10-26 00:06:08\n775    MongoDB Day 2015 深圳    //img4.mukewang.com/56779555000160d106000338-240-135.jpg    简介：本次年度大会由来自MongoDB内部的专家以及各行业MongoDB大牛关于数据安全、wiredtiger内部机制、OpsManager以及在其它行业方面的成功案例。大会吸引了200多位MongoDB爱好者，会场内座无虚席！    http://www.imooc.com/learn/562    2017-10-26 00:06:08\n774    web安全之SQL注入    //img1.mukewang.com/5991489e00019f5c06000338-240-135.jpg    简介：SQL注入自从WEB和数据库发展以来就一直存在，而且给WEB应用带来很大的安全问题，会造成用户隐私数据的泄露，数据库版本信息泄露和数据库攻击等，给业务带来很大的损失和不好的社会影响。所以对于我们WEB开发人员来说，项目开发过程中一定要培养一定的安全意识，了解SQL注入的定义，产生的原理、具体的一些攻击手法和相应的预防措施，为了更好的增加开发项目的健壮性和安全性    http://www.imooc.com/learn/883    2017-10-26 00:06:07\n773    那些年你遇到的错误与异常    //img3.mukewang.com/572b06f40001d1c806000338-240-135.jpg    简介：本课程主要讲解两部分内容，先从PHP中的错误模块谈起，讲解了PHP中常见的错误类型，剖析了PHP中的错误处理。接着又讲解了PHP5面向对象过程中新的错误处理方式--异常模块，由浅入深，讲解异常及异常的实战应用等。    http://www.imooc.com/learn/380    2017-10-26 00:06:07\n772    基于Websocket的火拼俄罗斯（基础）    //img3.mukewang.com/59ed96eb0001fe3606000338-240-135.jpg    简介：本课程主要带领大家了解要实现火拼俄罗斯的基础知识WebSocket，以及socket.io,为后续实现火拼俄罗斯打下基础。    http://www.imooc.com/learn/861    2017-10-26 00:06:07\n771    Java定时任务调度工具详解之Quartz篇    //img1.mukewang.com/5940992d0001cae906000338-240-135.jpg    简介：本课程是系列课程Java定时任务调度工具详解中的Quartz篇，本系列课程旨在通过详细讲述Java定时调度工具的基本概念、工具，和这些工具里面包含的各个组件之间的关系，以及如何使用这些工具来实现定时调度功能，让学生能够对Java定时调度工具有一个清晰而准确的认识。然后结合一些经典的使用场景通过手把手的命令行操作进行教学，使同学们得心用手地使用这些定时调度工具来实现自己想要的功能。讲师实战课程已经上线，详情：http://coding.imooc.com/learn/list/144.html    http://www.imooc.com/learn/846    2017-10-26 00:06:07\n原文 https://www.tech1024.cn/origi...\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "3"}