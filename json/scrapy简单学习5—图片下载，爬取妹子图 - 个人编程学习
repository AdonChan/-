{"title": "scrapy简单学习5—图片下载，爬取妹子图 - 个人编程学习 ", "index": "scrapy,python", "content": "学习网站：爬虫，整站爬取妹子图\n1.item.py(定义爬取的内容)\nimport scrapy\n\n\nclass MeizituItem(scrapy.Item):\n    url = scrapy.Field()\n    name = scrapy.Field()\n    tags = scrapy.Field()\n    image_urls = scrapy.Field()\n    images = scrapy.Field()\n2.spider的编写\n# -*- coding: utf-8 -*-\nimport scrapy\nfrom scrapy.selector import Selector\n#Item Loaders提供了一种便捷的方式填充抓取到的 :Items\nfrom scrapy.contrib.loader import ItemLoader, Identity\nfrom meizitu.items import MeizituItem\n\nclass MeiziSpider(scrapy.Spider):\n    name = \"meizi\"\n    allowed_domains = [\"meizitu.com\"]\n    start_urls = (\n        'http://www.meizitu.com/',\n    )\n\n    def parse(self, response):\n        #sel是页面源代码，载入scrapy.selector\n        sel = Selector(response)\n        #每个连接，用@href属性\n        for link in sel.xpath('//h2/a/@href').extract():\n            #请求=Request(连接，parese_item)\n            request = scrapy.Request(link, callback=self.parse_item)\n            yield request#返回请求\n        #获取页码集合\n        pages = sel.xpath('//*[@id=\"wp_page_numbers\"]/ul/li/a/@href').extract()\n        print('pages: %s' % pages)#打印页码\n        if len(pages) > 2:#如果页码集合>2\n            page_link = pages[-2]#图片连接=读取页码集合的倒数第二个页码\n            page_link = page_link.replace('/a/', '')#图片连接=page_link（a替换成空）\n            request = scrapy.Request('http://www.meizitu.com/a/%s' % page_link, callback=self.parse)\n            yield request#返回请求\n\n    def parse_item(self, response):\n        #l=用ItemLoader载入MeizituItem()\n        l = ItemLoader(item=MeizituItem(), response=response)\n        #名字\n        l.add_xpath('name', '//h2/a/text()')\n        #标签\n        l.add_xpath('tags', \"//div[@id='maincontent']/div[@class='postmeta  clearfix']/div[@class='metaRight']/p\")\n        #图片连接\n        l.add_xpath('image_urls', \"//div[@id='picture']/p/img/@src\", Identity())\n        #url\n        l.add_value('url', response.url)\n        \n        return l.load_item()\n3.pipeline的编写（下载图片，新增图片）\n# -*- coding: utf-8 -*-\n\n# Define your item pipelines here\n#图片下载部分（自动增量）\n# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n# See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html\nimport requests\nfrom meizitu import settings\nimport os\n\n#图片下载类\nclass ImageDownloadPipeline(object):\n    def process_item(self, item, spider):\n        if 'image_urls' in item:#如何‘图片地址’在项目中\n            images = []#定义图片空集\n            \n            dir_path = '%s/%s' % (settings.IMAGES_STORE, spider.name)\n\n            if not os.path.exists(dir_path):\n                os.makedirs(dir_path)\n            for image_url in item['image_urls']:\n                us = image_url.split('/')[3:]\n                image_file_name = '_'.join(us)\n                file_path = '%s/%s' % (dir_path, image_file_name)\n                images.append(file_path)\n                if os.path.exists(file_path):\n                    continue\n\n                with open(file_path, 'wb') as handle:\n                    response = requests.get(image_url, stream=True)\n                    for block in response.iter_content(1024):\n                        if not block:\n                            break\n\n                        handle.write(block)\n\n            item['images'] = images\n        return item\n4.settings\nBOT_NAME = 'meizitu'\n\nSPIDER_MODULES = ['meizitu.spiders']\nNEWSPIDER_MODULE = 'meizitu.spiders'\n#载入ImageDownLoadPipeline类\nITEM_PIPELINES = {'meizitu.pipelines.ImageDownloadPipeline': 1}\n#图片储存\nIMAGES_STORE = '.'\n结果\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "14"}