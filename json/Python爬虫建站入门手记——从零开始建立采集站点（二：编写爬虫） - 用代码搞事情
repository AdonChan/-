{"title": "Python爬虫建站入门手记——从零开始建立采集站点（二：编写爬虫） - 用代码搞事情 ", "index": "python爬虫,python", "content": "上回，我装了环境\n也就是一对乱七八糟的东西\n装了pip，用pip装了virtualenv，建立了一个virtualenv，在这个virtualenv里面，装了Django，创建了一个Django项目，在这个Django项目里面创建了一个叫做web的阿皮皮。\n\n接上回～\n\n第二部分，编写爬虫。\n\n工欲善其事，必先利其器。\n\nbashapt-get install vim # 接上回，我们在screen里面是root身份哦～\n\n\n当然了，现在我要想一个采集的目标，为了方便，我就选择segmentfault吧，这网站写博客不错，就是在海外上传图片有点慢。\n\n这个爬虫，就像我访问一样，要分步骤来。 我先看到segmentfault首页，然后发现里面有很多tags，每个tags下面，才是一个一个的问题的内容。\n\n所以，爬虫也要分为这几个步骤来写。 但是我要反着写，先写内容爬虫，再写分类爬虫, 因为我想。\n\n2.1 编写内容爬虫\n\n首先，给爬虫建立个目录，在项目里面和app同级，然后把这个目录变成一个python的package\n\nbashmkdir ~/python_spider/sfspider\ntouch ~/python_spider/sfspider/__init__.py\n\n\n以后，这个目录就叫爬虫包了\n\n在爬虫包里面建立一个spider.py用来装我的爬虫们\n\nbashvim ~/python_spider/sfspider/spider.py\n\n\n一个基本的爬虫，只需要下面几行代码：\n（代码下面会提供）\n然后呢，就可以玩玩我们的“爬虫”了。\n进入python shell\n\npython>>> from sfspider import spider\n>>> s = spider.SegmentfaultQuestionSpider('1010000002542775')\n>>> s.url\n>>> 'http://segmentfault.com/q/1010000002542775'\n>>> print s.dom('h1#questionTitle').text()\n>>> 微信JS—SDK嵌套选择图片和上传图片接口，实现一键上传图片，遇到问题\n\n\n看吧，我现在已经可以通过爬虫获取segmentfault的提问标题了。下一步，为了简化代码，我把标题，回答等等的属性都写为这个蜘蛛的属性。代码如下\n\npython# -*- coding: utf-8 -*-\nimport requests # requests作为我们的html客户端\nfrom pyquery import PyQuery as Pq # pyquery来操作dom\n\n\nclass SegmentfaultQuestionSpider(object):\n\n    def __init__(self, segmentfault_id): # 参数为在segmentfault上的id\n        self.url = 'http://segmentfault.com/q/{0}'.format(segmentfault_id)\n        self._dom = None # 弄个这个来缓存获取到的html内容，一个蜘蛛应该之访问一次\n\n    @property\n    def dom(self): # 获取html内容\n        if not self._dom:\n            document = requests.get(self.url)\n            document.encoding = 'utf-8'\n            self._dom = Pq(document.text)\n        return self._dom\n\n    @property \n    def title(self): # 让方法可以通过s.title的方式访问 可以少打对括号\n        return self.dom('h1#questionTitle').text() # 关于选择器可以参考css selector或者jquery selector, 它们在pyquery下几乎都可以使用\n\n    @property\n    def content(self):\n        return self.dom('.question.fmt').html() # 直接获取html 胆子就是大 以后再来过滤\n\n    @property\n    def answers(self):\n        return list(answer.html() for answer in self.dom('.answer.fmt').items()) # 记住，Pq实例的items方法是很有用的\n\n    @property\n    def tags(self):\n        return self.dom('ul.taglist--inline > li').text().split() # 获取tags，这里直接用text方法，再切分就行了。一般只要是文字内容，而且文字内容自己没有空格,逗号等，都可以这样弄，省事。\n\n\n\n然后，再把玩一下升级后的蜘蛛。\n\npython>>> from sfspider import spider\n>>> s = spider.SegmentfaultQuestionSpider('1010000002542775')\n>>> print s.title\n>>> 微信JS—SDK嵌套选择图片和上传图片接口，实现一键上传图片，遇到问题\n>>> print s.content\n>>> # [故意省略] #\n>>> for answer in s.answers\n        print answer\n>>> # [故意省略] #\n>>> print '/'.join(s.tags)\n>>> 微信js-sdk/python/微信开发/javascript\n\n\nOK，现在我的蜘蛛玩起来更方便了。\n\n2.2 编写分类爬虫\n\n下面，我要写一个抓取标签页面的问题的爬虫。\n代码如下， 注意下面的代码是添加在已有代码下面的， 和之前的最后一行之间 要有两个空行\n\npythonclass SegmentfaultTagSpider(object):\n\n    def __init__(self, tag_name, page=1):\n        self.url = 'http://segmentfault.com/t/%s?type=newest&page=%s' % (tag_name, page)\n        self.tag_name = tag_name\n        self.page = page\n        self._dom = None\n\n    @property\n    def dom(self):\n        if not self._dom:\n            document = requests.get(self.url)\n            document.encoding = 'utf-8'\n            self._dom = Pq(document.text)\n            self._dom.make_links_absolute(base_url=\"http://segmentfault.com/\") # 相对链接变成绝对链接 爽\n        return self._dom\n\n\n    @property\n    def questions(self):\n        return [question.attr('href') for question in self.dom('h2.title > a').items()]\n\n    @property\n    def has_next_page(self): # 看看还有没有下一页，这个有必要\n        return bool(self.dom('ul.pagination > li.next')) # 看看有木有下一页\n\n    def next_page(self): # 把这个蜘蛛杀了， 产生一个新的蜘蛛 抓取下一页。 由于这个本来就是个动词，所以就不加@property了\n        if self.has_next_page:\n            self.__init__(tag_name=self.tag_name ,page=self.page+1)\n        else:\n            return None\n\n\n\n现在可以两个蜘蛛一起把玩了，就不贴出详细把玩过程了。。。\n\npython>>> from sfspider import spider\n>>> s = spider.SegmentfaultTagSpider('微信')\n>>> question1 = s.questions[0]\n>>> question_spider = spider.SegmentfaultQuestionSpider(question1.split('/')[-1])\n>>> # [故意省略] #\n\n\n想做小偷站的，看到这里基本上就能搞出来了。 套个模板 加一个简单的脚本来接受和返回请求就行了。\n\n未完待续。下一篇，采集入库！\n\n                ", "mainLikeNum": ["6 "], "mainBookmarkNum": "89"}