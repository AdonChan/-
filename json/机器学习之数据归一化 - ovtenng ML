{"title": "机器学习之数据归一化 - ovtenng ML ", "index": "算法,python,scikit-learn,机器学习", "content": "机器学习中，数据归一化是非常重要，如果不进行数据归一化，可能会导致模型坏掉或者训练出一个奇怪的模型。\n为什么要进行数据归一化\n现在有一个训练数据集，包含两个样本，内容如下：\n\n\n \n肿瘤大小（cm）\n发现时间（day）\n\n\n\n样本1\n1\n200\n\n\n样本2\n5\n100\n\n\n\n以 k-近邻算法为例，“发现时间”的数值比“肿瘤大小”的数值大很多，样本间的距离被“发现时间”主导，训练出来的模型主要由“发现时间”影响，甚至“肿瘤大小”的影响可忽略不计。\n解决方法就是将是数据映射到同一尺度，这就是数据归一化。\n数据归一化的两个常用方式为：最值归一化和均值方差归一化。\n最值归一化（normalization）\n最值归一化就是将数据映射到 0～1 之间，适用于数据分布有明显边界的情况。将样本的特征值减去该特征的最小值，再除以该特征的取值区间，对应的数学公式为：\n$$\nx_{scale} = \\frac{x-x_{min}}{x_{max}-x_{min}}\n$$\n使用 np.random 生成一个 50*2 的二维整形数组，并转换成浮点型：\nimport numpy as np\n\nX = np.random.randint(0, 100, size=(50, 2))\nX = np.array(X, dtype=float)\n对于第一列数据，$x_{min}$ = np.min(X[:, 0])，$x_{max}$ = np.max(X[:, 0])：\nX[:, 0] = (X[:, 0] - np.min(X[:, 0])) / (np.max(X[:, 0]) - np.min(X[:, 0]))\n第二列数据同理：\nX[:, 1] = (X[:, 1] - np.min(X[:, 1])) / (np.max(X[:, 1]) - np.min(X[:, 1]))\n此时样本的所有特征值都在 0～1 之间。\n均值方差归一化（standardization）\n均值方差归一化就是把所有数据归一到均值为0、方差为1的分布中。对于数据分布有无明显边界都适用。数学公式为：\n$$\nx_{scale} = \\frac{x-x_{mean}}{s}\n$$\n$x_{mean}$：特征均值，$s$：特征方差。\n同样使用 np.random 生成一个 50*2 的二维整形数组，并转换成浮点型：\nX2 = np.random.randint(0, 100, size=(50, 2))\nX2 = np.array(X2, dtype=float)\n对于第一列数据，$x_{mean}$ = np.mean(X2[:, 0])，$s$ = np.std(X2[:, 0])：\nX2[:, 0] = (X2[:, 0] - np.mean(X2[:, 0])) / np.std(X2[:, 0])\n第二列数据同理：\nX2[:, 1] = (X2[:, 1] - np.mean(X2[:, 1])) / np.std(X2[:, 1])\n可以查看 X2 各列的均值非常接近0，方差非常接近1：\n# np.mean(X2[:, 0])\n-4.440892098500626e-18\n\n# np.mean(X2[:, 1])\n-1.2878587085651815e-16\n\n# np.std(X2[:, 0])\n0.9999999999999999\n\n# np.std(X2[:, 1])\n0.9999999999999999\n对测试数据集进行归一化处理\n前面都是在对训练数据集进行归一化处理，而对测试数据集的归一化处理有所不同。由于测试数据是在模拟真实环境，而在真实环境中很难拿到所有的测试数据的均值和方差，此时将测试数据集也进行上面的操作是错误的，正确的方法是利用训练数据集归一化的数据。\n如测试数据集的最值归一化处理为：\n$$\ntest_{scale} = \\frac{test-min_{train}}{max_{train}-min_{train}}\n$$\n测试数据集的均值方差归一化处理为：\n$$\ntest_{scale} = \\frac{test-mean_{train}}{s_{train}}\n$$\n以均值方差归一化处理为例，Scikit Learn 中封装了 StandardScaler 类用于训练数据集和测试数据集的归一化处理。\n以鸢尾花的数据为例：\nimport numpy as np\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\n\niris = datasets.load_iris()\nX = iris.data\ny = iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nStandardScaler 类位于 preprocessing 模块中：\nfrom sklearn.preprocessing import StandardScaler\nstandardScaler = StandardScaler()\n将训练数据传入 fit() 方法中，该方法会保存训练数据的方差和均值，并返回 StandardScaler 实例本身：\nstandardScaler.fit(X_train)\n其中 mean_、scale_ 属性保存了均值和方差：\n# standardScaler.mean_\narray([5.83416667, 3.08666667, 3.70833333, 1.17      ])\n\n# standardScaler.scale_\narray([0.81019502, 0.44327067, 1.76401924, 0.75317107])\n接着可以向 transform() 方法中传入训练数据和测试数据获取归一化处理后的数据：\nX_train = standardScaler.transform(X_train)\nX_test = standardScaler.transform(X_test)\n源码地址\nGithub | ML-Algorithms-Action\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}