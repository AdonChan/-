{"title": "sklearn中的gbdt源码分析 - DMLLLLL ", "index": "python", "content": "简单看了一下sklearn中的gbdt源码在这里记录一下，目前来说还不能把gbdt的所有理论都搞清楚sklearn有两个类似于gbdt的实现\nGradientBoostingClassifier\nGradientBoostingRegressor\n一个用于分类，另一个用于回归这两个类其实区别只在于mixin上，下面是类继承关系\nGradientBoostingRegressor继承了\n    BaseGradientBoosting\n    RegressorMixin\nGradientBoostingClassifier继承了\n    BaseGradientBoosting\n    ClassifierMixin\nClassifierMixin和RgressorMixin的区别：\n    classifierMixin使用的是准确率来计算误差\n    而回归的是使用r_square来计算误差\n实际上这两个模型的差距是很小的，就是计算一下拟合度\n\n然后是整个训练的过程训练的过程会先设置一些参数设置n_estimators是要训练的分类器数据如果损失函数是loss的话，那么就比较简单了每次训练弱分类器都会根据上一次的结果来上次生成的y - y_pred会作为新的y传进去这样来训练直到n_estimators足够\n不过在predict结果的时候有点看不懂代码后面看了再补充\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}