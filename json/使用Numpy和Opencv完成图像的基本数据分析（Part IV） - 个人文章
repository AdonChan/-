{"title": "使用Numpy和Opencv完成图像的基本数据分析（Part IV） - 个人文章 ", "index": "python,图像处理,边缘检测,数据处理,数据分析", "content": "\n摘要： 使用Numpy和Opencv完成图像的基本数据分析第四部分，主要包含阈值法、边缘检测、线型检测等操作\n图像\n本文是使用python进行图像基本处理系列的第四部分，在本人之前的文章里介绍了一些非常基本的图像分析操作，见文章《使用Numpy和Opencv完成图像的基本数据分析Part I》、《使用Numpy和Opencv完成图像的基本数据分析 Part II》及《使用Numpy和Opencv完成图像的基本数据分析 Part III》，下面我们将继续介绍一些有关图像处理的好玩内容。\n本文介绍的内容基本反映了我本人学习的图像处理课程中的内容，并不会加入任何工程项目中的图像处理内容，本文目的是尝试实现一些基本图像处理技术的基础知识，出于这个原因，本文继续使用 SciKit-Image,numpy数据包执行大多数的操作，此外，还会时不时的使用其他类型的工具库，比如图像处理中常用的OpenCV等：\n本系列分为四个部分，分别为part I、part II、part III及part IV。刚开始想把这个系列分成两个部分，但由于内容丰富且各种处理操作获得的结果是令人着迷，因此不得不把它分成四个部分。系列所有的源代码地址：GitHub-Image-Processing-Python。现在，让我们开始吧！\n阈值\n大津法|OTSU\n阈值处理是图像处理中非常基本的操作。将灰度图像转换为单色是常见的图像处理任务。而且，一个好的算法总是以良好的基础开始！\nOTSU阈值处理是一种简单而有效的全局自动阈值处理方法，用于二值化灰度图像，比如前景（foreground）和背景（background）。在图像处理中，OTSU阈值处理方法（1979）完全基于对图像直方图执行的计算，该算法假设图像由两个基本类组成——前景和背景。当取最佳阈值时，前景和背景两部分之间的差别应该是最大的，在OTSU算法中所采用的衡量差别的标准就是较为常见的最大类间方差。前景和背景之间的类间方差如果越大，就说明构成图像的两个部分之间的差别越大，当部分目标被错分为背景或部分背景被错分为目标，都会导致两部分差别变小，当所取阈值的分割使类间方差最大时就意味着错分概率最小 然后，它计算最小阈值，最小化这两个类的类方差的加权。\n目前，OTSU阈值法被广泛应用于医学成像、低级计算机视觉的许多应用中，该算法有很多优点和假设。\nOTSU阈值法的数学公式在我的个人主页上有所介绍，在那里详细解释了OTSU阈值法背后的数学原理。\n算法\n如果我们把一个简单的数学融入到简单的步进算法中，上述的解释就会演变成：\n\n计算每个强度等级的直方图和概率。\n设置初始μi。\n\n从阈值 t=0逐步到t=L-1：\n\n更新：wi和μi\n计算：σ2b(t)\n\n\n\n       期望阈值对应于σ2b(t)的最大值。\nimport numpy as np\nimport imageio\nimport matplotlib.pyplot as plt\n\npic = imageio.imread('img/potato.jpeg')\nplt.figure(figsize=(7,7))\nplt.axis('off')\nplt.imshow(pic);\n\ndef otsu_threshold(im):\n\n    # Compute histogram and probabilities of each intensity level\n    pixel_counts = [np.sum(im == i) for i in range(256)]\n\n    # Initialization\n    s_max = (0,0)\n\n    for threshold in range(256):\n\n        # update\n        w_0 = sum(pixel_counts[:threshold])\n        w_1 = sum(pixel_counts[threshold:])\n\n        mu_0 = sum([i * pixel_counts[i] for i in range(0,threshold)]) / w_0 if w_0 > 0 else 0       \n        mu_1 = sum([i * pixel_counts[i] for i in range(threshold, 256)]) / w_1 if w_1 > 0 else 0\n\n        # calculate - inter class variance\n        s = w_0 * w_1 * (mu_0 - mu_1) ** 2\n\n        if s > s_max[1]:\n            s_max = (threshold, s)\n\n    return s_max[0]\ndef threshold(pic, threshold):\n    return ((pic > threshold) * 255).astype('uint8')\n\ngray = lambda rgb : np.dot(rgb[... , :3] , [0.21 , 0.72, 0.07]) \n\nplt.figure(figsize=(7,7))\nplt.imshow(threshold(gray(pic), otsu_threshold(pic)), cmap='Greys')\nplt.axis('off');\n\n从上图可以看出，分离效果不错，但看起来并不是很好。如果假设直方图具有双峰分布（ bimodal distribution），并且假设在两个峰之间具有深且尖锐的波谷，则OTSU阈值法能够表现出相对良好的性能  。\n因此，假设图像的前景区域与背景区域差别比较小，则直方图不再呈现双峰分布，并且前景与背景强度的差异与平均差异相比较大，或图像被加性噪声严重破坏时，灰度直方图两峰之间的波谷值会降低，其尖锐性也会大打折扣。\n结论：由OTSU阈值法确定的某些可能不正确的阈值将导致分割错误，但我们可以进一步改进该方法。\nK均值聚类|KMeans Clustering\nk-均值聚类是矢量量化的一种方法，最初是应用于信号处理中，目前常用于数据挖掘中的聚类分析。在OTSU阈值法中，我们找到了最小化内插像素方差的阈值。因此，我们可以不从灰度图像中寻找合适的阈值，而可以在彩色空间中去寻找聚类，通过这样的处理，最终演变为 K-均值聚类技术。\nfrom sklearn import cluster\n\nimport matplotlib.pyplot as plt\n# load image\npic = imageio.imread('img/purple.jpg') \n\nplt.figure(figsize=(7,7))\nplt.imshow(pic)\nplt.axis('off');\n\n为了对图像进行聚类，需要将其转换为二维数组。 \nx, y, z = pic.shape\npic_2d = pic.reshape(x*y, z)\n接下来，我们使用scikit-learn中的集群方法来创建集群。我们将n_clusters设置为5，表明最终会形成五个簇。最终的聚类效果会在生成的图像中展示，从图中可以看到，已经将其划分为具有不同颜色的五个部分。\n将聚类簇的个数设置为5是为了演示例子，我们同样可以更改群集的数量，通过设置不同的集群数来进行对比实验，以可视化的方式验证具有不同颜色的图像，以最终确定，选择多少的群集数量才是比较合适的。\n%%time\n\n# fit on the image with cluster five\nkmeans_cluster = cluster.KMeans(n_clusters=5)\nkmeans_cluster.fit(pic_2d)\n\ncluster_centers = kmeans_cluster.cluster_centers_\ncluster_labels = kmeans_cluster.labels_\nWall time: 16.2 s\n一旦形成了簇，我们就可以使用簇中心和标签重新创建图像，以显示具有分组模式的图像。\nplt.figure(figsize=(7,7))\nplt.imshow(cluster_centers[cluster_labels].reshape(x, y, z))\nplt.axis('off');\n\n线型检测\n霍夫变换|Hough Transform\n霍夫变换是图像处理中比较流行的一种技术。如果我们能用数学形式表示出某个形状，那么它久可以用来检测出任何形状。即使图像形状被稍微扭曲或者被破坏，它也可以从中检测出形状。在通过代码实现该算法之前，我们不会过于深入地分析霍夫变换的基本原理，而是还提供一些资源来使得读者能够更详细地理解它。\n霍夫变换的数学公式可以在我的主页查看，并且，主页上也详细解释了霍夫变换算法背后的数学原理。\n\nwhere\nρ = distance from origin to the line. [-Dmax, Dmax]\nDmax is the diagonal length of the image.\n\nθ = angle from origin to the line. [-90° to 90°]\n算法\n\n拐角或边缘检测\n\nρ范围和θ范围创建\n\nρ：-Dmax ~Dmax；\nθ：-90~90；\n\n\n\n霍夫累加器\n二维数组的行数等于ρvalues的数量，列数等于θ的数量；\n\n\n在累加器中投票\n对于每个边缘点和每个θ值，找到最接近的ρvalue并在累加器中递增该索引；\n\n\n峰值检测\n累加器中的局部最大值表示输入图像中最突出线条的参数；\n\n\ndef hough_line(img):\n    # Rho and Theta ranges\n    thetas = np.deg2rad(np.arange(-90.0, 90.0))\n    width, height = img.shape\n    diag_len = int(np.ceil(np.sqrt(width * width + height * height)))   # Dmax\n    rhos = np.linspace(-diag_len, diag_len, diag_len * 2.0)\n\n    # Cache some resuable values\n    cos_t = np.cos(thetas)\n    sin_t = np.sin(thetas)\n    num_thetas = len(thetas)\n\n    # Hough accumulator array of theta vs rho\n    accumulator = np.zeros((2 * diag_len, num_thetas), dtype=np.uint64)\n    y_idxs, x_idxs = np.nonzero(img)  # (row, col) indexes to edges\n\n    # Vote in the hough accumulator\n    for i in range(len(x_idxs)):\n        x = x_idxs[i]\n        y = y_idxs[i]\n\n        for t_idx in range(num_thetas):\n            # Calculate rho. diag_len is added for a positive index\n            rho = round(x * cos_t[t_idx] + y * sin_t[t_idx]) + diag_len\n            accumulator[rho, t_idx] += 1\n    return accumulator, thetas, rhos\n边缘检测\n边缘检测是一种用于查找图像内对象边界的图像处理技术，其工作原理是检测亮度的不连续性。常见的边缘检测算法包括\n\n索贝尔算子（Sobel）\n卡尼算子（Canny）\n普鲁伊特算子（Prewitt）\n罗伯茨算子（Roberts）\n模糊逻辑方法（fuzzy logic）\n\n 在这里，我们介绍一种最流行的方法，即  Canny 边缘检测（Canny Edge Detection）。\nCanny边缘检测\n该方法是一种能够检测图像中宽范围边缘的多级边缘检测操作。一般而言，Canny边缘检测算法可以分解为以下5个步骤：\n\n1.应用高斯滤波器；\n2.找到强度梯度；\n3.应用非最大抑制；\n4.应用双重阈值；\n5.通过滞后跟踪边缘；\n\n以上是Canny边缘检测的算法概述，有关更全面的概述，请查看本文末尾给定链接。由于本文的长度限定，本文在此处不展示完整的实现代码，而是直观地概述该代码的相关算法。\nCanny边缘检测的处理过程可以在此查看，同样，该链接将重定向回我的个人主页，主页上详细解释了Canny边缘检测算法背后的数学知识。       以上是关于Python中基本图像处理最后的第4部分，整个系列的源代码可在此处访问。\n相关\n\n使用Numpy和Opencv完成图像的基本数据分析（Part I）；\n使用Numpy和Opencv完成图像的基本数据分析（Part II）；\n使用Numpy和Opencv完成图像的基本数据分析（Part III）；\n\n本文作者：【方向】\n阅读原文\n本文为云栖社区原创内容，未经允许不得转载。\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}