{"title": "数据分析遇到PDF文本，怎么用Python批量提取内容 - 个人文章 ", "index": "python", "content": "\n本文为你展示，如何用Python把许多PDF文件的文本内容批量提取出来，并且整理存储到数据框中，以便于后续的数据分析。\n问题\n最近，读者们在后台的留言，愈发五花八门了。\n写了几篇关于自然语言处理的文章后，一种呼声渐强：\npdf中的文本内容，有没有什么方便的方法提取出来呢？\n我能体会到读者的心情。\n我展示的例子中，文本数据都是直接可以读入数据框工具做处理的。它们可能来自开放数据集合、网站API，或者爬虫。\n但是，有的时候，你会遇到需要处理指定格式数据的问题。\n例如pdf。\n许多的学术论文、研究报告，甚至是资料分享，都采用这种格式发布。\n这时候，已经掌握了诸多自然语言分析工具的你，会颇有“拔剑四顾心茫然”的感觉——明明知道如何处理其中的文本信息，但就是隔着一个格式转换的问题，做不来。\n怎么办？\n办法自然是有的，例如专用工具、在线转换服务网站，甚至还可以手动复制粘贴嘛。\n但是，咱们是看重效率的，对不对？\n上述办法，有的需要在网上传输大量内容，花费时间较多，而且可能带来安全和隐私问题；有的需要专门花钱购买；有的干脆就不现实。\n怎么办？\n好消息是，Python就可以帮助你高效、快速地批量提取pdf文本内容，而且和数据整理分析工具无缝衔接，为你后续的分析处理做好基础服务工作。\n数据\n为了更好地说明流程，我为你准备好了一个压缩包。\n里面包括本教程的代码，以及我们要用到的数据。\n请你到 这个网址 下载本教程配套的压缩包。\n下载后解压，你会在生成的目录（下称“演示目录”）里面看到以下内容。\n\n演示目录里面包含：\nPipfile: pipenv 配置文件，用来准备咱们变成需要用到的依赖包。后文会讲解使用方法；pdf_extractor.py: 利用pdfminer.six编写的辅助函数。有了它你就可以直接调用pdfminer提供的pdf文本内容抽取功能，而不必考虑一大堆恼人的参数；demo.ipynb: 已经为你写好的本教程 Python 源代码 （Jupyter Notebook格式）。另外，演示目录中还包括了2个文件夹。\n这两个文件夹里面，都是中文pdf文件，用来给你展示pdf内容抽取。\npdf文件夹内容如下：\n\nnewpdf文件夹内容如下：\n\n代码\n首先，我们读入一些模块，以进行文件操作。\nimport glob\nimport os\n前文提到过，演示目录下，有两个文件夹，分别是pdf和newpdf。\n我们指定 pdf 文件所在路径为其中的pdf文件夹。\npdf_path = \"pdf/\"\n我们希望获得所有 pdf 文件的路径。用glob，一条命令就能完成这个功能。\npdfs = glob.glob(\"{}/*.pdf\".format(pdf_path))\n看看我们获得的 pdf 文件路径是否正确。\npdfs\n['pdf/复杂系统仿真的微博客虚假信息扩散模型研究.pdf',\n 'pdf/面向影子分析的社交媒体竞争情报搜集.pdf',\n 'pdf/面向人机协同的移动互联网政务门户探析.pdf']\n\n经验证。准确无误。\n下面我们利用 pdfminer 来从 pdf 文件中抽取内容。我们需要从辅助 Python 文件 pdf_extractor.py 中读入函数 extract_pdf_content。\nfrom pdf_extractor import extract_pdf_content\n\n用这个函数，我们尝试从 pdf 文件列表中的第一篇里，抽取内容，并且把文本保存在 content 变量里。\ncontent = extract_pdf_content(pdfs[0])\n\n我们看看 content 里都有什么：\ncontent\n\n\n\n\n显然，内容抽取并不完美，页眉页脚等信息都混了进来。\n不过，对于我们的许多文本分析用途来说，这无关紧要。\n你会看到 content 的内容里面有许多的 n，这是什么呢？\n我们用 print 函数，来显示 content 的内容。\nprint(content)\n\n\n\n可以清楚看到，那些 n 是换行符。\n通过一个 pdf 文件的抽取测试，我们建立了信心。\n下面，我们该建立辞典，批量抽取和存储内容了。\nmydict = {}\n\n我们遍历 pdfs 列表，把文件名称（不包含目录）作为键值。这样，我们可以很容易看到，哪些pdf文件已经被抽取过了，哪些还没有抽取。\n为了让这个过程更为清晰，我们让Python输出正在抽取的 pdf 文件名。\nfor pdf in pdfs:\n    key = pdf.split('/')[-1]\n    if not key in mydict:\n        print(\"Extracting content from {} ...\".format(pdf))\n        mydict[key] = extract_pdf_content(pdf)\n\n抽取过程中，你会看到这些输出信息：\nExtracting content from pdf/复杂系统仿真的微博客虚假信息扩散模型研究.pdf ...\nExtracting content from pdf/面向影子分析的社交媒体竞争情报搜集.pdf ...\nExtracting content from pdf/面向人机协同的移动互联网政务门户探析.pdf ...\n\n看看此时字典中的键值都有哪些：\nmydict.keys()\n\ndict_keys(['复杂系统仿真的微博客虚假信息扩散模型研究.pdf', '面向影子分析的社交媒体竞争情报搜集.pdf', '面向人机协同的移动互联网政务门户探析.pdf'])\n\n一切正常。\n下面我们调用pandas，把字典变成数据框，以利于分析。\nimport pandas as pd\n\n下面这条语句，就可以把字典转换成数据框了。注意后面的reset_index()把原先字典键值生成的索引也转换成了普通的列。\ndf = pd.DataFrame.from_dict(mydict, orient='index').reset_index()\n\n然后我们重新命名列，以便于后续使用。\ndf.columns = [\"path\", \"content\"]\n\n此时的数据框内容如下：\ndf\n\n\n\n可以看到，我们的数据框拥有了pdf文件信息和全部文本内容。这样你就可以使用关键词抽取、情感分析、相似度计算等等诸多分析工具了。\n篇幅所限，我们这里只用一个字符数量统计的例子来展示基本分析功能。\n我们让 Python 帮我们统计抽取内容的长度。\ndf[\"length\"] = df.content.apply(lambda x: len(x))\n\n此时的数据框内容发生以下变化：\ndf\n\n\n\n多出的一列，就是 pdf 文本内容的字符数量。\n为了在 Jupyter Notebook 里面正确展示绘图结果，我们需要使用以下语句：\n%matplotlib inline\n\n下面，我们让 Pandas 把字符长度一列的信息用柱状图标示出来。为了显示的美观，我们设置了图片的长宽比例，并且把对应的pdf文件名称以倾斜45度来展示。\n如果对Python编程、网络爬虫、机器学习、数据挖掘、web开发、人工智能、面试经验交流。感兴趣可以519970686，群内会有不定期的发放免费的资料链接，这些资料都是从各个技术网站搜集、整理出来的，如果你有好的学习资料可以私聊发我，我会注明出处之后分享给大家。\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(14, 6))\ndf.set_index('path').length.plot(kind='bar')\nplt.xticks(rotation=45)\n\n\n\n\n可视化分析完成。\n下面我们把刚才的分析流程整理成函数，以便于将来更方便地调用。\n我们先整合pdf内容提取到字典的模块：\ndef get_mydict_from_pdf_path(mydict, pdf_path):\n    pdfs = glob.glob(\"{}/*.pdf\".format(pdf_path))\n    for pdf in pdfs:\n        key = pdf.split('/')[-1]\n        if not key in mydict:\n            print(\"Extracting content from {} ...\".format(pdf))\n            mydict[key] = extract_pdf_content(pdf)\n    return mydict\n\n这里输入是已有词典和pdf文件夹路径。输出为新的词典。\n你可能会纳闷为何还要输入“已有词典”。别着急，一会儿我用实际例子展示给你看。\n下面这个函数非常直白——就是把词典转换成数据框。\ndef make_df_from_mydict(mydict):\n    df = pd.DataFrame.from_dict(mydict, orient='index').reset_index()\n    df.columns = [\"path\", \"content\"]\n    return df\n\n最后一个函数，用于绘制统计出来的字符数量。\ndef draw_df(df):\n    df[\"length\"] = df.content.apply(lambda x: len(x))\n    plt.figure(figsize=(14, 6))\n    df.set_index('path').length.plot(kind='bar')\n    plt.xticks(rotation=45)\n\n函数已经编好，下面我们来尝试一下。\n还记得演示目录下有个子目录，叫做newpdf对吧？\n我们把其中的2个pdf文件，移动到pdf目录下面。\n这样pdf目录下面，就有了5个文件：\n\n我们执行新整理出的3个函数。\n首先输入已有的词典（注意此时里面已有3条记录），pdf文件夹路径没变化。输出是新的词典。\nmydict = get_mydict_from_pdf_path(mydict, pdf_path)\n\nExtracting content from pdf/微博客 Twitter 的企业竞争情报搜集.pdf ...\nExtracting content from pdf/移动社交媒体用户隐私保护对策研究.pdf ...\n\n注意这里的提示，原先的3个pdf文件没有被再次抽取，只有2个新pdf文件被抽取。\n咱们这里一共只有5个文件，所以你直观上可能无法感受出显著的区别。\n但是，假设你原先已经用几个小时，抽取了成百上千个pdf文件信息，结果你的老板又丢给你3个新的pdf文件……\n如果你必须从头抽取信息，恐怕会很崩溃吧。\n这时候，使用咱们的函数，你可以在1分钟之内把新的文件内容追加进去。\n这差别，不小吧？\n下面我们用新的词典，构建数据框。\ndf = make_df_from_mydict(mydict)\n\n我们绘制新的数据框里，pdf抽取文本字符数量。结果如下：\ndraw_df(df)\n\n\n\n小结\n总结一下，本文为你介绍了以下知识点：\n如何用glob批量读取目录下指定格式的文件路径；如何用pdfminer从pdf文件中抽取文本信息；如何构建词典，存储与键值（本文中为文件名）对应的内容，并且避免重复处理数据；如何将词典数据结构轻松转换为Pandas数据框，以便于后续数据分析。如何用matplotlib和pandas自带的绘图函数轻松绘制柱状统计图形。\n讨论\n你之前做的数据分析工作中，遇到过需要从pdf文件抽取文本的任务吗？你是如何处理的？有没有更好的工具与方法？欢迎留言，把你的经验和思考分享给大家，我们一起交流讨论。\n出处 https://blog.csdn.net/Stephen...\n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "0"}