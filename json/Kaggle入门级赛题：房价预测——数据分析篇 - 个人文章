{"title": "Kaggle入门级赛题：房价预测——数据分析篇 - 个人文章 ", "index": "数据分析,python", "content": "本次分享的项目来自 Kaggle 的经典赛题：房价预测。分为数据分析和数据挖掘两部分介绍。本篇为数据分析篇。\n\n赛题解读\n比赛概述\n影响房价的因素有很多，在本题的数据集中有 79 个变量几乎描述了爱荷华州艾姆斯 (Ames, Iowa) 住宅的方方面面，要求预测最终的房价。\n技术栈\n\n特征工程 (Creative feature engineering)\n回归模型 (Advanced regression techniques like random forest and  gradient boosting)\n\n最终目标\n预测出每间房屋的价格，对于测试集中的每一个Id，给出变量SalePrice相应的值。\n提交格式\nId,SalePrice\n1461,169000.1\n1462,187724.1233\n1463,175221\netc.\n数据分析\n数据描述\n首先我们导入数据并查看：\ntrain_df = pd.read_csv('./input/train.csv', index_col=0)\ntest_df = pd.read_csv('./input/test.csv', index_col=0)\ntrain_df.head()\n\n我们可以看到有 80 列，也就是有 79 个特征。\n接下来将训练集和测试集合并在一起，这么做是为了进行数据预处理的时候更加方便，让测试集和训练集的特征变换为相同的格式，等预处理进行完之后，再把他们分隔开。\n我们知道SalePrice作为我们的训练目标，只出现在训练集中，不出现在测试集，因此我们需要把这一列拿出来再进行合并。在拿出这一列前，我们先来观察它，看看它长什么样子，也就是查看它的分布。\nprices = DataFrame({'price': train_df['SalePrice'], 'log(price+1)': np.log1p(train_df['SalePrice'])})\nprices.hist()\n\n因为label本身并不平滑，为了我们分类器的学习更加准确，我们需要首先把label给平滑化（正态化）。我在这里使用的是log1p, 也就是 log(x+1)。要注意的是我们这一步把数据平滑化了，在最后算结果的时候，还要把预测到的平滑数据给变回去，那么log1p()的反函数就是expm1()，后面用到时再具体细说。 \n然后我们把这一列拿出来：\ny_train = np.log1p(train_df.pop('SalePrice'))\n\ny_train.head()\n\n有\nId\n1    12.247699\n2    12.109016\n3    12.317171\n4    11.849405\n5    12.429220\nName: SalePrice, dtype: float64\n这时，y_train就是SalePrice那一列。\n然后我们把两个数据集合并起来：\ndf = pd.concat((train_df, test_df), axis=0)\n查看shape:\ndf.shape\n\n(2919, 79)\ndf就是我们合并之后的DataFrame。\n\n数据预处理\n根据 kaggle 给出的说明，有以下特征及其说明：\nSalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\nMSSubClass: The building class\nMSZoning: The general zoning classification\nLotFrontage: Linear feet of street connected to property\nLotArea: Lot size in square feet\nStreet: Type of road access\nAlley: Type of alley access\nLotShape: General shape of property\nLandContour: Flatness of the property\nUtilities: Type of utilities available\nLotConfig: Lot configuration\nLandSlope: Slope of property\nNeighborhood: Physical locations within Ames city limits\nCondition1: Proximity to main road or railroad\nCondition2: Proximity to main road or railroad (if a second is present)\nBldgType: Type of dwelling\nHouseStyle: Style of dwelling\nOverallQual: Overall material and finish quality\nOverallCond: Overall condition rating\nYearBuilt: Original construction date\nYearRemodAdd: Remodel date\nRoofStyle: Type of roof\nRoofMatl: Roof material\nExterior1st: Exterior covering on house\nExterior2nd: Exterior covering on house (if more than one material)\nMasVnrType: Masonry veneer type\nMasVnrArea: Masonry veneer area in square feet\nExterQual: Exterior material quality\nExterCond: Present condition of the material on the exterior\nFoundation: Type of foundation\nBsmtQual: Height of the basement\nBsmtCond: General condition of the basement\nBsmtExposure: Walkout or garden level basement walls\nBsmtFinType1: Quality of basement finished area\nBsmtFinSF1: Type 1 finished square feet\nBsmtFinType2: Quality of second finished area (if present)\nBsmtFinSF2: Type 2 finished square feet\nBsmtUnfSF: Unfinished square feet of basement area\nTotalBsmtSF: Total square feet of basement area\nHeating: Type of heating\nHeatingQC: Heating quality and condition\nCentralAir: Central air conditioning\nElectrical: Electrical system\n1stFlrSF: First Floor square feet\n2ndFlrSF: Second floor square feet\nLowQualFinSF: Low quality finished square feet (all floors)\nGrLivArea: Above grade (ground) living area square feet\nBsmtFullBath: Basement full bathrooms\nBsmtHalfBath: Basement half bathrooms\nFullBath: Full bathrooms above grade\nHalfBath: Half baths above grade\nBedroom: Number of bedrooms above basement level\nKitchen: Number of kitchens\nKitchenQual: Kitchen quality\nTotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\nFunctional: Home functionality rating\nFireplaces: Number of fireplaces\nFireplaceQu: Fireplace quality\nGarageType: Garage location\nGarageYrBlt: Year garage was built\nGarageFinish: Interior finish of the garage\nGarageCars: Size of garage in car capacity\nGarageArea: Size of garage in square feet\nGarageQual: Garage quality\nGarageCond: Garage condition\nPavedDrive: Paved driveway\nWoodDeckSF: Wood deck area in square feet\nOpenPorchSF: Open porch area in square feet\nEnclosedPorch: Enclosed porch area in square feet\n3SsnPorch: Three season porch area in square feet\nScreenPorch: Screen porch area in square feet\nPoolArea: Pool area in square feet\nPoolQC: Pool quality\nFence: Fence quality\nMiscFeature: Miscellaneous feature not covered in other categories\nMiscVal: $Value of miscellaneous feature\nMoSold: Month Sold\nYrSold: Year Sold\nSaleType: Type of sale\nSaleCondition: Condition of sale\n接下来我们对特征进行分析。上述列出了一个目标变量SalePrice和 79 个特征，数量较多，这一步的特征分析是为了之后的特征工程做准备。\n我们来查看哪些特征存在缺失值：\nprint(pd.isnull(df).sum())\n\n这样并不方便观察，我们先查看缺失值最多的 10 个特征：\ndf.isnull().sum().sort_values(ascending=False).head(10)\n\n为了更清楚的表示，我们用缺失率来考察缺失情况：\ndf_na = (df.isnull().sum() / len(df)) * 100\ndf_na = df_na.drop(df_na[df_na == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'缺失率': df_na})\nmissing_data.head(10)\n\n对其进行可视化：\nf, ax = plt.subplots(figsize=(15,12))\nplt.xticks(rotation='90')\nsns.barplot(x=df_na.index, y=df_na)\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.title('Percent missing data by feature', fontsize=15)\n\n我们可以看到PoolQC、MiscFeature、Alley、Fence、FireplaceQu 等特征存在大量缺失，LotFrontage 有 16.7% 的缺失率，GarageType、GarageFinish、GarageQual 和 GarageCond等缺失率相近，这些特征有的是 category 数据，有的是 numerical 数据，对它们的缺失值如何处理，将在关于特征工程的部分给出。\n最后，我们对每个特征进行相关性分析，查看热力图：\ncorrmat = train_df.corr()\nplt.subplots(figsize=(15,12))\nsns.heatmap(corrmat, vmax=0.9, square=True)\n\n\n\n我们看到有些特征相关性大，容易造成过拟合现象，因此需要进行剔除。在下一篇的数据挖掘篇我们来对这些特征进行处理并训练模型。\n\n不足之处，欢迎指正。\n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "1"}