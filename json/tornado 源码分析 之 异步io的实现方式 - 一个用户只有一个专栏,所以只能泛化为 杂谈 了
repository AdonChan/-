{"title": "tornado 源码分析 之 异步io的实现方式 - 一个用户只有一个专栏,所以只能泛化为 杂谈 了 ", "index": "python,tornado", "content": "前言\n\n本文将尝试详细的带大家一步步走完一个异步操作,从而了解tornado是如何实现异步io的.\n其实本文是对[上一篇文][1]的实践和复习\n主旨在于关注异步io的实现,所以会忽略掉代码中的一些异常处理.文字较多,凑合下吧\n\n接下来只会贴出部分源码,帮助理解,希望有耐心的同学打开tornado源码,一起跟踪一遍吧.\n\n\nAsyncHTTPClient :\n\n AsyncHTTPClient 继承 Configurable ,从__new__重看出是单例模式.  \n根据 Configurable 的__new__和 AsyncHTTPClient 的 configurable_base 和 configurable_default 得知,\n实例化后一定是 SimpleAsyncHTTPClient 的实例\n\n\nfetch\n\ndef fetch(self, request, callback=None, raise_error=True, **kwargs):\n\n        if self._closed:\n            raise RuntimeError(\"fetch() called on closed AsyncHTTPClient\")\n        if not isinstance(request, HTTPRequest):\n            request = HTTPRequest(url=request, **kwargs)\n        # We may modify this (to add Host, Accept-Encoding, etc),\n        # so make sure we don't modify the caller's object.  This is also\n        # where normal dicts get converted to HTTPHeaders objects.\n        request.headers = httputil.HTTPHeaders(request.headers)\n        request = _RequestProxy(request, self.defaults)\n        future = TracebackFuture()\n        if callback is not None:\n            callback = stack_context.wrap(callback)\n\n            def handle_future(future):\n                exc = future.exception()\n                if isinstance(exc, HTTPError) and exc.response is not None:\n                    response = exc.response\n                elif exc is not None:\n                    response = HTTPResponse(\n                        request, 599, error=exc,\n                        request_time=time.time() - request.start_time)\n                else:\n                    response = future.result()\n                self.io_loop.add_callback(callback, response)\n            future.add_done_callback(handle_future)\n        ##fetch_impl带上handle_response,重点\n        def handle_response(response):\n            if raise_error and response.error:\n                future.set_exception(response.error)\n            else:\n                future.set_result(response)\n        self.fetch_impl(request, handle_response)\n        return future\n\n\n fetch 中调用 fetch_impl,fetch_impl 中其中一个参数是 callback ,而代码中的 callback 包含了 future 的 set_result ,\n所以,当 callback 被调用时,外部的 yield 操作将被激活,程序会在 ioloop 中调用此 callback ,然后回到原函数的 yield 处,\n并且原函数返回此次 qeust 的 future 对象,以便在函数外部增加别的 callback \n\n\nfetch_impl\n\ndef _connection_class(self):\n        return _HTTPConnection\n\ndef _handle_request(self, request, release_callback, final_callback):\n        self._connection_class()(\n            self.io_loop, self, request, release_callback,\n            final_callback, self.max_buffer_size, self.tcp_client,\n            self.max_header_size, self.max_body_size)\n\n\n在 return 之前,继续查看 fetch_impl 内部是如何处理,根据推测,他一定是将继续处理网络请求,\n肯定会将网络请求交由 ioloop 的 epoll 部分处理,设定好处理的 hanlder 再返回\n future.set_result ,接下来继续分析 fetch_impl 内部是如果设置网络请求的.\n fetch_impl 的实现代码中查看,实例化中创建了 tcpclient 对象,这个肯定是关键\n\n根据之前的分析 SimpleAsyncHTTPClient 是单例模式,那他怎么处理各种 http 请求呢?\n查看代码得知,他将请求的 request 和 callback 存储在 self.queue 中,\n每次 fetch_impl 的时候,一个个 pop 出来处理就好了,这样就能处理n个请求了\n\n一步步跟踪到 _handle_request ,发现最后到了 _HTTPConnection 的实例化中了.\n实例化的参数有之前那个包含 future 的 callback .\n这样就可以保证 yield 操作可以回到原处了.好了,继续走\n\n\n_HTTPConnection\n\nclass _HTTPConnection(httputil.HTTPMessageDelegate):\n    _SUPPORTED_METHODS = set([\"GET\", \"HEAD\", \"POST\", \"PUT\", \"DELETE\", \"PATCH\", \"OPTIONS\"])\n\n    def __init__(self, io_loop, client, request, release_callback,\n                 final_callback, max_buffer_size, tcp_client,\n                 max_header_size, max_body_size):\n        self.start_time = io_loop.time()\n        self.io_loop = io_loop\n        self.client = client\n        self.request = request\n        self.release_callback = release_callback\n        self.final_callback = final_callback\n        self.max_buffer_size = max_buffer_size\n        self.tcp_client = tcp_client\n        self.max_header_size = max_header_size\n        self.max_body_size = max_body_size\n        self.code = None\n        self.headers = None\n        self.chunks = []\n        self._decompressor = None\n        # Timeout handle returned by IOLoop.add_timeout\n        self._timeout = None\n        self._sockaddr = None\n        with stack_context.ExceptionStackContext(self._handle_exception):\n            self.parsed = urlparse.urlsplit(_unicode(self.request.url))\n            if self.parsed.scheme not in (\"http\", \"https\"):\n                raise ValueError(\"Unsupported url scheme: %s\" %\n                                 self.request.url)\n            # urlsplit results have hostname and port results, but they\n            # didn't support ipv6 literals until python 2.7.\n            netloc = self.parsed.netloc\n            if \"@\" in netloc:\n                userpass, _, netloc = netloc.rpartition(\"@\")\n            host, port = httputil.split_host_and_port(netloc)\n            if port is None:\n                port = 443 if self.parsed.scheme == \"https\" else 80\n            if re.match(r'^\\[.*\\]$', host):\n                # raw ipv6 addresses in urls are enclosed in brackets\n                host = host[1:-1]\n            self.parsed_hostname = host  # save final host for _on_connect\n\n            if request.allow_ipv6 is False:\n                af = socket.AF_INET\n            else:\n                af = socket.AF_UNSPEC\n\n            ssl_options = self._get_ssl_options(self.parsed.scheme)\n\n            timeout = min(self.request.connect_timeout, self.request.request_timeout)\n            if timeout:\n                self._timeout = self.io_loop.add_timeout(\n                    self.start_time + timeout,\n                    stack_context.wrap(self._on_timeout))\n            self.tcp_client.connect(host, port, af=af,\n                                    ssl_options=ssl_options,\n                                    max_buffer_size=self.max_buffer_size,\n                                    callback=self._on_connect)\n\n\n _HTTPConnection 的实例化中有一堆成员变量,有点晕,\n先不管这么多,关注我们的 callback ,和 tcpclient .\n\n一行行往下看,是 host 和 port 的初始化操作 ,http 和 https 是不一样的嘛,当然得处理一下,\n\n终于到了最后,是 tcpclient.connect ,从 connect 的参数中看到 callback=self._on_connect ,\n应该是个重要的方法,出去那些字符串处理,发现 self.connection.write_headers(start_line ,  self.request.headers ) ,\n这应该是发送 http 头的操作吧,是网络请求,所以这是处理 connect 这个 url 后,发送 http 头的操作.\n\n还是回头看看是如何 connect 的吧,因为这是异步的关键,搞懂了这个,那剩下来的也是同出一则\n\n\nTCPClient\n\n转到 tcpclient 的代码去看他的实例化和 connect 操作,看来剩下的路还很长呢\n TCPClient 实例化的代码很短,有个 resolver 对象,先不管\n\n\nconnect\n\n    @gen.coroutine\n    def connect(self, host, port, af=socket.AF_UNSPEC, ssl_options=None,\n                max_buffer_size=None):\n        \"\"\"Connect to the given host and port.\n\n        Asynchronously returns an `.IOStream` (or `.SSLIOStream` if\n        ``ssl_options`` is not None).\n        \"\"\"\n        addrinfo = yield self.resolver.resolve(host, port, af)\n        connector = _Connector(\n            addrinfo, self.io_loop,\n            functools.partial(self._create_stream, max_buffer_size))\n        af, addr, stream = yield connector.start()\n        # TODO: For better performance we could cache the (af, addr)\n        # information here and re-use it on subsequent connections to\n        # the same host. (http://tools.ietf.org/html/rfc6555#section-4.2)\n        if ssl_options is not None:\n            stream = yield stream.start_tls(False, ssl_options=ssl_options,\n                                            server_hostname=host)\n        raise gen.Return(stream)\n\n\n去到 connect 方法里,发现 coroutine 装饰器,并且调用时设置了 callback=self._on_connect ,\n所以当这个 coroutine 的 future 被解决时,会调用 self._on_connect ,\n你也可以看到 _on_connect 的参数是 stream ,就是 gen.Return(stream )传过去的. \n因为 gen.coroutine 实现时的代码中,\n send 了 value 后,代码继续走,走到 gen.Return (其实这是个 exception ,\n就会走到 gen.coroutine 里的 set_result 了.)\n\n第一个 yield  右边是 self.resolver.resolve ,左边是 addrinfo ,是地址信息,\n这个异步操作处理的便是解析 url 的地址信息.此处 tornado 默认使用了阻塞的实现,暂时先不看,\n以后在新的篇幅补充,主要内容是 run_on_executor 装饰器的内容,\n此处其实是同步返回的,因为默认用的是 BlockingResolver 的代码,直接看下一个 yield \n\n\n_Connector\n\n    def __init__(self, addrinfo, io_loop, connect):\n        self.io_loop = io_loop\n        self.connect = connect\n\n        self.future = Future()\n        self.timeout = None\n        self.last_error = None\n        self.remaining = len(addrinfo)\n        self.primary_addrs, self.secondary_addrs = self.split(addrinfo)\n\n\n _Connector 实例化,参数有一个 callback ,是本类的 _create_stream ,\n并把 self.connect 设置成传过来的 callback \n所以 self.connect 就是 TCPClient._create_stream 了,\n成员变量有个 future 实例,我们需要全程高度关注 future 和 callback .\n\n实例化后调用了 start 方法 ,start 内部,调用 try_connect,set_timout ,\n根据函数名得知,是 connect 操作和设置超时的操作.最后返回实例化时创建的 future .\n\n\ntry_connect\n\ndef start(self, timeout=_INITIAL_CONNECT_TIMEOUT):\n        self.try_connect(iter(self.primary_addrs))\n        self.set_timout(timeout)\n        return self.future\n\n    def try_connect(self, addrs):\n        try:\n            af, addr = next(addrs)\n        except StopIteration:\n            # We've reached the end of our queue, but the other queue\n            # might still be working.  Send a final error on the future\n            # only when both queues are finished.\n            if self.remaining == 0 and not self.future.done():\n                self.future.set_exception(self.last_error or\n                                          IOError(\"connection failed\"))\n            return\n        future = self.connect(af, addr)\n        future.add_done_callback(functools.partial(self.on_connect_done,\n                                                   addrs, af, addr))\n\n\n future  =  self.connect(af ,  addr ),执行了 TCPClient._create_stream 方法,\n返回 future ,并且设置 future 的 callback=on_connect_done \n\n\n_create_stream\n\n    def _create_stream(self, max_buffer_size, af, addr):\n        # Always connect in plaintext; we'll convert to ssl if necessary\n        # after one connection has completed.\n        stream = IOStream(socket.socket(af),\n                          io_loop=self.io_loop,\n                          max_buffer_size=max_buffer_size)\n        return stream.connect(addr)\n\n\n实例化 IOStream ,执行并返回 stream.connect,stream.connect 返回的 future 便是 try_connect 中的 future ,\n所以,进去看看 stream.connect 内部是怎么”解决”这个 future 的.\n\n\nIOStream\n\nconnect\n\ndef connect(self, address, callback=None, server_hostname=None):\n        self._connecting = True\n        if callback is not None:\n            self._connect_callback = stack_context.wrap(callback)\n            future = None\n        else:\n            future = self._connect_future = TracebackFuture()\n        try:\n            self.socket.connect(address)\n        except socket.error as e:\n\n            if (errno_from_exception(e) not in _ERRNO_INPROGRESS and\n                    errno_from_exception(e) not in _ERRNO_WOULDBLOCK):\n                if future is None:\n                    gen_log.warning(\"Connect error on fd %s: %s\",\n                                    self.socket.fileno(), e)\n                self.close(exc_info=True)\n                return future\n        self._add_io_state(self.io_loop.WRITE)\n        return future\n\n\n self._connecting  =  True  设置此实例正在连接中,连接完毕设置成 false \n如果没有 callback 传入,生成 future 对象, 刚才返回的 future 记录在这个实例的成员变量 self._connect_future 中.\n然后执行 socket 的 connect 操作,因为 socket 设置成非阻塞,\n所以此处会立即返回,不会阻塞,当连接成功时,缓冲区可写,失败时缓冲区可读可写.这是基础知识,详情百度.\n然后调用 self._add_io_state ,返回 future \n\n\n_add_io_state\n\n    def _add_io_state(self, state):\n\n        if self.closed():\n            # connection has been closed, so there can be no future events\n            return\n        if self._state is None:\n            self._state = ioloop.IOLoop.ERROR | state\n            with stack_context.NullContext():\n                self.io_loop.add_handler(\n                    self.fileno(), self._handle_events, self._state)\n        elif not self._state & state:\n            self._state = self._state | state\n            self.io_loop.update_handler(self.fileno(), self._state)\n\n\n终于到了这一步,要用 epoll 了!!!根据实例化的代码得知 self._state=None ,\n会走 self.io_loop.add_handler 这步,根据我之前发的[文章][2],会将当前的 fd ,当前实例的 _handle_events ,和写,错误操作注册到 epoll 中\n接着!!!!!终于走完了这个 yield 的流程了!!!!!!\n\n\n小总结:\n\n 请一定弄清 future 是怎么传递的,每个 future 管理的 callback 是什么操作.\n  _HTTPConnection  中  tcpclient.connect 一个 future   ,callback=self._on_connect  .\n 他将在 raise   gen.Return(stream )时被添加到 ioloop 执行. \n  tcpclient.connect 内部的  connector.start 一个 future , \n  callback 是 on_connect_done ,他将在 poll 检测到 write 事件时,被添加到 ioloop 执行\n\n\nioloop\n\n    def start(self):\n        if self._running:\n            raise RuntimeError(\"IOLoop is already running\")\n        self._setup_logging()\n        if self._stopped:\n            self._stopped = False\n            return\n        old_current = getattr(IOLoop._current, \"instance\", None)\n        IOLoop._current.instance = self\n        self._thread_ident = thread.get_ident()\n        self._running = True\n\n        old_wakeup_fd = None\n        if hasattr(signal, 'set_wakeup_fd') and os.name == 'posix':\n\n            try:\n                old_wakeup_fd = signal.set_wakeup_fd(self._waker.write_fileno())\n                if old_wakeup_fd != -1:\n                    signal.set_wakeup_fd(old_wakeup_fd)\n                    old_wakeup_fd = None\n            except ValueError:\n                old_wakeup_fd = None\n\n        try:\n            while True:\n                with self._callback_lock:\n                    callbacks = self._callbacks\n                    self._callbacks = []\n\n                due_timeouts = []\n\n                if self._timeouts:\n                    now = self.time()\n                    while self._timeouts:\n                        if self._timeouts[0].callback is None:\n\n                            heapq.heappop(self._timeouts)\n                            self._cancellations -= 1\n                        elif self._timeouts[0].deadline <= now:\n                            due_timeouts.append(heapq.heappop(self._timeouts))\n                        else:\n                            break\n                    if (self._cancellations > 512\n                            and self._cancellations > (len(self._timeouts) >> 1)):\n\n                        self._cancellations = 0\n                        self._timeouts = [x for x in self._timeouts\n                                          if x.callback is not None]\n                        heapq.heapify(self._timeouts)\n\n                for callback in callbacks:\n                    self._run_callback(callback)\n                for timeout in due_timeouts:\n                    if timeout.callback is not None:\n                        self._run_callback(timeout.callback)\n                callbacks = callback = due_timeouts = timeout = None\n\n                if self._callbacks:\n                    poll_timeout = 0.0\n                elif self._timeouts:\n\n                    poll_timeout = self._timeouts[0].deadline - self.time()\n                    poll_timeout = max(0, min(poll_timeout, _POLL_TIMEOUT))\n                else:\n\n                    poll_timeout = _POLL_TIMEOUT\n\n                if not self._running:\n                    break\n\n                if self._blocking_signal_threshold is not None:\n\n                    signal.setitimer(signal.ITIMER_REAL, 0, 0)\n\n                try:\n                    event_pairs = self._impl.poll(poll_timeout)\n                except Exception as e:\n\n                    if errno_from_exception(e) == errno.EINTR:\n                        continue\n                    else:\n                        raise\n\n                if self._blocking_signal_threshold is not None:\n                    signal.setitimer(signal.ITIMER_REAL,\n                                     self._blocking_signal_threshold, 0)\n\n                self._events.update(event_pairs)\n                while self._events:\n                    fd, events = self._events.popitem()\n                    try:\n                        fd_obj, handler_func = self._handlers[fd]\n                        handler_func(fd_obj, events)\n                    except (OSError, IOError) as e:\n                        if errno_from_exception(e) == errno.EPIPE:\n                            # Happens when the client closes the connection\n                            pass\n                        else:\n                            self.handle_callback_exception(self._handlers.get(fd))\n                    except Exception:\n                        self.handle_callback_exception(self._handlers.get(fd))\n                fd_obj = handler_func = None\n\n        finally:\n            # reset the stopped flag so another start/stop pair can be issued\n            self._stopped = False\n            if self._blocking_signal_threshold is not None:\n                signal.setitimer(signal.ITIMER_REAL, 0, 0)\n            IOLoop._current.instance = old_current\n            if old_wakeup_fd is not None:\n                signal.set_wakeup_fd(old_wakeup_fd)\n\n\n接下来 tornado 终于也回到了 ioloop 代码中了(泪奔)!!当连接成功时,该 fd 的缓冲区可写,\n epoll 收到 fd 的 write 操作通知~进入到了 epoll 的 loop 中处理.然后!回到刚才注册的 _handle_events 了!\n注意这个 _handle_events 是 IOStream 的实例里的 _handle_events ,他有刚才我们处理的所有信息哦~\n\n接下来看 _handle_events 的代码,看他如果解决掉 future \n\n\nIOStream._handle_events\n\n    def _handle_events(self, fd, events):\n        if self.closed():\n            gen_log.warning(\"Got events for closed stream %s\", fd)\n            return\n        try:\n            if self._connecting:\n                # Most IOLoops will report a write failed connect\n                # with the WRITE event, but SelectIOLoop reports a\n                # READ as well so we must check for connecting before\n                # either.\n                self._handle_connect()\n            if self.closed():\n                return\n            if events & self.io_loop.READ:\n                self._handle_read()\n            if self.closed():\n                return\n            if events & self.io_loop.WRITE:\n                self._handle_write()\n            if self.closed():\n                return\n            if events & self.io_loop.ERROR:\n                self.error = self.get_fd_error()\n                # We may have queued up a user callback in _handle_read or\n                # _handle_write, so don't close the IOStream until those\n                # callbacks have had a chance to run.\n                self.io_loop.add_callback(self.close)\n                return\n            state = self.io_loop.ERROR\n            if self.reading():\n                state |= self.io_loop.READ\n            if self.writing():\n                state |= self.io_loop.WRITE\n            if state == self.io_loop.ERROR and self._read_buffer_size == 0:\n                # If the connection is idle, listen for reads too so\n                # we can tell if the connection is closed.  If there is\n                # data in the read buffer we won't run the close callback\n                # yet anyway, so we don't need to listen in this case.\n                state |= self.io_loop.READ\n            if state != self._state:\n                assert self._state is not None, \\\n                    \"shouldn't happen: _handle_events without self._state\"\n                self._state = state\n                self.io_loop.update_handler(self.fileno(), self._state)\n        except UnsatisfiableReadError as e:\n            gen_log.info(\"Unsatisfiable read, closing connection: %s\" % e)\n            self.close(exc_info=True)\n        except Exception:\n            gen_log.error(\"Uncaught exception, closing connection.\",\n                          exc_info=True)\n            self.close(exc_info=True)\n            raise\n\n    def _handle_connect(self):\n        err = self.socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)\n        if err != 0:\n            self.error = socket.error(err, os.strerror(err))\n            # IOLoop implementations may vary: some of them return\n            # an error state before the socket becomes writable, so\n            # in that case a connection failure would be handled by the\n            # error path in _handle_events instead of here.\n            if self._connect_future is None:\n                gen_log.warning(\"Connect error on fd %s: %s\",\n                                self.socket.fileno(), errno.errorcode[err])\n            self.close()\n            return\n        if self._connect_callback is not None:\n            callback = self._connect_callback\n            self._connect_callback = None\n            self._run_callback(callback)\n        if self._connect_future is not None:\n            future = self._connect_future\n            self._connect_future = None\n            future.set_result(self)\n        self._connecting = False\n\n\n判断是否在连接中,当然是了,刚才我也强调过了,\n然后进入 _handle_connect,_handle_connect 先判断 connect 有没成功,\n成功了就是设置 _connect_future 的 result,set_result(self ),把 self(iostream )设置进去了!   \n然后 _connect_future 的 callbacks 会在下一次循环被 ioloop 消化掉!!\n\n一步步返回看,这个 future 正是我们之前的那个 yiled 操作的右边的返回的 future ,\n所以刚才 _Connector.try_connect 设置的 callback   ,on_connect_done 会在 ioloop 的 callback 里执行. \n根据上一篇[文章][3]讲的 coroutine 的源码得知,此 future 里还有 Runner.run 的 callback 哦~\n所以 ,run 里 send 了 vaule 到 gen . \n终于终于!!程序回到了刚才的 yield 处了!!!!!\n\ntornado正是如此实现异步io的\n\n感觉一直讲完整个操作不太现实,剩下的大家还是自己跟踪吧,道理跟这个流程类似.\n yield 操作右边,一定是返回一个 future (旧版本貌似是 YieldPoint ,因为没看过旧版,所以不太清楚) ,\n然后在返回 future 之前,设置好 fd 的 handler ,和其他的解析工作,然后等待 epoll 检测到关心的 io   event ,\n在 io 的 handler 里把 future 解决,从而回到 yield 处~ 核心就是 ioloop 三部分 ,future,gen.coroutine . \n相互配合完成异步操作. 跟踪几遍消化一下,就可以写 tornado 的扩展了. \n\n祝大家武运亨通\n\n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "9"}