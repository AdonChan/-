{"title": "python实现在线分词 - 小胖纸的架构师之路 ", "index": "分词,python,django", "content": "写在前面\n最近在优化网站的搜索部分，网站是用Django实现的，主要业务是在线视频教育网站，之前搜索只是一段Django ORM模型中的icontains模糊匹配，所以只能搜索关键字，但是CEO(SB)突然又想在网站做个类似于百度问答的功能。但是搜索问题就成了一个棘手的事情，原有搜索不能满足需求，但是调研相关的elasticsearch之类的全文检索又有点重(除了有点重，主要是CEO不给时间啊！)，所以就把精力放在了分词上，能短平快的实现该功能，而且比较轻。\n因为关注的梁博，自然而然想到了他博士期间写的在线分词pullword（写这篇文章时他个人网站又挂掉了，哈哈哈，这里贴出了他的微博供大家膜拜），在此对梁博表示感谢！！\n下面是我写的分词的utils，不过梁博的分词现在只能支持中文，输入英文跟数字会返回error，之前是想调用梁博的原有的pullword，他的API地址，但是我测了一下需要6-7秒，对于网站搜索功能显然没办法使用，后来又找到他挂在百度的免费API，测试了一下数据返回在0.1秒左右，还不错，就使用了百度api。\n要注意，他原生的api中有个param1的参数，表示选词概率，param1=0.8表示只出概率在0.8以上的词，但是我调用传参的时候不好用，所以就通过返回的数据自己写了筛选。get_pullword需要两个参数，第一个是一段需要分词的话，第二个是筛选分词后选词概率，［0，1］区间，等同于他的param1的参数。\n\n# coding: utf-8\n__author__ = 'flyingpang'\nimport requests\nimport datetime\n\n\ndef get_pullword(s, probability):\n    \"\"\"\n    :param s: 一段需要分词的中文.\n    :param probability: 选词概率.\n    :return: 按照概率从大到小排序返回一个list.\n    \"\"\"\n    headers = {'apikey': '你自己的百度apikey'}\n    url = 'http://apis.baidu.com/apistore/pullword/words'\n    params = {'source': s, 'param1': '0', 'param2': '1'}\n    r = requests.get(url=url, headers=headers, params=params)\n\n    if r.status_code != 200 or r.content.strip().split('\\r\\n')[0].startswith('error'):\n        result = list()\n        result.append(s)\n        return result\n    else:\n        data = r.content.strip().split('\\r\\n')\n        return split_word(data, probability)\n\n\ndef split_word(words, probability=0):\n    \"\"\"\n    :param words: 分词结果的字典, 其中key为分词,value为概率.\n    :param probability: 最小分词概率\n    :return: 概率从大到小的分词列表.\n    \"\"\"\n    # 分词跟相关概率保存到字典中.\n    d = dict()\n\n    for i in words:\n        m = i.split(':')\n        d[m[0].decode('utf-8')] = float(m[1])\n\n    m = sorted(d.iteritems(), key=lambda k: k[1], reverse=True)\n    words_list = []\n    for i in range(len(m)):\n        if m[i][1] >= probability:\n            words_list.append(m[i][0])\n    return words_list\n\nif __name__ == '__main__':\n    source = u'清华大学是好学校'\n    t1 = datetime.datetime.now()\n    test = get_pullword(source, 0.8)\n    t2 = datetime.datetime.now()\n    print \"total time\", t2 - t1\n    print test\n\n因为我后端使用Diango的icontains来匹配，所以返回一个list的话没办法匹配，所以这里给出一个Django处理的方法。\nquery = self.request.GET.get(\"q\", None)\npull_words = get_pullword(query, 0.8)  # 筛选出大于0.8概率的词\nquery_list = reduce(operator.or_, (Q(title__icontains=item) for item in pull_words))\nquestion_list = Question.objects.filter(query_list).order_by(\"-id\")\n\n至此python实现简单分词就写完了。\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "2"}