{"title": "使用 TensorFlow 在卷积神经网络上实现 L2 约束的 softmax 损失函数 - 个人文章 ", "index": "python", "content": "作者：chen_h微信号 & QQ：862251340微信公众号：coderpai简书地址：https://www.jianshu.com/p/d6a...\n\n当我们要使用神经网络来构建一个多分类模型时，我们一般都会采用 softmax 函数来作为最后的分类函数。softmax 函数对每一个分类结果都会分配一个概率，我们把比较高的那个概率对应的类别作为模型的输出。这就是为什么我们能从模型中推导出具体分类结果。为了训练模型，我们使用 softmax 函数进行反向传播，进行训练。我们最后输出的就是一个 0-1 向量。\n在这篇文章中，我们不会去解释什么是 softmax 回归或者什么是 CNN。这篇文章的主要工作是如何在 TensorFlow 上面设计一个 L2 约束的 softmax 函数，我们使用的数据集是 MNIST。完整的理论分析可以查看这篇论文。\n在具体实现之前，我们先来弄清楚一些概念。\nsoftmax 损失函数\nsoftmax 损失函数可以定义如下：\n\n其中各个参数定义如下：\n\nL2 约束的 softmax 损失函数\n带约束的损失函数定义几乎和之前的一样，我们的目的还是最小化这个损失函数。\n\n但是，我们需要对 f(x) 函数进行修改。\n我们不是直接计算最后层权重与前一层网络输出 f(x) 之间的乘积，而是对前一层的 f(x) 先做一次归一化，然后对这个归一化的值进行 α 倍数的放大，最后我们进行常规的 softmax 函数进行计算。\n也就是说，损失函数是受到如下约束：\n\n程序细节\n所以，我们的架构看起来是如下图（这也是我想要实现的架构图）：\n\nC 表示卷积层，P 表示池化层，FC 表示全连接层，L2-Norm 层和Scale 层是我们重点要实现的层。\n利用 TensorFlow 进行实现\n为了实现这个模型，我们使用这个代码库 进行学习。\n在应用 dropout 之前，我们先对 N-1 层的输出进行正则化，然后把正则化之后的结果乘以参数 alpha，然后进行 softmax  函数计算。下面是具体的代码展示：\nfc1 = alpha * tf.divide(fc1, tf.norm(fc1, ord='euclidean'))\n如果我们把 alpha 设置为 0，那么这就是常规的 softmax 函数，否则就是一个 L2 约束。\n完整代码如下：\n# Actual Code : https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/convolutional_network.ipynb\n# Modified By: Manash\n\nfrom __future__ import division, print_function, absolute_import\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Training Parameters\nlearning_rate = 0.001\nnum_steps = 100\nbatch_size = 20\n\n\n# Network Parameters\nnum_input = 784 # MNIST data input (img shape: 28*28)\nnum_classes = 10 # MNIST total classes (0-9 digits)\ndropout = 0.75 # Dropout, probability to keep units\n\n\n# Create the neural network\ndef conv_net(x_dict, n_classes, dropout, reuse, is_training, alpha=5):\n    \n    # Define a scope for reusing the variables\n    with tf.variable_scope('ConvNet', reuse=reuse):\n        # TF Estimator input is a dict, in case of multiple inputs\n        x = x_dict['images']\n\n        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n        # Reshape to match picture format [Height x Width x Channel]\n        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n\n        # Convolution Layer with 32 filters and a kernel size of 5\n        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n\n        # Convolution Layer with 32 filters and a kernel size of 5\n        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n\n        # Flatten the data to a 1-D vector for the fully connected layer\n        fc1 = tf.contrib.layers.flatten(conv2)\n\n        # Fully connected layer (in tf contrib folder for now)\n        fc1 = tf.layers.dense(fc1, 1024)\n        \n        # If alpha is not zero then perform the l2-Normalization then scaling up\n        if alpha != 0:\n            fc1 = alpha * tf.divide(fc1, tf.norm(fc1, ord='euclidean'))\n    \n        # Apply Dropout (if is_training is False, dropout is not applied)\n        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n  \n        # Output layer, class prediction\n        out = tf.layers.dense(fc1, n_classes)\n\n    return out\n  \n# Define the model function (following TF Estimator Template)\ndef model_fn(features, labels, mode):\n    # Set alpha\n    alph = 50\n    \n    # Build the neural network\n    # Because Dropout have different behavior at training and prediction time, we\n    # need to create 2 distinct computation graphs that still share the same weights.\n    logits_train = conv_net(features, num_classes, dropout, reuse=False, is_training=True, alpha=alph)\n    \n    # At test time we don't need to normalize or scale, it's redundant as per paper : https://arxiv.org/abs/1703.09507\n    logits_test = conv_net(features, num_classes, dropout, reuse=True, is_training=False, alpha=0)\n    \n    # Predictions\n    pred_classes = tf.argmax(logits_test, axis=1)\n    pred_probas = tf.nn.softmax(logits_test)\n    \n    # If prediction mode, early return\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes) \n        \n    # Define loss and optimizer\n    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n    \n    # Evaluate the accuracy of the model\n    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n    \n    # TF Estimators requires to return a EstimatorSpec, that specify\n    # the different ops for training, evaluating, ...\n    estim_specs = tf.estimator.EstimatorSpec(\n      mode=mode,\n      predictions=pred_classes,\n      loss=loss_op,\n      train_op=train_op,\n      eval_metric_ops={'accuracy': acc_op})\n\n    return estim_specs\n\n  \n# Build the Estimator\nmodel = tf.estimator.Estimator(model_fn)\n\n# Define the input function for training\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    x={'images': mnist.train.images}, y=mnist.train.labels,\n    batch_size=batch_size, num_epochs=None, shuffle=False)\n# Train the Model\nmodel.train(input_fn, steps=num_steps)\n\n# Evaluate the Model\n# Define the input function for evaluating\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    x={'images': mnist.test.images}, y=mnist.test.labels,\n    batch_size=batch_size, shuffle=False)\n# Use the Estimator 'evaluate' method\nmodel.evaluate(input_fn)\n\n\n# Predict single images\nn_images = 4\n# Get images from test set\ntest_images = mnist.test.images[:n_images]\n# Prepare the input data\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    x={'images': test_images}, shuffle=False)\n# Use the model to predict the images class\npreds = list(model.predict(input_fn))\n\n# Display\nfor i in range(n_images):\n    plt.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\n    plt.show()\n    print(\"Model prediction:\", preds[i])\n    \n性能评估\n这个真的能提高性能吗？是的，而且效果非常好，它能提高大约 1% 的性能。我没有计算很多的迭代，主要是我没有很好的电脑。如果你对这个性能有你疑惑，你可以自己试试看。\n以下是不同 alpha 值对应的模型性能：\n\n橘黄色的线表示用常规的 softmax 函数，蓝色的线是用 L2 约束的 softmax 函数。\n算法社区直播课：请点击这里\n\n作者：chen_h微信号 & QQ：862251340简书地址：https://www.jianshu.com/p/d6a...\nCoderPai 是一个专注于算法实战的平台，从基础的算法到人工智能算法都有设计。如果你对算法实战感兴趣，请快快关注我们吧。加入AI实战微信群，AI实战QQ群，ACM算法微信群，ACM算法QQ群。长按或者扫描如下二维码，关注 “CoderPai” 微信号（coderpai）\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}