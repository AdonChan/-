{"title": "为采集动态网页安装和测试Python Selenium库 - 一起学习python网络爬虫 ", "index": "网络爬虫,python,编程语言,数据采集,网页抓取", "content": "\n1. 引言\n上一篇《为编写网络爬虫程序安装Python3.5》中测试小例子对静态网页做了一个简单的采集程序，而动态网页因为需要动态加载js获取数据，所以使用urllib直接openurl已经不能满足采集的需求了。这里我们使用selenium库，通过它我们可以很简单的使用浏览器来为我们加载动态内容，从而获取采集结果。\n在很多案例中，Selenium与PhantomJS搭配采集动态网页内容（可以参看我以前发表的案例文章），直接与Firefox或者Chrome搭配，可以应对一些更加复杂的采集情形，比如，在防爬方面，直接驱动普通浏览器更不容易被识别成爬虫。所以，本文讲解与Firefox搭配，开发难度并没有增加。\nPython版本：Python3\n2. 安装selenium库\n使用快捷键win + R或右键开始选择运行，输入cmd回车，打开命令提示符窗口，输入命令：pip install selenium\n3. 以亚马逊商品为例的一个简单爬虫\n3.1 引入Gooseeker规则提取器模块gooseeker.py\n(下载地址: https://github.com/FullerHua/gooseeker/tree/master/core), 自定义存放目录，这里为E:demogooseeker.py\n引入GooSeeker规则提取器，就省去手工编写XPath或者正则表达式的麻烦，用直观标注的方式自动生成采集规则后，通过API加载和使用采集规则。操作过程请参看《1分钟快速生成用于网页内容提取的xslt》。\n下面的代码就是使用了API，所以看不到冗长的XPath和正则表达式规则，代码中的API key和抓取规则名可以直接使用，这是公共的测试用的规则。\n3.2 在提取器模块gooseeker.py同级目录下创建一个.py后缀文件\n如这里为E:Demosecond.py，再以记事本打开，敲入代码:\n# -*- coding: utf-8 -*-\n# 使用gsExtractor类的示例程序\n# 以webdriver驱动Firefox采集亚马逊商品列表\n# xslt保存在xslt_bbs.xml中\n# 采集结果保存在result-2.xml中\n\nimport os\nimport time\nfrom lxml import etree\nfrom selenium import webdriver\n\nfrom gooseeker import GsExtractor\n\n#驱动火狐\ndriver = webdriver.Firefox()\n# 访问并读取网页内容\nurl = \"https://www.amazon.cn/b/ref=s9_acss_bw_ct_refTest_ct_1_h?_encoding=UTF8&node=658810051&pf_rd_m=A1AJ19PSB66TGU&pf_rd_s=merchandised-search-5&pf_rd_r=WJANDTHE4NFAYRR4P95K&pf_rd_t=101&pf_rd_p=289436412&pf_rd_i=658414051\"\n#开始加载\ndriver.get(url)\n#等待2秒，更据动态网页加载耗时自定义\ntime.sleep(2)\n# 获取网页内容\ncontent = driver.page_source.encode('utf-8')\n# 获取docment\ndoc = etree.HTML(content)\n\n# 引用提取器\nbbsExtra = GsExtractor()\nbbsExtra.setXsltFromAPI(\"31d24931e043e2d5364d03b8ff9cc77e\", \"亚马逊图书_test\") # 设置xslt抓取规则\nresult = bbsExtra.extract(doc)   # 调用extract方法提取所需内容\n\n# 当前目录\ncurrent_path = os.getcwd()\nfile_path = current_path + \"/result-2.xml\"\n\n# 保存结果\nopen(file_path,\"wb\").write(result)\n\n# 打印出结果\nprint(str(result).encode('gbk','ignore').decode('gbk'))\n\n3.3 执行second.py，打开命令提示窗口，进入second.py文件所在目录，输入命令 :python second.py 回车\n注：这里是以驱动Firefox为例，所以需要安装Firefox，若未安装可以去往Firefox官网下载安装\n3.4 查看保存结果文件,进入second.py文件所在目录，找到名称为result-2的xml文件\n\n4. 总结\n安装selenium，由于网络原因失败了一次，后面再次安装时才成功，如果碰到多次超时而安装失败，可以尝试连接vpn后再使用pip命令安装。\n下一篇《快速制作规则并获取提取器api》将会讲解：快速的将一个网页结构生成规则并通过规则Api方式得到需要采集的结果。\n5. 文档修改历史\n2016-10-25：V1.0\n6. 集搜客GooSeeker开源代码下载源\nGooSeeker开源Python网络爬虫GitHub源\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "2"}