{"title": "Scrapy学习（二） 入门 - 四畳半神话大系 ", "index": "scrapy,网页爬虫,python", "content": "快速入门\n接上篇Scrapy学习（一） 安装，安装后，我们利用一个简单的例子来熟悉如何使用Scrapy创建一个爬虫项目。\n创建一个Scrapy项目\n在已配置好的环境下输入\nscrapy startproject dmoz\n系统将在当前目录生成一个myproject的项目文件。该文件的目录结构如下\ndmoz/    # 项目根目录\n   scrapy.cfg    # 项目配置文件\n   dmoz/    # 项目模块\n       __init__.py\n        items.py    # 项目item文件，有点类似Django中的模型\n        pipelines.py    # 项目pipelines文件，负责数据的操作和存储\n        settings.py    # 项目的设置文件.\n        spiders/    # 项目spider目录，编写的爬虫脚步都放此目录下\n            __init__.py\n接下来我们以dmoz.org为爬取目标。开始变现简单的爬虫项目。\n编写items\n在items.py中编写我们所需的数据的模型\nfrom scrapy.item import Item, Field\n\nclass Website(Item):\n    name = Field()\n    description = Field()\n    url = Field()\n这个模型用来填充我们爬取的数据\n编写Spider\n在spiders文件下新建爬虫文件。这部分才是业务的核心部分。首先创建一个继承scrapy.spiders.Spider的类并且定义如下三个属性\n\nname 标识spider\nstart_urls 启动爬虫时进行爬取的url列表，默认为空\nparse() 每个初始的url下载后的response都会传到该方法内，在这个方法里可以对数据进行处理。\n\nfrom scrapy.spiders import Spider\nfrom scrapy.selector import Selector\nfrom dirbot.items import Website\n\nclass DmozSpider(Spider):\n    name = \"dmoz\"\n    allowed_domains = [\"dmoz.org\"]\n    start_urls = [\n        \"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/\",\n        \"http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/\",\n    ]\n\n    def parse(self, response):\n        sites = response.css('#site-list-content > div.site-item > div.title-and-desc')\n        items = []\n\n        for site in sites:\n            item = Website()\n            item['name'] = site.css(\n                'a > div.site-title::text').extract_first().strip()\n            item['url'] = site.xpath(\n                'a/@href').extract_first().strip()\n            item['description'] = site.css(\n                'div.site-descr::text').extract_first().strip()\n            items.append(item)\n        return items\n其中值得注意的是，在parse方法内，我们可以用Selector选择器来提取网站中我们所需的数据。提取的方式有几种。\n\nxpath() 传入xpath表达式获取节点值\ncss() 传入css表达式获取节点值\nre() 传入正则表达式获取节点值 # 此方法本人未测试\n\n运行并保存数据\n接下来我们运行爬虫，并将爬取的数据存储到json中\nscrapy crawl dmoz -o items.json\n其他\n在运行爬虫的过程中，我遇到了如下报错：\nKeyError: 'Spider not found: dmoz\n这个是因为我的spider类中设置的name的值和我scrapy crawl运行的spider不一致导致的。\n具体代码详见：scrapy入门项目\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "3"}