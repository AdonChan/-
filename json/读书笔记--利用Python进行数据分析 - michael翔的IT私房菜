{"title": "读书笔记--利用Python进行数据分析 - michael翔的IT私房菜 ", "index": "机器学习,数据分析,python", "content": "利用Python进行数据分析\n\n[TOC]\nchapter 05\n索引对象\n\nIndex对象是不可更改的（immutable）。index[1]='d'就会出错。但是，df.index=index_new是可以的。\n对于reindex可以修改（行）索引、列，或两个都修改。1frame.reindex(columns=states)重新索引列。\n\ndf.drop([list1,list2])默认是删除的指定的行，如果想要删除某一列，就需要df.drop([list1,list2],axis=1)。自己的认识，axis是指查找数据的一个方向，axis=0是指查找数据时是竖直方向去找，axis=1是水平方向去找数据。这样，这里想要删除某一列，就需要是水平方向去找到该列名。否则，提示找不到。\n索引、选取和过滤\nSeries索引，Series索引值不止是整数。\nobj = Series(np.arange(4.), index=['a', 'b', 'c', 'd'])\nobj[0]\nobj[:2]    #找到：obj[0],obj[1]\nobj['a']\nobj[['a','c']]\nobj['a':'c'] #找到：obj[0],obj[1],obj[2]  标签索引，闭区间！\n以上索引方式都可以。\n利用标签的切片运算和普通的Python切片运算是不同的，其末端是包含的（inclusive）。闭区间\n对DataFrame索引其实就是获取一个或多个列。\ndata = DataFrame(np.arange(16).reshape((4, 4)),\n                 index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                 columns=['one', 'two', 'three', 'four'])\ndata['two']\ndata[['three','one']]\n这时候，不能像Series那样直接选取行了，如：data['Ohio']\n那么，选择行怎么做呢？\n# 这里举例选取前三行\ndata[:3] 选取了0,1,2行\n# 或者\ndata.ix['Ohio':'Utah',:]   \n# 或者\ndata.ix[0:3]\n# 或者\ndata.loc['Ohio':'Utah',:]\n# 或者\ndata.iloc[0:3,:] \n以上,后边的冒号可以省略。\n\nix标签索引，位置索引都可以\nloc标签索引\niloc位置索引\n\n再强调一遍，标签索引是闭区间！\n布尔索引\ndata[data['three']>5]\ndata[data<5]\ndata.ix[data.three>5,:3]\n总结下来，ix索引最牛逼！灵活结合了标签索引和位置索引！\n算数运算和数据对齐\npandas最重要的一个功能是，它可以对不同索引的对象进行算数运算。\n对于DataFrame，对齐操作将会同时发生在行和列上。\n没有重叠的位置会产生NA值--NaN。\n在算数方法中填充值。\n广播功能，需要注意索引，如果某个索引值在DataFrame或者Series的索引中找不到，则参与运算就会容易形成NA值。\n如果希望匹配行且在列上广播，则必须使用算术运算方法。例如：\nseries3 = frame['d']\nframe.sub(series3, axis=0)\n结果：\n\n\nb\nd\ne\n\n\n\nUtah\n-1.0\n0.0\n1.0\n\n\nOhio\n-1.0\n0.0\n1.0\n\n\nTexas\n-1.0\n0.0\n1.0\n\n\nOregon\n-1.0\n0.0\n1.0\n\n\n\n函数应用和映射\n元素及的Python函数也是可以的。假如想得到frame中各个浮点值的格式化字符串，使用applymap函数。\nframe = DataFrame(np.random.randn(4, 3), columns=list('bde'),\n                  index=['Utah', 'Ohio', 'Texas', 'Oregon'])\nformat = lambda x: '%.2f' % x\nframe.applymap(format)\n之所以叫applymap，是因为Series有一个应用于元素级函数的map方法:\nframe['e'].map(format)\n带有重复值的轴索引\n虽然许多pandas函数（如reindex）都要求标签唯一，但这并不是强制的。\nobj = Series(range(5), index=['a', 'a', 'b', 'b', 'c'])\nobj.index.is_unique   #False\n索引的`is_unique属性可以告诉你它的值是否唯一。obj['a']会返回两个值。\n汇总和计算描述统计\nNA值会自动被排除。通过skipna选项可以禁用该功能。\n意思是，df.mean(axis=1,skipna=False)会计算水平方向的均值，并且，有NA出现，均值也会是NA，而不是忽视它。\n\nidxmin返回最小值的索引\nidxman返回最大值的索引\n\n\n\n相关系数与协方差\n有些汇总统计是通过参数对计算出来的。\n看几个DataFrame，他们的数据来自Yahoo!Finance的股票价格和成交量。\nimport pandas.io.data as web\n\nall_data = {}\nfor ticker in ['AAPL', 'IBM', 'MSFT', 'GOOG']:\n    all_data[ticker] = web.get_data_yahoo(ticker)\n\nprice = DataFrame({tic: data['Adj Close']\n                   for tic, data in all_data.iteritems()})\nvolume = DataFrame({tic: data['Volume']\n                    for tic, data in all_data.iteritems()})\n计算价格的百分数变化：\nreturns = price.pct_change()\nSeries的corr方法计算两个Series中重叠的、非NA的、按索引对齐的值的相关系数。与此类似，cov用于计算协方差。\nreturns.MSFT.corr(returns.IBM)\nreturns.MSFT.cov(returns.IBM)\n利用DataFrame的corrwith方法，可以计算其列或行跟另一个Series或者DataFrame之间的相关系数。\nreturns.corrwith(returns.IBM)\n#等价于\nreturns.corr()['IBM']\n无论如何，在计算相关系数之前，所有的数据项都会按标签对齐。\n唯一值、值计数以及成员资格\n\nunique函数可以得到Series中唯一值数组。\nvalue_counts函数用于计算Series中各值出现的频率。\nisin用于选取矢量化集合的成员资格。\n\n这几个函数都是Series数据的方法！\nresult = data.apply(pd.value_counts).fillna(0)\n利用上面这个方法，可以对df数据每列出现的数值频率进行统计，同时，对有的列中没有出现的数值的频率为NA的值设置为0\napply看来这个函数还是很有用啊，它是默认从列角度（axis=0）去应用里边的函数。而applymap是元素级应用函数。\n处理缺失数据\n之前看一篇文章，机器学习系列(3)_逻辑回归应用之Kaggle泰坦尼克之灾2，当中遇到缺失数据之后，运用机器学习的方法，结合其他变量拟合预测出值，然后作为缺失值的填充。\n而本书立足于数据分析，从处理数据角度出发，因此，不会采用那么复杂的方法。这里，是要介绍一些操作数据的函数方法，这是基础，是之后处理数据的基本功！缺失数据也是重中之重！\npandas的设计目标之一就是让缺失数据的处理任务尽量轻松。例如，pandas对象上的描述统计都排除了缺失数据！\nstring_data = Series(['aardvark', 'artichoke', np.nan, 'avocado'])\nstring_data\n0     aardvark\n1    artichoke\n2          NaN\n3      avocado\ndtype: object\nPython内置的None值也会被当做NA处理。\nNA处理方法\n\n滤除缺失数据\ndropna方法可能比较实用一点。\nfrom numpy import nan as NA\ndata = Series([1, NA, 3.5, NA, 7])\ndata.dropna()\n对于一个Series， dropna返回一个仅含非空数据和索引值的Series。\n0    1.0\n2    3.5\n4    7.0\ndtype: float64\n而对于一个DataFrame对象，事情就有点复杂了。dropna默认丢弃任何含有缺失值的行。\ndata = DataFrame([[1., 6.5, 3.], [1., NA, NA],\n                  [NA, NA, NA], [NA, 6.5, 3.]])\ncleaned = data.dropna()\ndata\n\ncleaned\n    0    1    2\n0    1.0    6.5    3.0\n传入how='all'将只丢弃全为NA的行。要用这种方式丢弃列，只需要传入参数axis=1。\ndata.dropna(how='all')\n0    1    2\n0    1.0    6.5    3.0\n1    1.0    NaN    NaN\n3    NaN    6.5    3.0\n另一个滤除DataFrame行的问题涉及时间序列。假设只想留下一部分观测数据，可以用tresh参数实现。\ndf = DataFrame(np.random.randn(7, 3))\ndf.ix[:4, 1] = NA; df.ix[:2, 2] = NA\ndf\n       0        1             2\n0    -0.577087    NaN            NaN\n1    0.523772    NaN            NaN\n2    -0.713544    NaN            NaN\n3    -1.860761    NaN            0.560145\n4    -1.265934    NaN            -1.063512\n5    0.332883    -2.359419    -0.199543\n6    -1.541996    -0.970736    -1.307030\ndf.dropna(thresh=3)\n保留至少3个非空值的行。\n\n        0        1            2\n5    0.332883    -2.359419    -0.199543\n6    -1.541996    -0.970736    -1.307030\n填充缺失数据\n对于大多数情况而言，fillna方法是最主要的函数。通过一个常数调用fillna就会将缺失值替换为那个常数。df.fillna(0)。\n若是通过一个字典调用fillna，就可以实现对不同的列填充不同的值。\ndf.fillna({1:0.5,3:-1})\nfillna默认会返回新对象，但也可以对现有对象进行就地修改：\ndf.fillna(0,inplace=True)\n对reindex有效地那些插值方法，也可用以fillna。\ndf = DataFrame(np.random.randn(6, 3))\ndf.ix[2:, 1] = NA; df.ix[4:, 2] = NA\ndf\ndf.fillna(method='ffill', limit=2)\n# 有很多灵活的填充方式\ndata = Series([1., NA, 3.5, NA, 7])\ndata.fillna(data.mean())\n\n层次化索引\n层次化索引（hierarchical indexing）是pandas的一项重要功能，它使你能在一个轴上拥有多个（两个以上）索引级别。\n抽象点说，它使你能以低纬度形式处理高纬度数据。\ndata = Series(np.random.randn(10),\n              index=[['a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'd', 'd'],\n                     [1, 2, 3, 1, 2, 3, 1, 2, 2, 3]])\ndata\na  1   -0.204708\n   2    0.478943\n   3   -0.519439\nb  1   -0.555730\n   2    1.965781\n   3    1.393406\nc  1    0.092908\n   2    0.281746\nd  2    0.769023\n   3    1.246435\ndtype: float64\n这段数据可以通过其unstack方法被重新安排到一个DataFrame中：\ndata.unstack()\n\n    1            2            3\na    -0.204708    0.478943    -0.519439\nb    -0.555730    1.965781    1.393406\nc    0.092908    0.281746    NaN\nd    NaN            0.769023    1.246435\nunstack的逆方法是stack.\n不要将索引名称(index.names)跟轴标签混为一谈！\n重排分级顺序（Reordering and sorting levels）\n有时，你需要重新调整某条轴上各级别的顺序，或根据指定级别上的值对数据进行排序。\nswaplevel接受两个级别编号或名称，并返回一个互换了级别的新对象（但数据不会发生变化）\n根据级别汇总统计\n许多对DataFrame和Series的描述和汇总统计都有一个level选项，它用于指定在某条轴上求和的级别。\n这其实是利用了pandas的groupby功能。\n使用DataFrame的列（充当索引）\n人们经常想要将DataFrame的一个或多个列当做行索引来用，或者可能希望将行索引变成DataFrame的列。\nframe = DataFrame({'a': range(7), 'b': range(7, 0, -1),\n                   'c': ['one', 'one', 'one', 'two', 'two', 'two', 'two'],\n                   'd': [0, 1, 2, 0, 1, 2, 3]})\nframe\n\nDataFrmae的set_index函数会将其一个或多个列转换为行索引，并创建一个新的DataFrame：\nframe2 = frame.set_index(['c', 'd'])\n默认情况下，那系列会从DataFrame中移除，但也可以将其保留下来。\nframe.set_index(['c', 'd'], drop=False)\n\nreset_index的功能跟set_index刚好相反，层次化索引的级别会被转移到列里边。\nframe2.reset_index()\n\n\n\n\npandas.DataFrame.reindex ↩\n\n\n机器学习系列(3)_逻辑回归应用之Kaggle泰坦尼克之灾 ↩\n\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "13"}