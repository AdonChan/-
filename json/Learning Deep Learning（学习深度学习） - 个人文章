{"title": "Learning Deep Learning（学习深度学习） - 个人文章 ", "index": "python", "content": "作者：chen_h微信号 & QQ：862251340微信公众号：coderpai简书地址：https://www.jianshu.com/p/e98...\n\nLearning Deep Learning（学习深度学习）\nThere are lots of awesome reading lists or posts that summarized materials related to Deep Learning. So why would I commit another one? Well, the primary objective is to develop a complete reading list that allows readers to build a solid academic and practical background of Deep Learning. And this list is developed while I’m preparing my Deep Learning workshop. My research is related to Deep Neural Networks (DNNs) in general. Hence, this posts tends to summary contributions in DNNs instead of generative models.\nFor Novice（给深度学习初学者的书单）\nIf you have no idea about Machine Learning and Scientific Computing, I suggest you learn the following materials while you are reading Machine Learning or Deep Learning books. You don’t have to master these materials, but basic understanding is important. It’s hard to open a meaningful conversation if the person has no idea about matrix or single variable calculus.\nIntroduction to Algorithms by Erik Demaine and Srinivas Devadas.\nSingle Variable Calculus by David Jerison.\nMultivariable Calculus by Denis Auroux.\nDifferential Equations by Arthur Mattuck, Haynes Miller, Jeremy Orloff, John Lewis.\nLinear Algebra by Gilbert Strang.\nTheory of Computation, Learning Theory, Neuroscience, etc （基于深度学习的计算理论，学习理论，神经科学等等）\nIntroduction to the Theory of Computation by Michael Sipser.\nArtificial Intelligence: A Modern Approach by Stuart Russell and Peter Norvig.\nPattern Recognition and Machine Learning by Christopher Bishop.\nMachine Learning: A probabilistic perspective by Kevin Patrick Murphy.\nCS229 Machine Learning Course Materials by Andrew Ng at Stanford University.\nReinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto.\nProbabilistic Graphical Models: Principles and Techniques by Daphne Koller and Nir Friedman.\nConvex Optimization by Stephen Boyd and Lieven Vandenberghe.\nAn Introduction to Statistical Learning with application in R by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani.\nNeuronal Dynamics: From single neurons to networks and models of cognition by Wulfram Gerstner, Werner M. Kistler, Richard Naud and Liam Paninski.\nTheoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems by Peter Dayan and Laurence F. Abbott.\nMichael I. Jordan Reading List of Machine Learning at Hacker News.\nFundamentals of Deep Learning （关于深度学习基础知识的文献）\nDeep Learning in Neural Networks: An Overview by Jürgen Schmidhuber.\nDeep Learning Book by Yoshua Bengio, Ian Goodfellow and Aaron Courville.\nLearning Deep Architectures for AI by Yoshua Bengio\nRepresentation Learning: A Review and New Perspectives by Yoshua Bengio, Aaron Courville, Pascal Vincent.\nReading lists for new LISA students by LISA Lab, University of Montreal.\nTutorials, Practical Guides, and Useful Software（关于深度学习的教材，实用手册以及有用的软件）\nMachine Learning by Andrew Ng.\nNeural Networks for Machine Learning by Geoffrey Hinton.\nDeep Learning Tutorial by LISA Lab, University of Montreal.\nUnsupervised Feature Learning and Deep Learning Tutorial by AI Lab, Stanford University.\nCS231n: Convolutional Neural Networks for Visual Recognition by Stanford University.\nCS224d: Deep Learning for Natural Language Processing by Stanford University.\nTheano by LISA Lab, University of Montreal.\nPyLearn2 by LISA Lab, University of Montreal.\nCaffe by Berkeley Vision and Learning Center (BVLC) and community contributor     Yangqing Jia.\nTorch 7\nneon by Nervana.\ncuDNN by NVIDIA.\nConvNetJS by Andrej Karpathy.\nDeepLearning4j\nChainer: Neural network framework by Preferred Networks, Inc.\nBlocks by LISA Lab, University of Montreal.\nFuel by LISA Lab, University of Montreal.\nTensorFlow by Google\nLiterature in Deep Learning and Feature Learning（关于深度学习和特征学习的文献）\nDeep Learning is a fast-moving community. Therefore the line between “Recent Advances” and “Literature that matter” is kind of blurred. Here I collected articles that are either introducing fundamental algorithms, techniques or highly cited by the community.\nAutomatic Speech Recognition - A Deep Learning Approach by Dong Yu and Li Deng (Published by Springer, no Open Access)\nBackpropagation Applied to Handwritten Zip Code Recognition by Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard and L. D. Jackel.\nComparison of Training Methods for Deep Neural Networks by Patrick O. Glauner.\nDeep Learning by Yann LeCun, Yoshua Bengio, Geoffrey Hinton. (NO FREE COPY AVAILABLE)\nDistributed Representations of Words and Phrases and their Compositionality by Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado and Jeffrey Dean.\nEfficient Estimation of Word Representations in Vector Space by Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean.\nEfficient Large Scale Video Classification by Balakrishnan Varadarajan, George Toderici, Sudheendra Vijayanarasimhan, Apostol Natsev.\nFoundations and Trends in Signal Processing: DEEP LEARNING — Methods and  Applications by Li Deng and Dong Yu.\nFrom Frequency to Meaning: Vector Space Models of Semantics by Peter D. Turney and Patrick Pantel.\nLSTM: A Search Space Odyssey by Klaus Greff, Rupesh Kumar Srivastava, Jan Koutník, Bas R. Steunebrink, Jürgen Schmidhuber.\nSupervised Sequence Labelling with Recurrent Neural Networks by Alex Graves.\nRecent Must-Read Advances in Deep Learning（最近必读的关于深度学习领域的最新进展）\nMost of papers here are produced in 2014 and after. Survey papers or review papers are not included.\nA Convolutional Attention Network for Extreme Summarization of Source Code by Miltiadis Allamanis, Hao Peng, Charles Sutton.\nA Deep Bag-of-Features Model for Music Auto-Tagging by Juhan Nam, Jorge Herrera, Kyogu Lee.\nA Deep Generative Deconvolutional Image Model by Yunchen Pu, Xin Yuan, Andrew Stevens, Chunyuan Li, Lawrence Carin.\nA Deep Neural Network Compression Pipeline: Pruning, Quantization, Huffman Encoding by Song Han, Huizi Mao, William J. Dally.\nA Deep Pyramid Deformable Part Model for Face Detection by Rajeev Ranjan, Vishal M. Patel, Rama Chellappa.\nA Deep Siamese Network for Scene Detection in Broadcast Videos by Lorenzo Baraldi, Costantino Grana, Rita Cucchiara.\nA Hierarchical Recurrent Encoder-Decoder For Generative Context-Aware Query Suggestion by Alessandro Sordoni, Yoshua Bengio, Hossein Vahabi, Christina Lioma, Jakob G. Simonsen, Jian-Yun Nie.\nA Large-Scale Car Dataset for Fine-Grained Categorization and Verification by Linjie Yang, Ping Luo, Chen Change Loy, Xiaoou Tang.\nA Lightened CNN for Deep Face Representation by Xiang Wu, Ran He, Zhenan Sun.\nA Mathematical Theory of Deep Convolutional Neural Networks for Feature Extraction by Thomas Wiatowski, Helmut Bölcskei.\nA Multi-scale Multiple Instance Video Description Network by Huijuan Xu, Subhashini Venugopalan, Vasili Ramanishka, Marcus Rohrbach, Kate Saenko.\nA Neural Attention Model for Abstractive Sentence Summarization by Alexander M. Rush, Sumit Chopra, Jason Weston.\nA Recurrent Latent Variable Model for Sequential Data by Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron Courville, Yoshua Bengio.\nA Restricted Visual Turing Test for Deep Scene and Event Understanding by Hang Qi, Tianfu Wu, Mun-Wai Lee, Song-Chun Zhu.\nA Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification by Ye Zhang, Byron Wallace.\nABC-CNN: An Attention Based Convolutional Neural Network for Visual Question Answering by Kan Chen, Jiang Wang, Liang-Chieh Chen, Haoyuan Gao, Wei Xu, Ram Nevatia.\nAccelerating Very Deep Convolutional Networks for Classification and Detection by Xiangyu Zhang, Jianhua Zou, Kaiming He, Jian Sun.\nAccurate Image Super-Resolution Using Very Deep Convolutional Networks by Jiwon Kim, Jung Kwon Lee, Kyoung Mu Lee.\nAction Recognition using Visual Attention by Shikhar Sharma, Ryan Kiros, Ruslan Salakhutdinov.\nAction Recognition With Trajectory-Pooled Deep-Convolutional Descriptors by Limin Wang, Yu Qiao, Xiaoou Tang.\nAction-Conditional Video Prediction using Deep Networks in Atari Games by Junhyuk Oh, Xiaoxiao Guo, Honglak Lee, Richard Lewis, Satinder Singh.\nActive Object Localization with Deep Reinforcement Learning by Juan C. Caicedo, Svetlana Lazebnik.\nadaQN: An Adaptive Quasi-Newton Algorithm for Training RNNs by Nitish Shirish Keskar, Albert S. Berahas.\nAdding Gradient Noise Improves Learning for Very Deep Networks by Arvind Neelakantan, Luke Vilnis, Quoc V. Le, Ilya Sutskever, Lukasz Kaiser, Karol Kurach, James Martens.\nAdversarial Autoencoders by Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow.\nAdversarial Manipulation of Deep Representations by Sara Sabour, Yanshuai Cao, Fartash Faghri, David J. Fleet.\nAll you need is a good init by Dmytro Mishkin, Jiri Matas.\nAn End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition by Baoguang Shi, Xiang Bai, Cong Yao.\nAnswer Sequence Learning with Neural Networks for Answer Selection in Community Question Answering by Xiaoqiang Zhou, Baotian Hu, Qingcai Chen, Buzhou Tang, Xiaolong Wang.\nAnticipating the future by watching unlabeled video by Carl Vondrick, Hamed Pirsiavash, Antonio Torralba.\nAre You Talking to a Machine? Dataset and Methods for Multilingual Image Question Answering by Haoyuan Gao, Junhua Mao, Jie Zhou, Zhiheng Huang, Lei Wang, Wei Xu.\nArtificial Neural Networks Applied to Taxi Destination Prediction by Alexandre de Brébisson, Étienne Simon, Alex Auvolat, Pascal Vincent, Yoshua Bengio.\nAsk, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering by Huijuan Xu, Kate Saenko.\nAsk Me Anything: Dynamic Memory Networks for Natural Language Processing by Ankit Kumar, Ozan Irsoy, Jonathan Su, James Bradbury, Robert English, Brian Pierce, Peter Ondruska, Ishaan Gulrajani, Richard Socher.\nAsk Me Anything: Free-form Visual Question Answering Based on Knowledge from External Sources by Qi Wu, Peng Wang, Chunhua Shen, Anton van den Hengel, Anthony Dick.\nAsk Your Neurons: A Neural-based Approach to Answering Questions about Images by Mateusz Malinowski, Marcus Rohrbach, Mario Fritz.\nAssociative Long Short-Term Memory by Ivo Danihelka, Greg Wayne, Benigno Uria, Nal Kalchbrenner, Alex Graves.\nAttentionNet: Aggregating Weak Directions for Accurate Object Detection by Donggeun Yoo, Sunggyun Park, Joon-Young Lee, Anthony Paek, In So Kweon.\nAttention-Based Models for Speech Recognition by Jan Chorowski, Dzmitry Bahdanau, Dmitriy Serdyuk, Kyunghyun Cho, Yoshua Bengio.\nAttention to Scale: Scale-aware Semantic Image Segmentation by Liang-Chieh Chen, Yi Yang, Jiang Wang, Wei Xu, Alan L. Yuille.\nAttention with Intention for a Neural Network Conversation Model by Kaisheng Yao, Geoffrey Zweig, Baolin Peng.\nAtomNet: A Deep Convolutional Neural Network for Bioactivity Prediction in Structure-based Drug Discovery by Izhar Wallach, Michael Dzamba, Abraham Heifets.\nBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift by Sergey Ioffe and Christian Szegedy.\nBatch Normalized Recurrent Neural Networks by César Laurent, Gabriel Pereyra, Philémon Brakel, Ying Zhang, Yoshua Bengio.\nBayesian SegNet: Model Uncertainty in Deep Convolutional Encoder-Decoder Architectures for Scene Understanding by Alex Kendall, Vijay Badrinarayanan, Roberto Cipolla.\nBetter Computer Go Player with Neural Network and Long-term Prediction by Yuandong Tian, Yan Zhu.\nBetter Exploiting OS-CNNs for Better Event Recognition in Images by Limin Wang, Zhe Wang, Sheng Guo, Yu Qiao.\nBenchmarking of LSTM Networks by Thomas M. Breuel.\nBeyond Short Snipets: Deep Networks for Video Classification by Joe Yue-Hei Ng, Matthew Hausknecht, Sudheendra Vijayanarasimhan, Oriol Vinyals, Rajat Monga, George Toderici.\nBeyond Temporal Pooling: Recurrence and Temporal Convolutions for Gesture Recognition in Video by Lionel Pigou, Aäron van den Oord, Sander Dieleman, Mieke Van Herreweghe, Joni Dambre.\nBinarized Neural Networks by Itay Hubara, Daniel Soudry, Ran El Yaniv.\nBinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1 by Matthieu Courbariaux, Yoshua Bengio.\nBinding via Reconstruction Clustering by Klaus Greff, Rupesh Kumar Srivastava, Jürgen Schmidhuber.\nBottom-up and top-down reasoning with convolutional latent-variable models by Peiyun Hu, Deva Ramanan.\nBrain4Cars: Car That Knows Before You Do via Sensory-Fusion Deep Learning Architecture by Ashesh Jain, Hema S Koppula, Shane Soh, Bharad Raghavan, Avi Singh, Ashutosh Saxena.\nBrain-Inspired Deep Networks for Image Aesthetics Assessment by Zhangyang Wang, Florin Dolcos, Diane Beck, Shiyu Chang, Thomas S. Huang.\nCharacter-level Convolutional Networks for Text Classification by Xiang Zhang, Junbo Zhao, Yann LeCun.\nCompositional Memory for Visual Question Answering by Aiwen Jiang, Fang Wang, Fatih Porikli, Yi Li.\nCompressing Convolutional Neural Networks by Wenlin Chen, James T. Wilson, Stephen Tyree, Kilian Q. Weinberger, Yixin Chen.\nCompressing LSTMs into CNNs by Krzysztof J. Geras, Abdel-rahman Mohamed, Rich Caruana, Gregor Urban, Shengjie Wang, Ozlem Aslan, Matthai Philipose, Matthew Richardson, Charles Sutton.\nCompression of Deep Neural Networks on the Fly by Guillaume Soulié, Vincent Gripon, Maëlys Robert.\nConfusing Deep Convolution Networks by Relabelling by Leigh Robinson, Benjamin Graham.\nConstrained Convolutional Neural Networks for Weakly Supervised Segmentation by Deepak Pathak, Philipp Krähenbühl, Trevor Darrell.\nContinuous control with deep reinforcement learning by Timothy P. Lillicrap, Jonathan J. Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, Daan Wierstra.\nConvergent Learning: Do different neural networks learn the same representations? by Yixuan Li, Jason Yosinski, Jeff Clune, Hod Lipson, John Hopcroft.\nConvolutional Clustering for Unsupervised Learning by Aysegul Dundar, Jonghoon Jin, Eugenio Culurciello.\nConvolutional Color Constancy by Jonathan T. Barron.\nConvolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting by Xingjian Shi, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, Wang-chun Woo.\nConvolutional Pose Machines by Shih-En Wei, Varun Ramakrishna, Takeo Kanade, Yaser Sheikh.\nDAG-Recurrent Neural Networks For Scene Labeling by Bing Shuai, Zhen Zuo, Gang Wang, Bing Wang.\nData-dependent Initializations of Convolutional Neural Networks by Philipp Krähenbühl, Carl Doersch, Jeff Donahue, Trevor Darrell.\nData-free parameter pruning for Deep Neural Networks by Suraj Srinivas, R. Venkatesh Babu.\nDecoupled Deep Neural Network for Semi-supervised Semantic Segmentation by Seunghoon Hong, Hyeonwoo Noh, Bohyung Han.\nDeepBox: Learning Objectness with Convolutional Networks by Weicheng Kuo, Bharath Hariharan, Jitendra Malik.\nDeepFont: Identify Your Font from An Image by Zhangyang Wang, Jianchao Yang, Hailin Jin, Eli Shechtman, Aseem Agarwala, Jonathan Brandt, Thomas S. Huang.\nDeepFool: a simple and accurate method to fool deep neural networks by Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Pascal Frossard.\nDeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection by Wanli Ouyang, Xiaogang Wang, Xingyu Zeng, Shi Qiu, Ping Luo, Yonglong Tian, Hongsheng Li, Shuo Yang, Zhe Wang, Chen-Change Loy, Xiaoou Tang.\nDeepLogo: Hitting Logo Recognition with the Deep Neural Network Hammer by Forrest N. Iandola, Anting Shen, Peter Gao, Kurt Keutzer.\nDeepProposal: Hunting Objects by Cascading Deep Convolutional Layers by Amir Ghodrati, Ali Diba, Marco Pedersoli, Tinne Tuytelaars, Luc Van Gool.\nDeepSaliency: Multi-Task Deep Neural Network Model for Salient Object Detection by Xi Li, Liming Zhao, Lina Wei, MingHsuan Yang, Fei Wu, Yueting Zhuang, Haibin Ling, Jingdong Wang.\nDeep Attention Recurrent Q-Network by Ivan Sorokin, Alexey Seleznev, Mikhail Pavlov, Aleksandr Fedorov, Anastasiia Ignateva.\nDeep Captioning with Multimodal Recurrent Neural Networks (m-RNN) by Junhua Mao, Wei Xu, Yi Yang, Jiang Wang, Zhiheng Huang, Alan Yuille.\nDeep Compositional Question Answering with Neural Module Networks by Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Dan Klein.\nDeep clustering: Discriminative embeddings for segmentation and separation by John R. Hershey, Zhuo Chen, Jonathan Le Roux, Shinji Watanabe.\nDeep CNN Ensemble with Data Augmentation for Object Detection by Jian Guo, Stephen Gould.\nDeep Compositional Captioning: Describing Novel Object Categories without Paired Training Data by Lisa Anne Hendricks, Subhashini Venugopalan, Marcus Rohrbach, Raymond Mooney, Kate Saenko, Trevor Darrell.\nDeep Convolutional Matching by Jerome Revaud, Philippe Weinzaepfel, Zaid Harchaoui, Cordelia Schmid.\nDeep Convolutional Networks are Hierarchical Kernel Machines by Fabio Anselmi, Lorenzo Rosasco, Cheston Tan, Tomaso Poggio.\nDeep Convolutional Networks on Graph-Structured Data by Mikael Henaff, Joan Bruna, Yann LeCun.\nDeep Fishing: Gradient Features from Deep Nets by Albert Gordo, Adrien Gaidon, Florent Perronnin.\nDeep Generative Image Models using a Laplacian Pyramid of Adversarial Networks by Emily Denton, Soumith Chintala, Arthur Szlam, Rob Fergus.\nDeep Kernel Learning by Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, Eric P. Xing.\nDeep Knowledge Tracing by Chris Piech, Jonathan Spencer, Jonathan Huang, Surya Ganguli, Mehran Sahami, Leonidas Guibas, Jascha Sohl-Dickstein.\nDeep Learning Face Attributes in the Wild by Ziwei Liu, Ping Luo, Xiaogang Wang, Xiaoou Tang.\nDeep Learning with S-shaped Rectified Linear Activation Units by Xiaojie Jin, Chunyan Xu, Jiashi Feng, Yunchao Wei, Junjun Xiong, Shuicheng Yan.\nDeep multi-scale video prediction beyond mean square error by Michael Mathieu, Camille Couprie, Yann LeCun.\nDeep Networks Resemble Human Feed-forward Vision in Invariant Object Recognition by Saeed Reza Kheradpisheh, Masoud Ghodrati, Mohammad Ganjtabesh, Timothée Masquelier.\nDeep Networks with Internal Selective Attention through Feedback Connections by Marijn Stollenga, Jonathan Masci, Faustino Gomez, Jürgen Schmidhuber.\nDeep Neural Networks predict Hierarchical Spatio-temporal Cortical Dynamics of Human Visual Object Recognition by Radoslaw M. Cichy, Aditya Khosla, Dimitrios Pantazis, Antonio Torralba, Aude Oliva.\nDeep Recurrent Q-Learning for Partially Observable MDPs by Matthew Hausknecht, Peter Stone.\nDeep Residual Learning for Image Recognition by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.\nDeeply-Recursive Convolutional Network for Image Super-Resolution.pdf by Jiwon Kim, Jung Kwon Lee, Kyoung Mu Lee.\nDeep Reinforcement Learning in Parameterized Action Space by Matthew Hausknecht, Peter Stone.\nDeep Reinforcement Learning with an Unbounded Action Space by Ji He, Jianshu Chen, Xiaodong He, Jianfeng Gao, Lihong Li, Li Deng, Mari Ostendorf.\nDeep Reinforcement Learning with Double Q-learning by Hado van Hasselt, Arthur Guez, David Silver.\nDeep Sliding Shapes for Amodal 3D Object Detection in RGB-D Images by Shuran Song, Jianxiong Xiao.\nDeep SimNets by Nadav Cohen, Or Sharir, Amnon Shashua.\nDeep Speech: Scaling up end-to-end speech recognition by Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich Elsen, Ryan Prenger, Sanjeev Satheesh, Shubho Sengupta, Adam Coates, Andrew Y. Ng.\nDeep Tracking: Seeing Beyond Seeing Using Recurrent Neural Networks by Peter Ondruska, Ingmar Posner.\nDeep Visual-Semantic Alignments for Generating Image Descriptions by Andrej Karpathy, Fei-Fei Li.\nDeeply Improved Sparse Coding for Image Super-Resolution by Zhaowen Wang, Ding Liu, Jianchao Yang, Wei Han, Thomas Huang.\nDeePM: A Deep Part-Based Model for Object Detection and Semantic Part Localization by Jun Zhu, Xianjie Chen, Alan L. Yuille.\nDelving Deeper into Convolutional Networks for Learning Video Representations by Nicolas Ballas, Li Yao, Chris Pal, Aaron Courville.\nDenoising Criterion for Variational Auto-Encoding Framework by Daniel Jiwoong Im, Sungjin Ahn, Roland Memisevic, Yoshua Bengio.\nDenseCap: Fully Convolutional Localization Networks for Dense Captioning by Justin Johnson, Andrej Karpathy, Li Fei-Fei.\nDenseBox: Unifying Landmark Localization with End to End Object Detection by Lichao Huang, Yi Yang, Yafeng Deng, Yinan Yu.\nDescribing Multimedia Content using Attention-based Encoder–Decoder Networks by Kyunghyun Cho, Aaron Courville, Yoshua Bengio.\nDescribing Videos by Exploiting Temporal Structure by Li Yao, Atousa Torabi, Kyunghyun Cho, Nicolas Ballas, Christopher Pal, Hugo Larochelle, Aaron Courville.\nDetecting Interrogative Utterances with Recurrent Neural Networks by Junyoung Chung, Jacob Devlin, Hany Hassan Awadalla.\nDictionary Learning and Sparse Coding for Third-order Super-symmetric Tensors by Piotr Koniusz, Anoop Cherian.\nDigging Deep into the layers of CNNs: In Search of How CNNs Achieve View Invariance by Amr Bakry, Mohamed Elhoseiny, Tarek El-Gaaly, Ahmed Elgammal.\nDiscriminative Unsupervised Feature Learning with Exemplar Convolutional Neural Networks by Alexey Dosovitskiy, Philipp Fischer, Jost Tobias Springenberg, Martin Riedmiller, Thomas Brox.\nDistributed Deep Q-Learning by Hao Yi Ong, Kevin Chavez, Augustus Hong.\nDo Deep Neural Networks Learn Facial Action Units When Doing Expression Recognition? by Pooya Khorrami, Tom Le Paine, Thomas S. Huang.\nDRAW: A Recurrent Neural Network For Image Generation by Karol Gregor, Ivo Danihelka, Alex Graves, Daan Wierstra.\nDropout: A Simple Way to Prevent Neural Networks from Overfitting by Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov.\nEIE: Efficient Inference Engine on Compressed Deep Neural Network by Song Han, Xingyu Liu, Huizi Mao, Jing Pu, Ardavan Pedram, Mark A. Horowitz, William J. Dally.\nEmpirical performance upper bounds for image and video captioning by Li Yao, Nicolas Ballas, Kyunghyun Cho, John R. Smith, Yoshua Bengio.\nEnd-to-End Attention-based Large Vocabulary Speech Recognition by Dzmitry Bahdanau, Jan Chorowski, Dmitriy Serdyuk, Philemon Brakel, Yoshua Bengio.\nEnd-to-end Learning of Action Detection from Frame Glimpses in Videos by Serena Yeung, Olga Russakovsky, Greg Mori, Li Fei-Fei.\nEnd-To-End Memory Networks by Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus.\nEnd-to-end people detection in crowded scenes by Russell Stewart, Mykhaylo Andriluka.\nEvaluating the visualization of what a Deep Neural Network has learned by Wojciech Samek, Alexander Binder, Grégoire Montavon, Sebastian Bach, Klaus-Robert Müller.\nExploring the Limits of Language Modeling by Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, Yonghui Wu.\nFaceNet: A Unified Embedding for Face Recognition and Clustering by Florian Schroff, Dmitry Kalenichenko, James Philbin.\nFactors in Finetuning Deep Model for object detection by Wanli Ouyang, Xiaogang Wang, Cong Zhang, Xiaokang Yang.\nFast Algorithms for Convolutional Neural Networks by Andrew Lavin.\nFast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) by Djork-Arné Clevert, Thomas Unterthiner, Sepp Hochreiter.\nFast-Classifying, High-Accuracy Spiking Deep Networks Through Weight and Threshold Balancing by Peter U. Diehl, Daniel Neil, Jonathan Binas, Matthew Cook, Shih-Chii Liu, and Michael Pfeiffer.\nFast and Accurate Recurrent Neural Network Acoustic Models for Speech Recognition by Haşim Sak, Andrew Senior, Kanishka Rao, Françoise Beaufays.\nFaster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks by Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun.\nFeature-based Attention in Convolutional Neural Networks by Grace W. Lindsay.\nFeed-Forward Networks with Attention Can Solve Some Long-Term Memory Problems by Colin Raffel, Daniel P. W. Ellis.\nFireCaffe: near-linear acceleration of deep neural network training on compute clusters by Forrest N. Iandola, Khalid Ashraf, Mattthew W. Moskewicz, Kurt Keutzer.\nFirst Step toward Model-Free, Anonymous Object Tracking with Recurrent Neural Networks by Quan Gan, Qipeng Guo, Zheng Zhang, Kyunghyun Cho.\nFitNets: Hints for Thin Deep Nets by Adriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta, Yoshua Bengio.\nFlowNet: Learning Optical Flow with Convolutional Networks by Philipp Fischer, Alexey Dosovitskiy, Eddy Ilg, Philip Häusser, Caner Hazırbaş, Vladimir Golkov, Patrick van der Smagt, Daniel Cremers, Thomas Brox.\nFrom Facial Parts Responses to Face Detection: A Deep Learning Approach by Shuo Yang, Ping Luo, Chen Change Loy, Xiaoou Tang.\nFusing Multi-Stream Deep Networks for Video Classification by Zuxuan Wu, Yu-Gang Jiang, Xi Wang, Hao Ye, Xiangyang Xue, Jun Wang.\nGenerating Images from Captions with Attention by Elman Mansimov, Emilio Parisotto, Jimmy Lei Ba, Ruslan Salakhutdinov.\nGenerating Text with Deep Reinforcement Learning by Hongyu Guo.\nGenerative Image Modeling Using Spatial LSTMs by Lucas Theis, Matthias Bethge.\nGenerating News Headlines with Recurrent Neural Networks by Konstantin Lopyrev.\nGeometry-aware Deep Transform by Jiaji Huang, Qiang Qiu, Robert Calderbank, Guillermo Sapiro.\nGradual DropIn of Layers to Train Very Deep Neural Networks by Leslie N. Smith, Emily M. Hand, Timothy Doster.\nGrid Long Short-Term Memory by Nal Kalchbrenner, Ivo Danihelka, Alex Graves.\nGuiding Long-Short Term Memory for Image Caption Generation by Xu Jia, Efstratios Gavves, Basura Fernando, Tinne Tuytelaars.\nHarvesting Discriminative Meta Objects with Deep CNN Features for Scene Classification by Ruobing Wu, Baoyuan Wang, Wenping Wang, Yizhou Yu.\nHierarchical Recurrent Neural Encoder for Video Representation with Application to Captioning by Pingbo Pan, Zhongwen Xu, Yi Yang, Fei Wu, Yueting Zhuang.\nHighway Networks by Rupesh Kumar Srivastava, Klaus Greff, Jürgen Schmidhuber.\nHow far can we go without convolution: Improving fully-connected networks by Zhouhan Lin, Roland Memisevic, Kishore Konda.\nHow Important is Weight Symmetry in Backpropagation? by Qianli Liao, Joel Z. Leibo, Tomaso Poggio.\nHuman Action Recognition using Factorized Spatio-Temporal Convolutional Networks by Lin Sun, Kui Jia, Dit-Yan Yeung, Bertram E. Shi.\nHuman-level control through deep reinforcement learning by Google DeepMind.\nImageNet Classification with Deep Convolutional Neural Networks by Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton.\nImage Captioning with an Intermediate Attributes Layer by Qi Wu, Chunhua Shen, Anton van den Hengel, Lingqiao Liu, Anthony Dick.\nImage Reconstruction from Bag-of-Visual-Words by Hiroharu Kato, Tatsuya Harada.\nImage Representations and New Domains in Neural Image Captioning by Jack Hessel, Nicolas Savva, Michael J. Wilber.\nImage Super-Resolution Using Deep Convolutional Networks by Chao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang.\nImage Question Answering: A Visual Semantic Embedding Model and a New Dataset by Mengye Ren, Ryan Kiros, Richard Zemel.\nImage Question Answering using Convolutional Neural Network with Dynamic Parameter Prediction by Hyeonwoo Noh, Paul Hongsuck Seo, Bohyung Han.\nImportance Weighted Autoencoders by Yuri Burda, Roger Grosse, Ruslan Salakhutdinov.\nIndexing of CNN Features for Large Scale Image Search by Ruoyu Liu, Yao Zhao, Shikui Wei, Zhenfeng Zhu, Lixin Liao, Shuang Qiu.\nInverting Convolutional Networks with Convolutional Networks by Alexey Dosovitskiy, Thomas Brox.\nIs Image Super-resolution Helpful for Other Vision Tasks? by Dengxin Dai, Yujian Wang, Yuhua Chen, Luc Van Gool.\nIs L2 a Good Loss Function for Neural Networks for Image Processing? by Hang Zhao, Orazio Gallo, Iuri Frosio, Jan Kautz.\nJoint Calibration for Semantic Segmentation by Holger Caesar, Jasper Uijlings, Vittorio Ferrari.\nLarge-scale Simple Question Answering with Memory Networks by Antoine Bordes, Nicolas Usunier, Sumit Chopra, Jason Weston.\nLarge Margin Deep Neural Networks: Theory and Algorithms by Shizhao Sun, Wei Chen, Liwei Wang, Tie-Yan Liu.\nLearning Contextual Dependencies with Convolutional Hierarchical Recurrent Neural Networks by Zhen Zuo, Bing Shuai, Gang Wang, Xiao Liu, Xingxing Wang, Bing Wang.\nLearning Deconvolution Network for Semantic Segmentation by Hyeonwoo Noh, Seunghoon Hong, Bohyung Han.\nLearning Fine-grained Features via a CNN Tree for Large-scale Classification by Zhenhua Wang, Xingxing Wang, Gang Wang.\nLearning like a Child: Fast Novel Visual Concept Learning from Sentence Descriptions of Images by Junhua Mao, Wei Xu, Yi Yang, Jiang Wang, Zhiheng Huang, Alan Yuille.\nLearning from LDA using Deep Neural Networks by Dongxu Zhang, Tianyi Luo, Dong Wang, Rong Liu.\nLearning Multiple Tasks with Deep Relationship Networks by Mingsheng Long, Jianmin Wang.\nLearning scale-variant and scale-invariant features for deep image classification by Nanne van Noord, Eric Postma.\nLearning Spatiotemporal Features with 3D Convolutional Networks by Du Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani, Manohar Paluri.\nLearning to Communicate to Solve Riddles with Deep Distributed Recurrent Q-Networks by Jakob N. Foerster, Yannis M. Assael, Nando de Freitas, Shimon Whiteson.\nLearning to Compose Neural Networks for Question Answering by Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Dan Klein.\nLearning to Linearize Under Uncertainty by Ross Goroshin, Michael Mathieu, Yann LeCun.\nLearning to See by Moving by Pulkit Agrawal, Joao Carreira, Jitendra Malik.\nLearning to Segment Object Candidates by Pedro O. Pinheiro, Ronan Collobert, Piotr Dollar.\nLearning to track for spatio-temporal action localization by Philippe Weinzaepfel, Zaid Harchaoui, Cordelia Schmid.\nLearning Transferable Features with Deep Adaptation Networks by Mingsheng Long, Yue Cao, Jianmin Wang, Michael I. Jordan.\nLearning Wake-Sleep Recurrent Attention Models by Jimmy Ba, Roger Grosse, Ruslan Salakhutdinov, Brendan Frey.\nLearning Visual Features from Large Weakly Supervised Data by Armand Joulin, Laurens van der Maaten, Allan Jabri, Nicolas Vasilache.\nLeveraging Context to Support Automated Food Recognition in Restaurants by Vinay Bettadapura, Edison Thomaz, Aman Parnami, Gregory Abowd, Irfan Essa.\nLipreading with Long Short-Term Memory by Michael Wand, Jan Koutník, Jürgen Schmidhuber.\nListen, Attend and Spell by William Chan, Navdeep Jaitly, Quoc V. Le, Oriol Vinyals.\nListen, Attend, and Walk: Neural Mapping of Navigational Instructions to Action Sequences by Hongyuan Mei, Mohit Bansal, Matthew R. Walter.\nLLNet: A Deep Autoencoder Approach to Natural Low-light Image Enhancement by Kin Gwn Lore, Adedotun Akintayo, Soumik Sarkar.\nLocally-Supervised Deep Hybrid Model for Scene Recognition by Sheng Guo, Weilin Huang, Yu Qiao.\nLocNet: Improving Localization Accuracy for Object Detection by Spyros Gidaris, Nikos Komodakis.\nLOGO-Net: Large-scale Deep Logo Detection and Brand Recognition with Deep Region-based Convolutional Networks by Steven C.H. Hoi, Xiongwei Wu, Hantang Liu, Yue Wu, Huiqiong Wang, Hui Xue, Qiang Wu.\nLong Short-Term Memory-Networks for Machine Reading by Jianpeng Cheng, Li Dong, Mirella Lapata.\nLong-term Recurrent Convolutional Networks for Visual Recognition and Description by Jeff Donahue, Lisa Anne Hendricks, Sergio Guadarrama, Marcus Rohrbach, Subhashini Venugopalan, Kate Saenko, Trevor Darrell.\nLove Thy Neighbors: Image Annotation by Exploiting Image Metadata by Justin Johnson, Lamberto Ballan, Fei-Fei Li.\nMADE: Masked Autoencoder for Distribution Estimation by Mathieu Germain, Karol Gregor, Iain Murray, Hugo Larochelle.\nManitest: Are classifiers really invariant? by Alhussein Fawzi, Pascal Frossard.\nMaxout Networks by Ian J. Goodfellow, David Warde-Farley, Mehdi Mirza, Aaron Courville, Yoshua Bengio.\nModelling Uncertainty in Deep Learning for Camera Relocalization by Alex Kendall, Roberto Cipolla.\nMultiagent Cooperation and Competition with Deep Reinforcement Learning by Ardi Tampuu, Tambet Matiisen, Dorian Kodelja, Ilya Kuzovkin, Kristjan Korjus, Juhan Aru, Jaan Aru, Raul Vicente.\nMulti-Instance Visual-Semantic Embedding by Zhou Ren, Hailin Jin, Zhe Lin, Chen Fang, Alan Yuille.\nMulti-task Sequence to Sequence Learning by Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, Lukasz Kaiser.\nMulti-view Machines by Bokai Cao, Hucheng Zhou, Philip S. Yu.\nMultimodal Deep Learning for Robust RGB-D Object Recognition by Andreas Eitel, Jost Tobias Springenberg, Luciano Spinello, Martin Riedmiller, Wolfram Burgard.\nMuProp: Unbiased Backpropagation for Stochastic Neural Networks by Shixiang Gu, Sergey Levine, Ilya Sutskever, Andriy Mnih.\nNamed Entity Recognition with Bidirectional LSTM-CNNs by Jason P.C. Chiu, Eric Nichols.\nNatural Neural Networks by Guillaume Desjardins, Karen Simonyan, Razvan Pascanu, Koray Kavukcuoglu.\nNeighborhood Watch: Stochastic Gradient Descent with Neighbors by Thomas Hofmann, Aurelien Lucchi, Brian McWilliams.\nNet2Net: Accelerating Learning via Knowledge Transfer by Tianqi Chen, Ian Goodfellow, Jonathon Shlens.\nNeural GPUs Learn Algorithms by Łukasz Kaiser, Ilya Sutskever.\nNeural Random-Access Machines by Karol Kurach, Marcin Andrychowicz, Ilya Sutskever.\nOn Learning to Think: Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models by Juergen Schmidhuber.\nOn the Convergence of SGD Training of Neural Networks by Thomas M. Breuel.\nOn the Expressive Power of Deep Learning: A Tensor Analysis by Nadav Cohen, Or Sharir, Amnon Shashua.\nOnline Batch Selection for Faster Training of Neural Networks by Ilya Loshchilov, Frank Hutter.\nParallel Multi-Dimensional LSTM, With Application to Fast Biomedical Volumetric Image Segmentation by Marijn F. Stollenga, Wonmin Byeon, Marcus Liwicki, Juergen Schmidhuber.\nPath-SGD: Path-Normalized Optimization in Deep Neural Networks by Behnam Neyshabur, Ruslan Salakhutdinov, Nathan Srebro.\nPerson Recognition in Personal Photo Collections by Seong Joon Oh, Rodrigo Benenson, Mario Fritz, Bernt Schiele.\nPixel Recurrent Neural Networks by Aaron van den Oord, Nal Kalchbrenner, Koray Kavukcuoglu.\nPoker-CNN: A Pattern Learning Strategy for Making Draws and Bets in Poker Games by Nikolai Yakovenko, Liangliang Cao, Colin Raffel, James Fan.\nPredicting Deep Zero-Shot Convolutional Neural Networks using Textual Descriptions by Jimmy Ba, Kevin Swersky, Sanja Fidler, Ruslan Salakhutdinov.\nProbabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks by José Miguel Hernández-Lobato, Ryan P. Adams.\nProposal-free Network for Instance-level Object Segmentation by Xiaodan Liang, Yunchao Wei, Xiaohui Shen, Jianchao Yang, Liang Lin, Shuicheng Yan.\nP-CNN: Pose-based CNN Features for Action Recognition by Guilhem Chéron, Ivan Laptev, Cordelia Schmid.\nR-CNN minus R by Karel Lenc, Andrea Vedaldi.\nRAID: A Relation-Augmented Image Descriptor by Paul Guerrero, Niloy J. Mitra, Peter Wonka.\nRATM: Recurrent Attentive Tracking Model by Samira Ebrahimi Kahou, Vincent Michalski, Roland Memisevic.\nRandom Maxout Features by Youssef Mroueh, Steven Rennie, Vaibhava Goel.\nRecurrent Instance Segmentation by Bernardino Romera-Paredes, Philip H. S. Torr.\nRecurrent Models of Visual Attention by Volodymyr Mnih, Nicolas Heess, Alex Graves, Koray Kavukcuoglu.\nRecurrent Network Models for Kinematic Tracking by Katerina Fragkiadaki, Sergey Levine, Jitendra Malik.\nRecurrent Neural Networks for Driver Activity Anticipation via Sensory-Fusion Architecture by Ashesh Jain, Avi Singh, Hema S Koppula, Shane Soh, Ashutosh Saxena.\nRecurrent Reinforcement Learning: A Hybrid Approach by Xiujun Li, Lihong Li, Jianfeng Gao, Xiaodong He, Jianshu Chen, Li Deng, Ji He.\nRecursive Training of 2D-3D Convolutional Networks for Neuronal Boundary Detection by Kisuk Lee, Aleksandar Zlateski, Ashwin Vishwanathan, H. Sebastian Seung.\nRender for CNN: Viewpoint Estimation in Images Using CNNs Trained with Rendered 3D Model Views by Hao Su, Charles R. Qi, Yangyan Li, Leonidas Guibas.\nReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks by Francesco Visin, Kyle Kastner, Kyunghyun Cho, Matteo Matteucci, Aaron Courville, Yoshua Bengio.\nReSeg: A Recurrent Neural Network for Object Segmentation by Francesco Visin, Kyle Kastner, Aaron Courville, Yoshua Bengio, Matteo Matteucci, Kyunghyun Cho.\nReuse of Neural Modules for General Video Game Playing by Alexander Braylan, Mark Hollenbeck, Elliot Meyerson, Risto Miikkulainen.\nRich feature hierarchies for accurate object detection and semantic segmentation by Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik.\nScaling Up Natural Gradient by Sparsely Factorizing the Inverse Fisher Matrix by Roger B. Grosse, Ruslan Salakhutdinov.\nSceneNet: Understanding Real World Indoor Scenes With Synthetic Data by Ankur Handa, Viorica Patraucean, Vijay Badrinarayanan, Simon Stent, Roberto Cipolla.\nScheduled Sampling for Sequence Prediction with Recurrent Neural Networks by Samy Bengio, Oriol Vinyals, Navdeep Jaitly, Noam Shazeer.\nSearch-Convolutional Neural Networks by James Atwood, Don Towsley.\nSearching for Higgs Boson Decay Modes with Deep Learning by Peter Sadowski, Pierre Baldi, Daniel Whiteson.\nSegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation by Vijay Badrinarayanan, Alex Kendall, Roberto Cipolla.\nSegNet: A Deep Convolutional Encoder-Decoder Architecture for Robust Semantic Pixel-Wise Labelling by Vijay Badrinarayanan, Ankur Handa, Roberto Cipolla.\nSemantic Image Segmentation via Deep Parsing Network by Ziwei Liu, Xiaoxiao Li, Ping Luo, Chen Change Loy, Xiaoou Tang.\nSemi-supervised Sequence Learning by Andrew M. Dai, Quoc V. Le.\nSentiCap: Generating Image Descriptions with Sentiments by Alexander Mathews, Lexing Xie, Xuming He.\nShow and Tell: A Neural Image Caption Generator by Oriol Vinyals, Alexander Toshev, Samy Bengio, Dumitru Erhan.\nShow, Attend and Tell: Neural Image Caption Generation with Visual Attention by Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard Zemel, Yoshua Bengio.\nSimple Baseline for Visual Question Answering by Bolei Zhou, Yuandong Tian, Sainbayar Sukhbaatar, Arthur Szlam, Rob Fergus.\nSkip-Thought Vectors by Ryan Kiros, Yukun Zhu, Ruslan Salakhutdinov, Richard S. Zemel, Antonio Torralba, Raquel Urtasun, Sanja Fidler.\nSparsifying Neural Network Connections for Face Recognition by Yi Sun, Xiaogang Wang, Xiaoou Tang.\nSpatial Semantic Regularisation for Large Scale Object Detection by Damian Mrowca, Marcus Rohrbach, Judy Hoffman, Ronghang Hu, Kate Saenko, Trevor Darrell.\nSpatial Transformer Networks by Max Jaderberg, Karen Simonyan, Andrew Zisserman, Koray Kavukcuoglu.\nSpiking Deep Networks with LIF Neurons by Eric Hunsberger, Chris Eliasmith.\nStacked Attention Networks for Image Question Answering by Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Smola.\nStacked What-Where Auto-encoders by Junbo Zhao, Michael Mathieu, Ross Goroshin, Yann Lecun.\nSTC: A Simple to Complex Framework for Weakly-supervised Semantic Segmentation by Yunchao Wei, Xiaodan Liang, Yunpeng Chen, Xiaohui Shen, Ming-Ming Cheng, Yao Zhao, Shuicheng Yan.\nStochastic Gradient Made Stable: A Manifold Propagation Approach for Large-Scale Optimization by Yadong Mu, Wei Liu, Wei Fan.\nStochasticNet: Forming Deep Neural Networks via Stochastic Connectivity by Mohammad Javad Shafiee, Parthipan Siva, Alexander Wong.\nStudying Very Low Resolution Recognition Using Deep Networks by Zhangyang Wang, Shiyu Chang, Yingzhen Yang, Ding Liu, Thomas S. Huang.\nSuper-Resolution with Deep Convolutional Sufficient Statistics by Joan Bruna, Pablo Sprechmann, Yann LeCun.\nSuperpixel Convolutional Networks using Bilateral Inceptions by Raghudeep Gadde, Varun Jampani, Martin Kiefel, Peter V. Gehler.\nStructured Depth Prediction in Challenging Monocular Video Sequences by Miaomiao Liu, Mathieu Salzmann, Xuming He.\nStructured Memory for Neural Turing Machines by Wei Zhang, Yang Yu.\nSymmetry-invariant optimization in deep networks by Vijay Badrinarayanan, Bamdev Mishra, Roberto Cipolla.\nTask Loss Estimation for Sequence Prediction by Dzmitry Bahdanau, Dmitriy Serdyuk, Philémon Brakel, Nan Rosemary Ke, Jan Chorowski, Aaron Courville, Yoshua Bengio.\nTeaching Machines to Read and Comprehend by Karl Moritz Hermann, Tomáš Kočiský, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, Phil Blunsom.\nText-Attentional Convolutional Neural Networks for Scene Text Detection by Tong He, Weilin Huang, Yu Qiao, Jian Yao.\nThe Effects of Hyperparameters on SGD Training of Neural Networks by Thomas M. Breuel.\nThe Unreasonable Effectiveness of Recurrent Neural Networks by Andrej Karpathy.\nTowards Automatic Image Editing: Learning to See another You by Amir Ghodrati, Xu Jia, Marco Pedersoli, Tinne Tuytelaars.\nTowards Biologically Plausible Deep Learning by Yoshua Bengio, Dong-Hyun Lee, Jorg Bornschein, Zhouhan Lin.\nTowards Good Practices for Very Deep Two-Stream ConvNets by Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao.\nTowards universal neural nets: Gibbs machines and ACE by Galin Georgiev.\nTowards Vision-Based Deep Reinforcement Learning for Robotic Motion Control by Fangyi Zhang, Juergen Leitner, Michael Milford, Ben Upcroft, Peter Corke.\nTrain faster, generalize better: Stability of stochastic gradient descent by Moritz Hardt, Benjamin Recht, Yoram Singer.\nTraining a Convolutional Neural Network for Appearance-Invariant Place Recognition by Ruben Gomez-Ojeda, Manuel Lopez-Antequera, Nicolai Petkov, Javier Gonzalez-Jimenez.\nTraining Deep Networks with Structured Layers by Matrix Backpropagation by Catalin Ionescu, Orestis Vantzos, Cristian Sminchisescu.\nTraining Deeper Convolutional Networks with Deep Supervision by Liwei Wang, Chen-Yu Lee, Zhuowen Tu, Svetlana Lazebnik.\nTrainable performance upper bounds for image and video captioning by Li Yao, Nicolas Ballas, Kyunghyun Cho, John R. Smith, Yoshua Bengio.\nTraining Very Deep Networks by Rupesh Kumar Srivastava, Klaus Greff, Jürgen Schmidhuber.\nTransfer Learning from Deep Features for Remote Sensing and Poverty Mapping by Michael Xie, Neal Jean, Marshall Burke, David Lobell, Stefano Ermon.\nTranslating Videos to Natural Language Using Deep Recurrent Neural Networks by Subhashini Venugopalan, Huijuan Xu, Jeff Donahue, Marcus Rohrbach, Raymond Mooney, Kate Saenko.\nUnconstrained Face Verification using Deep CNN Features by Jun-Cheng Chen, Vishal M. Patel, Rama Chellappa.\nUn-regularizing: approximate proximal point and faster stochastic algorithms for empirical risk minimization by Roy Frostig, Rong Ge, Sham M. Kakade, Aaron Sidford.\nUnderstanding Locally Competitive Networks by Rupesh Kumar Srivastava, Jonathan Masci, Faustino Gomez, Jürgen Schmidhuber.\nUnderstanding Neural Networks Through Deep Visualization by Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, Hod Lipson.\nUnderstand Scene Categories by Objects: A Semantic Regularized Scene Classifier Using Convolutional Neural Networks by Yiyi Liao, Sarath Kodagoda, Yue Wang, Lei Shi, Yong Liu.\nUnsupervised Extraction of Video Highlights Via Robust Recurrent Auto-encoders by Huan Yang, Baoyuan Wang, Stephen Lin, David Wipf, Minyi Guo, Baining Guo.\nUnsupervised Learning of Video Representations using LSTMs by Nitish Srivastava, Elman Mansimov, Ruslan Salakhutdinov.\nUnsupervised Learning of Visual Representations using Videos by Xiaolong Wang, Abhinav Gupta.\nUnsupervised Semantic Parsing of Video Collections by Ozan Sener, Amir Zamir, Silvio Savarese, Ashutosh Saxena.\nUnsupervised Visual Representation Learning by Context Prediction by Carl Doersch, Abhinav Gupta, Alexei A. Efros.\nUsing Descriptive Video Services to Create a Large Data Source for Video Annotation Research by Atousa Torabi, Christopher Pal, Hugo Larochelle, Aaron Courville.\nVariable Rate Image Compression with Recurrent Neural Networks by George Toderici, Sean M. O’Malley, Sung Jin Hwang, Damien Vincent, David Minnen, Shumeet Baluja, Michele Covell, Rahul Sukthankar.\nVideo Paragraph Captioning using Hierarchical Recurrent Neural Networks by Haonan Yu, Jiang Wang, Zhiheng Huang, Yi Yang, Wei Xu.\nVISALOGY: Answering Visual Analogy Questions by Fereshteh Sadeghi, C. Lawrence Zitnick, Ali Farhadi.\nVisualizing and Understanding Deep Texture Representations by Tsung-Yu Lin, Subhransu Maji.\nVisualizing and Understanding Recurrent Networks by Andrej Karpathy, Justin Johnson, Fei-Fei Li.\nVisualizing Deep Convolutional Neural Networks Using Natural Pre-Images by Aravindh Mahendran, Andrea Vedaldi.\nVisual7W: Grounded Question Answering in Images by Yuke Zhu, Oliver Groth, Michael Bernstein, Li Fei-Fei.\nWatch and Learn: Semi-Supervised Learning of Object Detectors from Videos by Ishan Misra, Abhinav Shrivastava, Martial Hebert.\nWe Are Humor Beings: Understanding and Predicting Visual Humor by Arjun Chandrasekaran, Ashwin K Vijayakumar, Stanislaw Antol, Mohit Bansal, Dhruv Batra, C. Lawrence Zitnick, Devi Parikh.\nWeakly-Supervised Alignment of Video With Text by P. Bojanowski, R. Lagugie, Edouard Grave, Francis Bach, I. Laptev, J. Ponce, C. Schmid.\nWeakly Supervised Deep Detection Networks by Hakan Bilen, Andrea Vedaldi.\nWeight Uncertainty in Neural Networks by Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, Daan Wierstra.\nWhat is Holding Back Convnets for Detection? by Bojan Pepik, Rodrigo Benenson, Tobias Ritschel, Bernt Schiele.\nWhat to talk about and how? Selective Generation using LSTMs with Coarse-to-Fine Alignment by Hongyuan Mei, Mohit Bansal, Matthew R. Walter.\nWhat can we learn about CNNs from a large scale controlled object dataset? by Ali Borji, Saeed Izadi, Laurent Itti.\nWhere To Look: Focus Regions for Visual Question Answering by Kevin J. Shih, Saurabh Singh, Derek Hoiem.\nWho’s Behind the Camera? Identifying the Authorship of a Photograph by Christopher Thomas, Adriana Kovashka.\nWhy Regularized Auto-Encoders learn Sparse Representation? by Devansh Arpit, Yingbo Zhou, Hung Ngo, Venu Govindaraju.\nWordRank: Learning Word Embeddings via Robust Ranking by Shihao Ji, Hyokun Yun, Pinar Yanardag, Shin Matsushima, S. V. N. Vishwanathan.\nYou Only Look Once: Unified, Real-Time Object Detection by Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi.\nZero-Shot Learning via Semantic Similarity Embedding by Ziming Zhang, Venkatesh Saligrama.\nZNN - A Fast and Scalable Algorithm for Training 3D Convolutional Networks on Multi-Core and Many-Core Shared Memory Machines by Aleksandar Zlateski, Kisuk Lee, H. Sebastian Seung.\nZoom Better to See Clearer: Huamn Part Segmentation with Auto Zoom Net by Fangting Xia, Peng Wang, Liang-Chieh Chen, Alan L. Yuille.\nPodcast, Talks, etc.(播客，访谈等等)\nTalking Machines hosted by Katherine Gorman and Ryan Adams.\nMachine Learning & Computer Vision Talks by computervisiontalks.\nHow we’re teaching computers to understand pictures by Fei-Fei Li, Stanford University.\nDeep Learning Community\n\n作者：chen_h微信号 & QQ：862251340简书地址：https://www.jianshu.com/p/e98...\nCoderPai 是一个专注于算法实战的平台，从基础的算法到人工智能算法都有设计。如果你对算法实战感兴趣，请快快关注我们吧。加入AI实战微信群，AI实战QQ群，ACM算法微信群，ACM算法QQ群。长按或者扫描如下二维码，关注 “CoderPai” 微信号（coderpai）\n\n\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "1"}