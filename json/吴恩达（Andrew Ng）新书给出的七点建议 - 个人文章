{"title": "吴恩达（Andrew Ng）新书给出的七点建议 - 个人文章 ", "index": "算法,python", "content": "摘要： 本文是阅读吴恩达老师新书后总结出最有用且最有趣的七点建议，对机器学习工程和学习研究人员而言有一定的帮助，\n对于绝大多数的机器学习研究者而言，吴恩达（Andrew Ng）是肯定不陌生的。很多人是通过他讲授的机器学习公开课入门机器学习，NG也一直致力于公共教育事业，是在线教育平台Coursera的联合创始人，推出了很多在线课程及书籍。他同时也是一位机器学习和人工智能领域的大牛，任教于斯坦福大学，早先被百度聘请作为首席科学家，极大的促进了中国人工智能行业的发展，培养了一批批优秀的人工智能研究者。从百度离职之后进行创业——主打项目是人工智能教育、自动驾驶出租车等，目前也正在写一本书《Machine Learning Yearning》，主要内容是教你如何构造机器学习项目。\n\nNG在书中写到：该书的重点不在于教会你一些机器学习算法，而是学会如何将机器学习算法应用于工作中，授人以鱼不如授人以渔，有些人工智能课程只是给你一把锤子，这本书将教你如何使用锤子。如果你渴望成为人工智能领域的引领者，并且想学习如何为团队确定研究方向，那么这本书将会对你有所帮助。在阅读完该书的草稿后，本文从书中选出了七条最有趣且最有用的建议：\n1.优化与满意度指标\n与其使用单个公式或指标来评估算法，不如考虑使用多个评价指标，这样做的目的是获得“优化”和“满意”两个度量指标。\n\n如上图所示，图中有三个不同的算法，分别为A、B、C，以及两个评价指标：精度和仿真运行时间。假设我们首先定义一个可接受的仿真运行时间，比如100ms以下，这个阈值就是我们“满意”的度量指标。设计的分类器仿真运行时间低于设定的阈值就认为是“满意”的。而对于精度而言，精度就是“优化”度量指标，即通过不断优化提升分类器的精度。\n2.快速选择验证集合测试集\nNG表示，当开始一个新项目时，一般应该先会从数据集中快速选择出验证集和测试集，这样能够给团队确定一个方向，即可以设定初始一周要完成的目标。最好的方法是有想法就迅速地去做，而不是在初始阶段花太多的精力和时间在思考上。即使突然发现第一次挑选的数据集不合适，也不要       害怕做出改变。以下三个原因可能造成数据集挑选不正确：\n\n数据实际分布与验证集/测试集不同；\n验证集、测试集过拟合；\n一些测试指标需要优化；\n\n改变数据集不是大难题，只要从问题中找到新的研究方向就好。\n3.机器学习是一个迭代过程\n机器学习是一个迭代过程，不要期望第一次就能获得好的结果。NG指出构建机器学习模型的方法一般分为三步：\n\n有一个想法；\n编程实现这个想法；\n通过实验总结这个想法的效果；\n\n\n这三步就是一个循环过程，只要实验结果不好，就得重新构想，之后再进行编程，后续进行新的实验来验证这个想法。这个过程循环得越快，取得的进展也越快。这也是为什么预先快速选择验证集合测试集是重要的原因，因为在迭代过程能够节约宝贵的时间，通过实验结果也能够确定团队是否走在正确的研究方向上。\n4.快速建立第一个模型，并迭代优化\n就像第三点说的，构建一个机器学习算法是一个迭代过程，NG在书中强调到：快速构建第一个模型并开始研究是很有好处的。不要试图一开始就设计出完美的模型，这有些不切实际。应该做的事情是快速的构建出第一个基本模型，即使这个模型离“最佳模型”还差十万八千里。但这也是值得的，因为能够快速检测出基本模型的性能，并从仿真结果中发现线索和优化方向，然后将时间尽可能的花在这个上面。\n5.并行评估多个想法\n当团队对某个算法有多个优化想法时，可以并行高效地评估这些想法。举例来说，一个用来检测猫图像的算法，NG说明他将如何创建一个电子表格，并在查看100个错误分类的验证集、测试集图像时填写。\n\n分析每一张图像，这些图像分类错误的原因是什么，以及任何额外的想法都有助于之后的研究。通过这张表格，可以看到哪些想法可以消除更多的错误，从中挑选出能消除错误最多的那个想法。\n6.考虑清楚错误标记的验证集、测试集是否是值得的\n在进行错误分析的过程中，可能会注意到验证集、测试集中的某些实例的标签不正确，即图像已被错误的人为标记，如果怀疑有一部分错误是由此原因造成的，可以在电子表格中为其添加附加类别。\n\n完成表格后，可以考虑是否值得花时间来解决这个问题。NG给出了两种可能的情况来判断是否值得修正这个问题：例子1：在验证集上的精度..............................90%（整体识别错误率为10%）由于错误标记例子造成的错误..........0.6%（占验证集错误率的6%）由于其他原因造成的错误..................9.4%（占验证集错误率的94%）在这个例子中，由于错误标记导致的0.6%的识别错误率占总的错误率6%，对模型的精度评估影响不是很显著，相对于9.4%错误率可供优化，对错误标签的修改没有太大作用。因此这不值得花时间来提升标签的质量，尽可能的将时间投入到9.4%的错误率优化上。例子2：在验证集上的精度..............................98%（整体识别错误率为2%）由于错误标记例子造成的错误..........0.6%（验证集造成的错误率30%）由于其他原因造成的错误..................9.4%（占验证集错误率的94%）在这个例子中，由于错误标记导致的0.6%的识别错误率占总的错误率30%，这会给模型的精度评估带来显著的错误，因此值得花时间来提升标签的质量，这个问题解决与否直接导致模型性能的错误率为1.4%还是2%，这个差距还是很明显的。\n7.考虑将验证集分成几个子集\nNG解释到：如果验证集比较大，且其错误率为20%，那么可能有必要将其分成两个独立的子集，分别为“眼球验证集”（Eyeball dev set）和“黑盒”验证集（Blackbox dev set）。“使用错误率为20%的算法对5000个例子进行分类，则会有1000个示例被错误分类。假设想手动检查大约100个错误错误分类的例子（占总分类错误数的10%），从验证集中随机选出10%的数据集，并将其放入称之为“眼球验证集”中，提醒自己用眼睛观察它。眼球验证集总共为500个例子，其中，期待算法识别错误的大约有100张图像。”验证集的第二个子集，被称作黑盒验证集，包含剩余的4500个示例。可以通过黑盒验证集评估分类器的性能，也可以根据实验结果来重新选择算法或调整算法的相关参数。但是，应该避免使用眼睛来观察它，使用“黑盒”这一术语就是因为只使用验证集的子集来获得分类器在“黑盒”验证集上的评估性能。\n本文作者：Dan clark，专注于数据可视化，本文由阿里云云栖社区组织翻译。文章原标题《7 Useful Suggestions from Andrew Ng “Machine Learning Yearning”》，译者：海棠，审校：Uncle_LLD。原文链接本文为云栖社区原创内容，未经允许不得转载。\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "1"}