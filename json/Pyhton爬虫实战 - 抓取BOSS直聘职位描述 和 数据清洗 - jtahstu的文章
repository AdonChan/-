{"title": "Pyhton爬虫实战 - 抓取BOSS直聘职位描述 和 数据清洗 - jtahstu的文章 ", "index": "网页爬虫,php,beautifulsoup,requests,python", "content": "原文地址：http://www.jtahstu.com/blog/s...\nPyhton爬虫实战 - 抓取BOSS直聘职位描述 和 数据清洗\n零、致谢\n感谢BOSS直聘相对权威的招聘信息，使本人有了这次比较有意思的研究之旅。\n由于爬虫持续爬取 www.zhipin.com 网站，以致产生的服务器压力，本人深感歉意，并没有 DDoS 和危害贵网站的意思。\n\n[2017-12-14更新] 在跑了一夜之后，服务器 IP 还是被封了，搞得本人现在家里、公司、云服务器三线作战啊[2017-12-19更新] 后续把拉勾网的数据也爬到，加了进来\n一、抓取详细的职位描述信息\n1.1 前提数据\n这里需要知道页面的 id 才能生成详细的链接，在 Python爬虫框架Scrapy实战 - 抓取BOSS直聘招聘信息 中，我们已经拿到招聘信息的大部分信息，里面有个 pid 字段就是用来唯一区分某条招聘，并用来拼凑详细链接的。\n是吧，明眼人一眼就看出来了。\n\n1.2 详情页分析\n详情页如下图所示\n\n在详情页中，比较重要的就是职位描述和工作地址这两个\n由于在页面代码中岗位职责和任职要求是在一个 div 中的，所以在抓的时候就不太好分，后续需要把这个连体婴儿，分开分析。\n\n1.3 爬虫用到的库\n使用的库有\n\nrequests\nBeautifulSoup4\npymongo\n\n对应的安装文档依次如下，就不细说了\n\n安装 Requests - Requests 2.18.1 文档\n安装 Beautiful Soup - Beautiful Soup 4.2.0 文档\nPyMongo安装使用笔记\n\n\n1.4 Python 代码\n\"\"\"\n@author: jtahstu\n@contact: root@jtahstu.com\n@site: http://www.jtahstu.com\n@time: 2017/12/10 00:25\n\"\"\"\n# -*- coding: utf-8 -*-\nimport requests\nfrom bs4 import BeautifulSoup\nimport time\nfrom pymongo import MongoClient\n\nheaders = {\n    'x-devtools-emulate-network-conditions-client-id': \"5f2fc4da-c727-43c0-aad4-37fce8e3ff39\",\n    'upgrade-insecure-requests': \"1\",\n    'user-agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36\",\n    'accept': \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n    'dnt': \"1\",\n    'accept-encoding': \"gzip, deflate\",\n    'accept-language': \"zh-CN,zh;q=0.8,en;q=0.6\",\n    'cookie': \"__c=1501326829; lastCity=101020100; __g=-; __l=r=https%3A%2F%2Fwww.google.com.hk%2F&l=%2F; __a=38940428.1501326829..1501326829.20.1.20.20; Hm_lvt_194df3105ad7148dcf2b98a91b5e727a=1501326839; Hm_lpvt_194df3105ad7148dcf2b98a91b5e727a=1502948718; __c=1501326829; lastCity=101020100; __g=-; Hm_lvt_194df3105ad7148dcf2b98a91b5e727a=1501326839; Hm_lpvt_194df3105ad7148dcf2b98a91b5e727a=1502954829; __l=r=https%3A%2F%2Fwww.google.com.hk%2F&l=%2F; __a=38940428.1501326829..1501326829.21.1.21.21\",\n    'cache-control': \"no-cache\",\n    'postman-token': \"76554687-c4df-0c17-7cc0-5bf3845c9831\"\n}\nconn = MongoClient('127.0.0.1', 27017)\ndb = conn.iApp  # 连接mydb数据库，没有则自动创建\n\n\ndef init():\n    items = db.jobs_php.find().sort('pid')\n    for item in items:\n        if 'detail' in item.keys(): # 在爬虫挂掉再此爬取时，跳过已爬取的行\n            continue\n        detail_url = \"https://www.zhipin.com/job_detail/%s.html?ka=search_list_1\" % item['pid']\n        print(detail_url)\n        html = requests.get(detail_url, headers=headers)\n        if html.status_code != 200: # 爬的太快网站返回403，这时等待解封吧\n            print('status_code is %d' % html.status_code)\n            break\n        soup = BeautifulSoup(html.text, \"html.parser\")\n        job = soup.select(\".job-sec .text\")\n        if len(job) < 1:\n            continue\n        item['detail'] = job[0].text.strip()  # 职位描述\n        location = soup.select(\".job-sec .job-location\")\n        item['location'] = location[0].text.strip()  # 工作地点\n        item['updated_at'] = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())  # 实时爬取时间\n        res = save(item) # 保存数据\n        print(res)\n        time.sleep(40) # 停停停\n\n\n# 保存数据到 MongoDB 中\ndef save(item):\n    return db.jobs_php.update_one({\"_id\": item['_id']}, {\"$set\": item})\n\n\nif __name__ == \"__main__\":\n    init()\n代码 easy，初学者都能看懂。\n\n1.5 再啰嗦几句\n在 上一篇文章 中只是爬了 上海-PHP 近300条数据，后续改了代码，把12个城市的 PHP 相关岗位的数据都抓下来了，有3500+条数据，慢慢爬吧，急不来。\n像这样\n二、数据清洗\n2.1 校正发布日期\n\"time\" : \"发布于03月31日\",\n\"time\" : \"发布于昨天\",\n\"time\" : \"发布于11:31\",\n这里拿到的都是这种格式的，所以简单处理下\nimport datetime\n\nfrom pymongo import MongoClient\n\ndb = MongoClient('127.0.0.1', 27017).iApp\n\ndef update(data):\n    return db.jobs_php.update_one({\"_id\": data['_id']}, {\"$set\": data})\n    \n# 把时间校正过来\ndef clear_time():\n    items = db.jobs_php.find({})\n    for item in items:\n        if not item['time'].find('布于'):\n            continue\n        item['time'] = item['time'].replace(\"发布于\", \"2017-\")\n        item['time'] = item['time'].replace(\"月\", \"-\")\n        item['time'] = item['time'].replace(\"日\", \"\")\n        if item['time'].find(\"昨天\") > 0:\n            item['time'] = str(datetime.date.today() - datetime.timedelta(days=1))\n        elif item['time'].find(\":\") > 0:\n            item['time'] = str(datetime.date.today())\n        update(item)\n    print('ok')\n\n2.2 校正薪水以数字保存\n\"salary\" : \"5K-12K\",\n\n#处理成下面的格式\n\"salary\" : {\n    \"low\" : 5000,\n    \"high\" : 12000,\n    \"avg\" : 8500.0\n},\n# 薪水处理成数字，符合 xk-yk 的数据处理，不符合的跳过\ndef clear_salary():\n    items = db.jobs_lagou_php.find({})\n    for item in items:\n        if type(item['salary']) == type({}):\n            continue\n        salary_list = item['salary'].lower().replace(\"k\", \"000\").split(\"-\")\n        if len(salary_list) != 2:\n            print(salary_list)\n            continue\n        try:\n            salary_list = [int(x) for x in salary_list]\n        except:\n            print(salary_list)\n            continue\n        item['salary'] = {\n            'low': salary_list[0],\n            'high': salary_list[1],\n            'avg': (salary_list[0] + salary_list[1]) / 2\n        }\n        update(item)\n    print('ok')\n\n[2017-12-19更新] 这里在处理 Boss 直聘的数据时，比较简单正常，但是后续抓到拉勾网的数据，拉勾网的数据有些不太规范。比如有‘20k以上’这种描述\n\n2.3 根据 工作经验年限 划分招聘等级\n# 校正拉勾网工作年限描述，以 Boss直聘描述为准\ndef update_lagou_workyear():\n    items = db.jobs_lagou_php.find({})\n    for item in items:\n        if item['workYear'] == '应届毕业生':\n            item['workYear'] = '应届生'\n        elif item['workYear'] == '1年以下':\n            item['workYear'] = '1年以内'\n        elif item['workYear'] == '不限':\n            item['workYear'] = '经验不限'\n        update_lagou(item)\n    print('ok')\n    \n# 设置招聘的水平，分两次执行\ndef set_level():\n    items = db.jobs_zhipin_php.find({})\n    # items = db.jobs_lagou_php.find({})\n    for item in items:\n        if item['workYear'] == '应届生':\n            item['level'] = 1\n        elif item['workYear'] == '1年以内':\n            item['level'] = 2\n        elif item['workYear'] == '1-3年':\n            item['level'] = 3\n        elif item['workYear'] == '3-5年':\n            item['level'] = 4\n        elif item['workYear'] == '5-10年':\n            item['level'] = 5\n        elif item['workYear'] == '10年以上':\n            item['level'] = 6\n        elif item['workYear'] == '经验不限':\n            item['level'] = 10\n        update(item)\n    print('ok')\n这里有点坑的就是，一般要求经验不限的岗位，需求基本都写在任职要求里了，所以为了统计的准确性，这个等级的数据，后面会被舍弃掉。\n\n[2017-12-14更新] 从后续的平均数据来看，这里的经验不限，一般要求的是1-3年左右，但是还是建议舍弃掉。[2017-12-19更新] 拉勾网的职位描述和 Boss直聘稍有不同，需要先校正，然后再设置等级\n\n2.4 区分开<岗位职责>和<任职要求>\n对于作者这个初学者来说，这里还没有什么好的方法，知道的同学，请务必联系作者，联系方式在个人博客里\nso , i'm sorry.\n为什么这两个不好划分出来呢？\n因为这里填的并不统一，可以说各种花样，有的要求在前，职责在后，有的又换个名字区分。目前看到的关于要求的有['任职条件', '技术要求', '任职要求', '任职资格', '岗位要求']这么多说法。然后顺序还不一样，有的要求在前，职责在后，有的又反之。\n举个栗子\n会基本的php编程！能够修改简单的软件！对云服务器和数据库能够运用！懂得微信公众账号对接和开放平台对接！我们不是软件公司，是运营公司！想找好的公司学习的陕西基本没有，要到沿海城市去！但是我们是实用型公司，主要是软件应用和更适合大众！\n啥也不说的，这里可以认为这是一条脏数据了。\n再举个栗子\nPHP中级研发工程师（ERP/MES方向）1、计算机或相关学科本科或本科以上学历；2、php和Java script的开发经验。3、Linux和MySQL数据库的开发经验；5、有ERP、MES相关开发经验优先；6、英语的读写能力；7、文化的开放性；我们提供1、有趣的工作任务；2、多元的工作领域；3、与能力相关的收入；4、年轻、开放并具有创造力的团队和工作氛围；5、不断接触最新科技（尤其是工业4.0相关）；6、可适应短期出差（提供差补）；\n这个只有要求，没职责，还多了个提供，我乐个趣  ╮(╯▽╰)╭\n所以，气的想骂人。\n2.5 缺失值分析 [2017-12-19]更新\n\nBoss直聘这里有部分招聘没有industryField、financeStage和companySize值，这个可以看前一篇的爬虫代码，拉勾网的数据基本没问题。\n2.6 异常值分析 [2017-12-19] 更新\n\n\n\n岗位要求工作年限和职位描述里的要求不一致，比如岗位列表里要求的是1年以内,但是职位描述里却是2年以上工作经验，这是由于 HR 填写不规范引起的误差。\n由第1点引起的另一个问题，就是与工作年限要求不对应的薪水，使计算的平均薪水偏高。比如一条记录，年限要求是一年以内，所以等级为2，但是薪水却是20k-30k，实际上这是等级为3的薪水，这里就得校正 level 字段，目前只是手动的把几个较高的记录手动改了，都校正过来很困难，得文本分析招聘要求。\n\n2.7 失效值排除 [2017-12-19] 更新\n\n首先这里需要一个判断某条招聘是否还挂在网站上的方法，这个暂时想到了还没弄\n然后对于发布时间在两个月之前的数据，就不进行统计计算\n\nok ，现在我们的数据基本成这样了\n{\n    \"_id\" : ObjectId(\"5a30ad2068504386f47d9a4b\"),\n    \"city\" : \"苏州\",\n    \"companyShortName\" : \"蓝海彤翔\",\n    \"companySize\" : \"100-499人\",\n    \"education\" : \"本科\",\n    \"financeStage\" : \"B轮\",\n    \"industryField\" : \"互联网\",\n    \"level\" : 3,\n    \"pid\" : \"11889834\",\n    \"positionLables\" : [ \n        \"PHP\", \n        \"ThinkPHP\"\n    ],\n    \"positionName\" : \"php研发工程师\",\n    \"salary\" : {\n        \"avg\" : 7500.0,\n        \"low\" : 7000,\n        \"high\" : 8000\n    },\n    \"time\" : \"2017-06-06\",\n    \"updated_at\" : \"2017-12-13 18:31:15\",\n    \"workYear\" : \"1-3年\",\n    \"detail\" : \"1、处理landcloud云计算相关系统的各类开发和调研工作；2、处理coms高性能计算的各类开发和调研工作岗位要求：1、本科学历，两年以上工作经验，熟悉PHP开发，了解常用的php开发技巧和框架；2、了解C++，python及Java开发；3、有一定的研发能力和钻研精神；4、有主动沟通能力和吃苦耐劳的精神。\",\n    \"location\" : \"苏州市高新区科技城锦峰路158号101park8幢\"\n}\n由于还没到数据展示的时候，所以现在能想到的就是先这样处理了\n项目开源地址：http://git.jtahstu.com/jtahst...\n三、展望和设想\n首先这个小玩意数据量并不够多，因为爬取时间短，站点唯一，再者广度局限在 PHP 这一个岗位上，以致存在一定的误差。\n所以为了数据的丰富和多样性，这个爬虫是一定要持续跑着的，至少要抓几个月的数据才算可靠吧。\n然后准备再去抓下拉勾网的招聘数据，这也是个相对优秀的专业 IT 招聘网站了，数据也相当多，想当初找实习找正式工作，都是在这两个 APP 上找的，其他的网站几乎都没看。\n最后，对于科班出身的学弟学妹们，过来人说一句，编程相关的职业就不要去志连、钱尘乌有、five eight桐城了，好吗？那里面都发的啥呀，看那些介绍心里没点数吗？\n四、help\n这里完全就是作者本人依据个人微薄的见识，主观臆断做的一些事情，所以大家有什么点子和建议，都可以评论一下，多交流交流嘛。\n后续会公开所有数据，大家自己可以自己分析分析。\n我们太年轻，以致都不知道以后的时光，竟然那么长，长得足够让我们把一门技术研究到顶峰，乱花渐欲迷人眼，请不要忘了根本好吗。\n生活总是让我们遍体鳞伤，但到后来，那些受伤的地方一定会变成我们最强壮的地方。 —海明威 《永别了武器》\n\n                ", "mainLikeNum": ["9 "], "mainBookmarkNum": "29"}