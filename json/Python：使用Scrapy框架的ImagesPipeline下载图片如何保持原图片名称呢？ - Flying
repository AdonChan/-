{"title": "Python：使用Scrapy框架的ImagesPipeline下载图片如何保持原图片名称呢？ - Flying ", "index": "imagepipeline,scrapy,python", "content": "默认情况下，使用ImagePipeline组件下载图片的时候，图片名称是以图片URL的SHA1值进行保存的。\n如：\n图片URL:http://www.example.com/image.jpg\nSHA1结果：3afec3b4765f8f0a07b78f98c07b83f013567a0a\n则图片名称：3afec3b4765f8f0a07b78f98c07b83f013567a0a.jpg\n但是，我想要以原来的图片名称进行保存，比如上面例子中的图片保存到本地的话，图片名称就应该是：image.jpgstackoverflow上说是可以重写image_key函数，不过我试了下，结果发现不行，重写的image_key函数没被调用。\n后面查看了下ImagePipeline的源码：\n\nclass ImagesPipeline(FilesPipeline):\n    \"\"\"Abstract pipeline that implement the image thumbnail generation logic\n\n    \"\"\"\n\n    MEDIA_NAME = 'image'\n    MIN_WIDTH = 0\n    MIN_HEIGHT = 0\n    THUMBS = {}\n    DEFAULT_IMAGES_URLS_FIELD = 'image_urls'\n    DEFAULT_IMAGES_RESULT_FIELD = 'images'\n\n    @classmethod\n    def from_settings(cls, settings):\n        cls.MIN_WIDTH = settings.getint('IMAGES_MIN_WIDTH', 0)\n        cls.MIN_HEIGHT = settings.getint('IMAGES_MIN_HEIGHT', 0)\n        cls.EXPIRES = settings.getint('IMAGES_EXPIRES', 90)\n        cls.THUMBS = settings.get('IMAGES_THUMBS', {})\n        s3store = cls.STORE_SCHEMES['s3']\n        s3store.AWS_ACCESS_KEY_ID = settings['AWS_ACCESS_KEY_ID']\n        s3store.AWS_SECRET_ACCESS_KEY = settings['AWS_SECRET_ACCESS_KEY']\n\n        cls.IMAGES_URLS_FIELD = settings.get('IMAGES_URLS_FIELD', cls.DEFAULT_IMAGES_URLS_FIELD)\n        cls.IMAGES_RESULT_FIELD = settings.get('IMAGES_RESULT_FIELD', cls.DEFAULT_IMAGES_RESULT_FIELD)\n        store_uri = settings['IMAGES_STORE']\n        return cls(store_uri)\n\n    def file_downloaded(self, response, request, info):\n        return self.image_downloaded(response, request, info)\n\n    def image_downloaded(self, response, request, info):\n        checksum = None\n        for path, image, buf in self.get_images(response, request, info):\n            if checksum is None:\n                buf.seek(0)\n                checksum = md5sum(buf)\n            width, height = image.size\n            self.store.persist_file(\n                path, buf, info,\n                meta={'width': width, 'height': height},\n                headers={'Content-Type': 'image/jpeg'})\n        return checksum\n\n    def get_images(self, response, request, info):\n        path = self.file_path(request, response=response, info=info)\n        orig_image = Image.open(StringIO(response.body))\n\n        width, height = orig_image.size\n        if width < self.MIN_WIDTH or height < self.MIN_HEIGHT:\n            raise ImageException(\"Image too small (%dx%d < %dx%d)\" %\n                                 (width, height, self.MIN_WIDTH, self.MIN_HEIGHT))\n\n        image, buf = self.convert_image(orig_image)\n        yield path, image, buf\n\n        for thumb_id, size in self.THUMBS.iteritems():\n            thumb_path = self.thumb_path(request, thumb_id, response=response, info=info)\n            thumb_image, thumb_buf = self.convert_image(image, size)\n            yield thumb_path, thumb_image, thumb_buf\n\n    def convert_image(self, image, size=None):\n        if image.format == 'PNG' and image.mode == 'RGBA':\n            background = Image.new('RGBA', image.size, (255, 255, 255))\n            background.paste(image, image)\n            image = background.convert('RGB')\n        elif image.mode != 'RGB':\n            image = image.convert('RGB')\n\n        if size:\n            image = image.copy()\n            image.thumbnail(size, Image.ANTIALIAS)\n\n        buf = StringIO()\n        image.save(buf, 'JPEG')\n        return image, buf\n\n    def get_media_requests(self, item, info):\n        return [Request(x) for x in item.get(self.IMAGES_URLS_FIELD, [])]\n\n    def item_completed(self, results, item, info):\n        if self.IMAGES_RESULT_FIELD in item.fields:\n            item[self.IMAGES_RESULT_FIELD] = [x for ok, x in results if ok]\n        return item\n\n    def file_path(self, request, response=None, info=None):\n        ## start of deprecation warning block (can be removed in the future)\n        def _warn():\n            from scrapy.exceptions import ScrapyDeprecationWarning\n            import warnings\n            warnings.warn('ImagesPipeline.image_key(url) and file_key(url) methods are deprecated, '\n                          'please use file_path(request, response=None, info=None) instead',\n                          category=ScrapyDeprecationWarning, stacklevel=1)\n\n        # check if called from image_key or file_key with url as first argument\n        if not isinstance(request, Request):\n            _warn()\n            url = request\n        else:\n            url = request.url\n\n        # detect if file_key() or image_key() methods have been overridden\n        if not hasattr(self.file_key, '_base'):\n            _warn()\n            return self.file_key(url)\n        elif not hasattr(self.image_key, '_base'):\n            _warn()\n            return self.image_key(url)\n        ## end of deprecation warning block\n\n        image_guid = hashlib.sha1(url).hexdigest()  # change to request.url after deprecation\n        return 'full/%s.jpg' % (image_guid)\n\n    def thumb_path(self, request, thumb_id, response=None, info=None):\n        ## start of deprecation warning block (can be removed in the future)\n        def _warn():\n            from scrapy.exceptions import ScrapyDeprecationWarning\n            import warnings\n            warnings.warn('ImagesPipeline.thumb_key(url) method is deprecated, please use '\n                          'thumb_path(request, thumb_id, response=None, info=None) instead',\n                          category=ScrapyDeprecationWarning, stacklevel=1)\n\n        # check if called from thumb_key with url as first argument\n        if not isinstance(request, Request):\n            _warn()\n            url = request\n        else:\n            url = request.url\n\n        # detect if thumb_key() method has been overridden\n        if not hasattr(self.thumb_key, '_base'):\n            _warn()\n            return self.thumb_key(url, thumb_id)\n        ## end of deprecation warning block\n\n        thumb_guid = hashlib.sha1(url).hexdigest()  # change to request.url after deprecation\n        return 'thumbs/%s/%s.jpg' % (thumb_id, thumb_guid)\n\n    # deprecated\n    def file_key(self, url):\n        return self.image_key(url)\n    file_key._base = True\n\n    # deprecated\n    def image_key(self, url):\n        return self.file_path(url)\n    image_key._base = True\n\n    # deprecated\n    def thumb_key(self, url, thumb_id):\n        return self.thumb_path(url, thumb_id)\n    thumb_key._base = True\n\n\n其中，有这么一句话：ImagesPipeline.image_key(url) and file_key(url) methods are deprecated, please use file_path(request, response=None, info=None) instead\n也就是说，在最新版本的Scrapy中（0.22.2），使用file_path代替image_key函数。\n因此，我在自定义的ImagePipeline类中，重写了file_path函数，代码如下：\n\n__author__ = 'Fly'\n#coding:utf-8\nfrom scrapy.contrib.pipeline.images import ImagesPipeline\nfrom scrapy.http import Request\nfrom scrapy.exceptions import DropItem\n\nclass MyImagesPipeline(ImagesPipeline):\n    def file_path(self, request, response=None, info=None):\n        image_guid = request.url.split('/')[-1]\n        return 'full/%s' % (image_guid)\n\n    def get_media_requests(self, item, info):\n        for image_url in item['image_urls']:\n            yield Request(image_url)\n\n    def item_completed(self, results, item, info):\n        image_paths = [x['path'] for ok, x in results if ok]\n        if not image_paths:\n            raise DropItem(\"Item contains no images\")\n        return item\n\n\n以上代码主要返回原图片名称+图片后缀。\n作者：曾是土木人（http://blog.csdn.net/php_fly）\n原文地址：http://blog.csdn.net/php_fly/article/details/19688595\n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "3"}