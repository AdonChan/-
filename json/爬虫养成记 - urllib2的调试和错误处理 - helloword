{"title": "爬虫养成记 - urllib2的调试和错误处理 - helloword ", "index": "python,网络爬虫", "content": "urllib2的timeout\ntimeout参数用于设置超时。我们在爬取一些响应较慢的网站的时候，需要设置一个比较长的超时时间。\nresponse = urllib2.urlopen(request, timeout=10)\n上述代码设置timeout为10秒。\n设置Debug\nimport urllib2\n\nhttpHandler = urllib2.HTTPHandler(debuglevel=1)\nopener = urllib2.build_opener(httpHandler)\nurllib2.install_opener(opener)\n\nurllib2.urlopen(\"http://www.zhihu.com\")\nURLError和HTTPError处理\n事实上，并不是所有urllib2发起的请求都能得到服务器的回应。例如\n\n网络无链接\n连接不到服务器\n链接不存在\n请求的方法不对\n\n等情况都会造成urllib2抛出错误。urllib2提供了两个Exception用于处理响应的错误。\n\nURLErrorURLError是HttpError的父类。上面说到的handlers出错就会抛出URLError。\nHTTPErrorHTTPError是URLError的子类。用于处理Http相关的错误。\n\nHTTPError除了reson属性外还有code属性。code属性即http状态码。更多状态码可以阅读：http://www.cnblogs.com/shanyo...\n下面我们来展示一下示例代码：\nimport urllib2\n\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36\"\n}\nrequest = urllib2.Request(\"http://blog.csdn.net/cqcre\", headers = headers)\n\nhttpHandler = urllib2.HTTPHandler(debuglevel=1)\nopener = urllib2.build_opener(httpHandler)\nurllib2.install_opener(opener)\n\ntry:\n    response = urllib2.urlopen(request)\n    print response.getcode()\nexcept urllib2.HTTPError, e:\n    print e.code, e.reason\nexcept urllib2.URLError, e:\n    print e.reason\n值得注意的是 HTTPError是URLError的子类，因此在捕获Exception的时候需要将子类放在前面避免Exception先被父类捕获。\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}