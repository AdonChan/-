{"title": "Celery任务队列 - 个人文章 ", "index": "队列,任务调度,python", "content": "文档\n\n中文文档\n官方文档\ncelery定时服务、celery与django结合使用\n\n简介\nCelery 是一个“自带电池”的的任务队列。它易于使用，所以你可以无视其所解决问题的复杂程度而轻松入门。它遵照最佳实践设计，所以你的产品可以扩展，或与其他语言集成，并且它自带了在生产环境中运行这样一个系统所需的工具和支持。\nCelery 的最基础部分。包括：\n\n\n选择和安装消息传输方式（中间人）----broker，如RabbitMQ，redis等。\n\nRabbitMQ的安装：sudo apt-get install rabbitmq-server\n本文使用redis\n官方推荐RabbitMQ\n当然部分nosql也可以\n\n\n安装 Celery 并创建第一个任务\n运行职程并调用任务。\n追踪任务在不同状态间的迁移，并检视返回值。\n\n安装\npip install celery\n简单使用\n定义任务\ntasks.py\nfrom celery import Celery\n#第一个参数是你的celery名称\n#backen 用于存储结果\n#broker 用于存储消息队列\napp = Celery('tasks',backend='redis://:password@host:port/db', broker='redis://:password@host:port/db')\n\n@app.task\ndef add(x, y):\n    return x + y\nCelery 的第一个参数是当前模块的名称，这个参数是必须的，这样的话名称可以自动生成。第二个参数是中间人关键字参数，指定你所使用的消息中间人的 URL，此处使用了 RabbitMQ，也是默认的选项。更多可选的中间人见上面的 选择中间人 一节。例如，对于 RabbitMQ 你可以写 amqp://localhost ，而对于 Redis 你可以写 redis://localhost .\n你定义了一个单一任务，称为 add ，返回两个数字的和。\n启动celery服务\n步骤：\n\n启动任务工作者worker\n讲任务放入celery队列\nworker读取队列，并执行任务\n\n启动一个工作者，创建一个任务队列\n// -A 指定celery名称，loglevel制定log级别，只有大于或等于该级别才会输出到日志文件\ncelery -A tasks worker --loglevel=info\n如果你没有安装redis库，请先pip install redis\n使用celery\n现在我们已经有一个celery队列了，我门只需要将工作所需的参数放入队列即可\nfrom tasks import add\n#调用任务会返回一个 AsyncResult 实例，可用于检查任务的状态，等待任务完成或获取返回值（如果任务失败，则为异常和回溯）。\n#但这个功能默认是不开启的，你需要设置一个 Celery 的结果后端(即backen，我们在tasks.py中已经设置了，backen就是用来存储我们的计算结果)\nresult=add.delay(4, 4)\n#如果任务已经完成\nif(result.ready()):\n  #获取任务执行结果\n  print(result.get(timeout=1))\n常用接口\n\ntasks.add(4,6) ---> 本地执行\ntasks.add.delay(3,4) --> worker执行\nt=tasks.add.delay(3,4)  --> t.get()  获取结果，或卡住，阻塞\nt.ready()---> False：未执行完，True：已执行完\nt.get(propagate=False) 抛出简单异常，但程序不会停止\nt.traceback 追踪完整异常\n\n使用配置\n\n使用配置来运行，对于正式项目来说可维护性更好。配置可以使用app.config.XXXXX_XXX='XXX'的形式如app.conf.CELERY_TASK_SERIALIZER = 'json'来进行配置\n配置资料\n\n配置文件\nconfig.py\n#broker\nBROKER_URL = 'redis://:password@host:port/db'\n#backen\nCELERY_RESULT_BACKEND = 'redis://:password@host:port/db'\n#导入任务，如tasks.py\nCELERY_IMPORTS = ('tasks', )\n#列化任务载荷的默认的序列化方式\nCELERY_TASK_SERIALIZER = 'json'\n#结果序列化方式\nCELERY_RESULT_SERIALIZER = 'json'\n\nCELERY_ACCEPT_CONTENT=['json']\n#时间地区与形式\nCELERY_TIMEZONE = 'Europe/Oslo'\n#时间是否使用utc形式\nCELERY_ENABLE_UTC = True\n\n#设置任务的优先级或任务每分钟最多执行次数\nCELERY_ROUTES = {\n    # 如果设置了低优先级，则可能很久都没结果\n    #'tasks.add': 'low-priority',\n    #'tasks.add': {'rate_limit': '10/m'}，\n    #'tasks.add': {'rate_limit': '10/s'}，\n    #'*': {'rate_limit': '10/s'}\n}\n#borker池，默认是10\nBROKER_POOL_LIMIT = 10\n#任务过期时间，单位为s，默认为一天\nCELERY_TASK_RESULT_EXPIRES = 3600\n#backen缓存结果的数目，默认5000\nCELERY_MAX_CACHED_RESULTS = 10000\n开启服务\ncelery.py\nfrom celery import Celery\n#指定名称\napp = Celery('mycelery')\n#加载配置模块\napp.config_from_object('config')\n\nif __name__=='__main__':\n      app.start()\n任务定义\ntasks.py\nfrom .celery import app\n@app.task\ndef add(a, b):\n  return a + b\n启动\n// -l 是 --loglevel的简写\ncelery -A mycelery worker -l info\n执行/调用服务\nfrom tasks import add\n#调用任务会返回一个 AsyncResult 实例，可用于检查任务的状态，等待任务完成或获取返回值（如果任务失败，则为异常和回溯）。\n#但这个功能默认是不开启的，你需要设置一个 Celery 的结果后端(即backen，我们在tasks.py中已经设置了，backen就是用来存储我们的计算结果)\nresult=add.delay(4, 4)\n#如果任务已经完成\nif(result.ready()):\n  #获取任务执行结果\n  print(result.get(timeout = 1))\n分布式\n\n启动多个celery worker，这样即使一个worker挂掉了其他worker也能继续提供服务\n方法一\n// 启动三个worker：w1,w2,w3\ncelery multi start w1 -A project -l info\ncelery multi start w2 -A project -l info\ncelery multi start w3 -A project -l info\n// 立即停止w1,w2，即便现在有正在处理的任务\ncelery multi stop w1 w2\n// 重启w1\ncelery multi restart w1 -A project -l info\n// celery multi stopwait w1 w2 w3    # 待任务执行完，停止\n方法二\n// 启动多个worker，但是不指定worker名字\n// 你可以在同一台机器上运行多个worker，但要为每个worker指定一个节点名字，使用--hostname或-n选项\n// concurrency指定处理进程数，默认与cpu数量相同，因此一般无需指定\n$ celery -A proj worker --loglevel=INFO --concurrency=10 -n worker1@%h\n$ celery -A proj worker --loglevel=INFO --concurrency=10 -n worker2@%h\n$ celery -A proj worker --loglevel=INFO --concurrency=10 -n worker3@%h\n\n错误处理\ncelery可以指定在发生错误的情况下进行自定义的处理config.py\ndef my_on_failure(self, exc, task_id, args, kwargs, einfo):\n    print('Oh no! Task failed: {0!r}'.format(exc))\n\n// 对所有类型的任务，当发生执行失败的时候所执行的操作\nCELERY_ANNOTATIONS = {'*': {'on_failure': my_on_failure}}    \n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "1"}