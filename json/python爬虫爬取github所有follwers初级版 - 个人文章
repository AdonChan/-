{"title": "python爬虫爬取github所有follwers初级版 - 个人文章 ", "index": "python", "content": "这几天我很焦虑，受不了那些先follow我，等我follow回去后又unfollow的人，因为是他们先follow我的，我出于人道主义想着互粉一下的，结果这么对我，太不厚道了。github又不像微博那样有互粉标志，这真的整得我很心烦，于是想着写一个爬虫，把这些“坏人”揪出来~第一步，当然是放出代码啦，代码放在我的github上，欢迎给star:\nhttps://github.com/laurel-he/...\n我是一个python初学者，完全小白，所以只能用比较蠢的方法来扒，以下是我的步骤：1 扒取整个页面\n# -*- coding:UTF-8 -*-\nimport requests\nif __name__ == '__main__':\ntarget = 'https://github.com/laurel-he?tab=followers'\nreq = requests.get(url=target)\nfo = open('1.txt', \"ab+\")        \nfo.write((req.text).encode('UTF-8'))  \nfo.close()    \n\n以上代码可以将整个文件的html扒取下来，接下来找到用户，在follower里面随便找到一个用户，在刚才生成的txt文件中搜索，然后就可以得到如下匹配：\ndata-octo-dimensions=\"link_type:self\".href=\"/(.?)\"\n可以直接匹配出用户名。2 根据正则获取匹配的用户刚才已经把整个页面扒取下来了，代码放在spider/follwers/url.py，txt文件效果如下：\n\n但是我想要获取的是所有follwer，之前已经得到了对应的正则表达式，那么得到所有的follwer很容易，最终代码如下：\n# -*- coding:UTF-8 -*-\nimport requests\nimport re\nif __name__ == '__main__':\ntarget = 'https://github.com/laurel-he?tab=followers'\nreq = requests.get(url=target)\ncontext = req.text\npatt = re.compile(r\"data-octo-dimensions=\\\"link_type:self\\\".*href=\\\"/(.*?)\\\"\")\nch = patt.findall(req.text)\nfo = open('flower.txt',\"ab+\")\nfor i in ch:\n    line = str(i) + \"\\n\"\n    fo.write((line).encode('UTF-8')+b'\\r\\n')\nfo.close\n\n以上代码可以直接扒取所有follwers，但是出现了两遍，因为我这个表达式每个名字会匹配到两次，下一版本会更换正则表达式，先将就用吧，然后如法炮制扒取第二页第三页，只需要更改链接地址，加上page就可以，同时也可以把文件写入方式变成追加方式，或者干脆每次都新建一个文件，无所谓，总之最终将所有用户扒取下来。按照同样的方式扒取所有的自己follwing的用户。这里注意的是，代码里一定要加上换行！换行符不加就是一团乱麻，啥也看不清。换行符添加后不成功的话试试加上'r'，也许就能成功了；还是不成功的话看看报错是不是这个样子滴：\n\n是的话加上b方法，转化成byte~3 接下来是最傻最骚的操作-对比想要找出来那个没有follow自己的人，只能进行对比，我目前用了一个很傻的办法就是新建一个excel文件，按照列粘贴所有数据，然后按照升序或降序排行（两列排列方式要一样），然后肉眼来对比！！！\n\n其实我还是觉得我要瞎了，但是真的比起一个个看好多了，以后继续想更好的办法，总之我是揪出来那个坏人了。。。但是为了尊重人家隐私权，好吧，就这样吧，我也不能做啥。\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}