{"title": "Python利用Phantomjs抓取渲染JS后的网页 - 码农咖啡馆 ", "index": "网页爬虫,phantomjs,python", "content": "最近需要爬取某网站，无奈页面都是JS渲染后生成的，普通的爬虫框架搞不定，于是想到用Phantomjs搭一个代理。\n\nPython调用Phantomjs貌似没有现成的第三方库（如果有，请告知小2），漫步了一圈，发现只有pyspider提供了现成的方案。\n\n简单试用了一下，感觉pyspider更像一个为新手打造的爬虫工具，好比一个老妈子，有时无微不至，有时喋喋不休。\n轻巧的小工具应该更受人喜爱，我也怀着一点私心，可以带着我最爱的BeautifulSoup一块儿用，而不用再学PyQuery（pyspider用来解析HTML），更不用忍受浏览器写Python的糟糕体验（偷笑）。\n\n所以花了一个下午的时间，把pyspider当中实现Phantomjs代理的部分拆了出来，独立成一个小的爬虫模块，希望大家会喜欢（感谢binux！）。\n\n准备工作\n\n\n你当然要有Phantomjs，废话！（Linux下最好用supervisord守护，必须保持抓取的时候Phantomjs一直处于开启状态）\n用项目路径下的phantomjs_fetcher.js启动：phantomjs phantomjs_fetcher.js [port]\n\n安装tornado依赖（使用了tornado的httpclient模块）\n\n调用是超级简单的\n\npythonfrom tornado_fetcher import Fetcher\n\n# 创建一个爬虫\n>>> fetcher=Fetcher(\n    user_agent='phantomjs', # 模拟浏览器的User-Agent\n    phantomjs_proxy='http://localhost:12306', # phantomjs的地址\n    poolsize=10, # 最大的httpclient数量\n    async=False # 同步还是异步\n    )\n# 开始连接Phantomjs的代理，可以渲染JS！\n>>> fetcher.phantomjs_fetch(url)\n# 渲染成功后执行额外的JS脚本（注意用function包起来！）\n>>> fetcher.phantomjs_fetch(url, js_script='function(){setTimeout(\"window.scrollTo(0,100000)}\", 1000)')\n\n\n老规矩，代码在小2的Github了，欢迎指正：PhantomjsFetcher\n\n\n  来自：建造者说\n\n\n                ", "mainLikeNum": ["5 "], "mainBookmarkNum": "43"}