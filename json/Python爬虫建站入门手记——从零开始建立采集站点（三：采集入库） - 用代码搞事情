{"title": "Python爬虫建站入门手记——从零开始建立采集站点（三：采集入库） - 用代码搞事情 ", "index": "python爬虫,python", "content": "上回，我已经大概把爬虫写出来了。\n我写了一个内容爬虫，一个爬取tag里面内容链接的爬虫\n其实还差一个，就是收集一共有哪些tag的爬虫。但是这里先不说这个问题，因为我上次忘了 这次又不想弄。。\n还有个原因：如果实际采集的话，直接用http://segmentfault.com/questions/newest?page=1这个链接 获取所有问题，挨个爬就行。\n\n进入正题\n\n第三部分，采集入库。\n\n3.1 定义数据库（or model or schema）\n\n为了入库，我需要在Django定义一个数据库的结构。（不说nosql和mongodb（也是一个nosql但是很像关系型）的事）\n还记得那个名叫web的app么，里面有个叫models.py的文件，我现在就来编辑它。\n\nbashvim ~/python_spider/web/models.py\n\n\n内容如下:\n\npython# -*- coding: utf-8 -*-\nfrom django.db import models\n\n# Create your models here.\n\n\nclass Tag(models.Model):\n    title = models.CharField(max_length=30)\n\n    def __unicode__(self):\n        return self.title\n\n\nclass Question(models.Model):\n    title = models.CharField(max_length=255)\n    content = models.TextField()\n    tags = models.ManyToManyField(Tag, related_name='questions')\n    sf_id = models.CharField(max_length=16, default='0')　＃　加上这个可以记住问题在sf的位置，方便以后更新或者其他操作\n    update_date = models.DateTimeField(auto_now=True)\n\n    def __unicode__(self):\n        return self.title\n\n\nclass Answer(models.Model):\n    question = models.ForeignKey(Question, related_name='answers')\n    content = models.TextField()\n\n    def __unicode__(self):\n        return 'To question %s' % self.question.title\n\n\n都很直白，关于各个field可以看看 Django 的文档。\n\n然后，我需要告诉我的python_spider项目，在运行的时候加载web这个app（项目不会自动加载里面的app）。\n\nbashvim ~/python_spider/python_spider/settings.py\n\n\n在INSTALLED_APPS里面加入web:\n\npythonINSTALLED_APPS = (\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'web',\n)\n\n\n下面，就可以用django自动生成数据库schema了\n\nbashcd ~/python_spider\npython manage.py makemigrations\npython manage.py migrate\n\n\n现在，我~/python_spider目录就产生了一个db.sqlite3文件，这是我的数据库。\n把玩一番我的模型\n\npython>>> from web.models import Answer, Question, Tag\n>>> tag = Tag()\n>>> tag.title = u'测试标签'\n>>> tag.save()\n>>> tag\n<Tag: 测试标签>\n>>> question = Question(title=u'测试提问', content=u'提问内容')\n>>> question.save()\n>>> question.tags.add(tag)\n>>> question.save()\n>>> answer = Answer(content=u'回答内容', question=question)\n>>> answer.save()\n>>> tag.questions.all() # 根据tag找question\n[<Question: 测试提问>]\n>>> question.tags.all() # 获取question的tags\n[<Tag: 测试标签>]\n>>> question.answers.all() # 获取问题的答案\n[<Answer: To question 测试提问>]\n\n\n以上操作结果正常，说明定义的models是可用的。\n\n3.2 入库\n\n接下来，我需要把采集的信息入库，说白了，就是把我自己蜘蛛的信息利用django的ORM存到django连接的数据库里面，方便以后再用Django读取用于做站。\n\n入库的方法太多了，这里随便写一种，就是在web app里面建立一个spider.py, 里面定义两个蜘蛛，继承之前自己写的蜘蛛，再添加入库方法。\n\nbashvim ~/python_spider/web/spider.py\n\n\n代码如下：\n\npython# -*- coding: utf-8 -*-\nfrom sfspider import spider\nfrom web.models import Answer, Question, Tag\n\n\nclass ContentSpider(spider.SegmentfaultQuestionSpider):\n\n    def save(self): # 添加save()方法\n        sf_id = self.url.split('/')[-1] # 1\n        tags = [Tag.objects.get_or_create(title=tag_title)[0] for tag_title in self.tags]　＃ 2\n        question, created = Question.objects.get_or_create(\n            sf_id=sf_id,\n            defaults={'title':self.title, 'content':self.content}\n        ) # 3\n        question.tags.add(*tags) # 4\n        question.save()\n        for answer in self.answers:\n            Answer.objects.get_or_create(content=answer, question=question)\n        return question, created\n\n\nclass TagSpider(spider.SegmentfaultTagSpider):\n\n    def crawl(self): # 采集当前分页\n        sf_ids = [url.split('/')[-1] for url in self.questions]\n        for sf_id in sf_ids:\n            question, created = ContentSpider(sf_id).save()\n\n    def crawl_all_pages(self):\n        while True:\n            print u'正在抓取TAG:%s, 分页:%s' % (self.tag_name, self.page) # 5\n            self.crawl()\n            if not self.has_next_page:\n                break\n            else:\n                self.next_page()\n\n\n\n  \n这个地方写得很笨，之前该在SegmentfaultQuestionSpider加上这个属性。\n  创建或者获取该提问的tags\n  创建或者获取提问，采用sf_id来避免重复\n  把tags都添加到提问，这里用*是因为这个方法原本的参数是(tag1, tag2, tag3)。但是我们的tags是个列表\n  测试的时候方便看看进度\n  \n\n\n然后，测试下我们的入库脚本\n\nbashpython manage.py shell\n\n\npython>>> from web.spider import TagSpider\n>>> t = TagSpider(u'微信')\n>>> t.crawl_all_pages()\n正在抓取TAG:微信, 分页:1\n正在抓取TAG:微信, 分页:2\n正在抓取TAG:微信, 分页:3\nKeyboardInterrupt # 用control-c中断运行，测试一下就行:)\n>>> from web.models import Tag, Question\n>>> Question.objects.all()\n[<Question: 测试提问>, <Question: 微信支付获取prepayid，返回签名不匹配，>, <Question: 微信js怎么获取openID的>, <Question: 微信支付时加入attach参数提示签名错误>, <Question: 微信支付JSAPI调用返回fail_invalid_appid>, <Question: 微信消息连接打开  和  扫码打开连接有什么区别>, <Question: django做微信开发后台时无法返回response>, <Question: 微信端内置浏览器对canvas的支持有问题>, <Question: 分享到微信朋友圈的网页为什么点开直接跳至页尾？>, <Question: 微信支付开发：发起微信支付的时候，报错：invalid signature>, <Question: 前端加密代码有什么好办法不被破解>, <Question: 有没有桌面移动一体化网站发布方案,有市场吗?>, <Question: 微信如何获取用户的头像>, <Question: 重新设置微信自定义菜单 手机端没有显示该菜单>, <Question: 如何在用户输入关键字时自动回复图片，一张整体图。>, <Question: 手机图片上传是倒着的>, <Question: 微信内网页上传图片问题>, <Question: 如何转码微信多媒体下载接口的音频文件？>, <Question: 微信开放平台创建应用时，不能上传应用图片>, <Question: 微信页面中，怎么打开已安装的app？>, '...(remaining elements truncated)...']\n>>> Question.objects.get(pk=5).tags.all() # 数据库中id=5的question的tags\n[<Tag: 微信>, <Tag: 微信公众平台>, <Tag: 微信js-sdk>, <Tag: openid>]\n\n\n3.3 设置django.contrib.admin来查看和编辑内容\n\n为了更直观的观察我采集的数据，我可以利用django自带的admin\n编辑文件\n\nbashvim ~/python_spider/web/admin.py\n\n\npythonfrom django.contrib import admin\nfrom web.models import Tag, Question, Answer\n\nadmin.site.register(Tag)\nadmin.site.register(Question)\nadmin.site.register(Answer)\n\n\n然后创建超级用户\n\nbashpython manage.py createsuperuser # 根据提示创建\n\n\n启动测试服务器\n\nbashpython manage.py runserver 0.0.0.0:80 # 我这是在runabove上，本地直接manage.py runserver\n\n\n然后，我访问http://192.99.71.91/admin/登录刚刚创建的账号，就能对内容进行查看和编辑了\n\nOK, 今天的内容到此，\n下一篇，是编写django的view，套用简单的模板来建站。\n\n                ", "mainLikeNum": ["3 "], "mainBookmarkNum": "73"}