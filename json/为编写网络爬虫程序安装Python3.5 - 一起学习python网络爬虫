{"title": "为编写网络爬虫程序安装Python3.5 - 一起学习python网络爬虫 ", "index": "python,网络爬虫,编程语言,数据采集,网页抓取", "content": "\n1. 下载Python3.5.1安装包\n1.1 进入python官网，点击menu->downloads，网址：Download Python\n1.2 根据系统选择32位还是64位，这里下载的可执行exe为64位安装包\n2. 安装Python3.5\n2.1 双击打开安装包，选择自定义路径(注意安装路径中尽量不要含有有中文或者空格)，然后选中Add Python 3.5 to PATH(将Python安装路径添加到系统变量Path中，这样做以后在任意目录下都可以执行pyhton命令了)\n2.2 默认全选，Next\n2.3 修改安装路径，勾选加上Install for all user为所有用户安装和Precompile standard library 预编译标准库，然后点击Install\n2.4 等待安装完成\n\n2.5 验证，使用快捷键win + R 或 右键开始选择运行，输入cmd回车，打开命令提示符窗口，然后输入python->回车，若出现python版本信息则软件安装完成\n3. 简单实践，敲一个简单小爬虫程序\n3.1 安装lxml库，由于直接使用pip lxml 对于3.0x以上的版本来说经常会出现版本不适应而失败，所以这里介绍直接使用whl文件安装\n3.1.1 下载对应python3.5版本的lxml库，下载网址：http://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml\n\n3.1.2 同检查python是否安装成功一样，使用快捷键win + R 或 右键开始选择运行，输入cmd回车，打开命令提示符窗口，然后\npip install E:\\demo\\lxml-3.6.4-cp35-cp35m-win_amd64.whl（下载的lxml库whl文件存放路径）\n\n可能碰到问题，pip的版本低了，需要更新一下pip的版本。更新pip版本命令:\npython -m pip install -U pip\n更新完成后，再次使用pip命令:\npip install E:\\demo\\lxml-3.6.4-cp35-cp35m-win_amd64.whl\n\n\n3.2 Lxml库安装成功后，环境就准备好了, 可以开始敲代码了\n3.2.1引入Gooseeker规则提取器模块gooseeker.py（引入该模块的原因和价值），在自定义目录下创建gooseeker.py文件，如：这里为E:Demogooseeker.py，再以记事本打开，复制下面的代码粘贴\n#!/usr/bin/python\n# -*- coding: utf-8 -*-\n# 模块名: gooseeker\n# 类名: GsExtractor\n# Version: 2.0\n# 说明: html内容提取器\n# 功能: 使用xslt作为模板，快速提取HTML DOM中的内容。\n# released by 集搜客(http://www.gooseeker.com) on May 18, 2016\n# github: https://github.com/FullerHua/jisou/core/gooseeker.py\n\nfrom urllib import request\nfrom urllib.parse import quote\nfrom lxml import etree\nimport time\n\nclass GsExtractor(object):\n    def _init_(self):\n        self.xslt = \"\"\n    # 从文件读取xslt\n    def setXsltFromFile(self , xsltFilePath):\n        file = open(xsltFilePath , 'r' , encoding='UTF-8')\n        try:\n            self.xslt = file.read()\n        finally:\n            file.close()\n    # 从字符串获得xslt\n    def setXsltFromMem(self , xsltStr):\n        self.xslt = xsltStr\n    # 通过GooSeeker API接口获得xslt\n    def setXsltFromAPI(self , APIKey , theme, middle=None, bname=None):\n        apiurl = \"http://www.gooseeker.com/api/getextractor?key=\"+ APIKey +\"&theme=\"+quote(theme)\n        if (middle):\n            apiurl = apiurl + \"&middle=\"+quote(middle)\n        if (bname):\n            apiurl = apiurl + \"&bname=\"+quote(bname)\n        apiconn = request.urlopen(apiurl)\n        self.xslt = apiconn.read()\n    # 返回当前xslt\n    def getXslt(self):\n        return self.xslt\n    # 提取方法，入参是一个HTML DOM对象，返回是提取结果\n    def extract(self , html):\n        xslt_root = etree.XML(self.xslt)\n        transform = etree.XSLT(xslt_root)\n        result_tree = transform(html)\n        return result_tree\n    # 提取方法，入参是html源码，返回是提取结果\n    def extractHTML(self , html):\n        doc = etree.HTML(html)\n        return self.extract(doc)\n\n3.2.2 在提取器模块gooseeker.py同级目录下创建一个.py后缀文件，如这里为E:Demofirst.py，再以记事本打开，敲入代码:\n# -*- coding: utf-8 -*-\n# 使用gsExtractor类的示例程序\n# 访问集搜客论坛，以xslt为模板提取论坛内容\n# xslt保存在xslt_bbs.xml中\n# 采集结果保存在result.xml中\n\nimport os\nfrom urllib import request\nfrom lxml import etree\nfrom gooseeker import GsExtractor\n\n# 访问并读取网页内容\nurl = \"http://www.gooseeker.com/cn/forum/7\"\nconn = request.urlopen(url)\ndoc = etree.HTML(conn.read())\n\nbbsExtra = GsExtractor()   \nbbsExtra.setXsltFromAPI(\"31d24931e043e2d5364d03b8ff9cc77e\" , \"gooseeker_bbs_xslt\")   # 设置xslt抓取规则\nresult = bbsExtra.extract(doc)   # 调用extract方法提取所需内容\n\n# 当前目录\ncurrent_path = os.getcwd()\nfile_path = current_path + \"/result.xml\"\n\n# 保存结果\nopen(file_path,\"wb\").write(result)\n\n# 打印出结果\nprint(str(result).encode('gbk','ignore').decode('gbk'))\n\n3.2.3 执行first.py，使用快捷键win + R 或 右键开始选择运行，输入cmd回车，打开命令提示窗口，进入first.py文件所在目录，输入命令 :python first.py 回车\n\n3.2.4 查看保存结果文件,进入first.py文件所在目录，查看名称为result的xml文件（即采集结果）\n4. 总结\n安装步骤还是很简单，主要需要注意的是：\n\n对应系统版本安装；\n将安装路径加入系统环境变量Path。\n\n后面将会讲到如何结合Scrapy快速开发Python爬虫。\n5. 集搜客GooSeeker开源代码下载源\nGooSeeker开源Python网络爬虫GitHub源\n6.相关文章\n《Python即时网络爬虫项目启动说明》\n7. 文章修改历史\n2016-09-28：V1.02016-10-25：补充3.2.1代码\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "2"}