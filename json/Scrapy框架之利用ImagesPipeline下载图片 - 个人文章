{"title": "Scrapy框架之利用ImagesPipeline下载图片 - 个人文章 ", "index": "scrapy,python", "content": "1.ImagesPipeline简介\nScrapy用ImagesPipeline类提供一种方便的方式来下载和存储图片。\n特点：\n\n将下载图片转换成通用的JPG和RGB格式\n避免重复下载\n缩略图生成\n图片大小过滤\n\n\n2.ImagesPipeline工作流程\n当使用图片管道 ImagePipeline,典型的工作流程如下:\n\n在一个爬虫里,你抓取一个项目,把其中图片的URL放入image_urls组内。\n项目从爬虫内返回,进入项目管道。\n当项目进入ImagePipeline, image_urls组内的URLs将被Scrapy的调度器和下载器安排下载(这意味着调度器和中间件可以复用),当优先级更高,会在其他页面被抓取前处理. 项目会在这个特定的管道阶段保持\"locker\"的状态,直到完成图片的下载(或者由于某些原因未完成下载)。\n当图片下载完, 另一个组(images)将被更新到结构中,这个组将包含一个字典列表,其中包括下载图片的信息,比如下载路径,源抓取地址(从image_urls组获得)和图片的校验码. images列表中的图片顺序将和源image_urls组保持一致.如果某个图片下载失败,将会记录下错误信息,图片也不会出现在images组中。\n\n\n3.操作过程\n项目目录结构：\n\n<font size=5>要想成功爬取图片，需要经过以下几个步骤：\n（1） 在items.py中添加image_urls、images和image_paths字段，代码如下：\nclass DoubanImgsItem(scrapy.Item):\n    # define the fields for your item here like:\n    # name = scrapy.Field()\n    image_urls = Field()\n    images = Field()\n    image_paths = Field()\n（2）在settings.py中设置条件和属性，代码如下：\n# Configure item pipelines\n# See http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.html\n\n# ImagePipeline的自定义实现类\nITEM_PIPELINES = {\n    'douban_imgs.pipelines.DoubanImgDownloadPipeline': 300,\n}\n#设置图片下载路径\nIMAGES_STORE = 'D:\\\\doubanimgs'\n# 过期天数\nIMAGES_EXPIRES = 90  #90天内抓取的都不会被重抓\n（3）在spiders/download_douban.py中书写ImageSpider的代码：\n# coding=utf-8\nfrom scrapy.spiders import Spider\nimport re\nfrom scrapy import Request\nfrom ..items import DoubanImgsItem\n\n\nclass download_douban(Spider):\n    name = 'download_douban'\n\n    default_headers = {\n        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n        'Accept-Encoding': 'gzip, deflate, sdch, br',\n        'Accept-Language': 'zh-CN,zh;q=0.8,en;q=0.6',\n        'Cache-Control': 'max-age=0',\n        'Connection': 'keep-alive',\n        'Host': 'www.douban.com',\n        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36',\n    }\n\n    def __init__(self, url='1638835355', *args, **kwargs):\n        self.allowed_domains = ['douban.com']\n        self.start_urls = [\n            'http://www.douban.com/photos/album/%s/' % (url)]\n        self.url = url\n        # call the father base function\n\n        # super(download_douban, self).__init__(*args, **kwargs)\n\n    def start_requests(self):\n\n        for url in self.start_urls:\n            yield Request(url=url, headers=self.default_headers, callback=self.parse)\n\n    def parse(self, response):\n        list_imgs = response.xpath('//div[@class=\"photolst clearfix\"]//img/@src').extract()\n        if list_imgs:\n            item = DoubanImgsItem()\n            item['image_urls'] = list_imgs\n            yield item\n\n（4）在pipelines.py中自定义ImagePipeline代码：\n# -*- coding: utf-8 -*-\n\n# Define your item pipelines here\n#\n# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n# See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html\nfrom scrapy.pipelines.images import ImagesPipeline\nfrom scrapy.exceptions import DropItem\nfrom scrapy import Request\nfrom scrapy import log\n\n\nclass DoubanImgsPipeline(object):\n    def process_item(self, item, spider):\n        return item\n\n\nclass DoubanImgDownloadPipeline(ImagesPipeline):\n    default_headers = {\n        'accept': 'image/webp,image/*,*/*;q=0.8',\n        'accept-encoding': 'gzip, deflate, sdch, br',\n        'accept-language': 'zh-CN,zh;q=0.8,en;q=0.6',\n        'cookie': 'bid=yQdC/AzTaCw',\n        'referer': 'https://www.douban.com/photos/photo/2370443040/',\n        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36',\n    }\n\n    def get_media_requests(self, item, info):\n        for image_url in item['image_urls']:\n            self.default_headers['referer'] = image_url\n            yield Request(image_url, headers=self.default_headers)\n\n    def item_completed(self, results, item, info):\n        image_paths = [x['path'] for ok, x in results if ok]\n        if not image_paths:\n            raise DropItem(\"Item contains no images\")\n        item['image_paths'] = image_paths\n        return item\n\n在自定义ImagePipeline代码中，作为重要的是要重载get_media_requests(self, item, info)和item_completed(self, results, item, info)这两个函数。\nget_media_requests(self,item, info)：\nImagePipeline根据image_urls中指定的url进行爬取，可以通过get_media_requests为每个url生成一个Request。如：\nfor image_url in item['image_urls']:\n            self.default_headers['referer'] = image_url\n            yield Request(image_url, headers=self.default_headers)\n\nitem_completed(self, results, item, info)：\n图片下载完毕后，处理结果会以二元组的方式返回给item_completed()函数。这个二元组定义如下：\n(success, image_info_or_failure)\n其中，第一个元素表示图片是否下载成功；第二个元素是一个字典。如：\n def item_completed(self, results, item, info):\n        image_paths = [x['path'] for ok, x in results if ok]\n        if not image_paths:\n            raise DropItem(\"Item contains no images\")\n        item['image_paths'] = image_paths\n        return item\n\n4.爬取结果\n运行结果如下：\n\n下载成功以后，你就会在刚才设置的保存图片的路径里看到下载完成的图片：IMAGES_STORE = 'D:\\doubanimgs'\n\n\n5.扩展\n默认情况下，使用ImagePipeline组件下载图片的时候，图片名称是以图片URL的SHA1值进行保存的。\n如：图片URL:http://www.example.com/image.jpgSHA1结果：3afec3b4765f8f0a07b78f98c07b83f013567a0a则图片名称：3afec3b4765f8f0a07b78f98c07b83f013567a0a.jpg\n如果想进行更改，请参考：使用scrapy框架的ImagesPipeline下载图片如何保持原文件名呢？\n\n\n                ", "mainLikeNum": ["5 "], "mainBookmarkNum": "6"}