{"title": "Python学习笔记：数据可视化(一) - 镜心的小树屋 ", "index": "python,数据可视化", "content": "python相关\n基础概念\n\n数据:离散的，客观事实的数字表示\n信息：处理后的数据，为实际问题提供答案\n\n　　- 为数据提供一种关系或一个关联后，数据就成了信息，这种关联通过提供数据背景来完成\n知识: 是数据、信息和通过经验获得的技能\n　　- 知识包括做出适当决策的能力和执行时所需的技能\n观点：\n　- 如何获取观点: 基于已有数据信息得到最佳或现实的决策，我们可以通过数据分析\n数据分析　依赖数学算法来确定产生观点的数据之间的关系\n信息是可量化的、可测度的、有形式的，可被访问、生成、存储、分发、搜索、压缩和复制。信息可以通过数量或信息量进行量化。，信息可转换为知识，知识要比信息更量化。在某些领域，知识持续经历一个不断发展周期。当数据发生变化时，这种演变过程随之发生。\n通过离散算法\n数据转换：数据被转换成信息，得到进一步处理，然后用来解决问题\n　- 数据的种类不同，包括表现数据, 实验数据,基准数据\n可视化的整个过程需要不用技能和专业领域的人。\n数据工人努力收集数据并完成分析数学家和统计学家理解可视化设计原则，并用这些原则完成数据交流设计师和艺术家和开发者具备可视化转换的技能业务分析员等找寻行为模式，离群点或突发趋势整个过程额步骤是：\n\n获取或收集数据：\n解析和过滤数据：用编程方法进行解析、清洗和减少数据\n分析提炼数据： 删除噪音和一些不必要维度，发展模式\n呈现和交互 用更容易得到和理解的方式展示数据\n\n数据预处理\n\n数据清洗：用于数据的噪音清理和矛盾纠正\n数据集成：将多个数据源的数据合并起来（仓库）\n数据压缩：通过合并、聚集、消除冗余特征等方法减少数据量\n\n数据转换：将数据缩放到一个较小的区间，从而提高处理和可视化的精确性和效率\n提取数据 -> 删除不一致数据 ->重建缺失数据 ->数据标准化 -> 验证数据\n\n\n-\n数据处理\n数据集资源\n数据分析与可视化\n数据的可视化是表达信息的过程，在可视化化过程我们要思考：\n\n要处理多少变量？我们试图画出怎样的图像？\nx轴和y轴指代什么？（三维图中有ｚ轴）\n数据的大小是否被标准化?数据点的大小意味着什么？\n我们的选色对吗？\n对于时间序列数据，我们是否试图识别趋势或相关性\n\n这里有个学生数据：http://www.knapdata.com/pytho... \n# -*- coding:utf-8 -*-\n# usr/bin/python 3.5+\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nstudents = pd.read_csv(\"data/ucdavis.csv\")\n\ng = sns.FacetGrid(students, hue=\"gender\", palette=\"Set1\", size=6)\ng.map(plt.scatter, \"gpa\", \"computer\", s=250, linewidth= 0.65, edgecolor=\"white\")\n\ng.add_legend()\nplt.show()\nseaborn: http://seaborn.pydata.org/api...\nFacetGrid 类可以刻画三个维度：　行、列、色调\n　- 用于对数据子集中的一个变量的分布或者多个变量关系进行可视化\nbarchart\nmatplotlib.pyplot.bar\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nN = 7\nwinnersplot = (142.6, 125.3, 62.0, 81.0, 145.6, 319.4, 178.1 )\nind = np.arange(N)\nwidth = 0.35\nfig, ax = plt.subplots()\nwinners = ax.bar(ind, winnersplot, width, color='#ffad00')\nprint(winners)\n\nnomineesplot = (109.4, 94.8, 60.7, 44.6, 116.9,262.5,102.0)\nnominees = ax.bar(ind + width, nomineesplot, width, color='#9b3c38')\n\n# add some text for labels ,title and axes ticks\n\nax.set_xticks(ind+width)\nax.set_xticklabels(('小明', '小红', '小凡', '小钱', '小刘', '小赵', '小文'))\nax.legend((winners[0], nominees[0]),('奥斯卡金奖得住','奥斯卡得住提名'))\n\ndef autolabel(rects):\n    # attach some text labels\n   for rect in rects:\n       height = rect.get_height()\n       hcap = \"$\" + str(height) + \"M\"\n       ax.text(rect.get_x() + rect.get_width()/2. ,height, hcap,ha = 'center',va='bottom',rotation='horizontal')\n\nautolabel(winners)\nautolabel(nominees)\n\nplt.show()\n\npiechart\nmatplotlib.pyplot.pie\nimport matplotlib.pyplot as plt\nlabels = 'Computer Science', 'Foreign Languges','Analytical Chemistry', 'Education', 'Humanities', 'Physics', 'Biology', 'Math and Statistics', 'Engineering'\nsizes = [21, 4, 7, 7, 8, 9, 10, 15, 19]\ncolors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral','red', 'purple', '#f280de', 'orange', 'green']\nexplode = (0,0,0,0,0,0,0,0,0.1)\nplt.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',colors=colors)\nplt.axis('equal')\nplt.show()\nbox chart\nscatter\n散点图\n散点图是同一组研究对象的两个变量间关系的可视化\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nstudents = pd.read_csv(\"data/ucdavis.csv\")\ng = sns.FacetGrid(students, palette=\"Set10\",size=7)\ng.map(plt.scatter, \"momheight\", \"height\",s=140, linewidth=.7,edgecolor = \"#ffad40\",color=\"#ff8000\")\ng.set_axis_labels(\"Mothers Heilsght\", \"Students Height\")\nplt.show()\n散点图最适合研究不同变量之间的关系：\n\n男性与女性人群中不同年龄阶段得皮肤病的可能性\nIQ测试得分和GPA之间的相关性\n\n另外我们还要考虑：\n\n添加一条趋势线或最佳拟合线（如果关系是线性的）：添加趋势线可以展示数据之间的关联性\n使用信息标记类型：信息标记类型适用于通过形状和颜色提高视觉效果来解读数据的情况\n\n气泡图\n气泡图展示了数据的三个维度，每个数据点有三重维度(a, b , c), xy轴的坐标表示两个维度变量，气泡的大小表示第三个维度的定量测度结果\nHistograms直方图\n直方图(Histogram)又称质量分布图。是一种统计报告图，由一系列高度不等的纵向条纹或线段表示数据分布的情况。 一般用横轴表示数据类型，纵轴表示分布情况。\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats, integrate\nimport matplotlib.pyplot as plt  #导入\n\nimport seaborn as sns\nsns.set(color_codes=True)#导入seaborn包设定颜色\n\nnp.random.seed(sum(map(ord, \"distributions\")))\nx = np.random.normal(size=100)\nsns.distplot(x, kde=False, rug=True);#kde=False关闭核密度分布,rug表示在x轴上每个观测上生成的小细条（边际毛毯）\nplt.show()\n当绘制直方图时，你最需要确定的参数是矩形条的数目以及如何放置它们。利用bins可以方便设置矩形条的数量。如下所示：\nsns.distplot(x, bins=20, kde=False, rug=True);#设置了20个矩形条\n\n核密度估计图\n核密度估计（Kernel Density Estimation, KDE）是一种用来估计概率密度函数的非参数方法。可以通过观测到的数据点取平均实现平滑逼近。\n核密度估计是在概率论中用来估计未知的密度函数，属于非参数检验方法之一。．由于核密度估计方法不利用有关数据分布的先验知识，对数据分布不附加任何假定，是一种从数据样本本身出发研究数据分布特征的方法，因而，在统计学理论和应用领域均受到高度的重视。\n核密度函数与直方图密切相关，但有时能够通过核概念用平滑性或连续性赋予实际含义。概率密度函数(Probablity Density Function,PDF)的核是PDF的形式。这种形式不考虑非变量函数因素。\n这里我们用一个鸢尾花数据集和seaborn包展示KDE图使用seaborn 和matplotlib演示KDE图\nseaborn.distplot\nThis function combines the matplotlib hist function (with automatic calculation of a good default bin size) with the seaborn kdeplot() and rugplot() functions. It can also fit scipy.stats distributions and plot the estimated PDF over the data.\nseaborn的displot()集合了matplotlib的hist()与核函数估计kdeplot的功能，增加了rugplot分布观测条显示与利用scipy库fit拟合参数分布的新颖用途。具体用法如下：\nseaborn入门（一）：distplot与kdeplotseaborn.kdeplot\ndistplot()\ndistplot 函数默认同时绘制直方图和KDE(核密度图)\nfrom numpy.random import randn\nimport matplotlib as mpl\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#引入鸢尾花数据集\ndf_iris = sns.load_dataset(\"iris\")\nfig, axes = plt.subplots(1,2)\n# print(df_iris['petal_length'])\n# print(axes[0])\n\n\n# distplot 函数默认同时绘制直方图和KDE(核密度图),开启rug细条\nsns.distplot(df_iris['petal_length'], ax= axes[0], rug = True)\n# shade 阴影\nsns.kdeplot(df_iris['petal_length'], ax = axes[1], shade = True)\n\nplt.show()\n如果不需要核密度图，可以将kde参数设置成False。\nsns.distplot(df_iris['petal_length'], ax= axes[0], kde = False, rug = True)\n如果不需要核密度图，可以将hist参数设置成False。\nsns.distplot(df_iris['petal_length'], ax= axes[0], hist = False, rug = True)\n\n# Fitting parametric distributions拟合参数分布\n\n# 可以利用distplot() 把数据拟合成参数分布的图形并且观察它们之间的差距,再运用fit来进行参数控制。\n\n\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set(style=\"white\", palette=\"muted\", color_codes=True)\nrs = np.random.RandomState(10)\n\n# Set up the matplotlib figure\nf, axes = plt.subplots(2, 2, figsize=(7, 7), sharex=True)\nsns.despine(left=True)\n\n#引入鸢尾花数据集\ndf_iris = sns.load_dataset(\"iris\")\n\n# Plot a simple histogram with binsize determined automatically\n\nsns.distplot(df_iris['petal_length'], ax= axes[0, 0], kde = False, color=\"b\")\n\n# Plot a kernel density estimate and rug plot\n\nsns.distplot(df_iris['petal_length'], ax= axes[0, 1], kde = False, color=\"r\", rug=True)\n\n# Plot a filled kernel density estimate\n\nsns.distplot(df_iris['petal_length'], ax= axes[1, 0], hist = False, color=\"g\", kde_kws={\"shade\": True})\n\n# Plot a historgram and kernel density estimate\nsns.distplot(df_iris['petal_length'], color=\"m\", ax=axes[1, 1])\n\nplt.setp(axes, yticks=[])\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nFitting parametric distributions拟合参数分布\n使用Scipy和Numpy演示KDE图\n\n我们用Scipy 和 Numpy表明概率密度函数\n首先用Scipy中的norm()创建正态分布样本\n然后用Numpy中的hstack()进行水平方向上的堆叠\n再用Scipy中的gaussian_kde()\n\nfrom scipy.stats.kde import gaussian_kde\nfrom scipy.stats import norm\nfrom numpy import linspace, hstack\nimport matplotlib.pyplot as plt\nfrom matplotlib.pylab import plot,show, hist\n\nsample1 = norm.rvs(loc=-0.1,scale=1,size=320)\nsample2 = norm.rvs(loc=2.0,scale=0.6,size=130)\nsample = hstack([sample1,sample2])\nprobDensityFun = gaussian_kde(sample)\nplt.title(\"KDE Demonstration using Scipy and Numpy\",fontsize=20)\nx = linspace(-5,5,200)\nplot(x,probDensityFun(x),'r')\nhist(sample,normed=1,alpha=0.45,color='purple')\nshow()\n\n利用kdeplot探索某大学学生消费习惯与助学金获得关系数据集如下所示：\n\n表面三维图\n常见案例\nEbola案例\n体育案例\n美国死亡率\n金融与统计模型\n统计与机器学习\n生物信息学、遗传学与网络模型\n高级可视化\n更多内容可好看白鲸鱼的另一个学习记录：可视化技术栈及学习计划\n参考\n数据可视化Python数据可视化-seabornmatplotlib 绘图可视化知识点整理10分钟python图表绘制 | seaborn入门（一）：distplot与kdeplot Python mpl_toolkits画3D图matplotlib basemap toolkit\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "1"}