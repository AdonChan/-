{"title": "scrapy的学习之路1(简单的例子) - 个人文章 ", "index": "python,scrapy", "content": "scrapy的安装\n环境:python3.6\n1\n    pip install -i https://pypi.douban.com/simple/  scrapy\n\n2\n    scrapy startproject ArticleSpider\nmain.py是后面创建用来运行scrapy的\n\n\n3\ncd ArticleSpider\n\nscrapy genspider jobbole blog.jobbole.com\n                 ------- ----------------\n                 spider名    网站域名\n\n\n4\n在ArticleSpider创建main.py,可以通过此文件运行scrapy\nfrom scrapy.cmdline import execute\nimport sys\nimport os\n\n\n# print(__file__) #本文件名\n# print(os.path.dirname(__file__)) #父文件名\n# print(os.path.abspath(os.path.dirname(__file__))) #路径和父文件名\n\nsys.path.append(os.path.dirname(os.path.abspath(__file__))) #设置环境，必须\n\nexecute([\"scrapy\", \"crawl\", \"jobbole\"])\n\n5\n以上运行可能在win下会报错\n\n\n6\nsettings.py\n\n准备工作完\n\n1\n在jobbole.py下\n# -*- coding: utf-8 -*-\nimport scrapy\nfrom scrapy.http import Request\nimport re\nfrom urllib import parse\n\n\nclass JobboleSpider(scrapy.Spider):\n    name = 'jobbole'\n    allowed_domains = ['blog.jobbole.com']\n    start_urls = ['http://blog.jobbole.com/all-posts/']\n    \n    def parse(self, response):\n        # 获取列表页每一个item的url\n        post_urls = response.css('#archive .floated-thumb .post-thumb a::attr(href)').extract()\n        for post_url in post_urls:\n            print(post_url)\n            yield Request(url=parse.urljoin(response.url, post_url), callback=self.parse_info)  # 把获取到的url交给详情页的方法处理\n        # 获取下一页的url\n        next_url = response.css('.next.page-numbers::attr(href)').extract_first()\n        if next_url:\n            yield Request(url=parse.urljoin(response.url, next_url), callback=self.parse)  # 把获取到的下一页的url交给自己的方法处理\n    \n    \"\"\"获取详情页的信息\"\"\"\n    def parse_info(self, response):\n        # 以下都是获取详情页信息\n        res_title = response.xpath('//div[@class=\"entry-header\"]/h1/text()').extract_first()\n        res_date = response.xpath('//p[@class=\"entry-meta-hide-on-mobile\"]/text()').extract_first().strip().replace('·', '').strip()\n        res_zhan = response.xpath('//span[contains(@class, \"vote-post-up\")]/h10/text()').extract_first()\n        res_content = response.xpath('//div[@class=\"entry\"]/p/text()').extract_first()\n\n        res_cate_a = response.xpath('//p[@class=\"entry-meta-hide-on-mobile\"]/a/text()').extract_first()\n        res_cate_b = [i.strip() for i in res_cate_a if not i.strip().endswith('评论')]\n        res_cate_c = ','.join(res_cate_b)\n\n        res_shoucang = response.xpath('//div[@class=\"post-adds\"]/span[2]/text()').extract_first().strip()\n        match_obj1 = re.match('.*(\\d+).*', res_shoucang)\n        if match_obj1:\n            res_shoucang = match_obj1.group(1)\n        else:\n            res_shoucang = 0\n\n        res_comment = response.xpath('//div[@class=\"post-adds\"]/a/span/text()').extract_first().strip()\n        match_obj2 = re.match('.*(\\d+).*', res_comment)\n        if match_obj2:\n            res_comment = match_obj2.group(1)\n        else:\n            res_comment = 0\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}