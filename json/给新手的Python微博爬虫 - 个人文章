{"title": "给新手的Python微博爬虫 - 个人文章 ", "index": "python,网页爬虫,微博采集", "content": "为什么说是给新手的呢？\n因为项目很小，算上空行才200来行代码，甚至有些“简陋”。相比于动不动写成几个大模块的教程，新手们能更快理解我在干什么，节省学习时间。当然，该有的模拟登陆，数据解析也都不少。\nTip: 结合项目代码看比较好\n一些说明\n\n爬的是手机端网页版的微博（听说这个爬起来简单，我就爬了）。\n模拟登陆采用POST表单实现，不是复制粘贴 cookie(复制粘贴没什么技术含量，都不用动脑子，想用的可以自己试一试)。\n最后的数据采用pickle序列化后存储在本地（想用数据库的自己改一下就好了，不会的可以去看看廖雪峰老师的教程）。\n微博内容只取文本内容。（因为我懒）\n为了不给别人添麻烦，亦本学习交流之意，对爬取的速度做了限制。\n\n代码结构\n\n大体上分为两部分，一个 WBCrawler 类，一个 show_random_data . 前者爬取并保存，后者随机检查一下。\n关于登录时所提交的表单涉及到的字段，我都在代码里面写了。看了它的javascript文件，有的字段在用帐号密码登录时就是空值。\nHTTP 请求用 requests.seesion 发送，并且在项目退出时会保存 session，以便再次使用。这里当然也是用的pickle序列化保存。\n为了节约，长微博和短微博会在不同的地方进行解析，所以大家会看到有的地方写了两种解析方式。\n其中有一个函数使用了  yield 语句，是为了降低耦合。关于  yield ，可以看廖雪峰老师的讲解。关于什么是耦合，我也不太清楚，我这里是为了不让函数之间调用得太紧凑，适当地独立出来。\n类的初始化函数中的 maximum 参数指爬取几页，默认爬两页。\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "4"}