{"title": "xiaolinBot（Twitter笑话集锦爬虫Bot）  Step1－最简爬虫 - 笔记 @BONFY ", "index": "twitter,python爬虫,python", "content": "Step1 - 最简爬虫\n环境准备\nPython3.5 最好使用venv\n另外需要两个必要的库：\n\nrequests : 一个封装了HTTP服务的python库\npyquery : 类似Jquery，使用非常方便\n\n$ pip install requests\n$ pip install pyquery\n开始\n实现第一个应用\n我们第一个应用实现的功能主要如下：\n\n访问一个页面,这里我们以 糗事百科(http://www.qiushibaike.com/) 为例\n获得页面的内容\n进行简单的处理，获得我们需要的内容\n\n\nimport requests\nfrom pyquery import PyQuery as pq\n\n__author__ = 'BONFY CHEN <foreverbonfy@163.com>'\n\n\nSITE = 'http://www.qiushibaike.com/'\nr = requests.get(SITE)\nassert r.status_code == 200\nd = pq(r.text)\ncontents = d(\"div .article\")\nfor item in contents:\n    i = pq(item)\n    content = i(\"div .content\").text()\n    print(content)\n\n结果\n\n简单分析\n\n利用 requests.get 获得页面\nassert 断言，如果网络问题 访问不到就退出\ncontents 利用 pyquery 获得所有文章 后续 读取 div class ＝ \"content\" 的为文本内容 （这里没有处理图片后续的讲解中会完善）\nprint 输出\n\n完整代码\n补充模仿浏览器的Headers,详情见 https://github.com/bonfy/xiaolinBot\n欢迎关注及一起交流\n请期待下一篇： 代码优化\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "1"}