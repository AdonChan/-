{"title": "Scrapy源码阅读之Scrapy的五大组件 - n_o_thi_ng ", "index": "scrapy,python", "content": "Scrapy五大组件介绍\nScrapy框架主要由五大组件组成，它们分别是调度器(Scheduler)、下载器(Downloader)、爬虫（Spider）和实体管道(Item Pipeline)、Scrapy引擎(Scrapy Engine)。下面我们分别介绍各个组件的作用。\n调度器\n调度器，说白了可以想像成一个URL（抓取网页的网址或者说是链接）的优先队列，由它来决定下一个要抓取的网址是什么，同时去除重复的网址（不做无用功）。用户可以跟据自己的需求定制调度器。\n下载器\n下载器，是所有组件中负担最大的，它用于高速地下载网络上的资源。Scrapy的下载器代码不会太复杂，但效率高，主要的原因是Scrapy下载器是建立在twisted这个高效的异步模型上的(其实整个框架都在建立在这个模型上的)。\n爬虫\n爬虫，是用户最关心的部份。用户定制自己的爬虫，用于从特定的网页中提取自己需要的信息，即所谓的实体(Item)。用户也可以从中提取出链接,让Scrapy继续抓取下一个页面。\n实体管道\n实体管道，用于处理爬虫提取的实体。主要的功能是持久化实体、验证实体的有效性、清除不需要的信息。\nScrapy引擎\nScrapy引擎是整个框架的核心。它用来控制调试器、下载器、爬虫。实际上，引擎相当于计算机的CPU,它控制着整个流程。\nScrapy运行流程\n\nScrapy运行流程大概如下：\n\n首先，引擎从调度器中取出一个链接(URL)用于接下来的抓取\n引擎把URL封装成一个请求(Request)传给下载器，下载器把资源下载下来，并封装成应答包(Response)\n然后，爬虫解析Response\n若是解析出实体（Item）,则交给实体管道进行进一步的处理。\n若是解析出的是链接（URL）,则把URL交给Scheduler等待抓取\n\n\n                ", "mainLikeNum": ["8 "], "mainBookmarkNum": "28"}