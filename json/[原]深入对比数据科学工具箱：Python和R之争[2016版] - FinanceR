{"title": "[原]深入对比数据科学工具箱：Python和R之争[2016版] - FinanceR ", "index": "python,r", "content": "\n概述\n在真实的数据科学世界里，我们会有两个极端，一个是业务，一个是工程。偏向业务的数据科学被称为数据分析（Data Analysis），也就是A型数据科学。偏向工程的数据科学被称为数据构建(Data Building)，也就是B型数据科学。\n从工具上来看，按由业务到工程的顺序，这个两条是：EXCEL >> R >> Python >> Scala\n在实际工作中，对于小数据集的简单分析来说，使用EXCEL绝对是最佳选择。当我们需要更多复杂的统计分析和数据处理时，我们就需要转移到 Python 和 R 上。在确定工程实施和大数据集操作时，我们就需要依赖 Scala 的静态类型等工程方法构建完整的数据分析系统。\nScala 和 Excel 是两个极端，对于大多数创业公司而言，我们没有足够多的人手来实现专业化的分工，更多情况下，我们会在 Python 和 R 上花费更多的时间同时完成数据分析（A型）和数据构建（B型）的工作。而许多人也对 Python 和 R 的交叉使用存在疑惑，所以本文将从实践角度对 Python 和 R 中做了一个详细的比较。\n应用场景对比\n应用Python的场景\n\n网络爬虫/抓取：尽管 rvest 已经让 R 的网络爬虫/抓取变得容易，但 Python 的 beautifulsoup 和 Scrapy 更加成熟、功能更强大，结合django-scrapy我们可以很快的构建一个定制化的爬虫管理系统。\n连接数据库:  R 提供了许多连接数据库的选择，但 Python 只用 sqlachemy 通过ORM的方式，一个包就解决了多种数据库连接的问题，且在生产环境中广泛使用。Python由于支持占位符操作，在拼接SQL语句时也更加方便。\n内容管理系统：基于Django，Python可以快速通过ORM建立数据库、后台管理系统，而R\n\n中的 Shiny 的鉴权功能暂时还需要付费使用。\nAPI构建：通过Tornado这个标准的网络处理库，Python也可以快速实现轻量级的API，而R则较为复杂。\n应用R的场景\n\n统计分析: 尽管 Python 里 Scipy、Pandas、statsmodels 提供了一系列统计工具 ，R 本身是专门为统计分析应用建立的，所以拥有更多此类工具。\n互动式图表/面板: 近来 bokeh、plotly、 intuitics 将 Python 的图形功能扩展到了网页浏览器，甚至我们可以用tornado+d3来进一步定制可视化页面，但 R 的 shiny 和 shiny dashboard 速度更快，所需代码更少。\n\n此外，当今数据分析团队拥有许多技能，选择哪种语言实际上基于背景知识和经验。对于一些应用，尤其是原型设计和开发类，工作人员使用已经熟悉的工具会比较快速。\n数据流编程对比\n接着，我们将通过下面几个方面，对Python 和 R 的数据流编程做出一个详细的对比。\n\n参数传递\n数据读取\n基本数据结构对照\n矩阵转化\n矩阵计算\n数据操作\n\n参数传递\nPython/R 都可以通过命令行的方式和其他语言做交互，通过命令行而不是直接调用某个类或方法可以更好地降低耦合性，在提高团队协作的效率。\n\n\n参数传递\nPython\nR\n\n\n\n命令行输入\nPython path/to/myscript.py arg1 arg2 arg3\nRscript path/to/myscript.R arg1 arg2 arg3\n\n\n脚本识别\nimport sys my_args = sys.argv\nmyArgs <- commandArgs(trailingOnly = TRUE)\n\n\n\n数据传输与解析\n对于数据传输与解析，我们首推的格式是csv，因为一方面，csv格式的读写解析都可以通过 Python 和 R 的原生函数完成，不需要再安装其他包。另一方面，csv格式可以很快的转化为 data frame 格式，而data frame 格式是数据流分析的核心。\n不过，实际情况中，我们需要传输一些非结构化的数据，这时候就必须用到 JSNO 或者 YAML。\n\n\n数据传输与解析\nPython\nR\n\n\n\nCSV(原生)\ncsv\nread.csv\n\n\nCSV(优化)\npandas.read_csv(\"nba_2013.csv\")\ndata.table::fread(\"nba_2013.csv\")\n\n\nJSON\njson(原生)\njsonlite\n\n\nYAML\nPyYAML\nyaml\n\n\n\n基本数据结构\n由于是从科学计算的角度出发，R 中的数据结构非常的简单，主要包括 向量（一维）、多维数组（二维时为矩阵）、列表（非结构化数据）、数据框（结构化数据）。而 Python 则包含更丰富的数据结构来实现数据更精准的访问和内存控制，多维数组（可读写、有序）、元组（只读、有序）、集合（唯一、无序）、字典（Key-Value）等等。\n\n\n基本数据结构\nPython\nR\n\n\n\n数组\nlist:[1,'a']\n:array:array(c(1,\"a\"),2)\n\n\nKey-Value（非结构化数据）\n字典:[\"a\":1]\nlists\n\n\n数据框（结构化数据）\ndataframe\ndata.frame\n\n\n\nPython dict 操作：dict[\"key\"] 或者 dict.get(\"key\",\"default_return\")R list 操作: list[\"key\"] 或者 list$key\n\n\nR 中数据结构转化(plyr)\nlist\ndata frame\narray\n\n\n\nlist\nllply()\nldply()\nlaply()\n\n\ndata frame\ndlply()\nddply()\ndaply()\n\n\narray\nalply()\nadply()\naaply()\n\n\n\nMapReduce\n\n\nPython\nR\n\n\n\nmap\nMap\n\n\nreduce\nReduce\n\n\nfilter\nfilter\n\n\n\n矩阵操作\n实际上，Python（numpy） 和 R中的矩阵都是通过一个多维数组（ndarray）实现的。\n\n\n矩阵转化\nPyhton\nR\n\n\n\n维度\ndata.shape\ndim(data)\n\n\n转为向量\ndata.flatten(1)\nas.vector(data)\n\n\n转为矩阵\nnp.array([[1,2,3],[3,2,1]])\nmatrix(c(1,2,3,3,2,1),nrow=2,byrow=T)\n\n\n转置\ndata.T\nt(data)\n\n\n矩阵变形\ndata.reshape(1,np.prod(data.shape))\nmatrix(data,ncol=nrow(data)*ncol(data))\n\n\n矩阵按行拼接\nnp.r_[A,B]\nrbind(A,B)\n\n\n矩阵按列拼接\nnp.c_[A,B]\ncbind(A,B)\n\n\n\n\n\n矩阵计算\nPyhton\nR\n\n\n\n矩阵乘法\nnp.dot(A,B)\nA %*% B\n\n\n矩阵幂指\nnp.power(A,3)\nA^3\n\n\n全零矩阵\nnp.zeros((3,3))\nmatrix(0,nrow=3,ncol=3)\n\n\n矩阵求逆\nnp.linalg.inv(A)\nsolve(A)\n\n\n协方差\nnp.cov(A,B)\ncov(A,B)\n\n\n特征值\nnp.linalg.eig(A)[0]\neigen(A)$values\n\n\n特征向量\nnp.linalg.eig(A)[1]\neigen(A)$vectors\n\n\n\n数据框操作\n参考 R 中的 data frame 结构，Python 的 Pandas包也实现了类似的 data frame 数据结构。现在，为了加强数据框的操作，R 中更是演进出了 data table 格式（简称dt），这种格式以 dt[where,select,group by] 的形式支持类似SQL的语法。\n\n\n数据框操作\nPython\nR\n\n\n\n按Factor的Select操作\ndf[['a', 'c']]\ndt[,.(a,c),]\n\n\n按Index的Select操作\ndf.iloc[:,1:2]\ndt[,1:2,with=FALSE]\n\n\n按Index的Filter操作\ndf[1:2]\ndt[1:2]\n\n\ngroupby分组操作\ndf.groupby(['a','b'])[['c','d']].mean()\naggregate(x=dt[, c(\"v1\", \"v2\")], by=list(mydt2$by1, mydt2$by2), FUN = mean)\n\n\n%in% 匹配操作 返回T/F\npd.Series(np.arange(5),dtype=np.float32).isin([2, 4])\n0:4 %in% c(2,4)\n\n\nmatch 匹配操作 返回Index\npd.Series(pd.match(pd.Series(np.arange(5),dtype=np.float32),[2,4],np.nan))\nmatch(0:4, c(2,4))\n\n\ntapply\ndf.pivot_table(values='a', columns='c', aggfunc=np.max)\ntapply(dt$a,dt$c,max)#其中dt$a是numeric，dt$c是nominal\n\n\n查询操作\ndf[df.a <= df.b]\ndt[ a<=b ]\n\n\nwith操作\npd.DataFrame({'a': np.random.randn(10), 'b': np.random.randn(10)}).eval('a + b')\nwith(dt,a + b)\n\n\nplyr操作\ndf.groupby(['month','week']).agg([np.mean, np.std])\nddply(dt, .(month, week), summarize,mean = round(mean(x), 2),sd = round(sd(x), 2))\n\n\n多维数组融合\npd.DataFrame([tuple(list(x)+[val]) for x, val in np.ndenumerate(np.array(list(range(1,24))+[np.NAN]).reshape(2,3,4))])\ndata.frame(melt(array(c(1:23, NA), c(2,3,4))))\n\n\n多维列表融合\npd.DataFrame(list(enumerate(list(range(1,5))+[np.NAN])))\ndata.frame(melt(as.list(c(1:4, NA))))\n\n\n数据框融合\npd.melt(pd.DataFrame({'first' : ['John', 'Mary'],'last' : ['Doe', 'Bo'],'height' : [5.5, 6.0],'weight' : [130, 150]}), id_vars=['first', 'last'])\nmelt(data.frame(first = c('John', 'Mary'),last = c('Doe', 'Bo'),height = c(5.5, 6.0),weight = c(130, 150), id=c(\"first\", \"last\"))\n\n\n数据透视表 pivot table\npd.pivot_table(pd.melt(pd.DataFrame({ 'x': np.random.uniform(1., 168., 12), 'y': np.random.uniform(7., 334., 12), 'z': np.random.uniform(1.7, 20.7, 12), 'month': [5,6,7]4, 'week': [1,2]6}), id_vars=['month', 'week']), values='value', index=['variable','week'],columns=['month'], aggfunc=np.mean)\nacast(melt(data.frame(x = runif(12, 1, 168),y = runif(12, 7, 334),z = runif(12, 1.7, 20.7),month = rep(c(5,6,7),4),week = rep(c(1,2), 6)), id=c(\"month\", \"week\")), week ~ month ~ variable, mean)\n\n\n连续型数值因子分类\npd.cut(pd.Series([1,2,3,4,5,6]), 3)\ncut(c(1,2,3,4,5,6), 3)\n\n\n名义型因子分类\npd.Series([1,2,3,2,2,3]).astype(\"category\")\nfactor(c(1,2,3,2,2,3))\n\n\n\n数据流编程对比的示例\nPython 的 Pandas 中的管道操作\n  (df\n   .groupby(['a', 'b', 'c'], as_index=False)\n   .agg({'d': sum, 'e': mean, 'f', np.std})\n   .assign(g=lambda x: x.a / x.c)\n   .query(\"g > 0.05\")\n   .merge(df2, on='a'))\nR 的 dplyr 中的管道操作\nflights %>% group_by(year, month, day) %>%\n  select(arr_delay, dep_delay) \n\n  summarise(\n\n    arr = mean(arr_delay, na.rm = TRUE),\n\n    dep = mean(dep_delay, na.rm = TRUE)) %>%\n\n  filter(arr > 30 | dep > 30)\n数据可视化对比\n绘制相关性散点图\n对比数据相关性是数据探索常用的一种方法，下面是Python和R的对比。\nPython\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.pairplot(nba[[\"ast\", \"fg\", \"trb\"]])\nplt.show()\n\nR\nlibrary(GGally)\nggpairs(nba[,c(\"ast\", \"fg\", \"trb\")])\n\n虽然我们最终得到了类似的图形，这里R中GGally是依赖于ggplot2，而Python则是在matplotlib的基础上结合Seaborn，除了GGally在R中我们还有很多其他的类似方法来实现对比制图，显然R中的绘图有更完善的生态系统。\n绘制聚类效果图\n这里以K-means为例，为了方便聚类，我们将非数值型或者有确实数据的列排除在外。\nPython\nfrom sklearn.cluster import KMeans\nkmeans_model = KMeans(n_clusters=5, random_state=1)\ngood_columns = nba._get_numeric_data().dropna(axis=1)\nkmeans_model.fit(good_columns)\nlabels = kmeans_model.labels_\n\nfrom sklearn.decomposition import PCA\npca_2 = PCA(2)\nplot_columns = pca_2.fit_transform(good_columns)\nplt.scatter(x=plot_columns[:,0], y=plot_columns[:,1], c=labels)\nplt.show()\n\nR\nlibrary(cluster)\nset.seed(1)\nisGoodCol <- function(col){\n   sum(is.na(col)) == 0 && is.numeric(col) \n}\ngoodCols <- sapply(nba, isGoodCol)\nclusters <- kmeans(nba[,goodCols], centers=5)\nlabels <- clusters$cluster\n\nnba2d <- prcomp(nba[,goodCols], center=TRUE)\ntwoColumns <- nba2d$x[,1:2]\nclusplot(twoColumns, labels)\n\n速度对比\nPython\nimport numpy as np\nxx = np.zeros(100000000)\n%timeit xx[:] = 1\nThe slowest run took 9.29 times longer than the fastest. This could mean that an intermediate result is being cached \n1 loops, best of 3: 111 ms per loop\nR\nxx <- rep(0, 100000000)\nsystem.time(xx[] <- 1)\nuser  system elapsed \n  1.326   0.103   1.433\n显然这里 R 1.326的成绩 比 Python 的 Numpy 3:111 的速度快了不少。\n事实上，现在 R 和 Python 的数据操作的速度已经被优化得旗鼓相当了。下面是R中的 data.table、dplyr 与 Python 中的 pandas 的数据操作性能对比：\n\n我曾经用data.table和pandas分别读取过一个600万行的IOT数据，反复10次，data.table以平均10s的成绩胜过了pandas平均15s的成绩，所以在IO上我倾向于选择使用data.table来处理大数据，然后喂给spark和hadoop进行进一步的分布式处理。\n结论\nPython 的 pandas 从 R 中偷师 dataframes，R 中的 rvest 则借鉴了 Python 的 BeautifulSoup，我们可以看出两种语言在一定程度上存在的互补性，通常，我们认为 Python 比 R 在泛型编程上更有优势，而 R 在数据探索、统计分析是一种更高效的独立数据分析工具。所以说，同时学会Python和R这两把刷子才是数据科学的王道。\n\n参考资料\n\npandas doucumentation: Comparison with R / R libraries\n    Comparison – R vs. Python: head to head data analysis\nHacker News: Comparison – R vs. Python\nQuora: How does R compare with pandas?\nyhat: R and pandas and what I've learned about each\nWhy are pandas merges in python faster than data.table merges in R?\nPython和R科学计算操作速查表\n知乎：R 和 Python (numpy scipy pandas) 用于统计学分析，哪个更好？\nChoosing R or Python for data analysis? An infographic\n散大大 写给Python数据科学家们 : 科学计算开发环境排雷\n\n作为分享主义者(sharism)，本人所有互联网发布的图文均遵从CC版权，转载请保留作者信息并注明作者 Harry Zhu 的 FinanceR专栏:https://segmentfault.com/blog...，如果涉及源代码请注明GitHub地址：https://github.com/harryprince。微信号: harryzhustudio商业使用请联系作者。\n\n                ", "mainLikeNum": ["11 "], "mainBookmarkNum": "46"}