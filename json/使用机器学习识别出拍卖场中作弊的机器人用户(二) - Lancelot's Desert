{"title": "使用机器学习识别出拍卖场中作弊的机器人用户(二) - Lancelot's Desert ", "index": "python,机器学习", "content": "本文承接上一篇文章:使用机器学习识别出拍卖场中作弊的机器人用户\n本项目为kaggle上Facebook举行的一次比赛，地址见数据来源，完整代码见我的github,欢迎来玩~\n代码\n\n数据探索——Data_Exploration.ipynb\n数据预处理&特征工程——Feature_Engineering.ipynb & Feature_Engineering2.ipynb\n模型设计及评测——Model_Design.ipynb\n\n项目数据来源\nkaggle\n项目所需额外工具包\n\nnumpy\npandas\nmatplotlib\nsklearn\nxgboost\nlightgbm\nmlxtend: 含有聚和算法Stacking 项目整体运行时间预估为60min左右，在Ubuntu系统，8G内存，运行结果见所提交的jupyter notebook文件\n\n\n由于文章内容过长，所以分为两篇文章，总共包含四个部分\n\n数据探索\n数据预处理及特征工程\n模型设计\n评估及总结\n\n\n特征工程(续)\nimport numpy as np\nimport pandas as pd\nimport pickle\n%matplotlib inline\nfrom IPython.display import display\n# bids = pd.read_csv('bids.csv')\nbids = pickle.load(open('bids.pkl'))\nprint bids.shape\ndisplay(bids.head())\n(7656329, 9)\n\n\n\n\n\n      bid_id\n      bidder_id\n      auction\n      merchandise\n      device\n      time\n      country\n      ip\n      url\n    \n\n\n0\n      0\n      8dac2b259fd1c6d1120e519fb1ac14fbqvax8\n      ewmzr\n      jewelry\n      phone0\n      9759243157894736\n      us\n      69.166.231.58\n      vasstdc27m7nks3\n    \n\n1\n      1\n      668d393e858e8126275433046bbd35c6tywop\n      aeqok\n      furniture\n      phone1\n      9759243157894736\n      in\n      50.201.125.84\n      jmqlhflrzwuay9c\n    \n\n2\n      2\n      aa5f360084278b35d746fa6af3a7a1a5ra3xe\n      wa00e\n      home goods\n      phone2\n      9759243157894736\n      py\n      112.54.208.157\n      vasstdc27m7nks3\n    \n\n3\n      3\n      3939ac3ef7d472a59a9c5f893dd3e39fh9ofi\n      jefix\n      jewelry\n      phone4\n      9759243157894736\n      in\n      18.99.175.133\n      vasstdc27m7nks3\n    \n\n4\n      4\n      8393c48eaf4b8fa96886edc7cf27b372dsibi\n      jefix\n      jewelry\n      phone5\n      9759243157894736\n      in\n      145.138.5.37\n      vasstdc27m7nks3\n    \n\n\nbidders = bids.groupby('bidder_id')\n针对国家、商品单一特征多类别转换为多个独立特征进行统计\ncates = (bids['merchandise'].unique()).tolist()\ncountries = (bids['country'].unique()).tolist()\n\ndef dummy_coun_cate(group):\n    coun_cate = dict.fromkeys(cates, 0)\n    coun_cate.update(dict.fromkeys(countries, 0))\n    for cat, value in group['merchandise'].value_counts().iteritems():\n        coun_cate[cat] = value\n\n    for c in group['country'].unique():\n        coun_cate[c] = 1\n\n    coun_cate = pd.Series(coun_cate)\n    return coun_cate\n\nbidder_coun_cate = bidders.apply(dummy_coun_cate)\ndisplay(bidder_coun_cate.describe())\nbidder_coun_cate.to_csv('coun_cate.csv')\n\n\n\n      ad\n      ae\n      af\n      ag\n      al\n      am\n      an\n      ao\n      ar\n      at\n      ...\n      vc\n      ve\n      vi\n      vn\n      ws\n      ye\n      za\n      zm\n      zw\n      zz\n    \n\n\ncount\n      6609.000000\n      6609.000000\n      6609.000000\n      6609.000000\n      6609.000000\n      6609.000000\n      6609.000000\n      6609.000000\n      6609.000000\n      6609.000000\n      ...\n      6609.000000\n      6609.000000\n      6609.000000\n      6609.000000\n      6609.000000\n      6609.000000\n      6609.000000\n      6609.000000\n      6609.000000\n      6609.000000\n    \n\nmean\n      0.002724\n      0.205629\n      0.054774\n      0.001059\n      0.048570\n      0.023907\n      0.000303\n      0.036314\n      0.120442\n      0.052655\n      ...\n      0.000605\n      0.033591\n      0.000303\n      0.130882\n      0.001967\n      0.040551\n      0.274474\n      0.067181\n      0.069753\n      0.000757\n    \n\nstd\n      0.052121\n      0.404191\n      0.227555\n      0.032530\n      0.214984\n      0.152770\n      0.017395\n      0.187085\n      0.325502\n      0.223362\n      ...\n      0.024596\n      0.180186\n      0.017395\n      0.337297\n      0.044311\n      0.197262\n      0.446283\n      0.250354\n      0.254750\n      0.027497\n    \n\nmin\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      ...\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n    \n\n25%\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      ...\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n    \n\n50%\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      ...\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n    \n\n75%\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      ...\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n    \n\nmax\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n      ...\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n    \n\n\n8 rows × 209 columns\n同样的，对于每个用户需要统计他对于自己每次竞拍行为的时间间隔情况\ndef bidder_interval(group):\n    time_diff = np.ediff1d(group['time'])\n    bidder_interval = {}\n    if len(time_diff) == 0:\n        diff_mean = 0\n        diff_std = 0\n        diff_median = 0\n        diff_zeros = 0\n    else:\n        diff_mean = np.mean(time_diff)\n        diff_std = np.std(time_diff)\n        diff_median = np.median(time_diff)\n        diff_zeros = time_diff.shape[0] - np.count_nonzero(time_diff)\n    bidder_interval['tmean'] = diff_mean\n    bidder_interval['tstd'] = diff_std\n    bidder_interval['tmedian'] = diff_median\n    bidder_interval['tzeros'] = diff_zeros\n    bidder_interval = pd.Series(bidder_interval)\n    return bidder_interval\nbidder_inv = bidders.apply(bidder_interval)\ndisplay(bidder_inv.describe())\nbidder_inv.to_csv('bidder_inv.csv')\n\n\n\n      tmean\n      tmedian\n      tstd\n      tzeros\n    \n\n\ncount\n      6.609000e+03\n      6.609000e+03\n      6.609000e+03\n      6609.000000\n    \n\nmean\n      2.933038e+12\n      1.860285e+12\n      3.440901e+12\n      122.986231\n    \n\nstd\n      8.552343e+12\n      7.993497e+12\n      6.512992e+12\n      3190.805229\n    \n\nmin\n      0.000000e+00\n      0.000000e+00\n      0.000000e+00\n      0.000000\n    \n\n25%\n      1.192853e+10\n      2.578947e+09\n      1.749995e+09\n      0.000000\n    \n\n50%\n      2.641139e+11\n      5.726316e+10\n      5.510107e+11\n      0.000000\n    \n\n75%\n      1.847456e+12\n      6.339474e+11\n      2.911282e+12\n      0.000000\n    \n\nmax\n      7.610295e+13\n      7.610295e+13\n      3.800092e+13\n      231570.000000\n    \n\n\n</div>\n按照用户-拍卖场分组进一步分析\n之前的统计是按照用户进行分组，针对各个用户从整体上针对竞标行为统计其各项特征，下面根据拍卖场来对用户进一步细分，看一看每个用户在不同拍卖场的行为模式,类似上述按照用户分组来统计各个用户的各项特征，针对用户-拍卖场结对分组进行统计以下特征\n\n基本计数统计，针对各个用户在各个拍卖场统计设备、国家、ip、url、商品类别、竞标次数等特征的数目作为新的特征\n时间间隔统计：统计各个用户在各个拍卖场每次竞拍的时间间隔的 均值、方差、中位数和0值\n针对商品类别、国家进一步转化为多类别进行统计\n\ndef auc_features_count(group):\n    time_diff = np.ediff1d(group['time'])\n    \n    if len(time_diff) == 0:\n        diff_mean = 0\n        diff_std = 0\n        diff_median = 0\n        diff_zeros = 0\n    else:\n        diff_mean = np.mean(time_diff)\n        diff_std = np.std(time_diff)\n        diff_median = np.median(time_diff)\n        diff_zeros = time_diff.shape[0] - np.count_nonzero(time_diff)\n\n    row = dict.fromkeys(cates, 0)\n    row.update(dict.fromkeys(countries, 0))\n\n    row['devices_c'] = group['device'].unique().shape[0]\n    row['countries_c'] = group['country'].unique().shape[0]\n    row['ip_c'] = group['ip'].unique().shape[0]\n    row['url_c'] = group['url'].unique().shape[0]\n#     row['merch_c'] = group['merchandise'].unique().shape[0]\n    row['bids_c'] = group.shape[0]\n    row['tmean'] = diff_mean\n    row['tstd'] = diff_std\n    row['tmedian'] = diff_median\n    row['tzeros'] = diff_zeros\n\n    for cat, value in group['merchandise'].value_counts().iteritems():\n        row[cat] = value\n\n    for c in group['country'].unique():\n        row[c] = 1\n\n    row = pd.Series(row)\n    return row\nbidder_auc = bids.groupby(['bidder_id', 'auction']).apply(auc_features_count)\nbidder_auc.to_csv('bids_auc.csv')\nprint bidder_auc.shape\n(382336, 218)\n\n模型设计与参数评估\n合并特征\n对之前生成的各项特征进行合并产生最终的特征空间\nimport numpy as np\nimport pandas as pd\n%matplotlib inline\nfrom IPython.display import display\n首先将之前根据用户分组的统计特征合并起来，然后将其与按照用户-拍卖场结对分组的特征合并起来，最后加上时间特征，分别于训练集、测试集连接生成后续进行训练和预测的特征数据文件\ndef merge_data():    \n    train = pd.read_csv('train.csv')\n    test = pd.read_csv('test.csv')\n\n    time_differences = pd.read_csv('tdiff.csv', index_col=0)\n    bids_auc = pd.read_csv('bids_auc.csv')\n\n    bids_auc = bids_auc.groupby('bidder_id').mean()\n    \n    bidders = pd.read_csv('cnt_bidder.csv', index_col=0)\n    country_cate = pd.read_csv('coun_cate.csv', index_col=0)\n    bidder_inv = pd.read_csv('bidder_inv.csv', index_col=0)\n    bidders = bidders.merge(country_cate, right_index=True, left_index=True)\n    bidders = bidders.merge(bidder_inv, right_index=True, left_index=True)\n\n    bidders = bidders.merge(bids_auc, right_index=True, left_index=True)\n    bidders = bidders.merge(time_differences, right_index=True,\n                            left_index=True)\n\n    train = train.merge(bidders, left_on='bidder_id', right_index=True)\n    train.to_csv('train_full.csv', index=False)\n\n    test = test.merge(bidders, left_on='bidder_id', right_index=True)\n    test.to_csv('test_full.csv', index=False)    \nmerge_data()\ntrain_full = pd.read_csv('train_full.csv')\ntest_full = pd.read_csv('test_full.csv')\nprint train_full.shape\nprint test_full.shape\n(1983, 445)\n(4626, 444)\n\n\ntrain_full['outcome'] = train_full['outcome'].astype(int)\nytrain = train_full['outcome']\ntrain_full.drop('outcome', 1, inplace=True)\n\ntest_ids = test_full['bidder_id']\n\nlabels = ['payment_account', 'address', 'bidder_id']\ntrain_full.drop(labels=labels, axis=1, inplace=True)\ntest_full.drop(labels=labels, axis=1, inplace=True)\n设计交叉验证\n模型选择\n根据之前的分析，由于当前的数据集中存在正负例不均衡的问题，所以考虑选取了RandomForestClassfier, GradientBoostingClassifier, xgboost, lightgbm等四种模型来针对数据及进行训练和预测，确定最终模型的基本思路如下：\n\n对四个模型分别使用评价函数roc_auc进行交叉验证并绘制auc曲线，对各个模型的多轮交叉验证得分取平均值并输出\n\n根据得分确定最终选用的一个或多个模型\n\n若最后发现一个模型的表现大幅度优于其他所有模型，则选择该模型进一步调参\n若最后发现多个模型表现都不错，则进行模型的集成，得到聚合模型\n使用GridSearchCV来从人为设定的参数列表中选择最佳的参数组合确定最终的模型\n\n\n\nfrom scipy import interp\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\n\n# from sklearn.cross_validation import StratifiedKFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\n\ndef kfold_plot(train, ytrain, model):\n#     kf = StratifiedKFold(y=ytrain, n_folds=5)\n    kf = StratifiedKFold(n_splits=5)\n    scores = []\n    mean_tpr = 0.0\n    mean_fpr = np.linspace(0, 1, 100)\n    exe_time = []\n    \n    colors = cycle(['cyan', 'indigo', 'seagreen', 'yellow', 'blue'])\n    lw = 2\n    \n    i=0\n    for (train_index, test_index), color in zip(kf.split(train, ytrain), colors):\n        X_train, X_test = train.iloc[train_index], train.iloc[test_index]\n        y_train, y_test = ytrain.iloc[train_index], ytrain.iloc[test_index]\n        begin_t = time.time()\n        predictions = model(X_train, X_test, y_train)\n        end_t = time.time()\n        exe_time.append(round(end_t-begin_t, 3))\n#         model = model\n#         model.fit(X_train, y_train)    \n#         predictions = model.predict_proba(X_test)[:, 1]        \n        scores.append(roc_auc_score(y_test.astype(float), predictions))        \n        fpr, tpr, thresholds = roc_curve(y_test, predictions)\n        mean_tpr += interp(mean_fpr, fpr, tpr)\n        mean_tpr[0] = 0.0\n        roc_auc = auc(fpr, tpr)\n        plt.plot(fpr, tpr, lw=lw, color=color, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n        i += 1\n    plt.plot([0, 1], [0, 1], linestyle='--', lw=lw, color='k', label='Luck')\n    \n    mean_tpr /= kf.get_n_splits(train, ytrain)\n    mean_tpr[-1] = 1.0\n    mean_auc = auc(mean_fpr, mean_tpr)\n    plt.plot(mean_fpr, mean_tpr, color='g', linestyle='--', label='Mean ROC (area = %0.2f)' % mean_auc, lw=lw)\n    \n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc='lower right')\n    plt.show()\n    \n#     print 'scores: ', scores\n    print 'mean scores: ', np.mean(scores)\n    print 'mean model process time: ', np.mean(exe_time), 's'\n    \n    return scores, np.mean(scores), np.mean(exe_time)\n收集各个模型进行交叉验证的结果包括每轮交叉验证的auc得分、auc的平均得分以及模型的训练时间\ndct_scores = {}\nmean_score = {}\nmean_time = {}\nRandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nimport time\nfrom sklearn.ensemble import RandomForestClassifier\n\ndef forest_model(X_train, X_test, y_train):\n#     begin_t = time.time()\n    model = RandomForestClassifier(n_estimators=160, max_features=35, max_depth=8, random_state=7)\n    model.fit(X_train, y_train)    \n#     end_t = time.time()\n#     print 'train time of forest model: ',round(end_t-begin_t, 3), 's'\n    predictions = model.predict_proba(X_test)[:, 1]\n    return predictions\ndct_scores['forest'], mean_score['forest'], mean_time['forest'] = kfold_plot(train_full, ytrain, forest_model)\n# kfold_plot(train_full, ytrain, model_forest)\n\nmean scores:  0.909571935157\nmean model process time:  0.643 s\n\n\nfrom sklearn.ensemble import GradientBoostingClassifier\ndef gradient_model(X_train, X_test, y_train):\n    model = GradientBoostingClassifier(n_estimators=200, random_state=7, max_depth=5, learning_rate=0.03)\n    model.fit(X_train, y_train)\n    predictions = model.predict_proba(X_test)[:, 1]\n    return predictions\ndct_scores['gbm'], mean_score['gbm'], mean_time['gbm'] = kfold_plot(train_full, ytrain, gradient_model)\n\nmean scores:  0.911847771023\nmean model process time:  4.1948 s\n\n\nimport xgboost as xgb\ndef xgboost_model(X_train, X_test, y_train):\n    X_train = xgb.DMatrix(X_train.values, label=y_train.values)\n    X_test = xgb.DMatrix(X_test.values)\n    params = {'objective': 'binary:logistic', 'eval_metric': 'auc', 'silent': 1, 'seed': 7,\n              'max_depth': 6, 'eta': 0.01}    \n    model = xgb.train(params, X_train, 600)\n    predictions = model.predict(X_test)\n    return predictions\n/home/lancelot/anaconda2/envs/udacity/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n\n\ndct_scores['xgboost'], mean_score['xgboost'], mean_time['xgboost'] = kfold_plot(train_full, ytrain, xgboost_model)\n\nmean scores:  0.915372340426\nmean model process time:  3.1482 s\n\n\nimport lightgbm as lgb\ndef lightgbm_model(X_train, X_test, y_train):\n    X_train = lgb.Dataset(X_train.values, y_train.values)\n    params = {'objective': 'binary', 'metric': {'auc'}, 'learning_rate': 0.01, 'max_depth': 6, 'seed': 7}\n    model = lgb.train(params, X_train, num_boost_round=600)\n    predictions = model.predict(X_test)\n    return predictions\ndct_scores['lgbm'], mean_score['lgbm'], mean_time['lgbm'] = kfold_plot(train_full, ytrain, lightgbm_model)\n\nmean scores:  0.921512158055\nmean model process time:  0.3558 s\n\n\n模型比较\n比较四个模型在交叉验证机上的roc_auc平均得分和模型训练的时间\ndef plot_model_comp(title, y_label, dct_result):\n    data_source = dct_result.keys()\n    y_pos = np.arange(len(data_source))\n    # model_auc = [0.910, 0.912, 0.915, 0.922]\n    model_auc = dct_result.values()\n    barlist = plt.bar(y_pos, model_auc, align='center', alpha=0.5)\n    # get the index of highest score\n    max_val = max(model_auc)\n    idx = model_auc.index(max_val)\n    barlist[idx].set_color('r')\n    plt.xticks(y_pos, data_source)\n    plt.ylabel(y_label)\n    plt.title(title)\n    plt.show()\n    print 'The highest auc score is {0} of model: {1}'.format(max_val, data_source[idx])\nplot_model_comp('Model Performance', 'roc-auc score', mean_score)\n\nThe highest auc score is 0.921512158055 of model: lgbm\n\n\ndef plot_time_comp(title, y_label, dct_result):\n    data_source = dct_result.keys()\n    y_pos = np.arange(len(data_source))\n    # model_auc = [0.910, 0.912, 0.915, 0.922]\n    model_auc = dct_result.values()\n    barlist = plt.bar(y_pos, model_auc, align='center', alpha=0.5)\n    # get the index of highest score\n    min_val = min(model_auc)\n    idx = model_auc.index(min_val)\n    barlist[idx].set_color('r')\n    plt.xticks(y_pos, data_source)\n    plt.ylabel(y_label)\n    plt.title(title)\n    plt.show()\n    print 'The shortest time is {0} of model: {1}'.format(min_val, data_source[idx])\nplot_time_comp('Time of Building Model', 'time(s)', mean_time)\n\nThe shortest time is 0.3558 of model: lgbm\n\n\nauc_forest = dct_scores['forest']\nauc_gb = dct_scores['gbm']\nauc_xgb = dct_scores['xgboost']\nauc_lgb = dct_scores['lgbm']\nprint 'std of forest auc score: ',np.std(auc_forest)\nprint 'std of gbm auc score: ',np.std(auc_gb)\nprint 'std of xgboost auc score: ',np.std(auc_xgb)\nprint 'std of lightgbm auc score: ',np.std(auc_lgb)\ndata_source = ['roc-fold-1', 'roc-fold-2', 'roc-fold-3', 'roc-fold-4', 'roc-fold-5']\ny_pos = np.arange(len(data_source))\nplt.plot(y_pos, auc_forest, 'b-', label='forest')\nplt.plot(y_pos, auc_gb, 'r-', label='gbm')\nplt.plot(y_pos, auc_xgb, 'y-', label='xgboost')\nplt.plot(y_pos, auc_lgb, 'g-', label='lightgbm')\nplt.title('roc-auc score of each epoch')\nplt.xlabel('epoch')\nplt.ylabel('roc-auc score')\nplt.legend()\nplt.show()\nstd of forest auc score:  0.0413757504568\nstd of gbm auc score:  0.027746291638\nstd of xgboost auc score:  0.0232931322563\nstd of lightgbm auc score:  0.0287156755513\n\n\n\n单从5次交叉验证的各模型roc-auc得分来看，xgboost的得分相对比较稳定\n聚合模型\n由上面的模型比较可以发现，四个模型的经过交叉验证的表现都不错，但是综合而言，xgboost和lightgbm更胜一筹，而且两者的训练时间也相对更短一些，所以接下来考虑进行模型的聚合，思路如下：\n\n先通过GridSearchCV分别针对四个模型在整个训练集上进行调参获得最佳的子模型\n\n针对子模型使用\n\nstacking: 第三方库mlxtend里的stacking方法对子模型进行聚合得到聚合模型，并采用之前相同的cv方法对该模型进行打分评价\nvoting: 使用sklearn内置的VotingClassifier进行四个模型的聚合\n\n\n最终对聚合模型在一次进行cv验证评分，根据结果确定最终的模型\n\n先通过交叉验证针对模型选择参数组合\ndef choose_xgb_model(X_train, y_train): \n    tuned_params = [{'objective': ['binary:logistic'], 'learning_rate': [0.01, 0.03, 0.05], \n                     'n_estimators': [100, 150, 200], 'max_depth':[4, 6, 8]}]\n    begin_t = time.time()\n    clf = GridSearchCV(xgb.XGBClassifier(seed=7), tuned_params, scoring='roc_auc')\n    clf.fit(X_train, y_train)\n    end_t = time.time()\n    print 'train time: ',round(end_t-begin_t, 3), 's'\n    print 'current best parameters of xgboost: ',clf.best_params_\n    return clf.best_estimator_\nbst_xgb = choose_xgb_model(train_full, ytrain)\ntrain time:  48.141 s\ncurrent best parameters of xgboost:  {'n_estimators': 150, 'objective': 'binary:logistic', 'learning_rate': 0.05, 'max_depth': 4}\n\n\ndef choose_lgb_model(X_train, y_train): \n    tuned_params = [{'objective': ['binary'], 'learning_rate': [0.01, 0.03, 0.05], \n                     'n_estimators': [100, 150, 200], 'max_depth':[4, 6, 8]}]\n    begin_t = time.time()\n    clf = GridSearchCV(lgb.LGBMClassifier(seed=7), tuned_params, scoring='roc_auc')\n    clf.fit(X_train, y_train)\n    end_t = time.time()\n    print 'train time: ',round(end_t-begin_t, 3), 's'\n    print 'current best parameters of lgb: ',clf.best_params_\n    return clf.best_estimator_\nbst_lgb = choose_lgb_model(train_full, ytrain)\ntrain time:  12.543 s\ncurrent best parameters of lgb:  {'n_estimators': 150, 'objective': 'binary', 'learning_rate': 0.05, 'max_depth': 4}\n\n\n先使用stacking集成两个综合表现最佳的模型lgb和xgb，此处元分类器使用较为简单的LR模型来在已经训练好了并且经过参数选择的模型上进一步优化预测结果\nfrom mlxtend.classifier import StackingClassifier\nfrom sklearn import linear_model\n\ndef stacking_model(X_train, X_test, y_train):    \n    lr = linear_model.LogisticRegression(random_state=7)\n    sclf = StackingClassifier(classifiers=[bst_xgb, bst_lgb], use_probas=True, average_probas=False, \n                              meta_classifier=lr)\n    sclf.fit(X_train, y_train)\n    predictions = sclf.predict_proba(X_test)[:, 1]\n    return predictions\ndct_scores['stacking_1'], mean_score['stacking_1'], mean_time['stacking_1'] = kfold_plot(train_full, ytrain, stacking_model)\n\nmean scores:  0.92157674772\nmean model process time:  0.7022 s\n\n\n可以看到相对之前的得分最高的模型lightgbm，将lightgbm与xgboost经过stacking集成并且使用lr作为元分类器得到的auc得分有轻微的提升，接下来考虑进一步加入另外的RandomForest和GBDT模型看看增加一点模型的差异性使用Stacking是不是会有所提升\ndef choose_forest_model(X_train, y_train):    \n    tuned_params = [{'n_estimators': [100, 150, 200], 'max_features': [8, 15, 30], 'max_depth':[4, 8, 10]}]\n    begin_t = time.time()\n    clf = GridSearchCV(RandomForestClassifier(random_state=7), tuned_params, scoring='roc_auc')\n    clf.fit(X_train, y_train)\n    end_t = time.time()\n    print 'train time: ',round(end_t-begin_t, 3), 's'\n    print 'current best parameters: ',clf.best_params_\n    return clf.best_estimator_\nbst_forest = choose_forest_model(train_full, ytrain)\ntrain time:  42.201 s\ncurrent best parameters:  {'max_features': 15, 'n_estimators': 150, 'max_depth': 8}\n\n\ndef choose_gradient_model(X_train, y_train):    \n    tuned_params = [{'n_estimators': [100, 150, 200], 'learning_rate': [0.03, 0.05, 0.07], \n                     'min_samples_leaf': [8, 15, 30], 'max_depth':[4, 6, 8]}]\n    begin_t = time.time()\n    clf = GridSearchCV(GradientBoostingClassifier(random_state=7), tuned_params, scoring='roc_auc')\n    clf.fit(X_train, y_train)\n    end_t = time.time()\n    print 'train time: ',round(end_t-begin_t, 3), 's'\n    print 'current best parameters: ',clf.best_params_\n    return clf.best_estimator_\nbst_gradient = choose_gradient_model(train_full, ytrain)\ntrain time:  641.872 s\ncurrent best parameters:  {'n_estimators': 100, 'learning_rate': 0.03, 'max_depth': 8, 'min_samples_leaf': 30}\n\n\ndef stacking_model2(X_train, X_test, y_train):    \n    lr = linear_model.LogisticRegression(random_state=7)\n    sclf = StackingClassifier(classifiers=[bst_xgb, bst_forest, bst_gradient, bst_lgb], use_probas=True, \n                              average_probas=False, meta_classifier=lr)\n    sclf.fit(X_train, y_train)\n    predictions = sclf.predict_proba(X_test)[:, 1]\n    return predictions\ndct_scores['stacking_2'], mean_score['stacking_2'], mean_time['stacking_2'] = kfold_plot(train_full, ytrain, stacking_model2)\n\nmean scores:  0.92686550152\nmean model process time:  4.0878 s\n\n\n可以看到四个模型的聚合效果比用两个模型的stacking聚合效果要好不少，接下来尝试使用voting对四个模型进行聚合\nfrom sklearn.ensemble import VotingClassifier\n\ndef voting_model(X_train, X_test, y_train):    \n    vclf = VotingClassifier(estimators=[('xgb', bst_xgb), ('rf', bst_forest), ('gbm',bst_gradient),\n                                       ('lgb', bst_lgb)], voting='soft', weights=[2, 1, 1, 2])\n    vclf.fit(X_train, y_train)\n    predictions = vclf.predict_proba(X_test)[:, 1]\n    return predictions\ndct_scores['voting'], mean_score['voting'], mean_time['voting'] = kfold_plot(train_full, ytrain, voting_model)\n\nmean scores:  0.926889564336\nmean model process time:  4.055 s\n\n\n再次比较单模型与集成模型的得分\nplot_model_comp('Model Performance', 'roc-auc score', mean_score)\n\nThe highest auc score is 0.926889564336 of model: voting\n\n\n由上可以看到最终通过voting将四个模型进行聚合可以得到得分最高的模型，确定为最终用来预测的模型\n综合模型，对测试文件进行最终预测\n# predict(train_full, test_full, y_train)\ndef submit(X_train, X_test, y_train, test_ids):\n    predictions = voting_model(X_train, X_test, y_train)\n\n    sub = pd.read_csv('sampleSubmission.csv')\n    result = pd.DataFrame()\n    result['bidder_id'] = test_ids\n    result['outcome'] = predictions\n    sub = sub.merge(result, on='bidder_id', how='left')\n\n    # Fill missing values with mean\n    mean_pred = np.mean(predictions)\n    sub.fillna(mean_pred, inplace=True)\n\n    sub.drop('prediction', 1, inplace=True)\n    sub.to_csv('result.csv', index=False, header=['bidder_id', 'prediction'])\nsubmit(train_full, test_full, ytrain, test_ids)\n最终结果提交到kaggle上进行评分，得分如下\n以上就是整个完整的流程，当然还有很多模型可以尝试，很多聚合方法也可以使用，此外，特征工程部分还有很多空间可以挖掘，就留给大家去探索啦~\n参考资料\n\nChen, K. T., Pao, H. K. K., & Chang, H. C. (2008, October). Game bot identification based on manifold learning. In Proceedings of the 7th ACM SIGCOMM Workshop on Network and System Support for Games (pp. 21-26). ACM.\nAlayed, H., Frangoudes, F., & Neuman, C. (2013, August). Behavioral-based cheating detection in online first person shooters using machine learning techniques. In Computational Intelligence in Games (CIG), 2013 IEEE Conference on (pp. 1-8). IEEE.\nhttps://www.kaggle.com/c/face...\nhttp://stats.stackexchange.co...\nhttps://en.wikipedia.org/wiki...\nhttps://en.wikipedia.org/wiki...\nhttps://en.wikipedia.org/wiki...\nhttps://xgboost.readthedocs.i...\nhttps://github.com/Microsoft/...\nhttps://en.wikipedia.org/wiki...\nhttp://stackoverflow.com/ques...\nhttp://pandas.pydata.org/pand...\nhttp://stackoverflow.com/a/18...\nhttp://www.cnblogs.com/jasonf...\n\n修改日志\n感谢评论区@Frank同学的指正，已修改原文中的stacking的错误，此外针对绘图等细节做了点优化处理。\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "5"}