{"title": "Nginx 中 map 模块的使用及性能测试 - 西兑的博客 ", "index": "node.js,python,nginx,ab", "content": "背景\n最近我操刀了leetcode的论坛迁移，整个过程持续了几周的时间，总算暂时告了一个段落。常使用leetcode论坛的用户应该已经发现论坛已经大变样了吧~\n期间遇到了不少坑坑洼洼，将来也还会有好多问题等待去一一解决。关于这个迁移过程中的收货，这篇文章中就不细说了，有时间再另开一篇博文。这篇文章主要关注在url-mapping以及它的性能问题。\n问：url-mapping的问题从何而来呢？\n旧的论坛和新的论坛是两个不同的discuss框架。前者是phpbb，现在是nodebb。两者的 url routing 完全不一样，比如说同一个topic，在原来的url是 http://hostname/discuss/<topic_id>/<topic_name>，在新的论坛中是 http://hostname/topic/<topic_id>/<topic_slug>（这里就不讨论两者甚至连topic_id都不一样的问题了）。\n而在广袤的互联网海洋中，旧论坛的url可能到处都存在。我们不希望在论坛迁移后，用户点那些链接就失效了。我们希望的是用户访问旧的url可以被重定向到新论坛的某个地址。所以就产生了url-mapping的问题。\n方法\n生成url-mapping\n感谢nodebb-plugin-import提供了数据迁移以后自动生成url-mapping的方式，省了我自己写脚本生成这些mapping的时间。每一条mapping大致是这样的：\n~^/discuss/questions/oj/add-two-numbers\\b(\\?[^/]*)*/?$  /category/10/add-two-numbers;\n其中的slug和id的mapping是由插件生成的。regular expression是为了匹配url中如果有param添加的。\nNginx Map\n官方文档的demo可能对于刚想上手的同学来说不是那么友好，还是直接看现成的配置学得快：\nhttp {\n  ...\n\n  map_hash_max_size 204800;\n  map_hash_bucket_size 204800;\n  map $request_uri $new {\n     include /path/of/your/map/file;\n  }\n\n  include /etc/nginx/conf.d/*.conf;\n  include /etc/nginx/sites-enabled/*;\n\n  ...\n}\nserver {\n  ...\n\n  if ($new) {\n    rewrite ^ https://discuss.leetcode.com$new redirect;\n  }\n\n  location / {\n    ...\n  }\n  ...\n}\n在server规则匹配中，$new值不为空，说明当前要访问的url已经在http模块的mapping文件中匹配到了，这个时候就不走各种location模块了，直接rewrite成新的地址。注:这里要是做成proxy_pass也行，后面的测试中就采用了proxy_pass。但线上的环境，担心nginx的压力太大了，就采用了rewrite方式给它减减压。\n测试\n考虑到mapping的条目有点多，几万量级，又都是正则匹配。每个请求来的时候都会先去看看mapping中有没有，即使mapping使用的是hash的方式也不免会让我对它的性能产生一些担忧，所以性能测试就必须要来一发了。\n测试方案：\n\n在新机器上跑helloworld\n自动生成随机100个url-mapping，都重定向到helloworld\n使用abtest分别对helloworld和随机url作压测\n增大url-mapping的条目，重复1,2\n\n压测机器\n临时租了两台阿里云服务器(因为是临时的，所以我也就不在意在后文暴露ip了)，配置都是：1核，2048M内存，40G硬盘。一台用作nginx和helloworld程序，一台专门做abtest。\n注：abtest也在阿里云执行只要是为了在一个数据中心降低网络延迟。最后发现效果真不错，rps从100多直接飙升到2700多。\nhelloworld\n采用了nodejs的helloworld：\nvar http = require('http');\nvar i = 0;\nhttp.createServer(function (req, res) {\n  console.log(i++);\n  res.writeHead(200, {'Content-Type': 'text/plain'});\n  res.end('Hello World\\n');\n}).listen(1337, \"0.0.0.0\");\nconsole.log('Server running at http://0.0.0.0:1337/');\nurl-mapping\n生成urlmapping写了一个python脚本：\nimport hashlib\n\nm2 = hashlib.md5()\ncurrent = \"hello world\"\nf = open('./url.map', 'w')\n\nfor i in range(100):\n    m2.update(current)\n    current = m2.hexdigest()\n    f.write('~^/hello/world/' + current + '\\\\b(\\?[^/]*)*/?$\\t/;\\n')\n\nf.close()\nnginx配置：\nserver {\n  listen 80;\n  server_name 120.26.138.197;\n\n  location ^~ /{\n    if ($new) {\n      proxy_pass http://120.26.138.197:1337$new;\n      break;\n    }\n\n    return 404;\n  }\n}\nabtest\nrps测试(request per second)：并发压测使用100000次请求，并发100个用户的方式。\n# 不走nginx\nab -n100000 -c100 120.26.138.197:1337/\n# 走nginx\nab -n100000 -c100 120.26.138.197/hello/world/5eb63bbbe01eeed093cb22bb8f5acdc3/\n\n\nmapping条目\n直接访问(rps)\nmap第一条url(rps)\nmap最后一条url(rps)\n不存在的url(rps)\n\n\n\n100\n2829.44\n1819.63\n1765.25\n9740.53\n\n\n1000\n-\n1816.00\n1509.52\n4094.68\n\n\n10000\n-\n1813.22\n514.24\n658.32\n\n\n100000\n-\n1836.02\n62.40\n65.80\n\n\n\n跟预想的一样，mapping的条目确实会对请求效率产生影响。而且几万条的映射在较高并发的情况下已经到了勉强能用的临界了。还好以后mapping的条目不会再增加了，并且论坛的并发很难到100的量级。\ntpr测试(time per request)：因为考虑到服务器比较稳定，减少压测总数。同时把并发用户减为1个。\n# 不走nginx\nab -n1000 -c1 120.26.138.197:1337/\n# 走nginx\nab -n1000 -c1 120.26.138.197/hello/world/5eb63bbbe01eeed093cb22bb8f5acdc3/\n\n\nmapping条目\n直接访问(ms)\nmap第一条url(ms)\nmap最后一条url(ms)\n不存在的url(ms)\n\n\n\n100\n0.690\n0.922\n0.933\n0.507\n\n\n1000\n-\n0.925\n1.043\n0.648\n\n\n10000\n-\n0.921\n2.340\n1.915\n\n\n100000\n-\n0.926\n16.321\n15.469\n\n\n\n在并发不是很高的时候mapping的条目可以更多。100000个条目大概只会影响整个请求15ms左右，可以忽略不计。如果说150ms的延迟是可以接受的，那么在一个并发不是很高的情况下，mapping最多可以有100w条，还是很多的。\n测试中的不足\n\n压测的url请求并不随机\n所有的url都被重定向到一个地方。不过从结果来看，nginx确实是根据条目一个个请求的。这点倒没有什么影响\n没有测试http://hostname/path?param=xxx这样类型的url\n\n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "10"}