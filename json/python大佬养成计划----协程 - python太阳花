{"title": "python大佬养成计划----协程 - python太阳花 ", "index": "python", "content": "协程，又称微线程，纤程。英文名Coroutine协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。\n最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。\n第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。\n因为协程是一个线程执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。\n\nyield实现协程\nPython对协程的支持还非常有限，用在generator中的yield可以一定程度上实现协程。虽然支持不完全，但已经可以发挥相当大的威力了。\nimport threading\nimport time\ndef producer(c):\n    c.__next__()\n    n=0\n    while n<5:\n        n+=1\n        print('[生产者]产出第%s条数据' %(n))\n        res = c.send(n)\n        print('[返回]:%s' %(res))\ndef consumer():\n    r='sheenstar'\n    while True:\n        # 更新r值: r = 'This is ok!', c.__next__()\n        # n= yield r --> c.send(n) --> n更新\n        n = yield r\n        if not n:\n            break\n        print('[消费者]正在调用第%s条数据' %(n))\n        time.sleep(1)\n        r = 'This is ok!'\n\nif __name__=='__main__':\n    print(threading.current_thread())   \n    print(threading.active_count())     #查看当前进行的线程\n    c = consumer()\n    producer(c)     #函数中有yield， 返回值为生成器;\n    print(threading.active_count()) #1\n\ngevent库实现协程\nPython通过yield提供了对协程的基本支持，但是不完全。而第三方的gevent为Python提供了比较完善的协程支持。\ngevent是第三方库，通过greenlet实现协程，其基本思想是：\n当一个greenlet遇到IO操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO。\n\n由于切换是在IO操作时自动完成，所以gevent需要修改Python自带的一些标准库，这一过程在启动时通过monkey patch完成。\n假设多协程执行的任务， 没有IO操作或者等待， 那么协程间是依次运行， 而不是交替运行;\n假设多协程执行的任务， IO操作或者等待， 那么协程间是交替运行;\n#没有等待\nimport gevent\nfrom gevent import monkey\nmonkey.patch_all()\ndef job(n):\n    for i in range(n):\n        print(gevent.getcurrent(),i)\n\ndef mian():\n    g1 = gevent.spawn(job,1)\n    g2 = gevent.spawn(job,2)\n    g3 = gevent.spawn(job,3)\n    gevent.joinall([g1,g2,g3])\n    print('协程执行任务结束...')\n\nif __name__==\"__main__\":\n    mian()\n\n\"\"\"\n#有等待\nimport time\nfrom gevent import  monkey\nmonkey.patch_all()\n\nimport  gevent\ndef job(n):\n    for i in range(n):\n        print(gevent.getcurrent(), i)\n        time.sleep(1)\n\ndef main1():\n    # 创建三个协程， 并让该协程执行job任务\n    g1 = gevent.spawn(job, 2)\n    g2 = gevent.spawn(job, 3)\n    g3 = gevent.spawn(job, 2)\n    # 等待所有的协程执行结束， 再执行主程序；\n    gevent.joinall([g1, g2, g3])\n    print(\"任务执行结束.....\")\n\nmain1()\n\n协程与线程\n做一个关于协程和线程花费时间的对比实验，不具有参考性 。\nimport time\nimport gevent   #导入协程\nfrom gevent import monkey\nfrom urllib.request import urlopen  #连接网络\nfrom mytimeit import timeit #导入计算时间的装饰器\nfrom concurrent.futures import ThreadPoolExecutor   #导入线程池\n\ndef get_len_url(url):\n    with urlopen(url) as u_conn:\n        data = u_conn.read()\n#       print('%s该网页共%s字节' %(url,len(data)))\nurls = ['http://httpbin.org', 'http://example.com/']*100\n\n@timeit\ndef coroutineall():\n    gevents = [gevent.spawn(get_len_url,url) for url in urls]\n    gevent.joinall(gevents)\n\n@timeit\ndef threadall():\n    with ThreadPoolExecutor(max_workers=100) as thpool:\n        thpool.map(get_len_url,urls)\nif __name__==\"__main__\":\n    coroutineall()\n    threadall()\n\n\n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "1"}