{"title": "在Python中使用科大讯飞Web API进行语音合成 - 学习笔记 ", "index": "语音合成,api,webapi,科大讯飞,python", "content": "前几日讯飞开放平台推出了WebAPI接口，恰好最近需要实现一个文字转语音的功能，于是就尝试着用了起来。但不知什么原因，官方文档的调用示例一直报错，最后自己照着示例的思路用python3重写了一遍。所以这次总结一下在Python中使用讯飞Web API进行语音合成的过程。\n注册讯飞开放平台\n首先注册讯飞开放平台：http://passport.xfyun.cn/regi...\n注册完成后进入控制台，在控制台创建一个新应用 ，填写一些基本信息，注意 应用平台 选择 WebAPI 。\n\n创建完成后，记录下 APPID 和 APIKey ，将在程序中用到。\n\n另外，请在 IP白名单 中添加自己的外网IP，可以在http://www.ip138.com/ 查看。（一般来说外网IP会常常发生变化，请注意）\n在Python3中使用讯飞Web API\n先上代码，后面进行必要的说明：\n* 使用python3执行\nimport base64\nimport json\nimport time\nimport hashlib\nimport urllib.request\nimport urllib.parse\n\n# API请求地址、API KEY、APP ID等参数，提前填好备用\napi_url = \"http://api.xfyun.cn/v1/service/v1/tts\"\nAPI_KEY = \"替换成你的APIKey\"\nAPP_ID = \"替换成你的APPID\"\nOUTPUT_FILE = \"/home/pi/chat/output.mp3\"    # 输出音频的保存路径，请根据自己的情况替换\nTEXT = \"苟利国家生死以，岂因祸福避趋之\"\n\n# 构造输出音频配置参数\nParam = {\n    \"auf\": \"audio/L16;rate=16000\",    #音频采样率\n    \"aue\": \"lame\",    #音频编码，raw(生成wav)或lame(生成mp3)\n    \"voice_name\": \"xiaoyan\",\n    \"speed\": \"50\",    #语速[0,100]\n    \"volume\": \"77\",    #音量[0,100]\n    \"pitch\": \"50\",    #音高[0,100]\n    \"engine_type\": \"aisound\"    #引擎类型。aisound（普通效果），intp65（中文），intp65_en（英文）\n}\n# 配置参数编码为base64字符串，过程：字典→明文字符串→utf8编码→base64(bytes)→base64字符串\nParam_str = json.dumps(Param)    #得到明文字符串\nParam_utf8 = Param_str.encode('utf8')    #得到utf8编码(bytes类型)\nParam_b64 = base64.b64encode(Param_utf8)    #得到base64编码(bytes类型)\nParam_b64str = Param_b64.decode('utf8')    #得到base64字符串\n\n# 构造HTTP请求的头部\ntime_now = str(int(time.time()))\nchecksum = (API_KEY + time_now + Param_b64str).encode('utf8')\nchecksum_md5 = hashlib.md5(checksum).hexdigest()\nheader = {\n    \"X-Appid\": APP_ID,\n    \"X-CurTime\": time_now,\n    \"X-Param\": Param_b64str,\n    \"X-CheckSum\": checksum_md5\n}\n\n# 构造HTTP请求Body\nbody = {\n    \"text\": TEXT\n}\nbody_urlencode = urllib.parse.urlencode(body)\nbody_utf8 = body_urlencode.encode('utf8')\n\n# 发送HTTP POST请求\nreq = urllib.request.Request(api_url, data=body_utf8, headers=header)\nresponse = urllib.request.urlopen(req)\n\n# 读取结果\nresponse_head = response.headers['Content-Type']\nif(response_head == \"audio/mpeg\"):\n    out_file = open(OUTPUT_FILE, 'wb')\n    data = response.read() # a 'bytes' object\n    out_file.write(data)\n    out_file.close()\n    print('输出文件: ' + OUTPUT_FILE)\nelse:\n    print(response.read().decode('utf8'))\n下面按照代码顺序进行各部分的说明。\nAPIKey等参数\n在代码开头填好各项参数，方面代码中使用。\nAPI_KEY和APP_ID请替换为上一步创建应用后得到的内容。请不要删除双引号。\nOUTPUT_FILE是最终输出音频的保存路径，根据自己的情况替换。\nTEXT是将要输出为语音的文本。\n音频配置参数\nParam 是字典格式的音频配置参数，其中 \"aue\" 可选 raw (生成wav)或 lame (生成mp3)，如果修改成raw请记得同时修改输出文件的扩展名。\n最后需要将配置参数编码为Base64字符串：字典类型→明文字符串→utf8编码→Base64(bytes)→Base64字符串，具体实现可以参考代码。\n音频配置参数的详细说明可以参考请求参数 | 语音合成 。\nHTTP请求头部\n根据 授权认证 | 科大讯飞RESET_API开发指南 ，在调用所有业务接口时，都需要在HTTP请求头部中配置以下参数用于授权认证：\n\n\n参数\n格式\n说明\n\n\n\nX-Appid\nstring\n讯飞开放平台注册申请应用的应用ID(appid)\n\n\nX-CurTime\nstring\n当前UTC时间戳，从1970年1月1日0点0 分0 秒开始到现在的秒数\n\n\nX-Param\nstring\n音频配置参数JSON串经Base64编码后的字符串\n\n\nX-CheckSum\nstring\n令牌，计算方法：MD5(apiKey + curTime + param)。三个值拼接的字符串，进行MD5哈希计算（32位小写）。\n\n\n\n具体实现参考代码中字典 header 。\nHTTP请求Body\n相比头部，Body中只需要配置一个参数 text ，也就是最终将被转换为语音的文字。但Body需要经过urlencode编码和utf-8编码：\nbody_urlencode = urllib.parse.urlencode(body)\nbody_utf8 = body_urlencode.encode('utf8')\n发送请求&读取结果\n最后使用urllib.request库发送HTTP POST请求，得到结果。根据响应的 header 可以判断是否合成成功。\n若响应头部包含Content-type: audio/mpeg，则响应Body为音频数据，可写入文件保存。\n若合成出现错误，响应头部包含Content-type: text/plain，响应Body为记载了错误类型的json字符串。\n返回值的具体说明请参考 返回值 | 语音合成 。\n运行结果\n\n使用几次后，感觉合成语音的断句做得不是很优秀，但响应速度很快，还是比较满意的。\noutput.mp3\n小结\n最近使用了几种Web API，对这类API的使用方法也算是有些经验了。最后，现在语音识别、图灵机器人、语音合成都试着做了一遍，下一篇博客将把他们组合起来，实现一个简单的语音助手。\n感谢你阅读文章！\n\n                ", "mainLikeNum": ["6 "], "mainBookmarkNum": "4"}