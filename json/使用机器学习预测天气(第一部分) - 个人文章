{"title": "使用机器学习预测天气(第一部分) - 个人文章 ", "index": "天气预报api,机器学习,python", "content": "概述\n  本章是使用机器学习预测天气系列教程的第一部分，使用Python和机器学习来构建模型，根据从Weather Underground收集的数据来预测天气温度。该教程将由三个不同的部分组成，涵盖的主题是：\n\n数据收集和处理（本文）\n线性回归模型（第2章）\n神经网络模型（第3章）\n\n  本教程中使用的数据将从Weather Underground的免费层API服务中收集。我将使用python的requests库来调用API，得到从2015年起Lincoln, Nebraska的天气数据。 一旦收集完成，数据将需要进行处理并汇总转成合适的格式，然后进行清理。  第二篇文章将重点分析数据中的趋势，目标是选择合适的特性并使用python的statsmodels和scikit-learn库来构建线性回归模型。 我将讨论构建线性回归模型，必须进行必要的假设，并演示如何评估数据特征以构建一个健壮的模型。 并在最后完成模型的测试与验证。  最后的文章将着重于使用神经网络。 我将比较构建神经网络模型和构建线性回归模型的过程，结果，准确性。\nWeather Underground介绍\n  Weather Underground是一家收集和分发全球各种天气测量数据的公司。 该公司提供了大量的API，可用于商业和非商业用途。 在本文中，我将介绍如何使用非商业API获取每日天气数据。所以，如果你跟随者本教程操作的话，您需要注册他们的免费开发者帐户。 此帐户提供了一个API密钥，这个密钥限制，每分钟10个，每天500个API请求。  获取历史数据的API如下：\nhttp://api.wunderground.com/api/API_KEY/history_YYYYMMDD/q/STATE/CITY.json  \n\nAPI_KEY: 注册账户获取\nYYYYMMDD: 你想要获取的天气数据的日期\nSTATE: 州名缩写\nCITY: 你请求的城市名\n\n调用API\n  本教程调用Weather Underground API获取历史数据时，用到如下的python库。\n\n\n名称\n描述\n来源\n\n\n\ndatetime\n处理日期\n标准库\n\n\ntime\n处理时间\n标准库\n\n\ncollections\n使用该库的namedtuples来结构化数据\n标准库\n\n\npandas\n处理数据\n第三方\n\n\nrequests\nHTTP请求处理库\n第三方\n\n\nmatplotlib\n制图库\n第三方\n\n\n\n  好，我们先导入这些库：\nfrom datetime import datetime, timedelta  \nimport time  \nfrom collections import namedtuple  \nimport pandas as pd  \nimport requests  \nimport matplotlib.pyplot as plt  \n接下里，定义常量来保存API_KEY和BASE_URL，注意，例子中的API_KEY不可用，你要自己注册获取。代码如下：\nAPI_KEY = '7052ad35e3c73564'  \n# 第一个大括号是API_KEY，第二个是日期\nBASE_URL = \"http://api.wunderground.com/api/{}/history_{}/q/NE/Lincoln.json\"  \n然后我们初始化一个变量，存储日期，然后定义一个list，指明要从API返回的内容里获取的数据。然后定义一个namedtuple类型的变量DailySummary来存储返回的数据。代码如下：\ntarget_date = datetime(2016, 5, 16)  \nfeatures = [\"date\", \"meantempm\", \"meandewptm\", \"meanpressurem\", \"maxhumidity\", \"minhumidity\", \"maxtempm\",  \n            \"mintempm\", \"maxdewptm\", \"mindewptm\", \"maxpressurem\", \"minpressurem\", \"precipm\"]\nDailySummary = namedtuple(\"DailySummary\", features)  \n定义一个函数，调用API，获取指定target_date开始的days天的数据，代码如下：\ndef extract_weather_data(url, api_key, target_date, days):  \n    records = []\n    for _ in range(days):\n        request = BASE_URL.format(API_KEY, target_date.strftime('%Y%m%d'))\n        response = requests.get(request)\n        if response.status_code == 200:\n            data = response.json()['history']['dailysummary'][0]\n            records.append(DailySummary(\n                date=target_date,\n                meantempm=data['meantempm'],\n                meandewptm=data['meandewptm'],\n                meanpressurem=data['meanpressurem'],\n                maxhumidity=data['maxhumidity'],\n                minhumidity=data['minhumidity'],\n                maxtempm=data['maxtempm'],\n                mintempm=data['mintempm'],\n                maxdewptm=data['maxdewptm'],\n                mindewptm=data['mindewptm'],\n                maxpressurem=data['maxpressurem'],\n                minpressurem=data['minpressurem'],\n                precipm=data['precipm']))\n        time.sleep(6)\n        target_date += timedelta(days=1)\n    return records\n首先，定义个list records，用来存放上述的DailySummary，使用for循环来遍历指定的所有日期。然后生成url，发起HTTP请求，获取返回的数据，使用返回的数据，初始化DailySummary，最后存放到records里。通过这个函数的出，就可以获取到指定日期开始的N天的历史天气数据，并返回。\n获取500天的天气数据\n  由于API接口的限制，我们需要两天的时间才能获取到500天的数据。你也可以下载我的测试数据，来节约你的时间。\nrecords = extract_weather_data(BASE_URL, API_KEY, target_date, 500)  \n格式化数据为Pandas DataFrame格式\n  我们使用DailySummary列表来初始化Pandas DataFrame。DataFrame数据类型是机器学习领域经常会用到的数据结构。\ndf = pd.DataFrame(records, columns=features).set_index('date')\n特征提取\n  机器学习是带有实验性质的，所以，你可能遇到一些矛盾的数据或者行为。因此，你需要在你用机器学习处理问题是，你需要对处理的问题领域有一定的了解，这样可以更好的提取数据特征。  我将采用如下的数据字段，并且，使用过去三天的数据作为预测。\n\nmean temperature\nmean dewpoint\nmean pressure\nmax humidity\nmin humidity\nmax dewpoint\nmin dewpoint\nmax pressure\nmin pressure\nprecipitation\n\n首先我需要在DataFrame里增加一些字段来保存新的数据字段，为了方便测试，我创建了一个tmp变量，存储10个数据，这些数据都有meantempm和meandewptm属性。代码如下：\ntmp = df[['meantempm', 'meandewptm']].head(10)  \ntmp  \n\n对于每一行的数据，我们分别获取他前一天、前两天、前三天对应的数据，存在本行，分别以属性_index来命名，代码如下：\n# 1 day prior\nN = 1\n\n# target measurement of mean temperature\nfeature = 'meantempm'\n\n# total number of rows\nrows = tmp.shape[0]\n\n# a list representing Nth prior measurements of feature\n# notice that the front of the list needs to be padded with N\n# None values to maintain the constistent rows length for each N\nnth_prior_measurements = [None]*N + [tmp[feature][i-N] for i in range(N, rows)]\n\n# make a new column name of feature_N and add to DataFrame\ncol_name = \"{}_{}\".format(feature, N)  \ntmp[col_name] = nth_prior_measurements  \ntmp  \n\n我们现在把上面的处理过程封装成一个函数，方便调用。\ndef derive_nth_day_feature(df, feature, N):  \n    rows = df.shape[0]\n    nth_prior_measurements = [None]*N + [df[feature][i-N] for i in range(N, rows)]\n    col_name = \"{}_{}\".format(feature, N)\n    df[col_name] = nth_prior_measurements\n好，我们现在对所有的特征，都取过去三天的数据，放在本行。\nfor feature in features:  \n    if feature != 'date':\n        for N in range(1, 4):\n            derive_nth_day_feature(df, feature, N)\n处理完后，我们现在的所有数据特征为：\ndf.columns  \n\nIndex(['meantempm', 'meandewptm', 'meanpressurem', 'maxhumidity',  \n       'minhumidity', 'maxtempm', 'mintempm', 'maxdewptm', 'mindewptm',\n       'maxpressurem', 'minpressurem', 'precipm', 'meantempm_1', 'meantempm_2',\n       'meantempm_3', 'meandewptm_1', 'meandewptm_2', 'meandewptm_3',\n       'meanpressurem_1', 'meanpressurem_2', 'meanpressurem_3',\n       'maxhumidity_1', 'maxhumidity_2', 'maxhumidity_3', 'minhumidity_1',\n       'minhumidity_2', 'minhumidity_3', 'maxtempm_1', 'maxtempm_2',\n       'maxtempm_3', 'mintempm_1', 'mintempm_2', 'mintempm_3', 'maxdewptm_1',\n       'maxdewptm_2', 'maxdewptm_3', 'mindewptm_1', 'mindewptm_2',\n       'mindewptm_3', 'maxpressurem_1', 'maxpressurem_2', 'maxpressurem_3',\n       'minpressurem_1', 'minpressurem_2', 'minpressurem_3', 'precipm_1',\n       'precipm_2', 'precipm_3'],\n      dtype='object')\n数据清洗\n  数据清洗时机器学习过程中最重要的一步，而且非常的耗时、费力。本教程中，我们会去掉不需要的样本、数据不完整的样本，查看数据的一致性等。  首先去掉我不感兴趣的数据，来减少样本集。我们的目标是根据过去三天的天气数据预测天气温度，因此我们只保留min, max, mean三个字段的数据。\n# make list of original features without meantempm, mintempm, and maxtempm\nto_remove = [feature  \n             for feature in features \n             if feature not in ['meantempm', 'mintempm', 'maxtempm']]\n\n# make a list of columns to keep\nto_keep = [col for col in df.columns if col not in to_remove]\n\n# select only the columns in to_keep and assign to df\ndf = df[to_keep]  \ndf.columns\nIndex(['meantempm', 'maxtempm', 'mintempm', 'meantempm_1', 'meantempm_2',  \n       'meantempm_3', 'meandewptm_1', 'meandewptm_2', 'meandewptm_3',\n       'meanpressurem_1', 'meanpressurem_2', 'meanpressurem_3',\n       'maxhumidity_1', 'maxhumidity_2', 'maxhumidity_3', 'minhumidity_1',\n       'minhumidity_2', 'minhumidity_3', 'maxtempm_1', 'maxtempm_2',\n       'maxtempm_3', 'mintempm_1', 'mintempm_2', 'mintempm_3', 'maxdewptm_1',\n       'maxdewptm_2', 'maxdewptm_3', 'mindewptm_1', 'mindewptm_2',\n       'mindewptm_3', 'maxpressurem_1', 'maxpressurem_2', 'maxpressurem_3',\n       'minpressurem_1', 'minpressurem_2', 'minpressurem_3', 'precipm_1',\n       'precipm_2', 'precipm_3'],\n      dtype='object')\n为了更好的观察数据，我们使用Pandas的一些内置函数来查看数据信息，首先我们使用info()函数，这个函数会输出DataFrame里存放的数据信息。\ndf.info()\n<class 'pandas.core.frame.DataFrame'>  \nDatetimeIndex: 1000 entries, 2015-01-01 to 2017-09-27  \nData columns (total 39 columns):  \nmeantempm          1000 non-null object  \nmaxtempm           1000 non-null object  \nmintempm           1000 non-null object  \nmeantempm_1        999 non-null object  \nmeantempm_2        998 non-null object  \nmeantempm_3        997 non-null object  \nmeandewptm_1       999 non-null object  \nmeandewptm_2       998 non-null object  \nmeandewptm_3       997 non-null object  \nmeanpressurem_1    999 non-null object  \nmeanpressurem_2    998 non-null object  \nmeanpressurem_3    997 non-null object  \nmaxhumidity_1      999 non-null object  \nmaxhumidity_2      998 non-null object  \nmaxhumidity_3      997 non-null object  \nminhumidity_1      999 non-null object  \nminhumidity_2      998 non-null object  \nminhumidity_3      997 non-null object  \nmaxtempm_1         999 non-null object  \nmaxtempm_2         998 non-null object  \nmaxtempm_3         997 non-null object  \nmintempm_1         999 non-null object  \nmintempm_2         998 non-null object  \nmintempm_3         997 non-null object  \nmaxdewptm_1        999 non-null object  \nmaxdewptm_2        998 non-null object  \nmaxdewptm_3        997 non-null object  \nmindewptm_1        999 non-null object  \nmindewptm_2        998 non-null object  \nmindewptm_3        997 non-null object  \nmaxpressurem_1     999 non-null object  \nmaxpressurem_2     998 non-null object  \nmaxpressurem_3     997 non-null object  \nminpressurem_1     999 non-null object  \nminpressurem_2     998 non-null object  \nminpressurem_3     997 non-null object  \nprecipm_1          999 non-null object  \nprecipm_2          998 non-null object  \nprecipm_3          997 non-null object  \ndtypes: object(39)  \nmemory usage: 312.5+ KB\n注意：每一行的数据类型都是object，我们需要把数据转成float。\ndf = df.apply(pd.to_numeric, errors='coerce')  \ndf.info()\n<class 'pandas.core.frame.DataFrame'>  \nDatetimeIndex: 1000 entries, 2015-01-01 to 2017-09-27  \nData columns (total 39 columns):  \nmeantempm          1000 non-null int64  \nmaxtempm           1000 non-null int64  \nmintempm           1000 non-null int64  \nmeantempm_1        999 non-null float64  \nmeantempm_2        998 non-null float64  \nmeantempm_3        997 non-null float64  \nmeandewptm_1       999 non-null float64  \nmeandewptm_2       998 non-null float64  \nmeandewptm_3       997 non-null float64  \nmeanpressurem_1    999 non-null float64  \nmeanpressurem_2    998 non-null float64  \nmeanpressurem_3    997 non-null float64  \nmaxhumidity_1      999 non-null float64  \nmaxhumidity_2      998 non-null float64  \nmaxhumidity_3      997 non-null float64  \nminhumidity_1      999 non-null float64  \nminhumidity_2      998 non-null float64  \nminhumidity_3      997 non-null float64  \nmaxtempm_1         999 non-null float64  \nmaxtempm_2         998 non-null float64  \nmaxtempm_3         997 non-null float64  \nmintempm_1         999 non-null float64  \nmintempm_2         998 non-null float64  \nmintempm_3         997 non-null float64  \nmaxdewptm_1        999 non-null float64  \nmaxdewptm_2        998 non-null float64  \nmaxdewptm_3        997 non-null float64  \nmindewptm_1        999 non-null float64  \nmindewptm_2        998 non-null float64  \nmindewptm_3        997 non-null float64  \nmaxpressurem_1     999 non-null float64  \nmaxpressurem_2     998 non-null float64  \nmaxpressurem_3     997 non-null float64  \nminpressurem_1     999 non-null float64  \nminpressurem_2     998 non-null float64  \nminpressurem_3     997 non-null float64  \nprecipm_1          889 non-null float64  \nprecipm_2          889 non-null float64  \nprecipm_3          888 non-null float64  \ndtypes: float64(36), int64(3)  \nmemory usage: 312.5 KB  \n现在得到我想要的数据了。接下来我们调用describe()函数，这个函数会返回一个DataFrame，这个返回值包含了总数、平均数、标准差、最小、25%、50%、75%、最大的数据信息。\n  接下来，使用四分位的方法，去掉25%数据里特别小的和75%数据里特别大的数据。\n# Call describe on df and transpose it due to the large number of columns\nspread = df.describe().T\n\n# precalculate interquartile range for ease of use in next calculation\nIQR = spread['75%'] - spread['25%']\n\n# create an outliers column which is either 3 IQRs below the first quartile or\n# 3 IQRs above the third quartile\nspread['outliers'] = (spread['min']<(spread['25%']-(3*IQR)))|(spread['max'] > (spread['75%']+3*IQR))\n\n# just display the features containing extreme outliers\nspread.ix[spread.outliers,]  \n  评估异常值的潜在影响是任何分析项目的难点。 一方面，您需要关注引入虚假数据样本的可能性，这些样本将严重影响您的模型。 另一方面，异常值对于预测在特殊情况下出现的结果是非常有意义的。 我们将讨论每一个包含特征的异常值，看看我们是否能够得出合理的结论来处理它们。\n  第一组特征看起来与最大湿度有关。 观察这些数据，我可以看出，这个特征类别的异常值是非常低的最小值。这数据看起来没价值，我想我想仔细看看它，最好是以图形方式。 要做到这一点，我会使用直方图。\n%matplotlib inline\nplt.rcParams['figure.figsize'] = [14, 8]  \ndf.maxhumidity_1.hist()  \nplt.title('Distribution of maxhumidity_1')  \nplt.xlabel('maxhumidity_1')  \nplt.show()\n查看maxhumidity字段的直方图，数据表现出相当多的负偏移。 在选择预测模型和评估最大湿度影响的强度时，我会牢记这一点。 许多基本的统计方法都假定数据是正态分布的。 现在我们暂时不管它，但是记住这个异常特性。\n  接下来我们看另外一个字段的直方图\ndf.minpressurem_1.hist()  \nplt.title('Distribution of minpressurem_1')  \nplt.xlabel('minpressurem_1')  \nplt.show() \n\n  要解决的最后一个数据质量问题是缺失值。 由于我构建DataFrame的时候，缺少的值由NaN表示。 您可能会记得，我通过推导代表前三天测量结果的特征，有意引入了收集数据前三天的缺失值。 直到第三天我们才能开始推导出这些特征，所以很明显我会想把这些头三天从数据集中排除出去。再回头再看一下上面info()函数输出的信息，可以看到包含NaN值的数据特征非常的少，除了我提到的几个字段，基本就没有了。因为机器学习需要样本字段数据的完整性，因为如果我们因为降水量那个字段为空，就去掉样本，那么会造成大量的样本不可用，对于这种情况，我们可以给为空的降水量字段的样本填入一个值。根据经验和尽量减少由于填入的值对模型的影响，我决定给为空的降水量字段填入值0。\n# iterate over the precip columns\nfor precip_col in ['precipm_1', 'precipm_2', 'precipm_3']:  \n    # create a boolean array of values representing nans\n    missing_vals = pd.isnull(df[precip_col])\n    df[precip_col][missing_vals] = 0\n填入值后，我们就可以删掉字段值为空的样本了，只用调用dropna()函数。\ndf = df.dropna()  \n总结\n  这篇文章主要介绍了数据的收集、处理、清洗的流程，本篇文章处理完的处理，将用于下篇文章的模型训练。  对你来说，这篇文章可能很枯燥，没啥干货，但好的样本数据，才能训练处好的模型，因此，样本数据的收集和处理能力，直接影响你后面的机器学习的效果。\n英文原文\n转自我的博客，捕蛇者说\n\n\n                ", "mainLikeNum": ["4 "], "mainBookmarkNum": "10"}