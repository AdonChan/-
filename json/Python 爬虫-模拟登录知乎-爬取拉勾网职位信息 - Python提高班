{"title": "Python 爬虫-模拟登录知乎-爬取拉勾网职位信息 - Python提高班 ", "index": "crawler,beautifulsoup,requests,网页爬虫,python", "content": "我开通了公众号【智能制造专栏】，以后技术类文章会发在专栏。用Python写爬虫是很方便的,最近看了xlzd.me的文章，他的文章写的很到位，提供了很好的思路。因为他的文章部分代码省略了。下面是基于他的文章的三个代码片段:基于Python3,Python2的话需要修改下input输入函数和print的用法。本文github代码地址\n\n爬取豆瓣电影top250\n爬取拉勾网职位信息\n模拟登陆知乎\n为什么没人给我点赞。？！\n\n有些代码做了更改。其中把获取的数据存储到excel中。关于存取数据到excel可以看我的另一篇文章：。\n用到的库\n\nrequests\nBeautiful Soup\nopenpyxl\n\n1. 爬取豆瓣电影top250，存到excel表格中\n#!/usr/bin/env python\n# encoding=utf-8\nimport requests,re\nimport codecs\nfrom bs4 import BeautifulSoup\nfrom openpyxl import Workbook\nwb = Workbook()\ndest_filename = '电影.xlsx'\nws1 = wb.active  \nws1.title = \"电影top250\"\n\nDOWNLOAD_URL = 'http://movie.douban.com/top250/'\n\ndef download_page(url):\n    \"\"\"获取url地址页面内容\"\"\"\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36'\n    }\n    data = requests.get(url, headers=headers).content\n    return data\n\n\ndef get_li(doc):\n    soup = BeautifulSoup(doc, 'html.parser')\n    ol = soup.find('ol', class_='grid_view')\n    name = [] #名字\n    star_con = [] #评价人数\n    score = []  #评分\n    info_list = []  #短评\n    for i in ol.find_all('li'):\n        detail = i.find('div', attrs={'class': 'hd'})\n        movie_name = detail.find('span', attrs={'class': 'title'}).get_text() #电影名字\n        level_star = i.find('span',attrs={'class':'rating_num'}).get_text() #评分\n        star = i.find('div',attrs={'class':'star'})\n        star_num = star.find(text=re.compile('评价'))  #评价\n\n        info = i.find('span',attrs={'class':'inq'})  #短评\n        if info:     #判断是否有短评\n            info_list.append(info.get_text())\n        else:\n            info_list.append('无')\n        score.append(level_star)\n        \n\n        name.append(movie_name)\n        star_con.append(star_num)\n    page = soup.find('span', attrs={'class': 'next'}).find('a') #获取下一页\n    if page:\n        return name,star_con,score,info_list,DOWNLOAD_URL + page['href']\n    return name,star_con,score,info_list,None\n\n\ndef main():\n    url = DOWNLOAD_URL\n    name = []\n    star_con=[]\n    score = []\n    info = []\n    while url:\n        doc = download_page(url)\n        movie,star,level_num,info_list,url = get_li(doc)\n        name = name + movie\n        star_con = star_con + star\n        score = score+level_num\n        info = info+ info_list\n    for (i,m,o,p) in zip(name,star_con,score,info):\n        col_A = 'A%s'%(name.index(i)+1)\n        col_B = 'B%s'%(name.index(i)+1)\n        col_C = 'C%s'%(name.index(i)+1)\n        col_D = 'D%s'%(name.index(i)+1)\n        ws1[col_A]=i\n        ws1[col_B] = m\n        ws1[col_C] = o\n        ws1[col_D] = p\n    wb.save(filename=dest_filename)\n\nif __name__ == '__main__':\n    main()\n\n结果如下：\n\n2. 爬取拉勾网Python职位信息\n职位信息存储在json中，获取到json对象，再从中遍历出公司名、地址、待遇等信息。\nimport requests\nfrom openpyxl import Workbook\n\ndef get_json(url, page, lang_name):\n    data = {'first': 'true', 'pn': page, 'kd': lang_name}\n    json = requests.post(url, data).json()\n    list_con = json['content']['positionResult']['result']\n    info_list = []\n    for i in list_con:\n        info = []\n        info.append(i['companyShortName'])\n        info.append(i['companyName'])\n        info.append(i['salary'])\n        info.append(i['city'])\n        info.append(i['education'])\n        info_list.append(info)\n    return info_list\n\n\ndef main():\n    lang_name = input('职位名：')\n    page = 1\n    url = 'http://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false'\n    info_result = []\n    while page < 31:\n        info = get_json(url, page, lang_name)\n        info_result = info_result + info\n        page += 1\n    wb = Workbook()\n    ws1 = wb.active\n    ws1.title = lang_name\n    for row in info_result:\n        ws1.append(row)\n    wb.save('职位信息.xlsx')\n\nif __name__ == '__main__':\n    main()\n\n运行结果：\n\n3. 模拟登录知乎\n通过开发者工具，获取post的数据。\nimport requests,time\nfrom bs4 import BeautifulSoup\ndef get_captcha(data):\n    with open('captcha.gif','wb') as fp:\n        fp.write(data)\n    return input('输入验证码：')\n\ndef login(username,password,oncaptcha):\n    sessiona = requests.Session()\n    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0'}\n    _xsrf = BeautifulSoup(sessiona.get('https://www.zhihu.com/#signin',headers=headers).content,'html.parser').find('input',attrs={'name':'_xsrf'}).get('value')\n    captcha_content = sessiona.get('https://www.zhihu.com/captcha.gif?r=%d&type=login'%(time.time()*1000),headers=headers).content\n    data = {\n        \"_xsrf\":_xsrf,\n        \"email\":username,\n        \"password\":password,\n        \"remember_me\":True,\n        \"captcha\":oncaptcha(captcha_content)\n    }\n    resp = sessiona.post('https://www.zhihu.com/login/email',data,headers=headers).content\n    print(resp)\n    return resp \n\nif __name__ == \"__main__\":\n    login('your_email','your_password',get_captcha)\n运行后会在运行目录下得到验证码图片：\n\n输入验证码后得到如下响应结果表明登录成功。\n\n\n                ", "mainLikeNum": ["10 "], "mainBookmarkNum": "43"}