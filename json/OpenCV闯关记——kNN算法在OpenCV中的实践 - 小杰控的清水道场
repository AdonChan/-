{"title": "OpenCV闯关记——kNN算法在OpenCV中的实践 - 小杰控的清水道场 ", "index": "python,opencv-python,opencv", "content": "什么是kNN算法\n邻近算法，或者说K最近邻(kNN，k-NearestNeighbor)分类算法是数据挖掘分类技术中最简单的方法之一。所谓K最近邻，就是k个最近的邻居的意思，说的是每个样本都可以用它最接近的k个邻居来代表。kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 kNN方法在类别决策时，只与极少量的相邻样本有关。由于kNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，kNN方法较其他方法更为适合。\n环境准备\n\n安装Ubuntu16.04桌面版 or 安装好桌面的服务器版\nOpenCV闯关记——Ubuntu16.04 OpenCV Python开发环境搭建\n安装numpy，numpy是什么\n\npip install numpy\n# 在国内往往会安装失败，如果安装失败，可通过先wget xxx.whl在运行pip install解决\n# 比如：\nwget https://pypi.python.org/packages/5e/d5/3433e015f3e4a1f309dbb110e8557947f68887fe9b8438d50a4b7790a954/numpy-1.11.2-cp27-cp27mu-manylinux1_x86_64.whl#md5=fa62a11922a9e0776963508fb5254d3d\npip install numpy-1.11.2-cp27-cp27mu-manylinux1_x86_64.whl\n安装matplotlib，matplotlib是什么\npip install matplotlib\n# 如安装失败的话，解决办法参考安装numpy的解决办法\nCoding\n# encoding: utf-8\n\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ntrain_data = np.random.randint(0, 100, (25, 2)).astype(np.float32)\n\nresponses = np.random.randint(0, 2, (25, 1)).astype(np.float32)\n\nred = train_data[responses.ravel() == 0]\nplt.scatter(red[:,0], red[:,1], 80, 'r', '^')\n\nblue = train_data[responses.ravel() == 1]\nplt.scatter(blue[:,0], blue[:,1], 80, 'b', 's')\n\n# plt.show()\n\nnewcomer = np.random.randint(0, 100, (1, 2)).astype(np.float32)\nplt.scatter(newcomer[:,0], newcomer[:,1], 80, 'g', 'o')\n\nknn = cv2.ml.KNearest_create()\nknn.train(train_data, cv2.ml.ROW_SAMPLE, responses)\nret, results, neighbours, dist = knn.findNearest(newcomer, 5)\n\nprint(\"result: \", results)\nprint(\"neighbours: \", neighbours)\nprint(\"distance: \", dist)\n\nplt.show()\n运行结果\n\n代码解释\n生成待训练的数据和标签\ntrain_data = np.random.randint(0, 100, (25, 2)).astype(np.float32)\n\nresponses = np.random.randint(0, 2, (25, 1)).astype(np.float32)\n在图中标记红色样本\nred = train_data[responses.ravel() == 0]\nplt.scatter(red[:,0], red[:,1], 80, 'r', '^')\n在图中标记蓝色样本\nblue = train_data[responses.ravel() == 1]\nplt.scatter(blue[:,0], blue[:,1], 80, 'b', 's')\n产生待分类数据\nnewcomer = np.random.randint(0, 100, (1, 2)).astype(np.float32)\nplt.scatter(newcomer[:,0], newcomer[:,1], 80, 'g', 'o')\n训练样本并产生分类\nknn = cv2.ml.KNearest_create()\nknn.train(train_data, cv2.ml.ROW_SAMPLE, responses)\n给新数据分类\nret, results, neighbours, dist = knn.findNearest(newcomer, 5)\n在图中显示所有数据\nplt.show()\nReferer\n\nUnderstanding k-Nearest Neighbour\nwikipedia: k-nearest neighbors algorithm\nkNN(K-Nearest Neighbor)最邻近规则分类\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}