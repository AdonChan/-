{"title": "Beautiful Soup的用法  - 个人文章 ", "index": "python", "content": "文章来源[Python爬虫利器二之Beautiful Soup的用法 | 静觅](http://cuiqingcai.com/1319.html\nBeautiful Soup的用法\n创建 Beautiful Soup 对象\n首先必须要导入 bs4 库\nfrom bs4 import BeautifulSoup\nfrom bs4 import BeautifulSoup\n我们创建一个字符串，后面的例子我们便会用它来演示\nPython\nhtml = \"\"\" <html><head><title>The Dormouse's story</title></head> <body> <p class=\"title\" name=\"dromouse\"><b>The Dormouse's story</b></p> <p class=\"story\">Once upon a time there were three little sisters; and their names were <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\"><!-- Elsie --></a>, <a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>; and they lived at the bottom of a well.</p> <p class=\"story\">...</p> \"\"\"\n创建 beautifulsoup 对象\nsoup = BeautifulSoup(html, \"lxml\")\n另外，我们还可以用本地 HTML 文件来创建对象，例如\nsoup = BeautifulSoup(open('index.html'), \"lxml\")\n上面这句代码便是将本地 index.html 文件打开，用它来创建 soup 对象下面我们来打印一下 soup 对象的内容，格式化输出\nprint soup.prettify()\n<html> <head> <title> The Dormouse's story </title> </head> <body> <p class=\"title\" name=\"dromouse\"> <b> The Dormouse's story </b> </p> <p class=\"story\"> Once upon a time there were three little sisters; and their names were <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"> <!-- Elsie --> </a> , <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"> Lacie </a> and <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\"> Tillie </a> ; and they lived at the bottom of a well. </p> <p class=\"story\"> ... </p> </body> </html>\n以上便是输出结果，格式化打印出了它的内容，这个函数经常用到，小伙伴们要记好咯。\n5. 四大对象种类\nBeautiful Soup将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象,所有对象可以归纳为4种:\n\nTag\nNavigableString\nBeautifulSoup\nComment\n\n下面我们进行一一介绍\n（1）Tag\nTag 是什么？通俗点讲就是 HTML 中的一个个标签，例如\n<title>The Dormouse's story</title>\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n上面的 title a 等等 HTML 标签加上里面包括的内容就是 Tag，下面我们来感受一下怎样用 Beautiful Soup 来方便地获取 Tags\n下面每一段代码中注释部分即为运行结果\nprint soup.title\n# <title>The Dormouse's story</title>\nprint soup.title\n # <title>The Dormouse's story</title>\nprint soup.head\n# <head><title>The Dormouse's story</title></head>\nprint soup.head\n # <head><title>The Dormouse's story</title></head>\nprint soup.a \n# <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>\nprint soup.a\n # <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>\nprint soup.p \n# <p class=\"title\" name=\"dromouse\"><b>The Dormouse's story</b></p>\nprint soup.p\n # <p class=\"title\" name=\"dromouse\"><b>The Dormouse's story</b></p>\n我们可以利用 soup加标签名轻松地获取这些标签的内容，是不是感觉比正则表达式方便多了？不过有一点是，它查找的是在所有内容中的第一个符合要求的标签，如果要查询所有的标签，我们在后面进行介绍。\n我们可以验证一下这些对象的类型\nprint type(soup.a) # <class 'bs4.element.Tag'>\nprint type(soup.a)\n # <class 'bs4.element.Tag'>\n对于 Tag，它有两个重要的属性，是 name 和 attrs，下面我们分别来感受一下\nname\nprint soup.name\nprint soup.head.name\n # [document]\n # head\nsoup 对象本身比较特殊，它的 name 即为 [document]，对于其他内部标签，输出的值便为标签本身的名称。\nattrs\nprint soup.p.attrs \n# {'class': ['title'], 'name': 'dromouse'}\nprint soup.p.attrs\n# {'class': ['title'], 'name': 'dromouse'}\n在这里，我们把 p 标签的所有属性打印输出了出来，得到的类型是一个字典。如果我们想要单独获取某个属性，可以这样，例如我们获取它的 class 叫什么\nprint soup.p['class']\n# ['title']\nprint soup.p['class']\n# ['title']\n还可以这样，利用get方法，传入属性的名称，二者是等价的\nprint soup.p.get('class') \n# ['title']\nprint soup.p.get('class')\n# ['title']\n我们可以对这些属性和内容等等进行修改，例如\nsoup.p['class']=\"newClass\"\nprint soup.p\n # <p class=\"newClass\" name=\"dromouse\"><b>The Dormouse's story</b></p>\n还可以对这个属性进行删除，例如\ndel soup.p['class']\nprint soup.p\n # <p name=\"dromouse\"><b>The Dormouse's story</b></p>\n不过，对于修改删除的操作，不是我们的主要用途，在此不做详细介绍了，如果有需要，请查看前面提供的官方文档\n（2）NavigableString\n既然我们已经得到了标签的内容，那么问题来了，我们要想获取标签内部的文字怎么办呢？很简单，用 .string 即可，例如\nprint soup.p.string\n# The Dormouse's story\n这样我们就轻松获取到了标签里面的内容，想想如果用正则表达式要多麻烦。它的类型是一个 NavigableString，翻译过来叫 可以遍历的字符串，不过我们最好还是称它英文名字吧。\n来检查一下它的类型\nprint type(soup.p.string)\n# <class 'bs4.element.NavigableString'>\n（3）BeautifulSoup\nBeautifulSoup 对象表示的是一个文档的全部内容.大部分时候,可以把它当作 Tag 对象，是一个特殊的 Tag，我们可以分别获取它的类型，名称，以及属性来感受一下\nprint type(soup.name)\n # <type 'unicode'>\nprint soup.name\n # [document]\nprint soup.attrs\n # {} 空字典\n（4）Comment\nComment 对象是一个特殊类型的 NavigableString 对象，其实输出的内容仍然不包括注释符号，但是如果不好好处理它，可能会对我们的文本处理造成意想不到的麻烦。\n我们找一个带注释的标签\nprint soup.a\nprint soup.a.string\nprint type(soup.a.string)\n运行结果如下\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>\nElsie\n<class 'bs4.element.Comment'>\na 标签里的内容实际上是注释，但是如果我们利用 .string 来输出它的内容，我们发现它已经把注释符号去掉了，所以这可能会给我们带来不必要的麻烦。\n另外我们打印输出下它的类型，发现它是一个 Comment 类型，所以，我们在使用前最好做一下判断，判断代码如下\nif type(soup.a.string)==bs4.element.Comment:\nprint soup.a.string\n上面的代码中，我们首先判断了它的类型，是否为 Comment 类型，然后再进行其他操作，如打印输出。\n6. 遍历文档树\n（1）直接子节点\n要点：.contents  .children   属性\n.contents\ntag 的 .content 属性可以将tag的子节点以列表的方式输出\nprint soup.head.contents\n # [<title>The Dormouse's story</title>]\n输出方式为列表，我们可以用列表索引来获取它的某一个元素\nprint soup.head.contents[0]\n # <title>The Dormouse's story</title>\n.children\n它返回的不是一个 list，不过我们可以通过遍历获取所有子节点。\n我们打印输出 .children 看一下，可以发现它是一个 list 生成器对象\nprint soup.head.children\n # <listiterator object at 0x7f71457f5710>\n我们怎样获得里面的内容呢？很简单，遍历一下就好了，代码及结果如下\nfor child in soup.body.children:\nprint child\n\n<p class=\"title\" name=\"dromouse\"><b>The Dormouse's story</b></p>\n<p class=\"story\">Once upon a time there were three little sisters; and their names were\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>,\n<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n（2）所有子孙节点\n知识点：.descendants 属性\n.descendants\n.contents 和 .children 属性仅包含tag的直接子节点，.descendants 属性可以对所有tag的子孙节点进行递归循环，和 children类似，我们也需要遍历获取其中的内容。\nfor child in soup.descendants:\nprint child\n运行结果如下，可以发现，所有的节点都被打印出来了，先生最外层的 HTML标签，其次从 head 标签一个个剥离，以此类推。\n<html><head><title>The Dormouse's story</title></head>\n<body>\n<p class=\"title\" name=\"dromouse\"><b>The Dormouse's story</b></p>\n<p class=\"story\">Once upon a time there were three little sisters; and their names were\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>,\n（3）节点内容\n知识点：.string 属性\n如果tag只有一个 NavigableString 类型子节点,那么这个tag可以使用 .string 得到子节点。如果一个tag仅有一个子节点,那么这个tag也可以使用 .string 方法,输出结果与当前唯一子节点的 .string 结果相同。\n通俗点说就是：如果一个标签里面没有标签了，那么 .string 就会返回标签里面的内容。如果标签里面只有唯一的一个标签了，那么 .string 也会返回最里面的内容。例如\nprint soup.head.string\n # The Dormouse's story\nprint soup.title.string\n # The Dormouse's story\n如果tag包含了多个子节点,tag就无法确定，string 方法应该调用哪个子节点的内容, .string 的输出结果是 None\nprint soup.html.string\n # None\n（4）多个内容\n知识点： .strings  .stripped_strings 属性\n.strings\n获取多个内容，不过需要遍历获取，比如下面的例子\nfor string in soup.strings:\n    print(repr(string))\n    # u\"The Dormouse's story\"\n    # u'\\n\\n'\n    # u\"The Dormouse's story\"\n    # u'\\n\\n'\n    # u'Once upon a time there were three little sisters; and their names were\\n'\n    # u'Elsie'\n    # u',\\n'\n    # u'Lacie'\n    # u' and\\n'\n    # u'Tillie'\n    # u';\\nand they lived at the bottom of a well.'\n    # u'\\n\\n'\n    # u'...'\n    # u'\\n'\n.stripped_strings\n输出的字符串中可能包含了很多空格或空行,使用 .stripped_strings 可以去除多余空白内容\nfor string in soup.stripped_strings:\n    print(repr(string))\n    # u\"The Dormouse's story\"\n    # u\"The Dormouse's story\"\n    # u'Once upon a time there were three little sisters; and their names were'\n    # u'Elsie'\n    # u','\n    # u'Lacie'\n    # u'and'\n    # u'Tillie'\n    # u';\\nand they lived at the bottom of a well.'\n    # u'...'\n（5）父节点\n知识点： .parent 属性\np = soup.p\nprint p.parent.name\n#body\ncontent = soup.head.title.string\nprint content.parent.name\n # title\n（6）全部父节点\n知识点：.parents 属性\n通过元素的 .parents 属性可以递归得到元素的所有父辈节点，例如\ncontent = soup.head.title.string\nfor parent in  content.parents:\n    print parent.name\ntitle\nhead\nhtml\n[document]\n（7）兄弟节点\n知识点：.next_sibling  .previous_sibling 属性\n兄弟节点可以理解为和本节点处在统一级的节点，.next_sibling 属性获取了该节点的下一个兄弟节点，.previous_sibling 则与之相反，如果节点不存在，则返回 None\n注意：实际文档中的tag的 .next_sibling 和 .previous_sibling 属性通常是字符串或空白，因为空白或者换行也可以被视作一个节点，所以得到的结果可能是空白或者换行\n\nprint soup.p.next_sibling\n#       实际该处为空白\nprint soup.p.prev_sibling\n#None   没有前一个兄弟节点，返回 None\nprint soup.p.next_sibling.next_sibling\n#<p class=\"story\">Once upon a time there were three little sisters; and their names were\n#<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>,\n#<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n#<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n#and they lived at the bottom of a well.</p>\n#下一个节点的下一个兄弟节点是我们可以看到的节点\n\n（8）全部兄弟节点\n知识点：.next_siblings  .previous_siblings 属性\n通过 .next_siblings 和 .previous_siblings 属性可以对当前节点的兄弟节点迭代输出\nfor sibling in soup.a.next_siblings:\n    print(repr(sibling))\n    # u',\\n'\n    # <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n    # u' and\\n'\n    # <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n    # u'; and they lived at the bottom of a well.'\n    # None\n（9）前后节点\n知识点：.next_element  .previous_element 属性\n与 .next_sibling  .previous_sibling 不同，它并不是针对于兄弟节点，而是在所有节点，不分层次\n比如 head 节点为\n<head><title>The Dormouse's story</title></head>\n那么它的下一个节点便是 title，它是不分层次关系的\nprint soup.head.next_element\n # <title>The Dormouse's story</title>\n（10）所有前后节点\n知识点：.next_elements  .previous_elements 属性\n通过 .next_elements 和 .previous_elements 的迭代器就可以向前或向后访问文档的解析内容,就好像文档正在被解析一样\nfor element in last_a_tag.next_elements:\n    print(repr(element))\n# u'Tillie'\n# u';\\nand they lived at the bottom of a well.'\n# u'\\n\\n'\n# <p class=\"story\">...</p>\n# u'...'\n# u'\\n'\n# None\n以上是遍历文档树的基本用法。\n7.搜索文档树\n（1）find_all( name , attrs , recursive , text , **kwargs )\nfind_all() 方法搜索当前tag的所有tag子节点,并判断是否符合过滤器的条件\n1）name 参数\nname 参数可以查找所有名字为 name 的tag,字符串对象会被自动忽略掉\nA.传字符串\n最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的标签\nsoup.find_all('b')\n # [<b>The Dormouse's story</b>]\nprint soup.find_all('a')\n # [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\nB.传正则表达式\n如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容.下面例子中找出所有以b开头的标签,这表示<body>和标签都应该被找到\nimport re\nfor tag in soup.find_all(re.compile(\"^b\")):\nprint(tag.name)\n # body\n # b\nC.传列表\n如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有标签和标签\nsoup.find_all([\"a\", \"b\"])\n # [<b>The Dormouse's story</b>,\n #   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n #   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n #   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\nD.传 True\nTrue 可以匹配任何值,下面代码查找到所有的tag,但是不会返回字符串节点\nfor tag in soup.find_all(True):\n    print(tag.name)\n# html\n# head\n# title\n# body\n# p\n# b\n# p\n# a\n# a\nE.传方法\n如果没有合适过滤器,那么还可以定义一个方法,方法只接受一个元素参数 [[4]](http://www.crummy.com/softwar... ,如果这个方法返回 True 表示当前元素匹配并且被找到,如果不是则反回 False\n下面方法校验了当前元素,如果包含 class 属性却不包含 id 属性,那么将返回True:\ndef has_class_but_no_id(tag):\nreturn tag.has_attr('class') and not tag.has_attr('id')\n将这个方法作为参数传入 find_all() 方法,将得到所有<p>标签:\nsoup.find_all(has_class_but_no_id)\n # [<p class=\"title\"><b>The Dormouse's story</b></p>,\n #   <p class=\"story\">Once upon a time there were...</p>,\n #   <p class=\"story\">...</p>]\n2）keyword 参数\n注意：如果一个指定名字的参数不是搜索内置的参数名,搜索时会把该参数当作指定名字tag的属性来搜索,如果包含一个名字为 id 的参数,Beautiful Soup会搜索每个tag的”id”属性\nsoup.find_all(id='link2')\n # [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n如果传入 href 参数,Beautiful Soup会搜索每个tag的”href”属性\nsoup.find_all(href=re.compile(\"elsie\"))\n # [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]\n使用多个指定名字的参数可以同时过滤tag的多个属性\nsoup.find_all(href=re.compile(\"elsie\"), id='link1')\n # [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">three</a>]\n在这里我们想用 class 过滤，不过 class 是 python 的关键词，这怎么办？加个下划线就可以\nsoup.find_all(\"a\", class_=\"sister\")\n # [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n #   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n #   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n有些tag属性在搜索不能使用,比如HTML5中的 data-* 属性\ndata_soup = BeautifulSoup('<div data-foo=\"value\">foo!</div>')\ndata_soup.find_all(data-foo=\"value\")\n # SyntaxError: keyword can't be an expression\n但是可以通过 find_all() 方法的 attrs 参数定义一个字典参数来搜索包含特殊属性的tag\ndata_soup.find_all(attrs={\"data-foo\": \"value\"})\n # [<div data-foo=\"value\">foo!</div>]\n3）text 参数\n通过 text 参数可以搜搜文档中的字符串内容.与 name 参数的可选值一样, text 参数接受 字符串 , 正则表达式 , 列表, True\n\nsoup.find_all(text=\"Elsie\")\n # [u'Elsie']\n\nsoup.find_all(text=[\"Tillie\", \"Elsie\", \"Lacie\"])\n # [u'Elsie', u'Lacie', u'Tillie']\n\nsoup.find_all(text=re.compile(\"Dormouse\"))\n[u\"The Dormouse's story\", u\"The Dormouse's story\"]\n\n4）limit 参数\nfind_all() 方法返回全部的搜索结构,如果文档树很大那么搜索会很慢.如果我们不需要全部结果,可以使用 limit 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 limit 的限制时,就停止搜索返回结果.\n文档树中有3个tag符合搜索条件,但结果只返回了2个,因为我们限制了返回数量\nsoup.find_all(\"a\", limit=2)\n # [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n #   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n5）recursive 参数\n调用tag的 find_all() 方法时,Beautiful Soup会检索当前tag的所有子孙节点,如果只想搜索tag的直接子节点,可以使用参数 recursive=False .\n一段简单的文档:\n<html>\n<head>\n<title>\nThe Dormouse's story\n</title>\n</head>\n...\n是否使用 recursive 参数的搜索结果:\nsoup.html.find_all(\"title\")\n # [<title>The Dormouse's story</title>]\n\nsoup.html.find_all(\"title\", recursive=False)\n # []\n（2）find( name , attrs , recursive , text , **kwargs )\n它与 find_all() 方法唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果\n（3）find_parents()  find_parent()\nfind_all() 和 find() 只搜索当前节点的所有子节点,孙子节点等. find_parents() 和 find_parent() 用来搜索当前节点的父辈节点,搜索方法与普通tag的搜索方法相同,搜索文档搜索文档包含的内容\n（4）find_next_siblings()  find_next_sibling()\n这2个方法通过 .next_siblings 属性对当 tag 的所有后面解析的兄弟 tag 节点进行迭代, find_next_siblings() 方法返回所有符合条件的后面的兄弟节点,find_next_sibling() 只返回符合条件的后面的第一个tag节点\n（5）find_previous_siblings()  find_previous_sibling()\n这2个方法通过 .previous_siblings 属性对当前 tag 的前面解析的兄弟 tag 节点进行迭代, find_previous_siblings() 方法返回所有符合条件的前面的兄弟节点, find_previous_sibling() 方法返回第一个符合条件的前面的兄弟节点\n（6）find_all_next()  find_next()\n这2个方法通过 .next_elements 属性对当前 tag 的之后的 tag 和字符串进行迭代, find_all_next() 方法返回所有符合条件的节点, find_next() 方法返回第一个符合条件的节点\n（7）find_all_previous() 和 find_previous()\n这2个方法通过 .previous_elements 属性对当前节点前面的 tag 和字符串进行迭代, find_all_previous() 方法返回所有符合条件的节点, find_previous()方法返回第一个符合条件的节点\n注：以上（2）（3）（4）（5）（6）（7）方法参数用法与 find_all() 完全相同，原理均类似，在此不再赘述。\n8.CSS选择器\n我们在写 CSS 时，标签名不加任何修饰，类名前加点，id名前加 # ，在这里我们也可以利用类似的方法来筛选元素，用到的方法是 soup.select()， 返回类型是 list\n（1）通过标签名查找\nprint soup.select('title')\n # [<title>The Dormouse's story</title>]\n\nprint soup.select('a')\n # [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n\nprint soup.select('b')\n # [<b>The Dormouse's story</b>]\n（2）通过类名查找\nprint soup.select('.sister')\n # [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n（3）通过 id 名查找\nprint soup.select(' # link1')\n # [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>]\n（4）组合查找\n组合查找即和写 class 文件时，标签名与类名、id名进行的组合原理是一样的，例如查找 p 标签中，id 等于 link1的内容，二者需要用空格分开\nprint soup.select('p # link1')\n # [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>]\n直接子标签查找\nprint soup.select(\"head > title\")\n # [<title>The Dormouse's story</title>]\n（5）属性查找\n查找时还可以加入属性元素，属性需要用中括号括起来，注意属性和标签属于同一节点，所以中间不能加空格，否则会无法匹配到。\nprint soup.select('a[class=\"sister\"]')\n # [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n\nprint soup.select('a[href=\"http://example.com/elsie\"]')\n # [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>]\n同样，属性仍然可以与上述查找方式组合，不在同一节点的空格隔开，同一节点的不加空格\nprint soup.select('p a[href=\"http://example.com/elsie\"]')\n # [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!-- Elsie --></a>]\n以上的 select 方法返回的结果都是列表形式，可以遍历形式输出，然后用 get_text() 方法来获取它的内容。\nsoup = BeautifulSoup(html, 'lxml')\nprint type(soup.select('title'))\nprint soup.select('title')[0].get_text()\n\nfor title in soup.select('title'):\n        print title.get_text()\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "5"}