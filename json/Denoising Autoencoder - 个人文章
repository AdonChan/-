{"title": "Denoising Autoencoder - 个人文章 ", "index": "python", "content": "作者：chen_h微信号 & QQ：862251340微信公众号：coderpai简书地址：https://www.jianshu.com/p/f7b...\n\n\n自编码器 Autoencoder\n稀疏自编码器 Sparse Autoencoder\n降噪自编码器 Denoising Autoencoder\n堆叠自编码器 Stacked Autoencoder\n\n\n降噪自编码器（DAE）是另一种自编码器的变种。强烈推荐 Pascal Vincent 的论文，该论文很详细的描述了该模型。降噪自编码器认为，设计一个能够恢复原始信号的自编码器未必是最好的，而能够对 “被污染/破坏” 的原始数据进行编码、解码，然后还能恢复真正的原始数据，这样的特征才是好的。\n从数学上来讲，假设原始数据 x 被我们“故意破坏”了，比如加入高斯噪声，或者把某些维度数据抹掉，变成 x'，然后在对 x' 进行编码、解码，得到回复信号 xx = g(f(x')) 。该恢复信号尽可能的逼近未被污染的原数据 x 。此时，监督训练的误差函数就从原来的 L(x, g(f(x))) 变成了 L(x, g(f(x')))。\n从直观上理解，降噪自编码器希望学到的特征尽可能鲁棒，能够在一定程度上对抗原始数据的污染、缺失等情况。Vincent 论文里也对 DAE 提出了基于流行学习的解释，并且在图像数据上进行测试，发现 DAE 能够学出类似 Gabor 边缘提取的特征变换。\nDAE 的系统结构如下图所示：\n\n现在使用比较多的噪声主要是 mask noise，即原始数据中部分数据缺失，这是有着强烈的实际意义的，比如图像部分像素被遮挡、文本因记录原因漏掉一些单词等等。\n实现代码如下：\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf \nimport numpy as np \nimport input_data\n\nN_INPUT = 784\nN_HIDDEN = 100\nN_OUTPUT = N_INPUT\ncorruption_level = 0.3\nepoches = 1000\n\ndef main(_):\n\n    w_init = np.sqrt(6. / (N_INPUT + N_HIDDEN))\n    weights = {\n        \"hidden\": tf.Variable(tf.random_uniform([N_INPUT, N_HIDDEN], minval = -w_init, maxval = w_init)),\n        \"out\": tf.Variable(tf.random_uniform([N_HIDDEN, N_OUTPUT], minval = -w_init, maxval = w_init))\n    }\n\n    bias = {\n        \"hidden\": tf.Variable(tf.random_uniform([N_HIDDEN], minval = -w_init, maxval = w_init)),\n        \"out\": tf.Variable(tf.random_uniform([N_OUTPUT], minval = -w_init, maxval = w_init))\n    }\n\n    with tf.name_scope(\"input\"):\n        # input data\n        x = tf.placeholder(\"float\", [None, N_INPUT])\n        mask = tf.placeholder(\"float\", [None, N_INPUT])\n\n    with tf.name_scope(\"input_layer\"):\n        # from input data to input layer\n        input_layer = tf.mul(x, mask)\n\n    with tf.name_scope(\"hidden_layer\"):\n        # from input layer to hidden layer\n        hidden_layer = tf.sigmoid(tf.add(tf.matmul(input_layer, weights[\"hidden\"]), bias[\"hidden\"]))\n\n    with tf.name_scope(\"output_layer\"):\n        # from hidden layer to output layer\n        output_layer = tf.sigmoid(tf.add(tf.matmul(hidden_layer, weights[\"out\"]), bias[\"out\"]))\n\n    with tf.name_scope(\"cost\"):\n        # cost function\n        cost = tf.reduce_sum(tf.pow(tf.sub(output_layer, x), 2))\n\n    optimizer = tf.train.AdamOptimizer().minimize(cost)\n\n    # load MNIST data\n    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n    trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n\n    with tf.Session() as sess:\n\n        init = tf.initialize_all_variables()\n        sess.run(init)\n\n        for i in range(epoches):\n            for start, end in zip(range(0, len(trX), 100), range(100, len(trX), 100)):\n                input_ = trX[start:end]\n                mask_np = np.random.binomial(1, 1 - corruption_level, input_.shape)\n                sess.run(optimizer, feed_dict={x: input_, mask: mask_np})\n\n            mask_np = np.random.binomial(1, 1 - corruption_level, teX.shape)\n            print i, sess.run(cost, feed_dict={x: teX, mask: mask_np})\n\nif __name__ == \"__main__\":\n    tf.app.run()\n\n\nReference:\n[《Extracting and Composing Robust Features with DenoisingAutoencoders》](http://machinelearning.org/ar...\n《Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion》\n\n作者：chen_h微信号 & QQ：862251340简书地址：https://www.jianshu.com/p/f7b...\nCoderPai 是一个专注于算法实战的平台，从基础的算法到人工智能算法都有设计。如果你对算法实战感兴趣，请快快关注我们吧。加入AI实战微信群，AI实战QQ群，ACM算法微信群，ACM算法QQ群。长按或者扫描如下二维码，关注 “CoderPai” 微信号（coderpai）\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}