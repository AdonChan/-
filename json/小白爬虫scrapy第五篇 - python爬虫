{"title": "小白爬虫scrapy第五篇 - python爬虫 ", "index": "mysql,python", "content": "接下来将数据保存到数据库中在项目路径下创建一个目录名字叫做:mysqlpipelines以便区分创建将其他目录的__init__.py文件拷贝一份放入该目录然后可以正式开始吧爬取的数据如何存放在数据库中了,客观代码来了\n打开settings.py文件在最下面添加\n# configure MySQL\nMYSQL_HOSTS = '127.0.0.1'#数据库地址\nMYSQL_USER = 'root'#数据库用户名\nMYSQL_PASSWORD = 'root'#数据库密码\nMYSQL_PORT = '3306'#数据库端口\nMYSQL_DB = 'test'#数据库中test库\n由于我的数据库是本地的那就所以直接酱紫之后呢,在mysqlpipelines目录中新建一个sql.py代码如下\nimport mysql.connector\nfrom dingdian import settings\n# 引用配置文件\nMYSQL_HOSTS = settings.MYSQL_HOSTS\nMYSQL_USER = settings.MYSQL_USER\nMYSQL_PASSWORD = settings.MYSQL_PASSWORD\nMYSQL_PORT = settings.MYSQL_PORT\nMYSQL_DB = settings.MYSQL_DB\n# 初始化MYSQL游标操作\ncnx = mysql.connector.connect(user=MYSQL_USER, password=MYSQL_PASSWORD, host=MYSQL_HOSTS, database=MYSQL_DB)\ncur = cnx.cursor(buffered=True)\n\n# 定义一个sql类\nclass Sql:\n    # @classmethod 做类修饰,相当于静态类\n    # 定义函数,将函数中的变量保存到数据库中\n    @classmethod\n    def insert_dd_name(cls, video_name, video_time, video_imgurl, video_url):\n        sql = \"INSERT INTO video_info(video_name, video_time, video_imgurl, video_url)\n            VALUES(%(video_name)s, %(video_time)s, %(video_imgurl)s, %(video_url)s)\"\n        value = {'video_name' : video_name,\n                 'video_time': video_time ,\n                 'video_imgurl': video_imgurl ,\n                 'video_url': video_url }\n        print(sql, value)\n        cur.execute(sql, value)\n        cnx.commit()\n        pass\n        \n    # 查找是否有重复的小说编号有则返回1 没有则返回0\n    @classmethod\n    def select_name(cls, video_name):\n        sql = 'SELECT EXISTS(SELECT 1 FROM video_info WHERE video_name= %(video_name)s)'\n        value = {\n            'video_name': video_name\n        }\n        cur.execute(sql, value)\n        return cur.fetchall()[0]\n上面代码中import mysql.connector可能会报错,如果报错的话就去百度python如何下载数据库连接包吧然后继续在mysqlpipelines创建一个pipelines.py代码如下:\nfrom .sql import Sql\nfrom AiQuer.items import AiquerItem\n\nclass DingdianPipeline(object):\n\n    def process_item(self, item, spider):\n        if isinstance(item, AiquerItem):\n            video_name= item['video_name']\n            ret = Sql.select_name(video_name)\n            if ret[0] == 1:\n                print(u'已存在')\n            else:\n                video_name= item['video_name']\n                video_time= item['video_time']\n                video_imgurl= item['video_imgurl']\n                video_url= item['video_url']\n                \n                Sql.insert_dd_name(video_name, video_time, video_imgurl, video_url)\n                print(u'开始存视频信息')\n        return item\n最后在settings.py里面去注册一下DingdianPipeline找到下面这一段\n# Configure item pipelines\n# See http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.html\nITEM_PIPELINES = {\n    'AiQuer.mysqlpipelines.pipelines.AiquerPipeline': 300,\n}\n注:我在这里面没有建立数据库表请同学们自己去创建表吧启用后你会发现数据库有你选择用户的所有视频,哈哈哈~python的就到这儿了.如果要详细了解进阶的话就看python的scrapy文档吧!附上链接Scrapy入门教程.拜拜~\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}