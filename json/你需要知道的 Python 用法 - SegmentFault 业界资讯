{"title": "你需要知道的 Python 用法 - SegmentFault 业界资讯 ", "index": "python", "content": "\n在使用Python多年以后，我偶然发现了一些我们过去不知道的功能和特性。一些可以说是非常有用，但却没有充分利用。考虑到这一点，我编辑了一些的你应该了解的Pyghon功能特色。\n\n带任意数量参数的函数\n\n你可能已经知道了Python允许你定义可选参数。但还有一个方法，可以定义函数任意数量的参数。\n首先，看下面是一个只定义可选参数的例子\n\ndef function(arg1=\"\",arg2=\"\"):\n    print \"arg1: {0}\".format(arg1)\n    print \"arg2: {0}\".format(arg2)\n\nfunction(\"Hello\", \"World\")\n# prints args1: Hello\n# prints args2: World\n\nfunction()\n# prints args1:\n# prints args2:\n\n\n现在，让我们看看怎么定义一个可以接受任意参数的函数。我们利用元组来实现。\n\ndef foo(*args): # just use \"*\" to collect all remaining arguments into a tuple\n    numargs = len(args)\n    print \"Number of arguments: {0}\".format(numargs)\n    for i, x in enumerate(args):\n        print \"Argument {0} is: {1}\".format(i,x)\n\nfoo()\n# Number of arguments: 0\n\nfoo(\"hello\")\n# Number of arguments: 1\n# Argument 0 is: hello\n\nfoo(\"hello\",\"World\",\"Again\")\n# Number of arguments: 3\n# Argument 0 is: hello\n# Argument 1 is: World\n# Argument 2 is: Again\n\n\n使用Glob()查找文件\n\n大多Python函数有着长且具有描述性的名字。但是命名为glob() 的函数你可能不知道它是干什么的除非你从别处已经熟悉它了。\n它像是一个更强大版本的 listdir() 函数。它可以让你通过使用模式匹配来搜索文件。\n\nimport glob\n\n# get all py files\nfiles = glob.glob('*.py')\nprint files\n\n# Output\n# ['arg.py', 'g.py', 'shut.py', 'test.py']\n\n\n你可以像下面这样查找多个文件类型：\n\nimport itertools as it, glob\n\ndef multiple_file_types(*patterns):\n    return it.chain.from_iterable(glob.glob(pattern) for pattern in patterns)\n\nfor filename in multiple_file_types(\"*.txt\", \"*.py\"): # add as many filetype arguements\n    print filename\n\n# output\n#=========#\n# test.txt\n# arg.py\n# g.py\n# shut.py\n# test.py\n\n\n如果你想得到每个文件的绝对路径，你可以在返回值上调用 realpath() 函数：\n\nimport itertools as it, glob, os\n\ndef multiple_file_types(*patterns):\n    return it.chain.from_iterable(glob.glob(pattern) for pattern in patterns)\n\nfor filename in multiple_file_types(\"*.txt\", \"*.py\"): # add as many filetype arguements\n    realpath = os.path.realpath(filename)\n    print realpath\n\n# output\n#=========#\n# C:\\xxx\\pyfunc\\test.txt\n# C:\\xxx\\pyfunc\\arg.py\n# C:\\xxx\\pyfunc\\g.py\n# C:\\xxx\\pyfunc\\shut.py\n# C:\\xxx\\pyfunc\\test.py\n\n\n调试\n\n下面的例子使用 inspect模块。该模块用于调试目的时是非常有用的，它的功能远比这里描述的要多。\n这篇文章不会覆盖这个模块的每个细节，但会展示给你一些用例。\n\nimport logging, inspect\n\nlogging.basicConfig(level=logging.INFO,\n    format='%(asctime)s %(levelname)-8s %(filename)s:%(lineno)-4d: %(message)s',\n    datefmt='%m-%d %H:%M',\n    )\nlogging.debug('A debug message')\nlogging.info('Some information')\nlogging.warning('A shot across the bow')\n\ndef test():\n    frame,filename,line_number,function_name,lines,index=\\\n        inspect.getouterframes(inspect.currentframe())[1]\n    print(frame,filename,line_number,function_name,lines,index)\n\ntest()\n\n# Should print the following (with current date/time of course)\n#10-19 19:57 INFO     test.py:9   : Some information\n#10-19 19:57 WARNING  test.py:10  : A shot across the bow\n#(, 'C:/xxx/pyfunc/magic.py', 16, '', ['test()\\n'], 0)\n\n\n生成唯一ID\n\n在有些情况下你需要生成一个唯一的字符串。我看到很多人使用md5()函数来达到此目的，但它确实不是以此为目的。\n其实有一个名为uuid()的Python函数是用于这个目的的。\n\nimport uuid\nresult = uuid.uuid1()\nprint result\n\n# output => various attempts\n# 9e177ec0-65b6-11e3-b2d0-e4d53dfcf61b\n# be57b880-65b6-11e3-a04d-e4d53dfcf61b\n# c3b2b90f-65b6-11e3-8c86-e4d53dfcf61b\n\n\n你可能会注意到，即使字符串是唯一的，但它们后边的几个字符看起来很相似。这是因为生成的字符串与电脑的MAC地址是相联系的。\n为了减少重复的情况，你可以使用这两个函数。\n\nimport hmac,hashlib\nkey='1'\ndata='a'\nprint hmac.new(key, data, hashlib.sha256).hexdigest()\n\nm = hashlib.sha1()\nm.update(\"The quick brown fox jumps over the lazy dog\")\nprint m.hexdigest()\n\n# c6e693d0b35805080632bc2469e1154a8d1072a86557778c27a01329630f8917\n# 2fd4e1c67a2d28fced849ee1bb76e7391b93eb12\n\n\n序列化\n\n你曾经需要将一个复杂的变量存储在数据库或文本文件中吧？你不需要想一个奇特的方法将数组或对象格转化为式化字符串，因为Python已经提供了此功能。\n\nimport pickle\n\nvariable = ['hello', 42, [1,'two'],'apple']\n\n# serialize content\nfile = open('serial.txt','w')\nserialized_obj = pickle.dumps(variable)\nfile.write(serialized_obj)\nfile.close()\n\n# unserialize to produce original content\ntarget = open('serial.txt','r')\nmyObj = pickle.load(target)\n\nprint serialized_obj\nprint myObj\n\n#output\n# (lp0\n# S'hello'\n# p1\n# aI42\n# a(lp2\n# I1\n# aS'two'\n# p3\n# aaS'apple'\n# p4\n29\n# a.\n# ['hello', 42, [1, 'two'], 'apple']\n\n\n这是一个原生的Python序列化方法。然而近几年来JSON变得流行起来，Python添加了对它的支持。现在你可以使用JSON来编解码。\n\nimport json\n\nvariable = ['hello', 42, [1,'two'],'apple']\nprint \"Original {0} - {1}\".format(variable,type(variable))\n\n# encoding\nencode = json.dumps(variable)\nprint \"Encoded {0} - {1}\".format(encode,type(encode))\n\n#deccoding\ndecoded = json.loads(encode)\nprint \"Decoded {0} - {1}\".format(decoded,type(decoded))\n\n# output\n\n# Original ['hello', 42, [1, 'two'], 'apple'] - <type 'list'=\"\">\n# Encoded [\"hello\", 42, [1, \"two\"], \"apple\"] - <type 'str'=\"\">\n# Decoded [u'hello', 42, [1, u'two'], u'apple'] - <type 'list'=\"\">\n\n\n这样更紧凑，而且最重要的是这样与JavaScript和许多其他语言兼容。然而对于复杂的对象，其中的一些信息可能丢失。\n\n压缩字符\n\n当谈起压缩时我们通常想到文件，比如ZIP结构。在Python中可以压缩长字符，不涉及任何档案文件。\n\nimport zlib\n\nstring =  \"\"\"   Lorem ipsum dolor sit amet, consectetur\n                adipiscing elit. Nunc ut elit id mi ultricies\n                adipiscing. Nulla facilisi. Praesent pulvinar,\n                sapien vel feugiat vestibulum, nulla dui pretium orci,\n                non ultricies elit lacus quis ante. Lorem ipsum dolor\n                sit amet, consectetur adipiscing elit. Aliquam\n                pretium ullamcorper urna quis iaculis. Etiam ac massa\n                sed turpis tempor luctus. Curabitur sed nibh eu elit\n                mollis congue. Praesent ipsum diam, consectetur vitae\n                ornare a, aliquam a nunc. In id magna pellentesque\n                tellus posuere adipiscing. Sed non mi metus, at lacinia\n                augue. Sed magna nisi, ornare in mollis in, mollis\n                sed nunc. Etiam at justo in leo congue mollis.\n                Nullam in neque eget metus hendrerit scelerisque\n                eu non enim. Ut malesuada lacus eu nulla bibendum\n                id euismod urna sodales. \"\"\"\n\nprint \"Original Size: {0}\".format(len(string))\n\ncompressed = zlib.compress(string)\nprint \"Compressed Size: {0}\".format(len(compressed))\n\ndecompressed = zlib.decompress(compressed)\nprint \"Decompressed Size: {0}\".format(len(decompressed))\n\n# output\n\n# Original Size: 1022\n# Compressed Size: 423\n# Decompressed Size: 1022\n\n\n注册Shutdown函数\n\n有可模块叫atexit，它可以让你在脚本运行完后立马执行一些代码。\n假如你想在脚本执行结束时测量一些基准数据，比如运行了多长时间：\n\nimport atexit\nimport time\nimport math\n\ndef microtime(get_as_float = False) :\n    if get_as_float:\n        return time.time()\n    else:\n        return '%f %d' % math.modf(time.time())\nstart_time = microtime(False)\natexit.register(start_time)\n\ndef shutdown():\n    global start_time\n    print \"Execution took: {0} seconds\".format(start_time)\n\natexit.register(shutdown)\n\n# Execution took: 0.297000 1387135607 seconds\n# Error in atexit._run_exitfuncs:\n# Traceback (most recent call last):\n#   File \"C:\\Python27\\lib\\atexit.py\", line 24, in _run_exitfuncs\n#     func(*targs, **kargs)\n# TypeError: 'str' object is not callable\n# Error in sys.exitfunc:\n# Traceback (most recent call last):\n#   File \"C:\\Python27\\lib\\atexit.py\", line 24, in _run_exitfuncs\n#     func(*targs, **kargs)\n# TypeError: 'str' object is not callable\n\n\n打眼看来很简单。只需要将代码添加到脚本的最底层，它将在脚本结束前运行。但如果脚本中有一个致命错误或者脚本被用户终止，它可能就不运行了。\n当你使用atexit.register()时，你的代码都将执行，不论脚本因为什么原因停止运行。\n\n结论\n\n你是否意识到那些不是广为人知Python特性很有用？请在评论处与我们分享。谢谢你的阅读！\n\n\n\n原文：Useful Python Functions and Features You Need to Know\n转载自：开源中国 -- 鄂世嘉, Garfielt, Rhys\n\n                ", "mainLikeNum": ["4 "], "mainBookmarkNum": "12"}