{"title": "Python爬虫_爬取豆瓣阅读提供方列表并写入excel文件中 - 活到老学到老 ", "index": "python3.x,python爬虫,python", "content": "爬取豆瓣阅读提供方\n\n代码中会有详细的注释\n关于python也是在看教程和书以及视频学习，纯种小白(哈士奇的那种)\n用到的库\n\nurllib     ->    爬虫库\nre     ->    正则模块\nxlwt     ->    excel写模块\ntime     ->    时间模块\n\nurllib库伪装浏览器的固定写法(也可以再加)\n加个代理ip，也可以不加直接使用自己的ip地址代理ip     ->     '123.116.129.176'\n西刺代理\n\n通过正则获取内容\n菜鸟教程的re模块\n更加详细的用法百度可以找到很多，我就不一一的列出来了这里有个坑，第一个匹配出来的url地址不对，原因是网页中有个非列表标签内的居然和正则开始的匹配(列表标签)是一致的\n\n写入excel的操作\n部分代码\n# 创建workbook和sheet对象\nworkbook = xlwt.Workbook()\n# excel 底部 sheet1\n# 覆盖单元格\nsheet1 = workbook.add_sheet('统计', cell_overwrite_ok=True)\n...\nfor i in content:\n  # 在第 row + 1 行第 1 列写入序号\n  sheet1.write(row + 1, 0, row + 1, style)\n  # 在第 row + 1 行第 2 列写入出版社_url\n  sheet1.write(row + 1, 1, \"https://read.douban.com{}\".format(str(i[0])), style)\n  # 在第 row + 1 行第 3 列写入LOGO_url\n  sheet1.write(row + 1, 2, i[1], style)\n  # 在第 row + 1 行第 4 列写入出版社名称\n  sheet1.write(row + 1, 3, i[2], style)\n  # 在第 row + 1 行第 5 列写入在售数量\n  sheet1.write(row + 1, 4, int(i[3]), style)\n  # 对在售数量求和\n  sum += int(i[3])\n  row += 1\n\n时间模块的用法获取当前时间并格式化：time.strftime(\"%Y%m%d%H%M%S\", time.localtime())\n将对一列数据(在售数量)求和以及数据保存\n需要注意，这里写个判断语句要等到基础数据都写入完毕之后在进行求和运算并写入\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "1"}