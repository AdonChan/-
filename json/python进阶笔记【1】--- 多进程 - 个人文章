{"title": "python进阶笔记【1】--- 多进程 - 个人文章 ", "index": "python", "content": "有关于 multiprocessing 中共享变量的问题\n现在的cpu都很强大，比方我用的至强2620有24核可以同时工作，并行执行进程程序。这在计算密集型的程序是很需要的，如沙漠中的绿洲，令人重获新生。那么，问题接踵而来，python中多进程能否共享一个变量，因为我需要更新矩阵。\n我的办法是用list存储三元组信息，信息包括矩阵位置以及value。那么首先我们设定一个全局变量叫result_list就可以了？\n答案是NO.\n进程间共享变量就需要独立开辟一块内存空间或是文件共享，在python里很方面，直接用一个模块可以解决这个问题，那就是 multiprocessing 里的 Manager。当然，这是针对我们需要的是list而言，如果我们只是共享一个简单的变量如一个整数，可以直接用 multiprocessing 里的 value。\n下面的实例是怎么去共享变量。\nfrom multiprocessing import Process, Manager, Lock\nimport os\n\nlock = Lock()\nmanager = Manager()\nsum = manager.list()\n\n\ndef testFunc(cc, lock):\n    with lock:\n        sum.append(1)\n\n\nif __name__ == '__main__':\n    threads = []\n\n    for ll in range(1000):\n        t = Process(target=testFunc, args=(1, lock))\n        t.daemon = True\n        threads.append(t)\n\n    sum = manager.list()\n    for i in range(len(threads)):\n        threads[i].start()\n\n    for j in range(len(threads)):\n        threads[j].join()\n\n    print \"------------------------\"\n    print 'process id:', os.getpid()\n    print sum\n\n很简单，manager这个模块实现了开辟一块共享内存空间，就好比c中的 shmget 方法一样，有兴趣的同学可以去查阅。 传送门\n这样简单的处理并不能满足我。首先，我需要一个线程池，当然，实现线程池也是非常简单的。但是就会遇到一个问题。\nlock = multiprocessing.Lock()  \npool = multiprocessing.Pool(processes=3)  \nfor i in range(0,3):  \n    pool.apply_async(child_worker, ((my_parameter, lock),))  \npool.close()  \npool.join()  \n\n\n以上代码执行时会出错。\nRuntimeError: Lock objects should only be shared between processes through inheritance\n\n查了下资料，multiprocessing.Manager()返回的manager对象控制了一个server进程，可用于多进程之间的安全通信，其支持的类型有list,dict,Namespace,Lock,RLock,Semaphore,BoundedSemaphore,Condition,Event,Queue,Value和Array等。 \n所以代码修改成这样后就可以正常运行了：\n\n\nlock = multiprocessing.Manager().Lock()  \npool = multiprocessing.Pool(processes=3)  \nfor i in range(0,3):  \n    pool.apply_async(child_worker, ((my_parameter, lock),))  \npool.close()  \npool.join()  \n\n所以,lock的问题解决了，真是厉害我们现在可以充分地（往死里）用我们的电脑了。\nBut,还不够，我想要多次执行这个并行化计算sum的函数。也就是说我需要每次去清空result_list的内容，这个可是一个很关键的细节，因为这个需要明白一个细节，你不能用sum = [] 这样的方式去重置，我个人认为是局部变量的原因，我后来找到了del sum[:]的方法，解决了我的大问题，so,final version 如下。\nfrom multiprocessing import Process, Manager,Pool\nimport os\n\nlock = Manager().Lock()\nmanager = Manager()\nsum = manager.list()\n\n\ndef testFunc(cc, lock):\n    with lock:\n        sum.append(1)\n\n# 配合 multiprocessing pool 对多参数的要求添加的函数\ndef multi_test(args):\n    testFunc(*args)\n\ndef testing():\n    threads = []\n    _pool = Pool(24)\n\n    del sum[:]\n    lst_vars = []\n    for shot in range(1000):\n        lst_vars.append((1,lock))\n    _pool.map(multi_test, lst_vars)\n    _pool.close()\n    _pool.join()\n    \n    print \"------------------------\"\n    print 'process id:', os.getpid()\n    print sum\n    \nif __name__ == '__main__':\n    testing()\n    testing()\n这些实例是我方便写博客想的，其实我是在写一个大工程遇到了这些个问题，忙的我焦头烂额，但是总结出了人生经验，希望帮到你，让你多活几年～～\n\n                ", "mainLikeNum": ["3 "], "mainBookmarkNum": "2"}