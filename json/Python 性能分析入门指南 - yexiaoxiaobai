{"title": "Python 性能分析入门指南 - yexiaoxiaobai ", "index": "性能分析,performance,python", "content": "\n  注： 本文的原作者是 Huy Nguyen ，原文地址为 A guide to analyzing Python performance\n\n\n虽然并非你编写的每个 Python 程序都要求一个严格的性能分析，但是让人放心的是，当问题发生的时候，Python 生态圈有各种各样的工具可以处理这类问题。\n\n分析程序的性能可以归结为回答四个基本问题：\n\n\n正运行的多快\n速度瓶颈在哪里\n内存使用率是多少\n内存泄露在哪里\n\n下面，我们将用一些神奇的工具深入到这些问题的答案中去。\n\n用 time 粗粒度的计算时间\n\n让我们开始通过使用一个快速和粗暴的方法计算我们的代码:传统的 unix time 工具。\n\n $ time python yourprogram.py\nreal    0m1.028s\nuser    0m0.001s\nsys     0m0.003s\n\n\n三个输出测量值之间的详细意义在这里 stackoverflow article，但简介在这：\n\n\nreal -- 指的是实际耗时\nuser -- 指的是内核之外的 CPU 耗时\nsys  -- 指的是花费在内核特定函数的 CPU 耗时\n\n你会有你的应用程序用完了多少 CPU 周期的即视感，不管系统上其他运行的程序添加的系统和用户时间。\n\n如果 sys 和 user 时间之和小于 real 时间，然后你可以猜测到大多数程序的性能问题最有可能与 IO wait 相关。\n\n用 timing context 管理器细粒度的计算时间\n\n我们下一步的技术包括直接嵌入代码来获取细粒度的计时信息。下面是我进行时间测量的代码的一个小片段\n\ntimer.py\n\nimport time\n\nclass Timer(object):\n    def __init__(self, verbose=False):\n        self.verbose = verbose\n\n    def __enter__(self):\n        self.start = time.time()\n        return self\n\n    def __exit__(self, *args):\n        self.end = time.time()\n        self.secs = self.end - self.start\n        self.msecs = self.secs * 1000  # millisecs\n        if self.verbose:\n            print 'elapsed time: %f ms' % self.msecs\n\n\n为了使用它，使用 Python 的 with 关键字和 Timer 上下文管理器来包装你想计算的代码。当您的代码块开始执行，它将照顾启动计时器,当你的代码块结束的时候，它将停止计时器。\n\n这个代码片段示例：\n\nfrom timer import Timer\nfrom redis import Redis\nrdb = Redis()\n\nwith Timer() as t:\n    rdb.lpush(\"foo\", \"bar\")\nprint \"=> elasped lpush: %s s\" % t.secs\n\nwith Timer() as t:\n    rdb.lpop(\"foo\")\nprint \"=> elasped lpop: %s s\" % t.secs\n\n\n为了看看我的程序的性能随着时间的演化的趋势，我常常记录这些定时器的输出到一个文件中。\n\n使用 profiler 逐行计时和分析执行的频率\n\n罗伯特·克恩有一个不错的项目称为 line_profiler , 我经常使用它来分析我的脚本有多快，以及每行代码执行的频率：\n\n为了使用它，你可以通过使用 pip 来安装它：\n\npip install line_profiler\n\n\n安装完成后，你将获得一个新模块称为 line_profiler 和 kernprof.py 可执行脚本。\n\n为了使用这个工具，首先在你想测量的函数上设置 @profile 修饰符。不用担心，为了这个修饰符，你不需要引入任何东西。kernprof.py 脚本会在运行时自动注入你的脚本。\n\nprimes.py\n\n@profile\ndef primes(n): \n    if n==2:\n        return [2]\n    elif n<2:\n        return []\n    s=range(3,n+1,2)\n    mroot = n ** 0.5\n    half=(n+1)/2-1\n    i=0\n    m=3\n    while m <= mroot:\n        if s[i]:\n            j=(m*m-3)/2\n            s[j]=0\n            while j<half:\n                s[j]=0\n                j+=m\n        i=i+1\n        m=2*i+3\n    return [2]+[x for x in s if x]\nprimes(100)\n\n\n一旦你得到了你的设置了修饰符  @profile 的代码，使用 kernprof.py 运行这个脚本。\n\nkernprof.py -l -v fib.py\n\n\n-l 选项告诉 kernprof 把修饰符 @profile 注入你的脚本，-v 选项告诉 kernprof 一旦你的脚本完成后，展示计时信息。这是一个以上脚本的类似输出：\n\nWrote profile results to primes.py.lprof\nTimer unit: 1e-06 s\n\nFile: primes.py\nFunction: primes at line 2\nTotal time: 0.00019 s\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n     2                                           @profile\n     3                                           def primes(n): \n     4         1            2      2.0      1.1      if n==2:\n     5                                                   return [2]\n     6         1            1      1.0      0.5      elif n<2:\n     7                                                   return []\n     8         1            4      4.0      2.1      s=range(3,n+1,2)\n     9         1           10     10.0      5.3      mroot = n ** 0.5\n    10         1            2      2.0      1.1      half=(n+1)/2-1\n    11         1            1      1.0      0.5      i=0\n    12         1            1      1.0      0.5      m=3\n    13         5            7      1.4      3.7      while m <= mroot:\n    14         4            4      1.0      2.1          if s[i]:\n    15         3            4      1.3      2.1              j=(m*m-3)/2\n    16         3            4      1.3      2.1              s[j]=0\n    17        31           31      1.0     16.3              while j<half:\n    18        28           28      1.0     14.7                  s[j]=0\n    19        28           29      1.0     15.3                  j+=m\n    20         4            4      1.0      2.1          i=i+1\n    21         4            4      1.0      2.1          m=2*i+3\n    22        50           54      1.1     28.4      return [2]+[x for x\n\n\n寻找 hits 值比较高的行或是一个高时间间隔。这些地方有最大的优化改进空间。\n\n它使用了多少内存？\n\n现在我们掌握了很好我们代码的计时信息，让我们继续找出我们的程序使用了多少内存。我们真是非常幸运， Fabian Pedregosa  仿照 Robert Kern 的 line_profiler 实现了一个很好的内存分析器 [memory profiler][5]。\n\n首先通过 pip 安装它：\n\n$ pip install -U memory_profiler\n$ pip install psutil\n\n\n在这里建议安装 psutil 是因为该包能提升 memory_profiler 的性能。\n\n想  line_profiler 一样， memory_profiler 要求在你设置 @profile 来修饰你的函数：\n\n@profile\ndef primes(n): \n    ...\n    ...\n\n\n运行如下命令来显示你的函数使用了多少内存：\n\n$ python -m memory_profiler primes.py\n\n\n一旦你的程序退出，你应该可以看到这样的输出：\n\nFilename: primes.py\n\nLine #    Mem usage  Increment   Line Contents\n==============================================\n     2                           @profile\n     3    7.9219 MB  0.0000 MB   def primes(n): \n     4    7.9219 MB  0.0000 MB       if n==2:\n     5                                   return [2]\n     6    7.9219 MB  0.0000 MB       elif n<2:\n     7                                   return []\n     8    7.9219 MB  0.0000 MB       s=range(3,n+1,2)\n     9    7.9258 MB  0.0039 MB       mroot = n ** 0.5\n    10    7.9258 MB  0.0000 MB       half=(n+1)/2-1\n    11    7.9258 MB  0.0000 MB       i=0\n    12    7.9258 MB  0.0000 MB       m=3\n    13    7.9297 MB  0.0039 MB       while m <= mroot:\n    14    7.9297 MB  0.0000 MB           if s[i]:\n    15    7.9297 MB  0.0000 MB               j=(m*m-3)/2\n    16    7.9258 MB -0.0039 MB               s[j]=0\n    17    7.9297 MB  0.0039 MB               while j<half:\n    18    7.9297 MB  0.0000 MB                   s[j]=0\n    19    7.9297 MB  0.0000 MB                   j+=m\n    20    7.9297 MB  0.0000 MB           i=i+1\n    21    7.9297 MB  0.0000 MB           m=2*i+3\n    22    7.9297 MB  0.0000 MB       return [2]+[x for x in s if x]\n\n\n\n\nline_profiler 和 memory_profiler 的 IPython 快捷命令\n\nline_profiler 和 memory_profiler 一个鲜为人知的特性就是在 IPython 上都有快捷命令。你所能做的就是在 IPython 上键入以下命令：\n\n%load_ext memory_profiler\n%load_ext line_profiler\n\n\n这样做了以后，你就可以使用魔法命令 %lprun 和 %mprun 了，它们表现的像它们命令行的副本，最主要的不同就是你不需要给你需要分析的函数设置 @profile 修饰符。直接在你的 IPython 会话上继续分析吧。\n\nIn [1]: from primes import primes\nIn [2]: %mprun -f primes primes(1000)\nIn [3]: %lprun -f primes primes(1000)\n\n\n这可以节省你大量的时间和精力,因为使用这些分析命令，你不需要修改你的源代码。\n\n哪里内存溢出了？\n\ncPython的解释器使用引用计数来作为它跟踪内存的主要方法。这意味着每个对象持有一个计数器，当增加某个对象的引用存储的时候，计数器就会增加，当一个引用被删除的时候，计数器就是减少。当计数器达到0， cPython 解释器就知道该对象不再使用，因此解释器将删除这个对象，并且释放该对象持有的内存。\n\n内存泄漏往往发生在即使该对象不再使用的时候，你的程序还持有对该对象的引用。\n\n最快速发现内存泄漏的方式就是使用一个由  Marius Gedminas 编写的非常好的称为 [objgraph][6] 的工具。\n这个工具可以让你看到在内存中对象的数量,也定位在代码中所有不同的地方,对这些对象的引用。\n\n开始，我们首先安装 objgraph\n\npip install objgraph\n\n\n一旦你安装了这个工具，在你的代码中插入一个调用调试器的声明。\n\nimport pdb; pdb.set_trace()\n\n\n哪个对象最常见\n\n在运行时,你可以检查在运行在你的程序中的前20名最普遍的对象\n\npdb) import objgraph\n(pdb) objgraph.show_most_common_types()\n\nMyBigFatObject             20000\ntuple                      16938\nfunction                   4310\ndict                       2790\nwrapper_descriptor         1181\nbuiltin_function_or_method 934\nweakref                    764\nlist                       634\nmethod_descriptor          507\ngetset_descriptor          451\ntype                       439\n\n\n哪个对象被增加或是删除了？\n\n我们能在两个时间点之间看到哪些对象被增加或是删除了。\n\n(pdb) import objgraph\n(pdb) objgraph.show_growth()\n.\n.\n.\n(pdb) objgraph.show_growth()   # this only shows objects that has been added or deleted since last show_growth() call\n\ntraceback                4        +2\nKeyboardInterrupt        1        +1\nframe                   24        +1\nlist                   667        +1\ntuple                16969        +1\n\n\n这个泄漏对象的引用是什么？\n\n继续下去，我们还可以看到任何给定对象的引用在什么地方。让我们以下面这个简单的程序举个例子。\n\nx = [1]\ny = [x, [x], {\"a\":x}]\nimport pdb; pdb.set_trace()\n\n\n为了看到持有变量 X 的引用是什么，运行 objgraph.show_backref() 函数：\n\n(pdb) import objgraph\n(pdb) objgraph.show_backref([x], filename=\"/tmp/backrefs.png\")\n\n\n该命令的输出是一个 PNG 图片，被存储在 /tmp/backrefs.png，它应该看起来像这样：\n\n\n\n盒子底部有红色字体就是我们感兴趣的对象，我们可以看到它被符号 x 引用了一次，被列表 y 引用了三次。如果 x 这个对象引起了内存泄漏，我们可以使用这种方法来追踪它的所有引用，以便看到为什么它没有被自动被收回。\n\n回顾一遍，objgraph 允许我们：\n\n\n显示占用 Python 程序内存的前 N 个对象\n显示在一段时期内哪些对象被增加了，哪些对象被删除了\n显示我们脚本中获得的所有引用\n\nEffort vs precision\n\n在这篇文章中,我展示了如何使用一些工具来分析一个python程序的性能。通过这些工具和技术的武装，你应该可以获取所有要求追踪大多数内存泄漏以及在Python程序快速识别瓶颈的信息。\n\n和许多其他主题一样,运行性能分析意味着要在付出和精度之间的平衡做取舍。当有疑问是，用最简单的方案，满足你当前的需求。\n\n相关阅读：\n\n\nstack overflow - time explained\nline_profiler\nmemory_profiler\nobjgraph\n\n\n                ", "mainLikeNum": ["10 "], "mainBookmarkNum": "57"}