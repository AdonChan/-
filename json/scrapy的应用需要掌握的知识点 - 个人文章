{"title": "scrapy的应用需要掌握的知识点 - 个人文章 ", "index": "scrapy,python", "content": "最近一个项目需要做spider。就开始找资料，分析几个工具后，得到最成熟稳定的应该首推Scrapy。 第一次使用Scrapy，写篇文章记录一下。\nScrapy的安装我就不复述了。网上一大把的资料。安装好环境后，就开始以下工作了。大概操作步骤如下：\n\n创建项目\n创建spider\n确定要获取的字段\n确定正则匹配的字段\n保存入库\n\n创建项目\nscrapy startproject projectName【项目名】\ncd projectName\n在命令行中进行以上操作。\n创建spider\n事先把要获取的网址准备好 eg: https://segmentfault.com\nscrapy genspider spiderName 'https://segmentfault.com'\n生成成功后，会在spider目录下生成一个名叫：spiderName.py文件。获取规则就需要书写在这里面。\n确定要获取的字段\n在item.py里面，定义好要获取的字段，例如我需要获取sf.gg的网站标题和首页内容。就需要定义两个字段，title,content。想获取的信息越细越好\nclass articleItem(Scrapy.Item):\n     # 获取网站标题\n     title = Scrapy.Field()\n     # 获取网站内容\n     content = Scrpay.Field()\n确定正则匹配字段内容\n要注册获取数据的内容是本身在HTML里面的，还是ajax获取渲染的，如果是ajax渲染的数据，使用传统的获取不到数据。这里是为了测试匹配数据的，需要掌握的知识点为xpath获取办法和css选择器获取办法。其中css类似jquery的选择器。\nscrapy shell 'https://segmentfault.com'\n确定入库\n保存形式有多种，json或数据库\n最好的学习资料，永远都是代码+说明文档：http://scrapy-chs.readthedocs...\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "2"}