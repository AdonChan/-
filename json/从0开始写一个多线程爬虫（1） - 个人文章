{"title": "从0开始写一个多线程爬虫（1） - 个人文章 ", "index": "网页爬虫,多线程,python", "content": "最近发现有个电影下载网站叫做比特大雄，下了几部电影之后，打算写个爬虫把网站的电影信息都爬取下来。\n\n一开始思路是这样的，从首页开始，解析首页的所有链接，如果这个链接是电影详情页的链接，就将其html解析成想要的电影信息，如果不是电影详情页的链接，就将其加入到待爬取的URL list里，等待后续继续从这个url的页面爬取更多的链接。\n\n爬虫代码Version 1\n直接给出代码如下（含注释）：\nimport requests\nimport re\nimport time\n\n\n\n# 网站首页\nbase_url = r'https://www.btdx8.com/'\n\n# 爬取到的新url会继续加入到这个list里\ntotal_url_list = [base_url]\n# 存放已经爬取过的url\nused_url_list = []\n# 存放是电影详情页的url\nmovie_url_list = []\n\n# 从html文本中抓取url的正则表达式\nurl_reg = 'href=\"(https://.*?)\"'\n# 判断url是不是电影详情页url的正则表达式\nmovie_url_reg = 'https://www.btdx8.com/torrent/.*?html'\n\nwhile 1:\n    # 取出url list中的第一个url\n    url = total_url_list.pop(0)\n    print('Current Url:', url)\n    print()\n    try:\n        # 获取url的html\n        text = requests.get(url).text\n        # 从html中找到所有的url链接\n        new_urls = re.findall(url_reg, text)\n        # 如果是之前没出现过的url，将其放入到total_url_list用于后续继续爬取\n        for n in new_urls:\n            if n not in total_url_list + used_url_list + movie_url_list:\n                total_url_list.append(n)\n        used_url_list.append(url)\n        # 如果当前url是电影详情页的链接，将其存入movie_url_list\n        if re.match(movie_url_reg, url):\n            movie_url_list.append(url)\n        print('Current url succeed')\n        time.sleep(0.1)\n    except:\n        print('Current url failed')\n    print('Total: %s, Used: %s, Movie: %s' % (len(total_url_list), len(used_url_list), len(movie_url_list)))\n    # 如果total_url_list已经为空了就停止循环\n    if len(total_url_list) == 0:\n        break\n# 打印所有的movie url\nprint(movie_url_list)\n这个代码肯定是有些问题的，比如total_url_list可能永远都不为空，循环无法停止，不过可以先跑一跑看看情况。结果我就发现，速度太慢了！因为决定将其改成多线程爬虫，欢迎继续阅读后续的此系列文章。\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}