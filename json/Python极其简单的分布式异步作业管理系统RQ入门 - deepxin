{"title": "Python极其简单的分布式异步作业管理系统RQ入门 - deepxin ", "index": "python,rq", "content": "Python极其简单的分布式异步作业管理系统RQ入门\n1. 什么是Job？\nJob直译过来就是工作，可以是任意的Python函数，你可以把你想要异步执行的任务都写成Job函数。简而言之，Job就是你想执行的操作。例如，我想统计任意网页的字符数量，可以写一个这样的Job函数：\nimport requests\n\ndef count_words(url):\n    return len(requests.get(url).text.split())\n这样一个函数就可以称之为Job。\n2. 什么是Queue？\n当我有很多Job时，假如我现在有3个Job，分别是j1、j2、j3，那么当计算机要执行这些任务的时候，会按照j1、j2、j3加入的顺序来执行这些Job，这样的一个可以忘里面添加Job，并且能够顺序执行队列称之为Queue。\n例如，我们可以这样来构建一个Queue：\nimport redis\nfrom rq import Queue\n\n\nredis_conn = redis.Redis()\nq = Queue('default', connection=redis_conn)  # 第一个参数是Queue的名称，可以不传，默认为default\n3. 怎么把Job放到队列里面去？\nj = q.enqueue(count_words, args=('https://www.baidu.com',))\nenqueue第一参数是Job函数，args是Job函数的参数，关键字参数可以通过kwargs传入。\n4. 什么是Worker？\nWorker是Job的消费者，简单来说，你把很多Job加入到了Queue，谁来运行这些Job呢？当然就是Worker啦，你也可以看出Worker必须是独立的进程，这个进程从Redis里面获取Job的信息（包括函数、参数等等），然后运行这个Job。\n启动Worker进程也很简单：\n$ rq worker low high default\n16:56:02 RQ worker 'rq:worker:s2.6443' started, version 0.8.1                                            \n16:56:02 Cleaning registries for queue: low         \n16:56:02 Cleaning registries for queue: high        \n16:56:02 Cleaning registries for queue: default     \n16:56:02                                            \n16:56:02 *** Listening on low, high, default...\n后面的三个参数low、high、default，就是这个Worker将要运行哪些Queue里面的Job，这个顺序很重要，排在前面的Queue里面的Job将优先被运行。\n5. 一个完整的例子\njobs.py\nimport requests\nimport redis\nfrom rq import Queue\n\n\ndef count_words(url):\n    return len(requests.get(url).text.split())\n    \ndef get_q():\n    redis_conn = redis.Redis()\n    return Queue(connection=redis_conn)\napp.py\nfrom jobs import get_q, count_words\n\ndef run():\n    q = get_q()\n    j = e.enqueue(count_words, 'https://www.baidu.com')\n    print(j.result)\n    \nif __name__ == '__main__':\n    run()\n启动Worker：\n$ rq worker\n运行：\n$ python app.py\n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "1"}