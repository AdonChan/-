{"title": "Python数据分析入门之pandas总结基础（二） - michael翔的IT私房菜 ", "index": "pandas,数据分析,数据挖掘,python", "content": "一.大熊猫世界来去自如：Pandas的I/O\n老生常谈，从基础来看，我们仍然关心pandas对于与外部数据是如何交互的。\n1.1 结构化数据输入输出\n\n\nread_csv与to_csv 是⼀对输⼊输出的⼯具，read_csv直接返回pandas.DataFrame，⽽to_csv只要执行命令即可写文件\n\nread_table：功能类似\nread_fwf：操作fixed width file\n\n\nread_excel与to_excel方便的与excel交互\nheader 表⽰数据中是否存在列名，如果在第0行就写就写0，并且开始读数据时跳过相应的行数，不存在可以写none\nnames 表示要用给定的列名来作为最终的列名\nencoding 表⽰数据集的字符编码，通常而言一份数据为了⽅便的进⾏⽂件传输都以utf-8作为标准\n\n这里用的是自己的一个csv数据，因为找不到参考的这个pdf中的数据。\n\ncnames=['经度','纬度']\n\ntaxidata2 = pd.read_csv('20140401.csv',header = 4,names=cnames,encoding='utf-8')\n\ntaxidata2\n\n\n\n全部参数的请移步API：\nhttp://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html#pandas.read_csv\n这里介绍一些常用的参数：\n读取处理：\n\nskiprows：跳过⼀定的⾏数\nnrows：仅读取⼀定的⾏数\nskipfooter：尾部有固定的⾏数永不读取\nskip_blank_lines：空⾏跳过\n\n内容处理：\n\nsep/delimiter：分隔符很重要，常⻅的有逗号，空格和Tab('\\t')\nna_values：指定应该被当作na_values的数值\nthousands：处理数值类型时，每千位分隔符并不统⼀ (1.234.567,89或者1,234,567.89都可能)，此时要把字符串转化为\n\n数字需要指明千位分隔符\n收尾处理：\n\nindex_col：将真实的某列（列的数⺫，甚⾄列名）当作index\nsqueeze：仅读到⼀列时，不再保存为pandas.DataFrame⽽是pandas.Series\n\n1.2 Excel ... ?\n对于存储着极为规整数据的Excel而言，其实是没必要一定用Excel来存，尽管Pandas也十分友好的提供了I/O接口。\n\ntaxidata.to_excel('t0401.xlsx',encoding='utf-8')\n\ntaxidata_from_excel = pd.read_excel('t0401.xlsx',header=0, encoding='utf-8')\n\ntaxidata_from_excel\n\n注意：当你的xls文件行数很多超过65536时，就会遇到错误，解决办法是将写入的格式变为xlsx。excel函数受限制问题\n唯一重要的参数：sheetname=k，标志着一个excel的第k个sheet页将会被取出。（从0开始）\n1.3 半结构化数据\nJSON：网络传输中常⽤的⼀种数据格式。\n仔细看一下，实际上这就是我们平时收集到异源数据的风格是一致的：\n\n列名不能完全匹配\nkey可能并不唯一\n元数据被保存在数据里\n\n\nimport json\n\njson_data = [{'name':'Wang','sal':50000,'job':'VP'},\\\n\n {'name':'Zhang','job':'Manager','report':'VP'},\\\n\n {'name':'Li','sal':5000,'report':'IT'}]\n\ndata_employee = pd.read_json(json.dumps(json_data))\n\ndata_employee_ri = data_employee.reindex(columns=['name','job','sal','report'])\n\ndata_employee_ri\n\n输出结果：\n\n二. 深入Pandas数据操纵\n在前面部分的基础上，数据会有更多种操纵方式：\n\n通过列名、行index来取数据，结合ix、iloc灵活的获取数据的一个子集（第一部分已经介绍）\n按记录拼接（就像Union All）或者关联（join）\n方便的统计函数与⾃定义函数映射\n排序\n缺失值处理\n与Excel一样灵活的数据透视表（在第四部分更详细介绍）\n\n2.1 数据集整合\n2.1.1 横向拼接：直接DataFrame\n\npd.DataFrame([np.random.rand(2),np.random.rand(2),np.random.rand(2)],columns=['C1','C2'])\n\n2.1.2 横向拼接：Concatenate\n\npd.concat([data_employee_ri,data_employee_ri,data_employee_ri])\n\n输出结果\n\n2.1.3 纵向拼接：Merge\n根据数据列关联，使用on关键字\n\n可以指定一列或多列\n可以使⽤left_on和right_on\n\n\npd.merge(data_employee_ri,data_employee_ri,on='name')\n\n\n\n根据index关联，可以直接使用left_index和right_index\nTIPS: 增加how关键字，并指定\n\nhow = 'inner'\nhow = 'left'\nhow = 'right'\nhow = 'outer'\n\n结合how，可以看到merge基本再现了SQL应有的功能，并保持代码整洁\n2.2 自定义函数映射\n\ndataNumPy32 = np.asarray([('Japan','Tokyo',4000),('S.Korea','Seoul',1300),('China','Beijing',9100)])\n\nDF32 = pd.DataFrame(dataNumPy32,columns=['nation','capital','GDP'])\n\nDF32\n\n\n2.2.1 map: 以相同规则将1列数据作1个映射，也就是进行相同函数的处理\n\ndef GDP_Factorize(v):\n\n    fv = np.float64(v)\n\n    if fv > 6000.0:\n\n         return 'High'\n\n    elif fv < 2000.0:\n\n         return 'Low'\n\n    else:\n\n         return 'Medium'\n\n\n\nDF32['GDP_Level'] = DF32['GDP'].map(GDP_Factorize)\n\nDF32['NATION'] = DF32.nation.map(str.upper)\n\nDF32\n\n\n2.3 排序\n\nsort: 按⼀列或者多列的值进行行级排序\nsort_index: 根据index⾥的取值进行排序，而且可以根据axis决定是重排行还是列\n\n2.3.1 sort\n\ndataNumPy33 = np.asarray([('Japan','Tokyo',4000),('S.Korea','Seoul',1300),('China','Beijing',9100)])\n\nDF33 = pd.DataFrame(dataNumPy33,columns=['nation','capital','GDP'])\n\nDF33\n\n\n\nDF33.sort(['capital','nation'],ascending=False)\n\n\nascending是降序的意思。\n2.3.2 sort_index\n\nDF33.sort_index(axis=1,ascending=True)\n\n\n2.3.3 一个好用的功能：Rank\n\nDF33.rank()\n\n\n2.4 缺失数据处理\n\n2.4.1 忽略缺失值：\n\nDF34.mean(skipna=True)\n\n不忽略缺失值的话，估计就不能计算均值了吧。\n如果不想忽略缺失值的话，就需要祭出fillna了：\n\n注：这里我在猜想，axis=1是不是就代表从行的角度呢？还是得多读书查资料呀。\n三. “一组”大熊猫：Pandas的groupby\ngroupby的功能类似SQL的group by关键字：\nSplit-Apply-Combine\n\nSplit，就是按照规则分组\nApply，通过⼀定的agg函数来获得输⼊pd.Series返回⼀个值的效果\nCombine，把结果收集起来\n\nPandas的groupby的灵活性：\n\n分组的关键字可以来⾃于index，也可以来⾃于真实的列数据\n分组规则可以通过⼀列或者多列\n\n没有具体数据，截图看一下吧，方便日后回忆。\n\n分组可以快速实现MapReduce的逻辑\n\nMap: 指定分组的列标签，不同的值就会被扔到不同的分组处理\nReduce: 输入多个值，返回1个值，一般可以通过agg实现，agg能接受1个函数\n\n参考：\n\nS1EP3_Pandas.pdf 不知道什么时候存到电脑里的资料，今天发现了它。感谢作者的资料。\nPython数据分析入门之pandas总结基础（一）\n\n欢迎来Michael翔的博客查看完成版。\n\n                ", "mainLikeNum": ["4 "], "mainBookmarkNum": "30"}