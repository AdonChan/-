{"title": "爬虫入门到精通-网页的下载 - 爬虫从入门到精通 ", "index": "python,python爬虫,网页爬虫", "content": "网页的下载\n本文章属于爬虫入门到精通系统教程第四讲\n在爬虫入门到精通第二讲中，我们了解了HTTP协议，那么我们现在使用这些协议来快速爬虫吧\n本文的目标\n当你看完本文后，你应该能爬取（几乎）任何的网页\n使用chrome抓包\n抓包（packet capture）就是将网络传输发送与接收的数据包进行截获、重发、编辑、转存等操作，也用来检查网络安全。抓包也经常被用来进行数据截取等。\n第一个案列：抓取轮子哥的动态\n\n\n打开轮子哥动态这个网页\n\n打开抓包工具\n\n点击F12打开开发者工具\n点击Network(或者网络)\n按F5刷新下页面（主要是让请求重发一次，这样就能抓到包了）\n应该会看到如下界面\n\n\n\n找到我们需要的请求\n\n可以看到如下截图，里面有这么多的请求，那么到底哪一个才是我们需要的呢 ？\n\n这边提供一个小技巧\n\n当你要抓的包是需要按F5刷新才出来的，一般我们需要的请求都在DOC里面(整个页面有刷新)\n当你要抓的包是点击按钮\"加载更多\"(或者拖到页面最下面会自动加载的,整个页面并没有刷新）一般我们需要的请求都在XHR里面\n\n\n简单来讲就是如果整个页面没有刷新的话，那就是在XHR里面，否则在DOC里面\n因为本次抓包整个页面有刷新，所以，我们需要找的请求在DOC下面，可以看到只有一个请求\n\n\n\n验证请求是对的\n\n\n有以下两种方法（基本上用1，因为比较快）\n\n在我们要抓包的页面随便copy出几个字，在Respoinse中使用ctrl+f 查找，如果有找到，说明我们找到的是对的 （我查找的是\"和微软粉丝谈\"）\n\n把response中所有的内容复制到一个txt中，并改名为\"#.html\"(这里的#可以随便取)然后打开这个html，看看是否和我们要抓的一样\n\n\n\n\n如果发现要找的不对，那你可以打开下一个请求检查下\n\n\n\n模拟发送\n\n点击Headers\n可以看到请求的url是： https://www.zhihu.com/people/...\n方法是： GET\nrequests headers 是（下图中框出来的地方）\n所以我们的代码应该是：\n\n\n\nimport requests\n\n# 这里的headers就是我们上图框中的headers\nrequest_headers = {        'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',   \n    'Accept-Encoding':'gzip, deflate, sdch, br',\n    'Accept-Language':'zh-CN,zh;q=0.8',\n    'Cache-Control':'max-age=0',\n    'Connection':'keep-alive',\n    'Cookie':'',\n    'Host':'www.zhihu.com',\n    'Referer':'https://www.zhihu.com/',\n    'Upgrade-Insecure-Requests':'1',\n    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36'\n}\n#上图中的url\nurl = \"https://www.zhihu.com/people/excited-vczh/activities\"\n# 上图中的请求方法（get）\nz = requests.get(url,headers=request_headers)\nprint z.content\n\n这段代码简单来说就是把 我们抓包看到的用程序来实现\n一个小总结\n我们爬取一个网页的步骤可以分为如下：\n\n打开要爬取的网页\n打开开发者工具，并让请求重发一次（简单讲就是抓包）\n找到正确的请求\n用程序模拟发送\n\n第二个案列：点赞\n1.打开要爬取的网页\n我们打开 \"知乎 - 与世界分享你的知识、经验和见解\"\n我们要点赞的回答是这个\n\n2.打开开发者工具，并让请求重发一次\n打开后\"点击赞一下\",可以看到有好多请求\n\n3.找到正确的请求\n我们一个一个的点开请求看，发现就一个有返回值，而且这个返回值没有意义，那么怎么确定这个就是我们要找的呢？\n\n我们可以点击Headers，看一下发送的参数\nvote_up 很明显，就是点赞的意思。所以这个应该就是我们要找的。\n\n这边说一下，右边\"Headers,Preview,Response,Cookies,Timing\"是什么意思\n我们经常要看的有，headers 和 preview\nheaders 里面我们都有介绍过（请求头，返回头）\npreview和response里面的内容是相同的（preview里面的内容格式化了，输出的好看一些），里面的内容是html返回值\ncookies 里面是cookie的值，只不过分成了key value的形式\nTiming基本用不上,所以也不介绍了（想了解的话可以自己百度...）\n\n4.用程序模拟发送\n我们把headers全部copy，\nurl也和上面一样\n参数也是对的\n请求方法是post\n但是发现最终返回http code 400,这是为什么呢？\n\n让我们留到后面讲解~\n最后再次总结一下\n看完本篇文章后，你应该要\n能学会抓包\n最后大家可以抓一下知乎登录的包哦~\n小提示：当你要抓的网页是会自动跳转的话，那么你需要选中“proserve log”\n意思是不要在页面重新加载后清除log（抓知乎登录的包会用到）\n\n\n最后的最后，收藏的大哥们，能帮忙点个赞么~\n\n                ", "mainLikeNum": ["6 "], "mainBookmarkNum": "31"}