{"title": "一行命令：从 ELK 迁移日志服务 - 个人文章 ", "index": "github,index,数据类型,python,nginx", "content": "\n摘要： 日志服务相比自建 ELK 在功能、性能、规模和成本等方面有诸多优势。对于已经存储在 Elasticsearch 中的数据，用户只需要一行命令就能方便地将数据迁移至日志服务。\n概述\n日志服务相比自建 ELK 在功能、性能、规模和成本等方面有诸多优势，参阅自建ELK vs 日志服务(SLS)全方位对比。对于已经存储在 Elasticsearch 中的数据，用户只需要一行命令就能方便地将数据迁移至日志服务。\n数据迁移简介\n数据迁移顾名思义是指将数据从某个数据源迁移到另外一个数据源。根据不同数据源存储引擎是否相同，可分为同源迁移和异构迁移。根据迁移类型的不同，可分为全量迁移和增量迁移。\n目前，各大云计算厂商都提供了各自的数据迁移方案，如 AWS DMS，Azure DMA，阿里云 DTS。这些方案主要专注于解决关系型数据库间的数据迁移问题，还未覆盖到 Elasticsearch 场景。\nElasticsearch 数据迁移方案\n针对 Elasticsearch 场景，日志服务团队提供了基于 aliyun-log-python-sdk 和 aliyun-log-cli 的解决方案。该方案主要针对历史数据做全量迁移。\n原理\n• 使用 Scroll API 从 Elasticsearch 抓取数据。Scroll API 可以从 Elasticsearch 里高效取出大量数据而无须付出深度分页的代价。\n• 针对 Elasticsearch 每个 index 的每个 shard 创建一个数据迁移任务，提交到内部进程池中执行，用来提高并行度和吞吐量。\n\n功能\n• 支持用户将 Elasticsearch 中的所有文档或某些索引中的文档迁移至日志服务指定的 project 中，工具会自动初始化好与索引同名的 logstore。\n• 支持用户自定义过滤条件，只迁移符合条件的文档至日志服务。\n• 支持用户自定义 Elasticsearch 的索引和日志服务的 logstore 之间的映射关系。\n• 支持用户通过参数 pool_size 来控制数据迁移任务的并行度。\n• 支持用户自定义日志字段 time、__source__、__topic__ 的取值。\n• 支持使用 HTTP 基本认证从 Elasticserch 中迁移数据。\n映射关系\nElasticsearch 数据模型中包含 - 索引（index），类型（type），文档（document），映射（mapping），数据类型（field datatypes）等概念，它们和日志服务中数据模型的映射关系如下表所示。\n\n使用样例\n下面通过一段视频向您展示如何使用 CLI 将 nginx 访问日志从 Elasticsearch 迁移至日志服务，以及如何对这批数据进行查询分析。\n视频地址\n迁移命令\n\n查询分析\n1.以天为单位统计各状态码的数量。\n\n2.统计请求分布在哪些国家。\n\n性能调优\n工具的性能主要取决于从 Elasticsearch 中读取数据的速度以及向日志服务写入数据的速度。\nElasticsearch 读取速度\nElasticsearch 中每个 index 由多个 shard 组成。工具会为每个 index 的每个 shard 创建一个数据迁移任务，并提交到内部进程池中执行（进程池大小可通过参数 pool_size 指定）。理论上目标 index 的 shard 越多，整体吞吐量越高。\n日志服务写入速度\n日志服务也有 shard 的概念，单个 shard 提供 5MB/s，500次/s 的写入能力。您可以通过为 logstore 开启更多的 shard 来提高向日志服务写入数据的速度。\n性能数据\n在 Elasticsearch 目标 index 只有1个 shard，日志服务 logstore 也只有1个 shard，单个文档大小 100B 的情况下，平均数据迁移速率为 3MB/s。\n本文作者：吴波bruce_wu\n阅读原文\n本文为云栖社区原创内容，未经允许不得转载。\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}