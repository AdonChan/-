{"title": "Python多进程的使用 - 个人文章 ", "index": "python", "content": "fork函数创建子进程\n基本使用\nLinux 操作系统提供了一个 fork函数用来创建子进程。fork()位于Python的os模块中。使用导入os模块即可。\nimport os\nos.fork()\n每次调用fork()函数后，相应的父进程都会生成一个子进程。例如下面这段代码：\nimport os\nos.fork()\nos.fork()\nos.fork()\n执行之后将会生成8个进程。\nfork()函数的返回值\nfork()函数对于子进程的返回值永远是0，而对父进程的返回值则为子进程的pid(进程号)。\n实例\n#!/usr/bin/env python\nimport os\nimport time\n\nrt = os.fork()\n\nif rt == 0:\n    print(f\"The child process is {os.getpid()} . His father is {os.getppid()}\")  # os.getpid()获取当前进程进程号，os.getppid()获取当前进程的父进程号\n    time.sleep(5)\nelse:\n    print(f\"The father process is {os.getpid()} . His father is {os.getppid()}\")\n    time.sleep(5)\n\nprint(f\"Now the process is {os.getpid()} . His father is {os.getppid()}\")\n执行结果：\n\n进程模块\n导入模块\nPython也提供了multiprocessing库给全平台提供了多线程编程。\nimport multiprocessing\n简单进程\n下面代码为一个简单进程：\nfrom multiprocessing import Process\n\n\ndef work(num):\n    for i in range(10):\n        num += 1\n    print(num)\n    return 0\n\n\ndef main():\n    num = 1\n    p1 = Process(target = work, args = (num,))\n    p1.start()\n\n\nif __name__ == '__main__':\n    main()\n\n这里从multiprocessing库引入Process这个类。p1 = Process(target = work, args = (num,))是创建一个进程。target为所要执行任务的函数，args则为接收的参数，必须以元组形式给与。start()是让进程开始运行。同时进程有一些方法：\njoin方法\nProcess的join方法与多线程类似。为等待进程运行结束。使用方法：join(timeout)。 使用join()，程序会等待进程结束后再继续进行下面的代码。如果加入了timeout参数，则程序会等待timeout秒后继续执行下面的程序。\nclose方法\nclose()用于关闭进程，但是不能关闭正在运行中的子进程。\n进程类\n可以通过创建类的方式实现多进程：\nfrom multiprocessing import Process\nimport time\n\n\nclass My_Process(Process):\n\n    def __init__(self,num):\n        Process.__init__(self)\n        self.num = num\n\n    def run(self):\n        time.sleep(2)\n        print(self.num)\n\n\ndef main():\n    for i in range(10):\n        p = My_Process(i)\n        p.start()\n\n\nif __name__ == '__main__':\n    main()\n进程池\nfrom multiprocessing import Pool\nimport time\n\n\ndef target(num):\n    time.sleep(2)\n    print(num)\n\n\ndef main():\n    pool = Pool(3)\n    for i in range(3):\n        pool.apply_async(target,(i,))\n    pool.close()\n    pool.join()\n    print('Finish!!!')\n\n\nif __name__ == '__main__':\n    main()\n对Pool对象调用join()方法会等待所有子进程执行完毕，调用join()之前必须先调用close()，调用close()之后就不能继续添加新的Process了。Pool(num)里的num为要添加到里面的进程数。不指定进程数，则默认为CPU核心数量。\n进程间相互独立\n多进程的每一个进程都有一份变量的拷贝，进程之间的操作互不影响。\nimport multiprocessing\nimport time\n\nzero = 0\n\ndef change_zero():\n    global zero\n    for i in range(3):\n        zero = zero + 1\n        print(multiprocessing.current_process().name, zero)\n\nif __name__ == '__main__':\n    p1 = multiprocessing.Process(target = change_zero)\n    p2 = multiprocessing.Process(target = change_zero)\n    p1.start()\n    p2.start()\n    p1.join()\n    p2.join()\n    print(zero)\n最后的执行结果：\n\n如果进行文件IO操作，则多进程都会写入同一个文件中。\n队列\n使用multiprocessing里的Queue可使不同进程访问相同的资源。\nfrom multiprocessing import Process, Queue\n\ndef addone(q):\n    q.put(1)\n\ndef addtwo(q):\n    q.put(2)\n\nif __name__ == '__main__':\n    q = Queue()\n    p1 = Process(target=addone, args = (q, ))\n    p2 = Process(target=addtwo, args = (q, ))\n    p1.start()\n    p2.start()\n    p1.join()\n    p2.join()\n    print(q.get())\n    print(q.get())\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}