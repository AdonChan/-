{"title": "scrapy下调试单个函数的方法 - 记录python学习中的点点滴滴 ", "index": "网页爬虫,scrapy,python", "content": "进行抓取任务时很苦恼的一点在于为了调试某个第三,四层以上的跳转链接需要等待将前面的链接都跑一遍,才能确定某个页面的parse函数是否正确,scrapy的命令行参数 parse就是为了解决这一问题.\n官网的描述\nSyntax: scrapy parse <url> [options]意思就是 scrpy parse 网址 可选参数\n官网给出的例子 $ scrapy shell       http://www.example.com/some/page.html\n我的实践之路\n开始运行时结果总是没有打印出任何log来,于是将原本0.25的scrapy升级到1.0这时再输入\nscrapy parse http://www.douban.com -c group_parse\n报了这样的错误\nERROR: Unable to find spider for: http://www.douban.com\n还有可能是这样的\nTraceback (most recent call last):\n  File \"/usr/local/bin/scrapy\", line 11, in <module>\n    sys.exit(execute())\n  File \"/Library/Python/2.7/site-packages/scrapy/cmdline.py\", line 143, in execute\n    _run_print_help(parser, _run_command, cmd, args, opts)\n  File \"/Library/Python/2.7/site-packages/scrapy/cmdline.py\", line 89, in _run_print_help\n    func(*a, **kw)\n  File \"/Library/Python/2.7/site-packages/scrapy/cmdline.py\", line 150, in _run_command\n    cmd.run(args, opts)\n  File \"/Library/Python/2.7/site-packages/scrapy/commands/parse.py\", line 220, in run\n    self.set_spidercls(url, opts)\n  File \"/Library/Python/2.7/site-packages/scrapy/commands/parse.py\", line 147, in set_spidercls\n    self.spidercls.start_requests = _start_requests\nAttributeError: 'NoneType' object has no attribute 'start_requests'\n好吧,自动找不到我们就显示指定下爬虫的名字就是在继承自spider类里定义的那个name里的值\nclass douban(Spider):\n    name = \"douban_spider\"\nok 问题解决\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "2"}