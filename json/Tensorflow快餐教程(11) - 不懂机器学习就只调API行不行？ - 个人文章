{"title": "Tensorflow快餐教程(11) - 不懂机器学习就只调API行不行？ - 个人文章 ", "index": "python,深度学习,api", "content": "摘要： Tensorflow高层API\n高层封装API\n有同学问，我们学习Tensorflow就是想学习一套可以用的套，像编程一样调用就行了，不想学习机器学习的细节，有没有这样的方式？\n针对于已经有成熟解决方案的模型，why not呢？在前面已经快速将CNN, RNN的大致概念和深度学习的简史走马观花过了一遍之后，我们就可以开始尝试使用高层封装的API。\n模型 - 训练 - 评估 三条语句搞定\n既然高层封装，我们就采用最简单的方式：首先是一个模型，然后就开始训练，最后评估一下效果如何。\n我们还是举祖传的MNIST的例子。核心三条语句，一句模型，一句训练，一句评估：\nestimator = tf.estimator.LinearClassifier(feature_columns=[image_column], n_classes=10)\n\n# Train.\nestimator.train(input_fn=train_input_fn, steps=2000)\n\n# Evaluate and report metrics.\neval_metrics = estimator.evaluate(input_fn=eval_input_fn, steps=1)\n\n我们首先知道MNIST是把手写图像分成十类，那么就用个线性回归分类器，指定分成10类：\nestimator = tf.estimator.LinearClassifier(feature_columns=[image_column], n_classes=10)\n\n训练也是无脑的，指定训练多少步就是了：\nestimator.train(input_fn=train_input_fn, steps=2000)\n\n评估也不需要懂啥，给个测试集就是了：\neval_metrics = estimator.evaluate(input_fn=eval_input_fn, steps=1)\n\n给大家一个完整能运行的例子，主要的工作量都在处理输入数据上，真正有功能的就是那三条语句：\nimport numpy as np\nimport tensorflow as tf\n\ndef get_input_fn(dataset_split, batch_size, capacity=10000, min_after_dequeue=3000):\n\n  def _input_fn():\n    images_batch, labels_batch = tf.train.shuffle_batch(\n        tensors=[dataset_split.images, dataset_split.labels.astype(np.int32)],\n        batch_size=batch_size,\n        capacity=capacity,\n        min_after_dequeue=min_after_dequeue,\n        enqueue_many=True,\n        num_threads=4)\n    features_map = {'images': images_batch}\n    return features_map, labels_batch\n\n  return _input_fn\n\ndata = tf.contrib.learn.datasets.mnist.load_mnist()\n\ntrain_input_fn = get_input_fn(data.train, batch_size=256)\neval_input_fn = get_input_fn(data.validation, batch_size=5000)\n\n# Specify the feature(s) to be used by the estimator.\nimage_column = tf.contrib.layers.real_valued_column('images', dimension=784)\nestimator = tf.estimator.LinearClassifier(feature_columns=[image_column], n_classes=10)\n\n# Train.\nestimator.train(input_fn=train_input_fn, steps=2000)\n\n# Evaluate and report metrics.\neval_metrics = estimator.evaluate(input_fn=eval_input_fn, steps=1)\nprint(eval_metrics)\n\n三步法进阶\n现在我们已经学会三步法了。虽然不涉及底层细节，我们还是有很多工具可以做得更好的。\n比如我们要自己设计优化方法, 从三条语句变成四条：\noptimizer2 = tf.train.FtrlOptimizer(learning_rate=5.0, l2_regularization_strength=1.0)\nestimator2 = tf.estimator.LinearClassifier(\n    feature_columns=[image_column], n_classes=10, optimizer=optimizer2)\n\n# Train.\nestimator2.train(input_fn=train_input_fn, steps=2000)\n\n# Evaluate and report metrics.\neval_metrics2 = estimator2.evaluate(input_fn=eval_input_fn, steps=1)\nprint(eval_metrics2)\n\n这段代码不是片断，拼接到上面的代码的后面就可以直接运行。\n更进一步：支持向量机\n默认的虽然通用，但是效果可能不如更专业的更好。比如我们想用前深度学习时代最强大的工具之一 - 支持向量机来进行MNIST识别。我们还是可以用高层API来实现。将LinearClassifier换成KernelLinearClassifier。\noptimizer3 = tf.train.FtrlOptimizer(\n   learning_rate=50.0, l2_regularization_strength=0.001)\n\nkernel_mapper3 = tf.contrib.kernel_methods.RandomFourierFeatureMapper(\n  input_dim=784, output_dim=2000, stddev=5.0, name='rffm')\nkernel_mappers3 = {image_column: [kernel_mapper3]}\nestimator3 = tf.contrib.kernel_methods.KernelLinearClassifier(\n   n_classes=10, optimizer=optimizer3, kernel_mappers=kernel_mappers3)\n\n# Train.\nestimator3.fit(input_fn=train_input_fn, steps=2000)\n\n# Evaluate and report metrics.\neval_metrics3 = estimator3.evaluate(input_fn=eval_input_fn, steps=1)\nprint(eval_metrics3)\n\n我们来比较一下三种方法：\nElapsed time: 80.69186925888062 seconds\n{'loss': 0.26811677, 'accuracy': 0.9228, 'global_step': 2000}\nElapsed time: 80.33205699920654 seconds\n{'loss': 0.26356304, 'accuracy': 0.9276, 'global_step': 2000}\nElapsed time: 98.87778902053833 seconds\n{'loss': 0.10834637, 'accuracy': 0.9668, 'global_step': 2000}\n\nSVM支持向量机力量果然强大，从92%的识别率提升到了96%.\n高层深度学习API\n准备数据的语句不变，我们再加一种采用深度学习的方式，也是三步：\nclassifier = tf.estimator.DNNClassifier(\n    feature_columns=[image_column],\n    hidden_units=[784, 625],\n    n_classes=10)\n\n# Train.\nclassifier.train(\n    input_fn=train_input_fn,\n    steps=2000)\n\neval_result = classifier.evaluate(\n    input_fn=eval_input_fn, steps=1)\n\nprint(eval_result)\n\n打印出来的结果如下：\n{'accuracy': 0.9812, 'average_loss': 0.064692736, 'loss': 323.46368, 'global_step': 2000}\n\n识别率达到98%，比支持向量机还要强一些。\nTensorflow的API结构\nTensorflow API\n\n我们从第一讲到第十讲学习的都是Mid-Level API。这一讲讲的是High-Level API。\nTensorflow r1.8 Estimators API的变化Tensorflow API的变化一向以迅速著称，兼容性也不是很好。tf.estimator.Estimators的前身是tf.contrib.learn.Estimators。\n我们对比一下LinearClassifier在这两个版本的区别：新版：\nestimator = tf.estimator.LinearClassifier(feature_columns=[image_column],\n                                          n_classes=10)\n\n# Train.\nestimator.train(input_fn=train_input_fn, steps=2000)\n\n# Evaluate and report metrics.\neval_metrics = estimator.evaluate(input_fn=eval_input_fn, steps=1)\n\n旧版：\nestimator = tf.contrib.learn.LinearClassifier(feature_columns=[image_column], n_classes=10)\n\n# Train.\nestimator.fit(input_fn=train_input_fn, steps=2000)\n\n# Evaluate and report metrics.\neval_metrics = estimator.evaluate(input_fn=eval_input_fn, steps=1)\nprint(eval_metrics)\n\n主要区别为：\n\n包名改变了\n新版的训练方法是train，而旧版是fit。\n因为新版本没有提供支持向量机的分类器，我们用的核函数版本的KernelLinearClassifier还是老的包中的，所以还是用的fit来训练。\n\n本文作者：lusing\n阅读原文\n本文为云栖社区原创内容，未经允许不得转载。\n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "2"}