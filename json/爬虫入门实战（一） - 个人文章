{"title": "爬虫入门实战（一） - 个人文章 ", "index": "python", "content": "python爬虫入门实战（一）\npost请求方式爬取肯德基配送地址解析url，通过post方式准确发送data信息是本次爬虫实战的重难点。代码如下：\n\n# 肯德基店铺位置案例\n\"\"\"\n需求:根据用户输入的页码的起始位置，\n把每页的餐厅信息存储到一个独立的json文件中\n\"\"\"\n\nfrom urllib import request\nfrom urllib import parse\nimport json\n\npost_url = 'http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=cname'\n\nstart_page = int(input('请输入起始页:'))\nend_page = int(input('请输入结束页:'))\n\nheaders = {\n    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'\n}\n\nfor page in range(start_page, end_page + 1):\n    p = str(page)\n\n    data = {\n        'cname': '北京',\n        'pid': '',\n        'pageIndex': p,\n        'pageSize': '10'\n    }\n\n    data = parse.urlencode(data).encode('utf-8')\n\n    req = request.Request(url=post_url,\n                          data=data,\n                          headers=headers)\n\n    response = request.urlopen(req)\n\n    content = response.read().decode('utf-8')\n\n    # 保存为本地json文件\n    filename = 'data/KFC/{}.json'.format(p)\n\n    json.dump(content, open(filename, 'w', encoding='utf-8'),\n              ensure_ascii=False)\n由于比较简单，我就不多解释了，，，关掉电脑，，，今天的修行到此结束。。。\n\n                ", "mainLikeNum": ["2 "], "mainBookmarkNum": "0"}