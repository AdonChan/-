{"title": "分布式爬虫原理 - 个人文章 ", "index": "python", "content": "分布式爬虫原理\n\n什么是分布式爬虫：   额，这个问题呢，我这样解释，例如爬取网站内的二级网站，我们就需要获取网站中的二级、三级...很多个网站，那么我们如果用自己一台主机爬取明显效率很低，这个时候我们就需要其他主机的帮助了，这个时候我们就将作为Master,为其他主机Slaver提供url的同时，启动程序，没错，我们的工作就这么多，而Slaver主机的作用就是接收url，解析并获取想要的数据。。。。\n\n\n那么问题来了，我们如何将Master抓取到的网站分给别的主机呢？那就需要数据库了，而且是基于内存的数据库，redis等。   redis安装配置：http://www.runoob.com/redis/r...   配置中需要将redis.conf文件做简单的修改：将bind 127.0.0.1和rdbcompression yes注释掉。\n\n\n\n最后如何单线程抓取网页呢？你可以和自己的小伙伴试一试一个Master和多个Slaver一起获取下bt影视网的网页url,很有意思：\n\n\"\"\"\n爬虫:\n    for  url  in urls:\n        r = requests.get(url)\n        html_doc = r.text\n\n多线程爬虫:\n\n    urls( 队列  内容)\n\n    work(  从队列中获取url  --> 发送请求  --> 解析response -- >保存数据)\n\n    创建多个线程,每个线程启动一个work,从而实现并发,提高爬虫效率\n\n\n分布式爬虫:\n    urls(保存到redis中,因为redis可被多台电脑访问,从而实现分布式)\n    每台电脑从redis内存中获取url-->发送请求 --> 解析response -- >保存数据\n\n目标 :\n    使用分布式爬虫,爬去http://www.btbtdy.net/btfl/dy30.html中所有页\n\n部署:\n    Master端不需要任何修改(Master必须安装redis server)\n    Slaver端需要修改两处:\n        1) 把rds = Redis('127.0.0.1',6379)修改成  rds = Redis('master的ip',6379)\n        2) 把第64行的代码start_request()注释掉\n\n\n\"\"\"\nfrom redis import Redis\nimport requests\n# pip install redis\n\n\n# 存储 urls\nREDIS_KEY = \"btdy:urls\"\n\nrds = Redis('127.0.0.1',6379)\n\ndef fetch(url):\n    \"\"\"\n    下载页面,如果下载成功,返回response对象,否则返回None\n    :param url:待爬取的url\n    :return:返回response对象或者None\n    \"\"\"\n    r = requests.get(url)\n    if r.status_code == 200:\n        return r\n    return None\n\n\ndef start_request():\n    \"\"\"\n    获取电视剧所有页的地址,并把地址push到REDIS_KEY中\n    :return:\n    \"\"\"\n    start_url = 'http://www.btbtdy.net/btfl/dy30.html'\n    urls = ['http://www.btbtdy.net/btfl/dy30-{0}.html'.format(str(page+1)) for page in range(62)]\n    rds.lpush(REDIS_KEY,*urls)\n\nif __name__ == '__main__':\n    # 从redis中的REDIS_URLS中获取url\n    start_request()\n    while True:\n        _, url = rds.blpop(REDIS_KEY)\n        fetch(url)\n爬虫，，从入门到放弃，，，哈哈哈哈哈哈\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}