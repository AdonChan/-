{"title": "Day 1_Data PreProcessing - 数据搬运工 ", "index": "python", "content": "Data PreProcessing\n\nAs shown in the infograph we will break down data preprocessing in 6 essential steps.Get the dataset from here that is used in this example\nStep 1: Importing the libraries\nimport numpy as np\nimport pandas as pd\nStep 2: Importing dataset\ndataset = pd.read_csv('Data.csv')\nX = dataset.iloc[ : , :-1].values\nY = dataset.iloc[ : , 3].values\nStep 3: Handling the missing data\nfrom sklearn.preprocessing import Imputer\nimputer = Imputer(missing_values = \"NaN\", strategy = \"mean\", axis = 0)\nimputer = imputer.fit(X[ : , 1:3])\nX[ : , 1:3] = imputer.transform(X[ : , 1:3])\nStep 4: Encoding categorical data\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabelencoder_X = LabelEncoder()\nX[ : , 0] = labelencoder_X.fit_transform(X[ : , 0])\nCreating a dummy variable\nonehotencoder = OneHotEncoder(categorical_features = [0])\nX = onehotencoder.fit_transform(X).toarray()\nlabelencoder_Y = LabelEncoder()\nY =  labelencoder_Y.fit_transform(Y)\nStep 5: Splitting the datasets into training sets and Test sets\nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split( X , Y , test_size = 0.2, random_state = 0)\nStep 6: Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.fit_transform(X_test)\nDone \n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}