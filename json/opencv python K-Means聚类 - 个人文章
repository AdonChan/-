{"title": "opencv python K-Means聚类 - 个人文章 ", "index": "python,opencv,opencv-python", "content": "K-Means Clustering in OpenCV\ncv2.kmeans(data, K, bestLabels, criteria, attempts, flags[, centers]) -> retval, bestLabels, centers\n\ndata: np.float32数据类型，每个功能应该放在一个列中\nnclusters（K）：集群数\nbestLabels：预设的分类标签：没有的话 None\ncriteria：它是迭代终止标准,满足此条件时，算法迭代停止,实际上，它应该是3个参数的元组。它们是（type，max_iter，epsilon）\n\n\n\n\ntype又有两种选择:\n\n\ncv2.TERM_CRITERIA_EPS - 如果达到指定的精度epsilon，则停止算法迭代。\n\ncv.TERM_CRITERIA_MAX_ITER - 在指定的迭代次数max_iter之后停止算法。\n\ncv.TERM_CRITERIA_EPS+ cv.TERM_CRITERIA_MAX_ITER - 当满足上述任何条件时停止迭代。\n\n\nmax_iter - 指定最大迭代次数的整数\nepsilon - 要求的准确性\n\n\nattempts：重复试验kmeans算法次数，将会返回最好的一次结果\nflags：该标志用于指定初始中心的采用方式。通常会使用两个标志：cv2.KMEANS_PP_CENTERS和cv2.KMEANS_RANDOM_CENTERS\n\nretval：它是从每个点到它们相应中心的平方距离之和\nbestLabels：这是标签数组\ncenters：这是一组聚类中心\n\nData with Only One Feature\n假设只有一个特征的数据，即一维的，我们可以采用我们的T恤问题，只使用人的高度来决定T恤的大小。因此，我们首先创建数据并在Matplotlib中绘制它\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\nx = np.random.randint(25,100,25)\ny = np.random.randint(175,255,25)\nz = np.hstack((x,y))\nz = z.reshape((50,1))\nz = np.float32(z)\nplt.hist(z,256,[0,256]),plt.show()\n\n现在我们应用KMeans功能。我们的标准是，每当运行10次迭代算法或达到epsilon = 1.0的精度时，停止算法并返回答案.\n# Define criteria = ( type, max_iter = 10 , epsilon = 1.0 )\ncriteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n\n# Set flags (Just to avoid line break in the code)\nflags = cv2.KMEANS_RANDOM_CENTERS\n\n# Apply KMeans\ncompactness,labels,centers = cv2.kmeans(z,2,None,criteria,10,flags)\n\n\nA = z[labels==0]\nB = z[labels==1]\n\n# Now plot 'A' in red, 'B' in blue, 'centers' in yellow\nplt.hist(A,256,[0,256],color = 'r')\nplt.hist(B,256,[0,256],color = 'b')\nplt.hist(centers,32,[0,256],color = 'y')\nplt.show()\n\n\n\nData with Multiple Features\n我们设置大小为50x2的测试数据，其高度和权重为50人。 第一列对应于所有50个人的高度，第二列对应于它们的权重。 第一行包含两个元素，其中第一行是第一人的高度，第二行是他的重量。 类似地，剩余的行对应于其他人的高度和重量。      \n\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\n\nX = np.random.randint(25,50,(25,2))\nY = np.random.randint(60,85,(25,2))\nZ = np.vstack((X,Y))\n\n# convert to np.float32\nZ = np.float32(Z)\n\n# define criteria and apply kmeans()\ncriteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\nret,label,center=cv2.kmeans(Z,2,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n\n# Now separate the data, Note the flatten()\nA = Z[label.ravel()==0]\nB = Z[label.ravel()==1]\n\n# Plot the data\nplt.scatter(A[:,0],A[:,1])\nplt.scatter(B[:,0],B[:,1],c = 'r')\nplt.scatter(center[:,0],center[:,1],s = 80,c = 'y', marker = 's')\nplt.xlabel('Height'),plt.ylabel('Weight')\nplt.show()\n\nColor Quantization\n颜色量化是减少图像中颜色数量的过程，这样做的一个原因是减少内存，某些设备可能具有限制，使得它只能产生有限数量的颜色，在那些情况下，也执行颜色量化，这里我们使用k均值聚类进行颜色量化。\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\n\nimg = cv2.imread('img.jpg')\nZ = img.reshape((-1,3))\n\n# convert to np.float32\nZ = np.float32(Z)\n\n# define criteria, number of clusters(K) and apply kmeans()\ncriteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\nK = 8\nret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n\n# Now convert back into uint8, and make original image\ncenter = np.uint8(center)\nres = center[label.flatten()]\nres2 = res.reshape((img.shape))\n\ncv2.imshow('res2',res2)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "0"}