{"title": "两句话轻松掌握python最难知识点——元类 - node.js优雅之道 ", "index": "django,网页爬虫,python", "content": "两句话掌握python最难知识点——元类\n千万不要被所谓“元类是99%的python程序员不会用到的特性”这类的说辞吓住。因为每个中国人，都是天生的元类使用者\n学懂元类，你只需要知道两句话：\n\n道生一，一生二，二生三，三生万物\n我是谁？我从哪来里？我要到哪里去？\n\n在python世界，拥有一个永恒的道，那就是“type”，请记在脑海中，type就是道。如此广袤无垠的python生态圈，都是由type产生出来的。\n\n道生一，一生二，二生三，三生万物。\n\n\n道 即是 type\n\n一 即是 metaclass(元类，或者叫类生成器)\n\n二 即是 class(类，或者叫实例生成器)\n\n三 即是 instance(实例)\n\n万物 即是 实例的各种属性与方法，我们平常使用python时，调用的就是它们。\n\n道和一，是我们今天讨论的命题，而二、三、和万物，则是我们常常使用的类、实例、属性和方法，用hello world来举例：\n# 创建一个Hello类，拥有属性say_hello ----二的起源\nclass Hello():\n    def say_hello(self, name='world'):\n        print('Hello, %s.' % name)\n\n\n# 从Hello类创建一个实例hello ----二生三\nhello = Hello()\n\n# 使用hello调用方法say_hello ----三生万物\nhello.say_hello()\n输出效果：\nHello, world.\n这就是一个标准的“二生三，三生万物”过程。 从类到我们可以调用的方法，用了这两步。\n那我们不由自主要问，类从何而来呢？回到代码的第一行。class Hello其实是一个函数的“语义化简称”，只为了让代码更浅显易懂，它的另一个写法是：\ndef fn(self, name='world'): # 假如我们有一个函数叫fn\n    print('Hello, %s.' % name)\n    \nHello = type('Hello', (object,), dict(say_hello=fn)) # 通过type创建Hello class ---- 神秘的“道”，可以点化一切，这次我们直接从“道”生出了“二”\n\n这样的写法，就和之前的Class Hello写法作用完全相同，你可以试试创建实例并调用\n# 从Hello类创建一个实例hello ----二生三，完全一样\nhello = Hello()\n\n# 使用hello调用方法say_hello ----三生万物，完全一样\nhello.say_hello()\n输出效果：\nHello, world. ----调用结果完全一样。\n我们回头看一眼最精彩的地方，道直接生出了二：\nHello = type('Hello', (object,), dict(say_hello=fn))\n这就是“道”，python世界的起源，你可以为此而惊叹。注意它的三个参数！暗合人类的三大永恒命题：我是谁，我从哪里来，我要到哪里去。\n\n第一个参数：我是谁。  在这里，我需要一个区分于其它一切的命名，以上的实例将我命名为“Hello”\n第二个参数：我从哪里来在这里，我需要知道从哪里来，也就是我的“父类”，以上实例中我的父类是“object”——python中一种非常初级的类。\n第三个参数：我要到哪里去在这里，我们将需要调用的方法和属性包含到一个字典里，再作为参数传入。以上实例中，我们有一个say_hello方法包装进了字典中。\n\n值得注意的是，三大永恒命题，是一切类，一切实例，甚至一切实例属性与方法都具有的。理所应当，它们的“创造者”，道和一，即type和元类，也具有这三个参数。但平常，类的三大永恒命题并不作为参数传入，而是以如下方式传入\nclass Hello(object){\n# class 后声明“我是谁”\n# 小括号内声明“我来自哪里”\n# 中括号内声明“我要到哪里去”\n    def say_hello(){\n        \n    }\n}\n\n造物主，可以直接创造单个的人，但这是一件苦役。造物主会先创造“人”这一物种，再批量创造具体的个人。并将三大永恒命题，一直传递下去。\n“道”可以直接生出“二”，但它会先生出“一”，再批量地制造“二”。\ntype可以直接生成类（class），但也可以先生成元类（metaclass），再使用元类批量定制类（class）。\n\n元类——道生一，一生二\n一般来说，元类均被命名后缀为Metalass。想象一下，我们需要一个可以自动打招呼的元类，它里面的类方法呢，有时需要say_Hello，有时需要say_Hi，有时又需要say_Sayolala，有时需要say_Nihao。\n如果每个内置的say_xxx都需要在类里面声明一次，那将是多么可怕的苦役！ 不如使用元类来解决问题。\n以下是创建一个专门“打招呼”用的元类代码：\nclass SayMetaClass(type):\n\n    def __new__(cls, name, bases, attrs):\n        attrs['say_'+name] = lambda self,value,saying=name: print(saying+','+value+'!')\n        return type.__new__(cls, name, bases, attrs)\n记住两点：1、元类是由“type”衍生而出，所以父类需要传入type。【道生一，所以一必须包含道】\n2、元类的操作都在 __new__中完成，它的第一个参数是将创建的类，之后的参数即是三大永恒命题：我是谁，我从哪里来，我将到哪里去。 它返回的对象也是三大永恒命题，接下来，这三个参数将一直陪伴我们。\n在__new__中，我只进行了一个操作，就是\nattrs['say_'+name] = lambda self,value,saying=name: print(saying+','+value+'!')\n它跟据类的名字，创建了一个类方法。比如我们由元类创建的类叫“Hello”，那创建时就自动有了一个叫“say_Hello”的类方法，然后又将类的名字“Hello”作为默认参数saying，传到了方法里面。然后把hello方法调用时的传参作为value传进去，最终打印出来。\n那么，一个元类是怎么从创建到调用的呢？来！一起根据道生一、一生二、二生三、三生万物的准则，走进元类的生命周期吧！\n# 道生一：传入type\nclass SayMetaClass(type):\n\n    # 传入三大永恒命题：类名称、父类、属性\n    def __new__(cls, name, bases, attrs):\n        # 创造“天赋”\n        attrs['say_'+name] = lambda self,value,saying=name: print(saying+','+value+'!')\n        # 传承三大永恒命题：类名称、父类、属性\n        return type.__new__(cls, name, bases, attrs)\n\n# 一生二：创建类\nclass Hello(object, metaclass=SayMetaClass):\n    pass\n\n# 二生三：创建实列\nhello = Hello()\n\n# 三生万物：调用实例方法\nhello.say_Hello('world!')\n\n输出为\nHello, world!\n注意：通过元类创建的类，第一个参数是父类，第二个参数是metaclass\n普通人出生都不会说话，但有的人出生就会打招呼说“Hello”，“你好”,“sayolala”，这就是天赋的力量。它会给我们面向对象的编程省下无数的麻烦。\n现在，保持元类不变，我们还可以继续创建Sayolala， Nihao类，如下：\n# 一生二：创建类\nclass Sayolala(object, metaclass=SayMetaClass):\n    pass\n\n# 二生三：创建实列\ns = Sayolala()\n\n# 三生万物：调用实例方法\ns.say_Sayolala('japan!')\n输出\nSayolala, japan!\n也可以说中文\n# 一生二：创建类\nclass Nihao(object, metaclass=SayMetaClass):\n    pass\n\n# 二生三：创建实列\nn = Nihao()\n\n# 三生万物：调用实例方法\nn.say_Nihao('中华!')\n输出\nNihao, 中华!\n再来一个小例子：\n# 道生一\nclass ListMetaclass(type):\n    def __new__(cls, name, bases, attrs):\n        # 天赋：通过add方法将值绑定\n        attrs['add'] = lambda self, value: self.append(value)\n        return type.__new__(cls, name, bases, attrs)\n        \n# 一生二\nclass MyList(list, metaclass=ListMetaclass):\n    pass\n    \n# 二生三\nL = MyList()\n\n# 三生万物\nL.add(1)\n现在我们打印一下L\nprint(L)\n\n>>> [1]\n而普通的list没有add()方法\nL2 = list()\nL2.add(1)\n\n>>>AttributeError: 'list' object has no attribute 'add'\n太棒了！学到这里，你是不是已经体验到了造物主的乐趣？\npython世界的一切，尽在掌握。\n\n年轻的造物主，请随我一起开创新世界。\n我们选择两个领域，一个是Django的核心思想，“Object Relational Mapping”，即对象-关系映射，简称ORM。\n这是Django的一大难点，但学完了元类，一切变得清晰。你对Django的理解将更上一层楼！\n另一个领域是爬虫领域（黑客领域），一个自动搜索网络上的可用代理，然后换着IP去突破别的人反爬虫限制。\n这两项技能非常有用，也非常好玩！\n挑战一：通过元类创建ORM\n准备工作，创建一个Field类\nclass Field(object):\n\n    def __init__(self, name, column_type):\n        self.name = name\n        self.column_type = column_type\n\n    def __str__(self):\n        return '<%s:%s>' % (self.__class__.__name__, self.name)\n        \n它的作用是在Field类实例化时将得到两个参数，name和column_type，它们将被绑定为Field的私有属性，如果要将Field转化为字符串时，将返回“Field:XXX” ， XXX是传入的name名称。\n准备工作：创建StringField和IntergerField\nclass StringField(Field):\n\n    def __init__(self, name):\n        super(StringField, self).__init__(name, 'varchar(100)')\n\nclass IntegerField(Field):\n\n    def __init__(self, name):\n        super(IntegerField, self).__init__(name, 'bigint')\n它的作用是在StringField,IntegerField实例初始化时，时自动调用父类的初始化方式。\n道生一\nclass ModelMetaclass(type):\n\n    def __new__(cls, name, bases, attrs):\n        if name=='Model':\n            return type.__new__(cls, name, bases, attrs)\n        print('Found model: %s' % name)\n        mappings = dict()\n        for k, v in attrs.items():\n            if isinstance(v, Field):\n                print('Found mapping: %s ==> %s' % (k, v))\n                mappings[k] = v\n        for k in mappings.keys():\n            attrs.pop(k)\n        attrs['__mappings__'] = mappings # 保存属性和列的映射关系\n        attrs['__table__'] = name # 假设表名和类名一致\n        return type.__new__(cls, name, bases, attrs)\n\n它做了以下几件事\n\n创建一个新的字典mapping\n将每一个类的属性，通过.items()遍历其键值对。如果值是Field类，则打印键值，并将这一对键值绑定到mapping字典上。\n将刚刚传入值为Field类的属性删除。\n创建一个专门的__mappings__属性，保存字典mapping。\n创建一个专门的__table__属性，保存传入的类的名称。\n\n一生二\nclass Model(dict, metaclass=ModelMetaclass):\n\n    def __init__(self, **kwarg):\n        super(Model, self).__init__(**kwarg)\n\n    def __getattr__(self, key):\n        try:\n            return self[key]\n        except KeyError:\n            raise AttributeError(\"'Model' object has no attribute '%s'\" % key)\n\n    def __setattr__(self, key, value):\n        self[key] = value\n\n    # 模拟建表操作\n    def save(self):\n        fields = []\n        args = []\n        for k, v in self.__mappings__.items():\n            fields.append(v.name)\n            args.append(getattr(self, k, None))\n        sql = 'insert into %s (%s) values (%s)' % (self.__table__, ','.join(fields), ','.join([str(i) for i in args]))\n        print('SQL: %s' % sql)\n        print('ARGS: %s' % str(args))\n如果从Model创建一个子类User：\nclass User(Model):\n    # 定义类的属性到列的映射：\n    id = IntegerField('id')\n    name = StringField('username')\n    email = StringField('email')\n    password = StringField('password')\n这时id= IntegerField('id')就会自动解析为：\nModel.__setattr__(self, 'id', IntegerField('id'))\n因为IntergerField('id')是Field的子类的实例，自动触发元类的__new__，所以将IntergerField('id')存入__mappings__并删除这个键值对。\n二生三、三生万物\n当你初始化一个实例的时候并调用save()方法时候\nu = User(id=12345, name='Batman', email='batman@nasa.org', password='iamback')\nu.save()\n这时先完成了二生三的过程：\n\n先调用Model.__setattr__，将键值载入私有对象\n然后调用元类的“天赋”，ModelMetaclass.__new__，将Model中的私有对象，只要是Field的实例，都自动存入u.__mappings__。\n\n接下来完成了三生万物的过程：\n通过u.save()模拟数据库存入操作。这里我们仅仅做了一下遍历__mappings__操作，虚拟了sql并打印，在现实情况下是通过输入sql语句与数据库来运行。\n输出结果为\nFound model: User\nFound mapping: name ==> <StringField:username>\nFound mapping: password ==> <StringField:password>\nFound mapping: id ==> <IntegerField:id>\nFound mapping: email ==> <StringField:email>\nSQL: insert into User (username,password,id,email) values (Batman,iamback,12345,batman@nasa.org)\nARGS: ['Batman', 'iamback', 12345, 'batman@nasa.org']\n\n年轻的造物主，你已经和我一起体验了由“道”演化“万物”的伟大历程，这也是Django中的Model版块核心原理。\n接下来，请和我一起进行更好玩的爬虫实战（嗯，你现在已经是初级黑客了）：网络代理的爬取吧！\n\n挑战二：网络代理的爬取\n准备工作，先爬个页面玩玩\n请确保已安装requests和pyquery这两个包。\n# 文件：get_page.py\nimport requests\n\nbase_headers = {\n    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36',\n    'Accept-Encoding': 'gzip, deflate, sdch',\n    'Accept-Language': 'zh-CN,zh;q=0.8'\n}\n\n\ndef get_page(url):\n    headers = dict(base_headers)\n    print('Getting', url)\n    try:\n        r = requests.get(url, headers=headers)\n        print('Getting result', url, r.status_code)\n        if r.status_code == 200:\n            return r.text\n    except ConnectionError:\n        print('Crawling Failed', url)\n        return None\n\n这里，我们利用request包，把百度的源码爬了出来。\n试一试抓百度\n把这一段粘在get_page.py后面，试完删除\nif(__name__ == '__main__'):\n    rs = get_page('https://www.baidu.com')\n    print('result:\\r\\n', rs)\n试一试抓代理\n把这一段粘在get_page.py后面，试完删除\nif(__name__ == '__main__'):\n    from pyquery import PyQuery as pq\n    start_url = 'http://www.proxy360.cn/Region/China'\n    print('Crawling', start_url)\n    html = get_page(start_url)\n    if html:\n        doc = pq(html)\n        lines = doc('div[name=\"list_proxy_ip\"]').items()\n        for line in lines:\n            ip = line.find('.tbBottomLine:nth-child(1)').text()\n            port = line.find('.tbBottomLine:nth-child(2)').text()\n            print(ip+':'+port)\n接下来进入正题：使用元类批量抓取代理\n批量处理抓取代理\nfrom getpage import get_page\nfrom pyquery import PyQuery as pq\n\n\n# 道生一：创建抽取代理的metaclass\nclass ProxyMetaclass(type):\n    \"\"\"\n        元类，在FreeProxyGetter类中加入\n        __CrawlFunc__和__CrawlFuncCount__\n        两个参数，分别表示爬虫函数，和爬虫函数的数量。\n    \"\"\"\n    def __new__(cls, name, bases, attrs):\n        count = 0\n        attrs['__CrawlFunc__'] = []\n        attrs['__CrawlName__'] = []\n        for k, v in attrs.items():\n            if 'crawl_' in k:\n                attrs['__CrawlName__'].append(k)\n                attrs['__CrawlFunc__'].append(v)\n                count += 1\n        for k in attrs['__CrawlName__']:\n            attrs.pop(k)\n        attrs['__CrawlFuncCount__'] = count\n        return type.__new__(cls, name, bases, attrs)\n\n\n# 一生二：创建代理获取类\n\nclass ProxyGetter(object, metaclass=ProxyMetaclass):\n    def get_raw_proxies(self, site):\n        proxies = []\n        print('Site', site)\n        for func in self.__CrawlFunc__:\n            if func.__name__==site:\n                this_page_proxies = func(self)\n                for proxy in this_page_proxies:\n                    print('Getting', proxy, 'from', site)\n                    proxies.append(proxy)\n        return proxies\n\n\n    def crawl_daili66(self, page_count=4):\n        start_url = 'http://www.66ip.cn/{}.html'\n        urls = [start_url.format(page) for page in range(1, page_count + 1)]\n        for url in urls:\n            print('Crawling', url)\n            html = get_page(url)\n            if html:\n                doc = pq(html)\n                trs = doc('.containerbox table tr:gt(0)').items()\n                for tr in trs:\n                    ip = tr.find('td:nth-child(1)').text()\n                    port = tr.find('td:nth-child(2)').text()\n                    yield ':'.join([ip, port])\n\n    def crawl_proxy360(self):\n        start_url = 'http://www.proxy360.cn/Region/China'\n        print('Crawling', start_url)\n        html = get_page(start_url)\n        if html:\n            doc = pq(html)\n            lines = doc('div[name=\"list_proxy_ip\"]').items()\n            for line in lines:\n                ip = line.find('.tbBottomLine:nth-child(1)').text()\n                port = line.find('.tbBottomLine:nth-child(2)').text()\n                yield ':'.join([ip, port])\n\n    def crawl_goubanjia(self):\n        start_url = 'http://www.goubanjia.com/free/gngn/index.shtml'\n        html = get_page(start_url)\n        if html:\n            doc = pq(html)\n            tds = doc('td.ip').items()\n            for td in tds:\n                td.find('p').remove()\n                yield td.text().replace(' ', '')\n\n\nif __name__ == '__main__':\n    # 二生三：实例化ProxyGetter\n    crawler = ProxyGetter()\n    print(crawler.__CrawlName__)\n    # 三生万物\n    for site_label in range(crawler.__CrawlFuncCount__):\n        site = crawler.__CrawlName__[site_label]\n        myProxies = crawler.get_raw_proxies(site)\n道生一：元类的__new__中，做了四件事：\n\n将“crawl_”开头的类方法的名称推入ProxyGetter.__CrawlName__\n将“crawl_”开头的类方法的本身推入ProxyGetter.__CrawlFunc__\n计算符合“crawl_”开头的类方法个数\n删除所有符合“crawl_”开头的类方法\n\n怎么样？是不是和之前创建ORM的__mappings__过程极为相似？\n一生二：类里面定义了使用pyquery抓取页面元素的方法\n分别从三个免费代理网站抓取了页面上显示的全部代理。\n如果对yield用法不熟悉，可以查看：廖雪峰的python教程：生成器\n二生三：创建实例对象crawler\n略\n三生万物：遍历每一个__CrawlFunc__\n\n在ProxyGetter.__CrawlName__上面，获取可以抓取的的网址名。\n触发类方法ProxyGetter.get_raw_proxies(site)\n遍历ProxyGetter.__CrawlFunc__,如果方法名和网址名称相同的，则执行这一个方法\n把每个网址获取到的代理整合成数组输出。\n\n那么。。。怎么利用批量代理，冲击别人的网站，套取别人的密码，狂发广告水贴，定时骚扰客户？ 呃！想啥呢！这些自己悟！如果悟不到，请听下回分解！\n年轻的造物主，创造世界的工具已经在你手上，请你将它的威力发挥到极致！\n请记住挥动工具的口诀：\n\n道生一，一生二，二生三，三生万物\n我是谁，我来自哪里，我要到哪里去\n\n\n                ", "mainLikeNum": ["41 "], "mainBookmarkNum": "120"}