{"title": "手把手教你写电商爬虫-第四课 淘宝网商品爬虫自动JS渲染 - 爬虫开发教程 ", "index": "大数据,网页爬虫,电商,python,javascript", "content": "系列教程：\n手把手教你写电商爬虫-第一课 找个软柿子捏捏\n手把手教你写电商爬虫-第二课 实战尚妆网分页商品采集爬虫\n手把手教你写电商爬虫-第三课 实战尚妆网AJAX请求处理和内容提取\n都已经三节课了，大家活动活动手脚，咱们开始一场真正的硬仗， 我们要来爬电商老大，淘宝的数据了。\n老规矩，爬之前首先感谢淘宝公布出这么多有价值的数据，才让我们这些爬虫们有东西可以搜集啊，不过淘宝就不用我来安利了\n广大剁手党相信睡觉的时候都能把网址打出来吧。\n工欲善其事，必先利其器，先上工具：\n1、神箭手云爬虫，2、Chrome浏览器 3、Chrome的插件XpathHelper 不知道是干嘛的同学请移步第一课好了，咱们还是先打开淘宝网：\n清新的画面，琳琅满目的商品，隐约感到的是前方是一场恶战：\n淘宝这么多的商品，这么多的主题，到底从哪里开始呢？要不就女装了，别问我为什么，咱们先打开一个女装的列表页面：\nhttps://s.taobao.com/list?q=%E5%A5%97%E8%A3%85%E5%A5%B3%E5%A4%8F\n\n我们点击一下下一页看看连接：\nhttps://s.taobao.com/list?q=%E5%A5%97%E8%A3%85%E5%A5%B3%E5%A4%8F&bcoffset=-4&s=60\n\n看着好像不难，很简单，不过值得注意的是，我们把鼠标移到下一页可以看到连接本身并不是这个，这个是js处理的，这种情况类似前面我们遇到的尚妆网下一页，我们一会再说。\n我们再看下详情页\nhttps://item.taobao.com/item.htm?spm=a217f.7283053.1997524073.204.hEmtfc&id=527101625954&scm=1029.minilist-17.1.16&ppath=&sku=&ug=#detail\n\nhttps://item.taobao.com/item.htm?spm=a217f.7283053.1997524073.209.hEmtfc&id=528697742170&scm=1029.minilist-17.1.16&ppath=&sku=&ug=#detail\n\n看着比较简单，就直接提取成：\nhttps://item\\\\.taobao\\\\.com/item\\\\.htm\\\\?.*\n\n我比较懒，这个就先这样吧，然后我们来看看详情页我们需要抽取哪些信息，商品名称，价格自然不能少，这次再来一个新鲜的，就是缩略图列表，因为淘宝的商品不只有一个缩略图，因此需要爬取一个缩略图数组。\n同样，用chrome开发者工具和xpathhelper对抽取项进行分析，看了一下结果，尝试过滤xhr，结果：\n\n高手就是高手，在大量的请求中，找到响应的请求，相当的困难。不要紧，还记得我们上节课提到的核武器吗-JS渲染引擎，只要我们把JS渲染引擎打开，那么我们完全不用操心大量ajax请求的判断，当然他的问题是效率低一些，不过没关系，反正在云上跑嘛，睡一觉就好了。\n在神箭手里调用JS渲染引擎的方式很简单，只需要一行代码设置既可：\nconfigs.enableJS=true  \n\n好了，那我们现在可以无视ajax请求了，直接用chrome工具打开，直接提取：\n//em[@id=\"J_PromoPriceNum\"]  \n\n简单暴啦，然后高兴没有1秒钟，瞬间蒙逼，淘宝上的价格不仅有这种促销价格，还有价格区间，还有的是普通的价格，我的天的，这不是要人命吗~没办法，再难也要硬着头皮上，目前来看，一共有两种价格的抽取方式，当然不排除有其他多种的情况，我们先对这两种分别写一下抽取规则：\n//em[@id=\"J_PromoPriceNum\"]  \n//em[contains(@class,\"tb-rmb-num\")]  \n\n我们可以通过 | 这个来连接，表达不同页面的选取可以共存\n//em[@id=\"J_PromoPriceNum\"] | //em[contains(@class,\"tb-rmb-num\")]  \n\n不容易。我们再看看商品名称，这个相对简单：\n//h3[contains(@class,'tb-main-title')]/@data-title  \n\n最后，我们需要抽取图片的地址：\n//ul[@id=\"J_UlThumb\"]/li//img/@src  \n\n由于这一项存在多项，因此需要将该抽取规则的repeated字段设置成true\nvar configs = {  \n    domains: [\"www.taobao.com\",\"item.taobao.com\"],  \n    scanUrls: [\"https://www.taobao.com/go/market/nvzhuang/citiao/taozhuangqun.php\"],  \n    contentUrlRegexes: [\"https://item\\\\.taobao\\\\.com/item\\\\.htm\\\\?.*\"],  \n    helperUrlRegexes: [\"https://www\\\\.taobao\\\\.com/go/market/nvzhuang/citiao/taozhuangqun.php\"],//可留空  \n    enableJS:true,  \n    fields: [  \n        {  \n            // 第一个抽取项  \n            name: \"title\",  \n            selector: \"//h3[contains(@class,'tb-main-title')]/@data-title\",//默认使用XPath  \n            required: true //是否不能为空  \n        },  \n        {  \n            // 第二个抽取项  \n            name: \"price\",  \n            selector: \"//em[@id='J_PromoPriceNum'] | //em[contains(@class,'tb-rmb-num')]\",//默认使用XPath  \n        },  \n        {  \n            // 第三个抽取项  \n            name: \"thumbs\",  \n            selector: \"//ul[@id='J_UlThumb']/li//img/@src\",//默认使用XPath  \n        },  \n    ]  \n};  \nvar crawler = new Crawler(configs);  \ncrawler.start();  \n\n好了，虽然淘宝比尚妆网难的多，但是在我们拿出核武器之后，一切迎刃而解，回头我们在来处理下一页的问题，这里虽然和尚妆网不一样，但是整体的原理大同小异，就不一一解释，我们直接上代码：\nvar configs = {  \n    domains: [\"s.taobao.com\",\"item.taobao.com\"],  \n    scanUrls: [\"https://s.taobao.com/list?q=%E5%A5%97%E8%A3%85%E5%A5%B3%E5%A4%8F\"],  \n    contentUrlRegexes: [\"https?://item\\\\.taobao\\\\.com/item\\\\.htm\\\\?.*\"],  \n    helperUrlRegexes: [\"https?://s\\\\.taobao\\\\.com/list\\\\?q=%E5%A5%97%E8%A3%85%E5%A5%B3%E5%A4%8F.*\"],//可留空  \n    enableJS:true,  \n    fields: [  \n        {  \n            // 第一个抽取项  \n            name: \"title\",  \n            selector: \"//h3[contains(@class,'tb-main-title')]/@data-title\",//默认使用XPath  \n            required: true //是否不能为空  \n        },  \n        {  \n            // 第二个抽取项  \n            name: \"price\",  \n            selector: \"//em[@id='J_PromoPriceNum'] | //em[contains(@class,'tb-rmb-num')]\",//默认使用XPath  \n            required: true //是否不能为空  \n        },  \n        {  \n            // 第三个抽取项  \n            name: \"thumbs\",  \n            selector: \"//ul[@id='J_UlThumb']/li//img/@src\",//默认使用XPath  \n            repeated:true  \n        },  \n    ]  \n};  \nconfigs.onProcessHelperUrl = function(url, content, site){  \n    if(!content.indexOf(\"未找到与\")){  \n        var currentStart = parseInt(url.substring(url.indexOf(\"&s=\") + 3));  \n        var start = currentStart + 60;  \n        var nextUrl = url.replace(\"&s=\" + currentStart, \"&s=\" + start);  \n        site.addUrl(nextUrl);  \n    }  \n    return true;  \n};  \nvar crawler = new Crawler(configs);  \ncrawler.start();  \n\nOK 大功告成，测试结果如下，由于开启的js渲染，所以爬取的速度比较慢，只能耐心等待了。\n\n对爬虫感兴趣的童鞋可以加qq群讨论：342953471。\n\n                ", "mainLikeNum": ["2 "], "mainBookmarkNum": "9"}