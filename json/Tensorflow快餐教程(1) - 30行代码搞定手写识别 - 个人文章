{"title": "Tensorflow快餐教程(1) - 30行代码搞定手写识别 - 个人文章 ", "index": "python,算法,tensorflow,神经网络,深度学习", "content": "\n摘要： Tensorflow入门教程1\n去年买了几本讲tensorflow的书，结果今年看的时候发现有些样例代码所用的API已经过时了。看来自己维护一个保持更新的Tensorflow的教程还是有意义的。这是写这一系列的初心。\n快餐教程系列希望能够尽可能降低门槛，少讲，讲透。\n为了让大家在一开始就看到一个美好的场景，而不是停留在漫长的基础知识积累上，参考网上的一些教程，我们直接一开始就直接展示用tensorflow实现MNIST手写识别的例子。然后基础知识我们再慢慢讲。\nTensorflow安装速成教程\n由于Python是跨平台的语言，所以在各系统上安装tensorflow都是一件相对比较容易的事情。GPU加速的事情我们后面再说。\nLinux平台安装tensorflow\n我们以Ubuntu 16.04版为例，首先安装python3和pip3。pip是python的包管理工具。\n\n然后就可以通过pip3来安装tensorflow:\n\nMacOS安装tensorflow\n建议使用Homebrew来安装python。\n\n安装python3之后，还是通过pip3来安装tensorflow.\n\nWindows平台安装Tensorflow\nWindows平台上建议通过Anaconda来安装tensorflow，下载地址在：https://www.anaconda.com/down...\n然后打开Anaconda Prompt，输入：\n\n这样就安装好了Tensorflow。\n我们迅速来个例子试下好不好用：\n\n输出结果为2. \nTensorflow顾名思义，是一些Tensor张量的流组成的运算。\n运算需要一个Session来运行。如果print(c)的话，会得到\n\n就是说这是一个乘法运算的Tensor，需要通过Session.run()来执行。\n入门捷径：线性回归\n我们首先看一个最简单的机器学习模型，线性回归的例子。\n线性回归的模型就是一个矩阵乘法：\n\n然后我们通过调用Tensorflow计算梯度下降的函数tf.train.GradientDescentOptimizer来实现优化。\n我们看下这个例子代码，只有30多行，逻辑还是很清晰的。例子来自github上大牛的工作：https://github.com/nlintz/Ten...，不是我的原创。\n\n最终会得到一个接近2的值，比如我这次运行的值为1.9183811\n多种方式搞定手写识别\n线性回归不过瘾，我们直接一步到位，开始进行手写识别。\n\n我们采用深度学习三巨头之一的Yann Lecun教授的MNIST数据为例。如上图所示，MNIST的数据是28x28的图像，并且标记了它的值应该是什么。\n线性模型：logistic回归\n我们首先不管三七二十一，就用线性模型来做分类。\n算上注释和空行，一共加起来30行左右，我们就可以解决手写识别这么困难的问题啦！请看代码：\n\n经过100轮的训练，我们的准确率是92.36%。\n无脑的浅层神经网络\n用了最简单的线性模型，我们换成经典的神经网络来实现这个功能。神经网络的图如下图所示。\n\n我们还是不管三七二十一，建立一个隐藏层，用最传统的sigmoid函数做激活函数。其核心逻辑还是矩阵乘法，这里面没有任何技巧。\n\n完整代码如下，仍然是40多行，不长：\n\n第一轮运行，我这次的准确率只有69.11% ，第二次就提升到了82.29%。最终结果是95.41%，比Logistic回归的强！\n请注意我们模型的核心那两行代码，完全就是无脑地全连接做了一个隐藏层而己，这其中没有任何的技术。完全是靠神经网络的模型能力。\n深度学习时代的方案 - ReLU和Dropout显神通\n上一个技术含量有点低，现在是深度学习的时代了，我们有很多进步。比如我们知道要将sigmoid函数换成ReLU函数。我们还知道要做Dropout了。于是我们还是一个隐藏层，写个更现代一点的模型吧：\n\n除了ReLU和dropout这两个技巧，我们仍然只有一个隐藏层，表达能力没有太大的增强。并不能算是深度学习。\n\n从结果看到，第二次就达到了96%以上的正确率。后来就一直在98.4%左右游荡。仅仅是ReLU和Dropout，就把准确率从95%提升到了98%以上。\n卷积神经网络出场\n真正的深度学习利器CNN，卷积神经网络出场。这次的模型比起前面几个无脑型的，的确是复杂一些。涉及到卷积层和池化层。这个是需要我们后面详细讲一讲了。\n\n我们看下这次的运行数据：\n\n在第6轮的时候，就跑出了99.6%的高分值，比ReLU和Dropout的一个隐藏层的神经网络的98.4%大大提高。因为难度是越到后面越困难。\n在第16轮的时候，竟然跑出了100%的正确率：\n\n综上，借助Tensorflow和机器学习工具，我们只有几十行代码，就解决了手写识别这样级别的问题，而且准确度可以达到如此程度。\n下一节，我们回到基础讲起。\n本文作者：lusing\n阅读原文\n本文为云栖社区原创内容，未经允许不得转载。\n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "1"}