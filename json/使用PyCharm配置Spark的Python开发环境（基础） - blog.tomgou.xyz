{"title": "使用PyCharm配置Spark的Python开发环境（基础） - blog.tomgou.xyz ", "index": "pyspark,pycharm,spark,python", "content": "在本地搭建好Spark 1.6.0后，除了使用spark-submit提交Python程序外，我们可以使用PyCharm这个IDE在本地进行开发调试,提升我们的开发效率。配置过程也十分简单，在stackoverflow上搜索到的。同时，IntelliJ IDEA加入Python插件后也可以使用Python开发Spark程序，配置步骤一致。\n我的博客原文地址链接：http://blog.tomgou.xyz/shi-yong-pycharmpei-zhi-sparkde-pythonkai-fa-huan-jing.html\n0.安装PyCharm和py4j\n我的系统环境（Ubuntu 14.04.4 LTS）\n下载安装最新版本的PyCharm，官网地址：https://www.jetbrains.com/pycharm/download/ 。\n安装步骤：\n\nUnpack the pycharm-5.0.4.tar.gz using the following command: tar xfz pycharm-5.0.4.tar.gz\nRun pycharm.sh from the bin subdirectory\n\n安装py4j：\n$ sudo pip install py4j\n\n1.配置Pycharm\n打开PyCharm，创建一个Project。然后选择“Run” ->“Edit Configurations” ->“Environment variables”增加SPARK_HOME目录与PYTHONPATH目录。\n\nSPARK_HOME:Spark安装目录\nPYTHONPATH:Spark安装目录下的Python目录\n\n\n2.测试Pycharm\n运行一个小的Spark程序看看：\n\"\"\"SimpleApp\"\"\"\n\nfrom pyspark import SparkContext\n\nlogFile = \"/home/tom/spark-1.6.0/README.md\"\nsc = SparkContext(\"local\",\"Simple App\")\nlogData = sc.textFile(logFile).cache()\n\nnumAs = logData.filter(lambda s: 'a' in s).count()\nnumBs = logData.filter(lambda s: 'b' in s).count()\n\nprint(\"Lines with a: %i, lines with b: %i\"%(numAs, numBs))\n运行结果：\nLines with a: 58, lines with b: 26\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "8"}