{"title": "Simplest Linear Regression on Keras Framework - machine learning ", "index": "jupyter-notebook,机器学习,python", "content": "It's a regression problem with one feature inputted.\nI wrote this script for fun and for the preparation of oncoming Mathematical modeling contest(also simply in order to complete the task of a daily blog✌( •̀ ω •́ )y), didn't took a lot of time(It means I can have time to sleep...).\nIt was accomplished all by myself, that means there is no reference to github's code. Well, great progress!\nI committed it onto my own GitHub, which was not well organized.\nImport Packages\nimport numpy as np\nfrom keras.models import Sequential \nfrom keras.layers import Dense \nimport matplotlib.pyplot as plt \nprint (\"Import finished\")\nBecause the importing of Keras took a little bit more time, I need a hint that they've been successfully imported:\n\nGenerating Data\nMake them out of sequence in order to make random splitting,Add some noise:\nX = np.linspace(0, 2, 300) \nnp.random.shuffle(X)\nY = 3 * X + np.random.randn(*X.shape) * 0.33\nData visualization\nplt.scatter(X,Y)\nplt.show()\nprint (X[:10],'\\n',Y[:10])\n\nDefine Train and Test Data\nX_train,Y_train = X[:260],Y[:260]\nX_test,Y_test = X[260:],Y[260:]\nEstablish LR Modelinput and output dimensions are both set as 1\nmodel = Sequential()\nmodel.add(Dense(units=1, kernel_initializer=\"uniform\", activation=\"linear\", input_dim=1))\nweights = model.layers[0].get_weights() \nw_init = weights[0][0][0] \nb_init = weights[1][0] \nprint('Linear regression model is initialized with weights w: %.2f, b: %.2f' % (w_init, b_init)) \nsee the default coefficients:\n\nChoose Loss-Function and OptimizerDefine loss as mean squared error, choose stochastic gradient descent as optimizer:\nmodel.compile(loss='mse', optimizer='sgd')\nTrain ModelRun 500 epochs of iterations of sgd.\nmodel.fit(X_train, Y_train, epochs=500, verbose=1)\nThe loss eventually stabilizes at around 0.0976:\n\nTest Model\nY_pred = model.predict(X_test)\nplt.scatter(X_test,Y_test)\nplt.plot(X_test,Y_pred)\nplt.show()\nweights = model.layers[0].get_weights() \nw_init = weights[0][0][0] \nb_init = weights[1][0] \nprint('Linear regression model is trained with weights w: %.2f, b: %.2f' % (w_init, b_init)) \nThe final weights are 3.00 and 0.03, very close to the setted one(3.00, 0.33), the error of 0.03 might caused by the noise.\n\nUse model\nInput 1.66 as feature:\na = np.array([1.66])\nPre=model.predict(a)\nprint (Pre)\n\nTomorrow I would change this script into multi-dimensional regression machine, which can solve multi-feature regression problems.\n\n                ", "mainLikeNum": ["0 "], "mainBookmarkNum": "1"}