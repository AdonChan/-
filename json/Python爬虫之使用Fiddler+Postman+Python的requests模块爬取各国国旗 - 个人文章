{"title": "Python爬虫之使用Fiddler+Postman+Python的requests模块爬取各国国旗 - 个人文章 ", "index": "postman,fiddler,网页爬虫,python", "content": "介绍\n  本篇博客将会介绍一个Python爬虫，用来爬取各个国家的国旗，主要的目标是为了展示如何在Python的requests模块中使用POST方法来爬取网页内容。  为了知道POST方法所需要传递的HTTP请求头部和请求体，我们可以使用Fiddler来进行抓包，抓取上网过程中HTTP请求中的POST方法。为了验证Fiddler抓取到的POST请求，可以使用Postman进行测试验证。在Postman中完成测试后，我们就可以用Python的request.POST()方法来写我们的爬虫了。\n流程\n  作为上述过程的一个演示，我们使用的网址为： http://country.911cha.com/ , 页面如下：\n\n在表单中输入德国，跳转后的页面如下：\n\n我们可以发现，在搜索的结果中，会出现德国这个搜索结果。点击该搜索结果，跳转后的页面如下：\n\n在这个页面中有我们需要的德国的国旗。但是，怎么知道该网页的具体网址呢？换句话说，就是怎样得到http://country.911cha.com/GER... ？别担心，在刚才出来的德国这个搜索结果中，我们查看其源代码，不难发现，在HTML源代码中，有我们想要的东西：\n\n在源代码中我们能看到“GER.html”，这就意味着，只要得到搜索的结果，我们可以分析HTML源码来得到这个搜索结果的连接网址，然后在该连接网址中获取该国的国旗。所以，在这个爬虫中，最困难的地方在于，如何获取搜索结果？即，得到提交表单后的结果，也就是POST方法提交后的响应结果。我们利用Fiddler来抓取该POST方法。  我们打开Fiddler, 同时重复上面的操作，可以得到该过程的HTTP请求，如下图：\n\nFiddler帮助我们找到了刚才提交表单过程中的一个POST请求，具体分析该POST请求，其请求头部如下：\n\n其请求体如下：\n\n  为了验证Fiddler抓取的POST请求，我们需要要Postman来进行测试。在用Postman进行测试前，我们需要问：是否所有请求头部中的数据都需要呢？答案是否定的，实际上，我们只需要User-Agent和Content-Type即可。在Postman中，先输入请求头部，如下：\n\n再输入请求体，如下：\n\n点击\"SEND\"按钮，得到响应后的结果，如下：\n\nOK，这样我们就完成了Postman的测试。\n爬虫\n  于是，借助这些信息来完成request.post()的提交，同时，借助BeautifulSoup来解析网页，得到国家的国旗下载地址并完成下载。具体的Python代码如下：\n# -*- coding: utf-8 -*-\n\nimport urllib.request\nimport requests\nfrom bs4 import BeautifulSoup\n\n# 函数：下载指定国家的国旗\n# 参数： country: 国家\ndef download_flag(country):\n\n    # 请求头部\n    headers = {\n                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36',\n                'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n              }\n    # POST数据\n    data = {'q': country}\n    # 网址\n    url = 'http://country.911cha.com/'\n\n    # 提交POST请求\n    r = requests.post(url=url, data=data, headers=headers)\n\n    # 利用BeautifulSoup解析网页\n    content = BeautifulSoup(r.text, 'lxml')\n\n    # 得到搜索结果（国家）所在网页地址\n    country = content.find_all('div', class_='mcon')[1]('ul')[0]('li')[0]('a')[0]\n    link = country['href']\n\n    #利用GET方法得到搜索国家的网页\n    r2 = requests.get(url='%s/%s'%(url, link))\n    # 利用BeautifulSoup解析网页\n    content = BeautifulSoup(r2.text, 'lxml')\n    # 获取网页中的图片\n    images = content.find_all('img')\n\n    # 获取指定国家的国旗名称及下载地址\n    for image in images:\n        if 'alt' in image.attrs:\n            if '国旗' in image['alt']:\n                name = image['alt'].replace('国旗', '')\n                link = image['src']\n\n    # 下载国旗图片\n    urllib.request.urlretrieve('%s/%s'%(url, link), 'E://flag/%s.gif'%name)\n\n\ndef main():\n\n    # countries.txt储存各个国家的名称\n    file = 'E://flag/countries.txt'\n    with open(file, 'r') as f:\n        counties = [_.strip() for _ in f.readlines()]\n\n    # 遍历各个国家，下载国旗\n    for country in counties:\n        try:\n            download_flag(country)\n            print('%s国旗下载成功！'%country)\n        except:\n            print('%s国旗下载失败~'%country)\n\nmain()\n其中countries.txt的部分内容如下：\n\n运行上述Python代码，我们发现在E盘的flag文件夹下，已经下载了各个国家的国旗，如下：\n\n这样我们就完成了本次爬虫的任务！\n总结\n  本次爬虫利用Python的requests模块的POST方法，来模拟网页中的表单提交。为了得到表单提交过程中的HTTP请求，即请求头部和请求体，我们利用了抓包工具Fiddler，而Postman的作用是为了帮助我们验证Fiddler抓取的POST请求是否正是我们需要的POST请求，同时也能验证请求头部及请求体。  虽然整个爬虫的过程写的不免麻烦，但是操作的思路应该是清晰的，再说，熟能生巧，多用几次，也就能熟悉整个流程了。本次爬虫只是作为整个流程的一个简单展示，读者可以在此基础上，去实现更为复杂的爬虫，希望本次的分享能够帮助到读者。谢谢大家能读到这儿，也欢迎大家交流~~\n注意：本人现已开通两个微信公众号： 因为Python（微信号为：python_math）以及轻松学会Python爬虫（微信号为：easy_web_scrape）， 欢迎大家关注哦~~\n\n                ", "mainLikeNum": ["4 "], "mainBookmarkNum": "4"}