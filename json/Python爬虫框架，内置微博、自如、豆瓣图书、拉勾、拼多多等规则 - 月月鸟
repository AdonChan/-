{"title": "Python爬虫框架，内置微博、自如、豆瓣图书、拉勾、拼多多等规则 - 月月鸟 ", "index": "python,网页爬虫,后端", "content": "PyLoom想为有价值的网站编写爬虫，让开发者便捷地获取结构化的数据。\nPyLoom由三个部分组成，\n\n框架，减少编写、运行、维护爬虫的工作量。\n爬虫，寻找有价值的目标为其开发爬虫，并维护既有爬虫的可用性。预期19年底，PyLoom将拥有围绕电子商务、房屋租售、社交网络、新闻媒体的数十个爬虫。\n\n\n升级爬虫，对于频繁使用的爬虫，增强其能力\n\n增强定制能力，例如支持限定地区、类别、关键字抓取；\n增强抓取策略，减少对代理、打码接口的使用；\n增强更新策略，更细粒度地计算重复抓取的时间。\n\n\n\n目前进度，\n①部分完成，开发常见爬虫够用了，随爬虫的开发迭代出更多功能；\n②已开源自如、微博、拉钩、豆瓣图书、拼多多爬虫，放置于spiders目录。\n安装\n\n\n环境要求\n\npython 3.6.0+\nredis 2.6+\n类unix系统\n\n\n\n安装PyLoom\ngit clone https://github.com/spencer404/PyLoom.git\npython3.6 -m pip install -e ./PyLoom\n添加 -i https://pypi.douban.com/simple 参数，利用豆瓣镜像提速。出现错误fatal error: Python.h: No such file or directory时，\n需安装对应平台的python3.x-devel包\n\n\n\n运行\n以运行spiders/WeiBo为例，\n\n\n最简参数启动爬虫\npyloom run -s PyLoom/spiders/WeiBo\n在爬虫目录中执行run时，可省略-s参数。\n\n\n\n启动代理池\npyloom proxy run\n\n\n添加代理\n根据命令提示，添加名为\"xxx\"的代理\npyloom proxy add\n\n\n使用代理启动爬虫\npyloom run --proxy xxx\n命令run的部分常用参数：\n-l, --level    日志级别\n-s, --spider   指定爬虫目录\n-r, --redis    指定redis地址(URL形式)\n-C, --clear    清空队列、代理数据后运行\n--proxy        使用指定代理运行，逗号分隔多个代理\n--damon        作为守护进程运行\n-p             子进程数量\n-t             每个子进程的线程数量\n在多台服务器上运行时，若参数-s、-r所指向的目标相同，即可横向扩容性能。\n默认地，PyLoom将抓到数据打印在日志中，你可以修改on_save函数自定义如何保存。\n\n\nGitHub地址：https://github.com/spencer404...\n\n                ", "mainLikeNum": ["28 "], "mainBookmarkNum": "20"}