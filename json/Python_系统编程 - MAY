{"title": "Python_系统编程 - MAY ", "index": "python", "content": "多任务：同一个时间段中，执行多个函数/运行多个程序.\n操作系统可以同时运行多个任务:操作系统轮流让各个任务交替执行，任务1执行0.01秒，切换到任务2，任务2执行0.01秒，再切换到任务3，执行0.01秒……这样反复执行下去。表面上看，每个任务都是交替执行的，但是，由于CPU的执行速度实在是太快了，感觉就像所有任务都在同时执行一样。(时间片轮转)\n任务 执行算法：\n\n时间片轮转\n优先级调度\n调度算法（什么样的情况下按照什么样的规则，让哪个任务执行）\n\n真正的并行执行多任务只能在多核CPU上实现，但是，由于任务数量远远多于CPU的核心数量，所以，操作系统也会自动把很多任务轮流调度到每个核心上执行。\n\n进程\n线程\n协程\n\n并发：看上去一齐执行（任务数>内核数）并行：真正一齐执行（内核数>任务数）\n程序：编写完毕的代码，在没有运行的时候（一个可执行的代码，可以理解称没有生命）进程：正在运行的代码（除了包含代码外，还需要运行环境，占用的内存，键盘，显示器等，可以理解称具有生命）\n进程\n创建子进程\nos.fork()创建新的进程，为子进程\nimport os\nimport time\n\nret = os.fork() # 返回二个特殊值， 其中一个等于0（子进程），一个不固定的大于0的值（父进程，pid）。都是int类型。\n\nif ret == 0:\n    while True:\n        print('1')\n        time.sleep(1)\nelse:\n    while True:\n        print('2')\n        time.sleep(1)\n不一定父进程先执行，或子进程先执行，哪个进程先执行，是依靠操作系统调度算法。\nNote: os.fork()，只在Unix/Linux/Mac上运行，windows不可以。\ngetpid、getppid\nimport os\n\nret = os.fork()\nprint(ret)\nif ret > 0:\n    print('父进程 - %d'%os.getpid())\nelse:\n    print('子进程 - %d - %d'%(os.getpid(), os.getppid()))\n    \n\"\"\"\n1535\n父进程 - 1534\n0\n子进程 - 1535 - 1534\n\"\"\"\nos.getpid(): 子进程的pid的值os.getppid(): 父进程的pid的值\n父进程中fork的返回值，就是刚刚创建出来的子进程的pid\n父子进程的先后顺序\n主进程执行完结束后，子进程没有结束。照样主进程结束掉，而子进程一样执行完程序。\nimport os\nimport time\n\nret = os.fork()\n\nif ret == 0:\n    print('子进程')\n    time.sleep(5)\n    print('子进程over')\nelse:\n    print('父进程')\n    time.sleep(3)\n\nprint('over')\n执行结果：\n父进程\n子进程\nover\nlinxingzhangdeMacBook-Air:python linxingzhang$ 子进程over\nover\n光标定位到当前位置\n全局变量在多个进程中不共享\nimport os\nimport time\n\ng_num = 100\n\nret = os.fork()\n\nif ret == 0:\n    g_num += 1\n    print('process-c - %d'%g_num)\nelse:\n    time.sleep(3)\n    print('process-p - %d'%g_num)\n执行结果：\nprocess-c - 101\nprocess-p - 100\n在进程中，全局变量，局部变量，在各自进程的命名空间中，互不干预。进程和进程之间，数据无法共享。\n同一台电脑进程之间通信：管道，消息队列...不同一台电脑进程之间通信：网络\n多个fork\n第一种：多个fork情况，并列fork。\nimport os\n\n# 父进程\nret = os.fork()\n\nif ret == 0:\n    # 子进程\n    print('1')\nelse:\n    # 父进程\n    print('2')\n\n# 父子进程\nret = os.fork()\n\nif ret == 0:\n    # 孙子进程\n    # 2儿子进程\n    print('11')\nelse:\n    # 儿子进程\n    # 父进程\n    print('22')\n执行结果：\n2\n22\n1\n11\n11\n22\n第二种fork情况，包含fork\nimport os\n\n# 父进程\nret = os.fork()\n\nif ret == 0:\n    # 子进程\n    print('1')\nelse:\n    # 父进程\n    print('2')\n\n    ret = os.fork()\n\n    if ret == 0: \n        # 2儿子进程\n        print('11')\n    else:\n        # 父进程\n        print('22')\n执行结果：\n2\n22\n1\n11\n父子进程的执行顺序：父进程、子进程执行顺序没有规律，完全取决于操作系统的调度算法\nProcess创建子进程\nmultiprocessing模块是跨平台版本的多进程模块。\n# coding=utf-8\nfrom multiprocessing import Process\nimport time\n\ndef test():\n        while True:\n                print('--test')\n                time.sleep(2)\nret = Process(target=test)\n\nret.start() # 子进程执行代码\n\nwhile True:\n        print('--mian')\n        time.sleep(1)\n当前执行结果：\n--mian\n--test\n--mian\n--test\n--mian\n--mian\n--test\n--mian\n--mian\n... # 循环\n\n# coding=utf-8\nfrom multiprocessing import Process\nimport os\n\n# 子进程执行的代码\ndef run_proc(name):\n    print('子进程运行中，name= %s ,pid=%d...' % (name,  os.getpid()))\n\nif __name__ == '__main__':\n    print('父进程 %d.' % os.getpid())\n    p = Process(target=run_proc, args=('test',))\n    print('子进程将要执行')\n    p.start() # 子进程开始\n    p.join() # 等待进程标记结束后才继续往下走 # 堵塞 \n    print('子进程已结束')\n    \n执行结果\n父进程 3045.\n子进程将要执行\n子进程运行中，name= test ,pid=3046...\n子进程已结束\n创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，用start()方法启动join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。\n主进程会等待所有的Process子进程先结束，然后再结束主进程。 \n创建新的进程还能够使用类的方式，可以自定义一个类，继承Process类，每次实例化这个类的时候，就等同于实例化一个进程对象\n创建新的进程的另一种方式：使用自定义类，继承Process类，每次实例化当前自定义类的时候，等同与实例话一个进程对象。\nfrom multiprocessing import Process\nimport time\n\nclass New_Process (Process):\n    # 重写run方法\n    def run(nPro): #run\n        print(nPro) # t=<New_Process(New_Process-1, started)>\n        while True:\n            print('11')\n            time.sleep(1)\n\np = New_Process()\np.start() # 没有传递target参数，会调用run方法\n\nwhile True:\n    print('main')\n    time.sleep(1)\n\nfrom multiprocessing import Process\nimport time\nimport os\n\n# 继承Process\nclass Process_Class (Process):\n    # 因为Process类本身也有__init__方法，这个子类相当于重写了Process的__init__方法，导致，并没有完全的初始化一个Process类，所以不能子类不能使用继承的方法和属性。\n    # 解决：将继承类的本身传递给Process.__init__方法，完成这些初始化操作。\n    def __init__(self, interval):\n        Process.__init__(self)\n        self.interval = interval\n    \n    # 重写Process类的run()方法\n    def run(self):\n        print(\"子进程(%s) 开始执行，父进程为（%s）\"%(os.getpid(),os.getppid()))\n        t_start = time.time()\n        time.sleep(self.interval)\n        t_stop = time.time()\n        print(\"(%s)执行结束，耗时%0.2f秒\"%(os.getpid(),t_stop-t_start))\n\nif __name__ == '__main__':\n    t_start = time.time()\n    print(\"当前程序进程(%s)\"%os.getpid())        \n    p1 = Process_Class(2) # 实例化\n    # 对一个不包含target属性的Process类执行start()方法，就会运行这个类中的run()方法，所以这里会执行p1.run()\n    p1.start()\n    p1.join()\n    t_stop = time.time()\n    print(\"(%s)执行结束，耗时%0.2f\"%(os.getpid(),t_stop-t_start))        \nProcess语法结构\nProcess([group [, target [, name [, args [, kwargs]]]]])\n\n\ntarget: 这个进程实例所调用对象\n\nargs: 调用对象的位置参数元组\n\nkwargs: 调用对象的关键字参数字典\n\nname: 当前进程实例的别名\n\nProcess类常用方法:\nis_alive(): 判断进程实例是否还在执行join([timeout]): 是否等待进程实例执行结果，或等待多少秒start(): 创建子进程run(): 如果没有给定target参数，对这个对象调用start()方法时，就执行对象中的run()方法terminate(): 不管任务是否完成，立即终止\nProcess类常用属性：\n\n\nname: 当前进程的实例别名，默认为Process-N, N从1开始递增的整数。\n\npid: 当前进程的实例PID值\n\n\n# coding=utf-8\nfrom multiprocessing import Process\nimport time\nimport os\n\n# 两个子进程将会调用的两个方法\ndef  worker_1(interval):\n    print(\"worker_1,父进程(%s),当前进程(%s)\"%(os.getppid(),os.getpid()))\n    t_start = time.time()\n    time.sleep(interval) # 程序将会被挂起interval秒\n    t_end = time.time()\n    print(\"worker_1,执行时间为'%0.2f'秒\"%(t_end - t_start))\n\ndef  worker_2(interval):\n    print(\"worker_2,父进程(%s),当前进程(%s)\"%(os.getppid(),os.getpid()))\n    t_start = time.time()\n    time.sleep(interval)\n    t_end = time.time()\n    print(\"worker_2,执行时间为'%0.2f'秒\"%(t_end - t_start))\n\n# 输出当前程序的ID\nprint(\"进程ID：%s\"%os.getpid())\n\n# 创建两个进程对象，target指向这个进程对象要执行的对象名称，\n# args后面的元组中，是要传递给worker_1方法的参数，\n# 因为worker_1方法就一个interval参数，这里传递一个整数2给它，\n# 如果不指定name参数，默认的进程对象名称为Process-N，N为一个递增的整数\np1 = Process(target=worker_1,args=(2,))\np2 = Process(target=worker_2,name=\"alogy\",args=(1,))\n\n# 使用\"进程对象名称.start()\"来创建并执行一个子进程，\n# 这两个进程对象在start后，就会分别去执行worker_1和worker_2方法中的内容\np1.start()\np2.start()\n\n# 同时父进程仍然往下执行，如果p2进程还在执行，将会返回True\nprint(\"p2.is_alive=%s\"%p2.is_alive())\n\n# 输出p1和p2进程的别名和pid\nprint(\"p1.name=%s\"%p1.name)\nprint(\"p1.pid=%s\"%p1.pid)\nprint(\"p2.name=%s\"%p2.name)\nprint(\"p2.pid=%s\"%p2.pid)\n\n# join括号中不携带参数，表示父进程在这个位置要等待p1进程执行完成后，\n# 再继续执行下面的语句，一般用于进程间的数据同步，如果不写这一句，\n# 下面的is_alive判断将会是True，在shell（cmd）里面调用这个程序时\n# 因为p2需要2秒以上才可能执行完成，父进程等待1秒很可能不能让p1完全执行完成，\n# 所以下面的print会输出True，即p1仍然在执行\np1.join()\nprint(\"p1.is_alive=%s\"%p1.is_alive())\n执行结果：\n进程ID：14889\np2.is_alive=True\np1.name=Process-1\np1.pid=14890\np2.name=alogy\np2.pid=14891\nworker_1,父进程(14889),当前进程(14890)\nworker_2,父进程(14889),当前进程(14891)\nworker_2,执行时间为'1.00'秒\nworker_1,执行时间为'2.00'秒\np1.is_alive=False\n进程池\n池Pool作用：缓冲进程池优点：增加使用率\n创建新的进程的另一种方式：进程池Pool\n创建一定数量的进程，然后需要使用的时候拿去使用，使用完毕后归还。\nfrom multiprocessing import Pool\nimport os\nimport random\nimport time\n\ndef worker(num):\n    for i in range(random.randint(1, 3)):\n        print('pid = %d, num=%d'%(os.getpid(), num) )\n        time.sleep(1)\n\np = Pool(3)\n\nfor i in range(10):\n    p.apply_async(worker,(i )) # 向进程池中添加任务\n    # 如果添加的任务数超过了进程池中的进程个数的话，那么会导致添加不进入到进程池中。\n    # 添加到进程池中的任务，如果还没有被执行的话，那么会等待进程池中的进程完成一个任务之后，会自动去使用已经结束的进程，完成没有被执行的任务。\n\np.close() # 关闭进程池，关闭后p实例不再接收新的请求\np.join() # 等待p实例中的所有子进程执行完毕，主进程才会退出， 必须放在close语句之后。    \n多种方式的比较\n\nos.fork()\nProcess(target)\nPool\n\nos.fork():\nret = os.fork()\nif ret == 0:\n    # 子进程\nelse:\n    # 父进程\n\n# 主进程会立马结束  \nProcess(target, args):\np1 = Process(atrget=fun)\np1.start()\np1.join() # 主进程会等待所有子进程都结束\nPool()\npool = Pool(3)\npool.apply_asnyc(fun)\npool.join() # 主进程在不join()的情况下，会立马结束，不会等待子进程结束之后再结束主进程。\n# 主进程一般都用来等待，任务在子进程中执行。（一般使用进程池）\napply堵塞式添加任务\n阻塞式apply()创建多进程\nfrom multiprocessing import Pool\n\ndef worker():\n    print(1)\n\np = Pool(3)\n\nfor i in range(5):\n    p.apply(worker)\n\np.close()\np.join()   \n进程间通信-Queue\nQueue本身是一个消息列队程序\n\n\nProcess方式创建进程需要通过Queue创建通信\n进程池创建进程需要通过Manager().Queue()创建通信\n\n\n#coding=utf-8\nfrom multiprocessing import Queue\nq = Queue(3) # 初始化一个Queue对象，最多可接收三条put消息\nq.put(\"消息1\") \nq.put(\"消息2\")\nprint(q.full())  # False\nq.put(\"消息3\")\nprint(q.full()) # True\n\n# 因为消息列队已满下面的try都会抛出异常，第一个try会等待2秒后再抛出异常，第二个Try会立刻抛出异常\ntry:\n    q.put(\"消息4\",True,2)\nexcept:\n    print(\"消息列队已满，现有消息数量:%s\"%q.qsize())\n\ntry:\n    q.put_nowait(\"消息4\")\nexcept:\n    print(\"消息列队已满，现有消息数量:%s\"%q.qsize())\n\n\n# 先判断消息列队是否已满，再写入\nif not q.full():\n    q.put_nowait(\"消息4\")\n\n# 读取消息时，先判断消息列队是否为空，再读取\nif not q.empty():\n    for i in range(q.qsize()):\n        print(q.get_nowait())\nQueue()语法：\n初始化Queue()对象时，(例如：q = Queue())，若参数没有指定最大可接受消息的数量，或数量为负值，那么就代表可接受的消息数量没有上限(直到内存的尽头)\nQueue.qsize(): 返回当前队列包含的消息数量Queue.empty(): 如果队列为空，返回True，反之False Queue.full(): 如果队列满了，返回True，反之FalseQueue.get_nowait(): 相当于Queue.get(False)Queue.put_nowait(item): 相当Queue.put(item, False)Queue.get([block [, timeout]]): 获取队列中的一条信息，然后将其队列中移除，block默认值为True\n\n如果block使用默认值，且没有设置timeout(单位秒)，消息队列如果为空，此时程序将被阻塞（停在读取状态)，直到从消息队列读到消息为止，如果设置了timeout，则会等待timeout秒，若没有读取到任何消息，则抛出Queue.Empty异常。\n如果block为False,消息队列为空，则会立刻抛出Queue.Empty异常\n\nQueue.put(item, [block [, timeout]]): 将item消息写入队列，block默认值为True\n\n如果block使用默认值，且没有设置timeout（单位秒），消息列队如果已经没有空间可写入，此时程序将被阻塞（停在写入状态），直到从消息列队腾出空间为止，如果设置了timeout，则会等待timeout秒，若还没空间，则抛出Queue.Full异常；\n如果block值为False，消息列队如果没有空间可写入，则会立刻抛出Queue.Full异常；\n\n多进程拷贝文件\n#coding=utf-8\nfrom multiprocessing import Pool, Manager\nimport os\n\ndef copy_task (name, old_file, new_file, queue):\n    print(old_file + '/' + name)\n    fr = open(old_file + '/' + name)\n    fw = open(new_file + '/' + name, 'w')\n\n    con = fr.read()\n    fw.write(con)\n\n    fr.close()\n    fw.close()\n\n    queue.put(name)\n\ndef main ():\n    old_file = input('文件夹名字:')\n    new_file = old_file + '_附件'\n    os.mkdir(new_file)\n    file_names = os.listdir(old_file)\n\n    pool = Pool(5)\n    queue = Manager().Queue()\n\n    for file in file_names:\n        pool.apply_async(copy_task, args=(file,  old_file, new_file, queue))\n\n    num = 0\n    all_num = len(file_names)\n    while num < all_num:\n        queue.get()\n        num += 1\n        copy_rate = num / all_num\n        print('\\rcopy进度是:%.2f%%'%(copy_rate * 100), end='')\n\n    print('\\n完成copy')\n\nif __name__ == '__main__':\n    main()\n线程\nThread创建多线程\n进程：程序运行起来，程序的资源(资源分配的代码)线程：进程中的一种，真正执行代码的东西(CPU调度的代码)\nfrom threading import Thread\nimport time\n\ndef test():\n    print('111')\n    time.sleep(1)\n\nfor i in range(5):\n    t = Thread(target=test)\n    t.start()\n\n创建好的线程，需要调用start()方法来启动。\n主线程任务结束，不会理解结束，会等待所有子线程结束。\n\n使用Thread子类完成创建多线程\npid: 进程号tid: 线程号\n0号进程：切换进程，处理CPU。（切换进程）1号进程：间接或直接生成其它进程。\nfrom threading import Thread\nimport time\n\n\nclass My_Thread(Thread):\n    def run (self):\n        for i in range(3):\n            time.sleep(1)\n            print(self.name) # name 属性中保存的是当前线程的名字\n\nif __name__ == '__main__':\n    t = My_Thread()\n    t.start()\n线程的执行顺序\n#coding=utf-8\nimport threading\nimport time\n\nclass MyThread(threading.Thread):\n    def run(self):\n        for i in range(3):\n            time.sleep(1)\n            msg = \"I'm \"+self.name+' @ '+str(i)\n            print(msg)\ndef test():\n    for i in range(5):\n        t = MyThread()\n        t.start()\nif __name__ == '__main__':\n    test()\n    \n# 只能保证每个线程都运行完整个run函数，但是线程的启动顺序、\n# run函数中每次循环的执行顺序都不能确定。  \n多线程程序的执行顺序是不确定的。当执行到sleep语句时，线程将被阻塞（Blocked），到sleep结束后，线程进入就绪（Runnable）状态，等待调度。而线程调度将自行选择一个线程执行。\n\n每个线程一定会有一个名字，尽管上面的例子中没有指定线程对象的name，但是python会自动为线程指定一个名字。\n当线程的run()方法结束时该线程完成。\n无法控制线程调度程序，但可以通过别的方式来影响线程调度的方式。\n线程的几种状态:\n\n\n线程共享全局变量\n\nfrom threading import Thread\nimport time\n\ng_num = 100\n\ndef work1():\n    global g_num\n    for i in range(3):\n        g_num += 1\n\n    print(\"----in work1, g_num is %d---\"%g_num)\n\n\ndef work2():\n    global g_num\n    print(\"----in work2, g_num is %d---\"%g_num)\n\n\nprint(\"---线程创建之前g_num is %d---\"%g_num)\n\nt1 = Thread(target=work1)\nt1.start()\n\ntime.sleep(1)\n\nt2 = Thread(target=work2)\nt2.start()\n执行结果：\n---线程创建之前g_num is 100---\n----in work1, g_num is 103---\n----in work2, g_num is 103---\n\n在一个进程内的所有线程共享全局变量，能够在不适用其他方式的前提下完成多线程之间的数据共享。\n线程是对全局变量的随意更改，造成多线程之间的全局变量的混乱（及线程非安全）\n\n全局变量共享的方式（修改）：\n\n变量前加global\n\n可变数据类型，例如list\n\n\n进程和线程的区别\n进程：能够完成多任务，比如：在一台电脑上能够同时运行多个QQ线程：能够完成多任务，比如：一个QQ中的多个聊天窗口\n定义的不同：\n\n进程是系统进行资源分配和调度的一个独立单位\n线程是进程的一个实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计算器，一组寄存器和栈)，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。\n\n区别：\n\n一个程序至少有一个进程,一个进程至少有一个线程.\n线程的划分尺度小于进程(资源比进程少)，使得多线程程序的并发性高。\n进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率\n线线程不能够独立执行，必须依存在进程中\n\n优缺点：\n线程和进程在使用上各有优缺点：线程执行开销小，但不利于资源的管理和保护；而进程正相反。\n避免全局变量被修改的方式\n避免多线程多全局数据影响\n\n轮询\n互斥锁 (线程同步) 同步就是协同步调，按预定的先后次序进行运行\n\n\n轮询:\nfrom threading import Thread\nimport time\n\ng_num = 0\ng_flag = 1\n\ndef test1 ():\n    global g_num\n    global g_flag\n    if g_flag == 1:\n        for i in range(1000000):\n            g_num += 1\n        g_flag = 0\n    print('--test--g_num=%d'%g_num)\n\ndef test2 ():\n    global g_num\n    # 轮询\n    while True:\n        if g_flag != 1:\n            for i in range(1000000):\n                g_num += 1\n            break\n    print('--test2--g_num=%d'%g_num)\n\np1 = Thread(target=test1)\np1.start()\np2 = Thread(target=test2)\np2.start()\n互斥锁\nfrom threading import Thread, Lock\nimport time\n\n\ng_num = 0\n\ndef test1 ():\n    global g_num\n    mutex.acquire()\n    for i in range(1000000):\n        g_num += 1\n    mutex.release()\n    print('--test--g_num=%d'%g_num)\n\ndef test2 ():\n    global g_num\n    # 轮询\n    mutex.acquire()\n    for i in range(1000000):\n        g_num += 1\n    mutex.release()\n    print('--test2--g_num=%d'%g_num)\n\nmutex = Lock() # 互斥锁，默认是没有上锁到\n# 一方成功上锁，那么另一方会堵塞(一直等待)到这个锁被解开为止\n# 一个线程释放，其它线程都会执行\n\np1 = Thread(target=test1)\np1.start()\n\np2 = Thread(target=test2)\np2.start()\n\n# 创建锁\nmutex = threading.Lock()\n# 锁定\nmutex.acquire([blocking])\n# 释放\nmutex.release()\n锁的好处：\n确保了某段关键代码只能由一个线程从头到尾完整地执行\n锁的坏处:\n\n阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大的下降\n由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁，可能会造成死锁。\n\n多线程使用非共享变量\n仅仅是读取值，不用调用global设置值的时候，需要加互斥锁\n在多线程开发中，全局变量是多个线程都共享的数据，而局部变量等是各自线程的，是非共享的（线程中的局部变量，各自不能访问，各自不影响。）\n死锁\n在线程间共享多个资源的时候，如果两个线程分别占用一部分资源并且同时等待对方的资源，就会造成死锁。尽管死锁很少发生，但一旦发生就会造成应用的停止响应。\n死锁例子：\n#coding=utf-8\nimport threading\nimport time\n\nclass MyThread1(threading.Thread):\n    def run(self):\n        if mutexA.acquire():\n            print(self.name+'----do1---up----')\n            time.sleep(1)\n\n            if mutexB.acquire():\n                print(self.name+'----do1---down----')\n                mutexB.release()\n            mutexA.release()\n\nclass MyThread2(threading.Thread):\n    def run(self):\n        if mutexB.acquire():\n            print(self.name+'----do2---up----')\n            time.sleep(1)\n            if mutexA.acquire():\n                print(self.name+'----do2---down----')\n                mutexA.release()\n            mutexB.release()\n\nmutexA = threading.Lock()\nmutexB = threading.Lock()\n\nif __name__ == '__main__':\n    t1 = MyThread1()\n    t2 = MyThread2()\n    t1.start()\n    t2.start()\n避免死锁\n\n程序设计时要尽量避免（银行家算法）\n添加超时时间: mutexB.acquire(timeout=2)\n\n\n多线程有序执行\n同步就是协调步调，按预定的先后次序进行运行\n阻塞，非阻塞：等下执行，还是不等立刻执行。同步，异步：多方协同执行，是一同执行，还是顺序执行。\nfrom threading import Thread,Lock\nfrom time import sleep\n\nclass Task1(Thread):\n    def run(self):\n        while True:\n            if lock1.acquire():\n                print(\"------Task 1 -----\")\n                sleep(0.5)\n                lock2.release()\n\nclass Task2(Thread):\n    def run(self):\n        while True:\n            if lock2.acquire():\n                print(\"------Task 2 -----\")\n                sleep(0.5)\n                lock3.release()\n\nclass Task3(Thread):\n    def run(self):\n        while True:\n            if lock3.acquire():\n                print(\"------Task 3 -----\")\n                sleep(0.5)\n                lock1.release()\n\n# 使用Lock创建出的锁默认没有“锁上”\nlock1 = Lock()\n# 创建另外一把锁，并且“锁上”\nlock2 = Lock()\nlock2.acquire()\n# 创建另外一把锁，并且“锁上”\nlock3 = Lock()\nlock3.acquire()\n\nt1 = Task1()\nt2 = Task2()\nt3 = Task3()\n\nt1.start()\nt2.start()\nt3.start()\n线程的同步：可以使用互斥锁完成多个任务，有序的进程工作。\nQueue\n生产者与消费者模式来解决耦合的问题\nQueue：\n\n对于Queue，在多线程通信之间扮演重要的角色(解耦)\n添加数据到队列中，使用put()方法\n从队列中取数据，使用get()方法\n判断队列中是否还有数据，使用qsize()方法\n\nThreadLocal对象\nThreadLocal对象在线程中的使用\n在多线程环境下，每个线程都有自己的数据。一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。\n既可以具有各自线程的单独变量，有可以互不影响方法：\n\n使用字典，定义全局变量。\n\nThreadLocal对象\n\n一个ThreadLocal变量虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰。ThreadLocal解决了参数在一个线程中各个函数之间互相传递的问题\nimport threading\n\n\nlocal = threading.local()\n\ndef process_student():\n    std = local.student\n    print('Hello, %s (in %s)'%(std, threading.current_thread().name))\n\ndef process_thread(name):\n    local.student = name\n    process_student()\n\nt1 = threading.Thread(target=process_thread, args=('xixixi',), name='Thread-A')\nt2 = threading.Thread(target=process_thread, args=('hahaha',), name='Thread-B')\n\nt1.start()\nt2.start()\nt1.join()\nt1.join()\nThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。\n异步的实现\nfrom multiprocessing import Pool\nimport time\nimport os\n\ndef test():\n    print(\"---进程池中的进程---pid=%d,ppid=%d--\"%(os.getpid(),os.getppid()))\n    for i in range(3):\n        print(\"----%d---\"%i)\n        time.sleep(1)\n    return \"hhhh\"\n\ndef test2(args):\n    print(\"---callback func--pid=%d\"%os.getpid())\n    print(\"---callback func--args=%s\"%args)\n\npool = Pool(3)\npool.apply_async(func=test,callback=test2)\n\ntime.sleep(5)\n\nprint(\"----主进程-pid=%d----\"%os.getpid())\ncallback主进程返回执行。子进程返回值到主进程中。主进程放下当前到任务，去执行其它任务，然后回到执行放下到任务。\nGIL问题\n全局解释器锁（GIL）\nPython使用了全局解释锁(GIL)的原因，代码并不能同时在多核上并发的运行，也就是说，Python多线程不能并发。\nGIL是多线程间的一把互斥锁，并且是一把全局锁，它保证了Cpython在内存管理上面是线程安全的。\n原因：为了发挥多核CPU性能，程序多采用多线程/多进程方式设计。对于多核CPU，操作系统是同时可以启动多个线程分别在不同的核心上运行，但是由于GIL是关于线程的全局锁，就可能导致某个任务不停的acquire到GIL，使得其它核心线程停在retry GIL，造成了阻塞的现象。\n解决方法：\n\n使用多进程。GIL是针对线程的锁，在Python中使用多进程编程。\n在Python不合适大量的数学计算，将这些需要大量计算的程序移到C/C++中去实现。\n从Python 3.2开始，实现了新的GIL比之前的GIL增加了一个flag，来控制等待或释放的状态\n\n\n                ", "mainLikeNum": ["1 "], "mainBookmarkNum": "2"}